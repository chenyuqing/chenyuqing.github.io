<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hexo</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2023-07-13T04:01:28.214Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>Tim Chan</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Training your own datasets with Darknet</title>
    <link href="http://example.com/2021/11/07/Training-your-own-datasets-with-Darknet/"/>
    <id>http://example.com/2021/11/07/Training-your-own-datasets-with-Darknet/</id>
    <published>2021-11-07T06:48:57.000Z</published>
    <updated>2023-07-13T04:01:28.214Z</updated>
    
    <content type="html"><![CDATA[<ul><li>date, 2018-11-07 14:48:57</li></ul><h3 id="Data-collection-amp-labeling"><a href="#Data-collection-amp-labeling" class="headerlink" title="Data collection &amp; labeling"></a>Data collection &amp; labeling</h3><ol><li>Use your own way to collect your data, usually the size of image doesn’t matter. It’ll better to be fit in (48, 48) ~ (1280, 720)</li><li>When you finished your own dataset, you should label your images.<ul><li>tools : <a class="link"   href="https://github.com/tzutalin/labelImg" >labelImage<i class="fas fa-external-link-alt"></i></a> </li><li>Usage : refer to the github</li></ul></li></ol><hr><h3 id="Install-Darknet"><a href="#Install-Darknet" class="headerlink" title="Install Darknet"></a>Install Darknet</h3><ol><li><a class="link"   href="https://pjreddie.com/darknet/install/" >Darknet Installation<i class="fas fa-external-link-alt"></i></a> , compile with GPU and Opencv if it’s necessary</li></ol><hr><h3 id="Create-VOC-format-dataset"><a href="#Create-VOC-format-dataset" class="headerlink" title="Create VOC format dataset"></a>Create VOC format dataset</h3><ul><li><p>(1)  In the root of darknet, create a folder names ‘VOCdevkit’, and create a folder names what you want to name your dataset. like ‘VOC2019_oppo’, which has to start with ‘VOC’.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /path/darknet</span><br><span class="line">mkdir VOCdevkit</span><br><span class="line">cd VOCdevkit</span><br><span class="line">mkdir VOC2019_oppo</span><br></pre></td></tr></table></figure></li><li><p>(2) Directory like this :</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">└── VOCdevkit</span><br><span class="line">    └── VOC2019_oppo</span><br><span class="line">        ├── Annotations</span><br><span class="line">        ├── ImageSets</span><br><span class="line">        │   └── Main</span><br><span class="line">        └── JPEGImages</span><br></pre></td></tr></table></figure></li><li><p>(3) Move the images into <strong>JPEGImages</strong> and xml files into <strong>Annotations</strong>.</p></li><li><p>(4) Split the train, val and test, create a py script like belows</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## split_train_val.py</span></span><br><span class="line"><span class="keyword">import</span> os,random</span><br><span class="line"></span><br><span class="line"><span class="comment"># read the filenames from a file</span></span><br><span class="line">dirname = <span class="string">&#x27;./Annotations&#x27;</span></span><br><span class="line">files = [f[:-<span class="number">4</span>] <span class="keyword">for</span> f <span class="keyword">in</span> os.listdir(dirname) <span class="keyword">if</span> f[-<span class="number">4</span>:].lower() == <span class="string">&#x27;.xml&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># random divide  </span></span><br><span class="line">trainval = random.sample(files, <span class="built_in">len</span>(files)//<span class="number">2</span>)</span><br><span class="line">test = [f <span class="keyword">for</span> f <span class="keyword">in</span> files <span class="keyword">if</span> f <span class="keyword">not</span> <span class="keyword">in</span> trainval]</span><br><span class="line"></span><br><span class="line"><span class="comment"># random divide </span></span><br><span class="line">train = random.sample(trainval, <span class="built_in">len</span>(trainval)//<span class="number">2</span>)</span><br><span class="line">val = [f <span class="keyword">for</span> f <span class="keyword">in</span> trainval <span class="keyword">if</span> f <span class="keyword">not</span> <span class="keyword">in</span> train]</span><br><span class="line"></span><br><span class="line"><span class="comment"># save to txt file</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">list2txt</span>(<span class="params">arr, fname</span>):</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(fname+<span class="string">&#x27;.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> a <span class="keyword">in</span> arr:</span><br><span class="line">            f.write(a+<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line">list2txt(trainval, <span class="string">&#x27;trainval&#x27;</span>)</span><br><span class="line">list2txt(test, <span class="string">&#x27;test&#x27;</span>)</span><br><span class="line">list2txt(train, <span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">list2txt(val, <span class="string">&#x27;val&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>then run the script, you will get four files, then move them into the <strong>ImageSets&#x2F;Main&#x2F;</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">python split_train_val.py</span><br><span class="line"></span><br><span class="line">mv test.txt ImageSets/Main/</span><br><span class="line">mv train.txt ImageSets/Main/</span><br><span class="line">mv trainval.txt ImageSets/Main/</span><br><span class="line">mv val.txt ImageSets/Main/</span><br></pre></td></tr></table></figure></li><li><p>(5) Now you have the directory like this</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">└── VOCdevkit</span><br><span class="line">    └── VOC2019_oppo</span><br><span class="line">        ├── Annotations</span><br><span class="line">        ├── ImageSets</span><br><span class="line">        │   └── Main</span><br><span class="line">        │       ├── test.txt</span><br><span class="line">        │       ├── train.txt</span><br><span class="line">        │       ├── trainval.txt</span><br><span class="line">        │       └── val.txt</span><br><span class="line">        ├── JPEGImages</span><br><span class="line">        └── split_train_val.py</span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ul><hr><h3 id="Use-the-voc-labe-to-generate-Image-path-list"><a href="#Use-the-voc-labe-to-generate-Image-path-list" class="headerlink" title="Use the voc_labe to generate Image path list"></a>Use the voc_labe to generate Image path list</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /path/darknet</span><br><span class="line">touch voc_label.py</span><br><span class="line">vim voc_label.py</span><br></pre></td></tr></table></figure><ul><li>(1) create a python script<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## name voc_label.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> xml.etree.ElementTree <span class="keyword">as</span> ET</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> os <span class="keyword">import</span> listdir, getcwd</span><br><span class="line"><span class="keyword">from</span> os.path <span class="keyword">import</span> join</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. change to your labels</span></span><br><span class="line"><span class="comment"># oppo for example</span></span><br><span class="line"><span class="comment"># 4 classes, A5s, A7, reno, reno10x</span></span><br><span class="line">sets = [(<span class="string">&#x27;2019_oppo&#x27;</span>, <span class="string">&#x27;train&#x27;</span>), (<span class="string">&#x27;2019_oppo&#x27;</span>, <span class="string">&#x27;val&#x27;</span>), (<span class="string">&#x27;2019_oppo&#x27;</span>, <span class="string">&#x27;test&#x27;</span>)]</span><br><span class="line">classes = [<span class="string">&#x27;A5s&#x27;</span>, <span class="string">&#x27;A7&#x27;</span>, <span class="string">&#x27;reno&#x27;</span>, <span class="string">&#x27;reno10x&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convert</span>(<span class="params">size, box</span>):</span><br><span class="line">    dw = <span class="number">1.</span>/(size[<span class="number">0</span>])</span><br><span class="line">    dh = <span class="number">1.</span>/(size[<span class="number">1</span>])</span><br><span class="line">    x = (box[<span class="number">0</span>] + box[<span class="number">1</span>])/<span class="number">2.0</span> - <span class="number">1</span></span><br><span class="line">    y = (box[<span class="number">2</span>] + box[<span class="number">3</span>])/<span class="number">2.0</span> - <span class="number">1</span></span><br><span class="line">    w = box[<span class="number">1</span>] - box[<span class="number">0</span>]</span><br><span class="line">    h = box[<span class="number">3</span>] - box[<span class="number">2</span>]</span><br><span class="line">    x = x*dw</span><br><span class="line">    w = w*dw</span><br><span class="line">    y = y*dh</span><br><span class="line">    h = h*dh</span><br><span class="line">    <span class="keyword">return</span> (x,y,w,h)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convert_annotation</span>(<span class="params">year, image_id</span>):</span><br><span class="line">    <span class="comment"># 2. change to your path </span></span><br><span class="line">    in_file = <span class="built_in">open</span>(<span class="string">&#x27;/home/ares2/darknet/VOCdevkit/VOC%s/Annotations/%s.xml&#x27;</span>%(year, image_id))</span><br><span class="line">    out_file = <span class="built_in">open</span>(<span class="string">&#x27;/home/ares2/darknet/VOCdevkit/VOC%s/labels/%s.txt&#x27;</span>%(year, image_id), <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line">    tree=ET.parse(in_file)</span><br><span class="line">    root = tree.getroot()</span><br><span class="line">    size = root.find(<span class="string">&#x27;size&#x27;</span>)</span><br><span class="line">    w = <span class="built_in">int</span>(size.find(<span class="string">&#x27;width&#x27;</span>).text)</span><br><span class="line">    h = <span class="built_in">int</span>(size.find(<span class="string">&#x27;height&#x27;</span>).text)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> obj <span class="keyword">in</span> root.<span class="built_in">iter</span>(<span class="string">&#x27;object&#x27;</span>):</span><br><span class="line">        difficult = obj.find(<span class="string">&#x27;difficult&#x27;</span>).text</span><br><span class="line">        cls = obj.find(<span class="string">&#x27;name&#x27;</span>).text</span><br><span class="line">        <span class="keyword">if</span> cls <span class="keyword">not</span> <span class="keyword">in</span> classes <span class="keyword">or</span> <span class="built_in">int</span>(difficult)==<span class="number">1</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        cls_id = classes.index(cls)</span><br><span class="line">        xmlbox = obj.find(<span class="string">&#x27;bndbox&#x27;</span>)</span><br><span class="line">        b = (<span class="built_in">float</span>(xmlbox.find(<span class="string">&#x27;xmin&#x27;</span>).text), <span class="built_in">float</span>(xmlbox.find(<span class="string">&#x27;xmax&#x27;</span>).text), <span class="built_in">float</span>(xmlbox.find(<span class="string">&#x27;ymin&#x27;</span>).text), <span class="built_in">float</span>(xmlbox.find(<span class="string">&#x27;ymax&#x27;</span>).text))</span><br><span class="line">        bb = convert((w,h), b)</span><br><span class="line">        out_file.write(<span class="built_in">str</span>(cls_id) + <span class="string">&quot; &quot;</span> + <span class="string">&quot; &quot;</span>.join([<span class="built_in">str</span>(a) <span class="keyword">for</span> a <span class="keyword">in</span> bb]) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line">wd = getcwd()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> year, image_set <span class="keyword">in</span> sets:</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&#x27;VOCdevkit/VOC%s/labels/&#x27;</span>%(year)):</span><br><span class="line">        os.makedirs(<span class="string">&#x27;VOCdevkit/VOC%s/labels/&#x27;</span>%(year))</span><br><span class="line">    <span class="comment"># 3. change to your path</span></span><br><span class="line">    image_ids = <span class="built_in">open</span>(<span class="string">&#x27;/home/ares2/darknet/VOCdevkit/VOC%s/ImageSets/Main/%s.txt&#x27;</span>%(year, image_set)).read().strip().split()</span><br><span class="line">    list_file = <span class="built_in">open</span>(<span class="string">&#x27;%s_%s.txt&#x27;</span>%(year, image_set), <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> image_id <span class="keyword">in</span> image_ids:</span><br><span class="line">        list_file.write(<span class="string">&#x27;%s/VOCdevkit/VOC%s/JPEGImages/%s.jpg\n&#x27;</span>%(wd, year, image_id))</span><br><span class="line">        convert_annotation(year, image_id)</span><br><span class="line">    list_file.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li>remember that there are 3 places you need to change</li><li>this will generate 3 files: <ul><li><strong>2019_oppo_train.txt</strong></li><li><strong>2019_oppo_val.txt</strong></li><li><strong>2019_oppo_test.txt</strong></li></ul></li><li>Usually I merge <strong>2019_oppo_train.txt</strong> and <strong>2019_oppo_test.txt</strong> as <strong>2019_oppo_train.txt</strong> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /path/darknet</span><br><span class="line">mkdir oppo_od_bak</span><br><span class="line">cd oppo_od_bak</span><br><span class="line">mkdir cfg</span><br></pre></td></tr></table></figure></li><li>from the <strong>darknet&#x2F;cfg&#x2F;</strong> you can find the <strong>yolo-voc.cfg</strong> and the <strong>yolo-tiny.cfg</strong> and from the <a class="link"   href="https://pjreddie.com/darknet/yolo/" >official website<i class="fas fa-external-link-alt"></i></a> you can download the <strong>pretrained models</strong>, like for the <strong>yolo-voc</strong> is <a class="link"   href="https://pjreddie.com/media/files/darknet53.conv.74" >darknet53.conv.74<i class="fas fa-external-link-alt"></i></a>.</li></ul><hr><h3 id="Prepare-your-cfg-file"><a href="#Prepare-your-cfg-file" class="headerlink" title="Prepare your cfg file"></a>Prepare your cfg file</h3><ul><li>the 3 files you use to train the yolo is <ul><li><strong>yourdata.names</strong></li><li><strong>yourdata.data</strong></li><li><strong>yourcfg.cfg</strong></li></ul></li><li>(1) <strong>yourdata.names</strong> contains the labels of your dataset, each label for a line</li><li>(2) <strong>yourdata.data</strong> example<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">classes= #classes #类别数目</span><br><span class="line">train  = /path/yourfilename_train.txt # 训练数据</span><br><span class="line">valid  = /path/yourfilenane_val.txt # 验证数据</span><br><span class="line">names = data/yourname.names # class labels</span><br><span class="line">backup = /backup/ # 权重保存所在文件</span><br></pre></td></tr></table></figure></li><li>remember to delete the comments</li><li>(3) <strong>yourcfg.cfg</strong><ul><li>you can use the <strong>yolo-voc.cfg</strong> or the <strong>yolo-tiny.cfg</strong></li><li>remember to change these places</li></ul></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">vim yolo-voc.cfg</span><br><span class="line"></span><br><span class="line">## Remember to comment the testing and uncomment the training</span><br><span class="line">[net]</span><br><span class="line"># Testing</span><br><span class="line"># batch=1</span><br><span class="line"># subdivisions=1</span><br><span class="line"># Training</span><br><span class="line">batch=64</span><br><span class="line">subdivisions=16</span><br></pre></td></tr></table></figure><ul><li>YOU should change every [yolo] layer.<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[convolutional]</span><br><span class="line">size=1</span><br><span class="line">stride=1</span><br><span class="line">pad=1</span><br><span class="line">filters=27 ## YOU SHOULD CHANGE THE # OF FILTERS</span><br><span class="line">## filters = (classes + 5) * 3</span><br><span class="line">activation=linear</span><br><span class="line"></span><br><span class="line">[yolo]</span><br><span class="line">mask = 6,7,8</span><br><span class="line">anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326</span><br><span class="line">classes=4  ## CHANGE TO THE NUMBER OF YOUR LABELS</span><br><span class="line">num=9</span><br><span class="line">jitter=.3</span><br><span class="line">ignore_thresh = .5</span><br><span class="line">truth_thresh = 1</span><br><span class="line">random=1</span><br></pre></td></tr></table></figure></li></ul><hr><h3 id="Start-Training"><a href="#Start-Training" class="headerlink" title="Start Training"></a>Start Training</h3><ul><li>First time you train, use the pretrained classification model<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd path/darknet/</span><br><span class="line"># yolo-tiny</span><br><span class="line">./darknet detector train cfg/yourdata.data cfg/yourcfg.cfg backup/bo_can_tiny_176.weights</span><br><span class="line"># yolo-voc</span><br><span class="line">./darknet detector train cfg/yourdata.data cfg/yourcfg.cfg backup/darknet53.conv.74</span><br></pre></td></tr></table></figure></li></ul><hr><h3 id="Know-your-log"><a href="#Know-your-log" class="headerlink" title="Know your log"></a>Know your log</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Region <span class="number">82</span> Avg IOU: <span class="number">0.801934</span>, Class: <span class="number">0.737764</span>, Obj: <span class="number">0.782024</span>, No Obj: <span class="number">0.006216</span>, <span class="number">.5</span>R: <span class="number">1.000000</span>, <span class="number">.75</span>R: <span class="number">1.000000</span>, count: <span class="number">5</span> </span><br><span class="line">Region <span class="number">94</span> Avg IOU: <span class="number">0.706899</span>, Class: <span class="number">0.073915</span>, Obj: <span class="number">0.544467</span>, No Obj: <span class="number">0.000506</span>, <span class="number">.5</span>R: <span class="number">1.000000</span>, <span class="number">.75</span>R: <span class="number">0.000000</span>, count: <span class="number">1</span> </span><br><span class="line">Region <span class="number">106</span> Avg IOU: <span class="number">0.831056</span>, Class: <span class="number">0.037965</span>, Obj: <span class="number">0.026004</span>, No Obj: <span class="number">0.000057</span>, <span class="number">.5</span>R: <span class="number">1.000000</span>, <span class="number">.75</span>R: <span class="number">1.000000</span>, count: <span class="number">1</span> </span><br><span class="line">Region <span class="number">82</span> Avg IOU: <span class="number">0.731572</span>, Class: <span class="number">0.800899</span>, Obj: <span class="number">0.793200</span>, No Obj: <span class="number">0.005694</span>, <span class="number">.5</span>R: <span class="number">1.000000</span>, <span class="number">.75</span>R: <span class="number">0.333333</span>, count: <span class="number">3</span> </span><br><span class="line">Region <span class="number">94</span> Avg IOU: <span class="number">0.607969</span>, Class: <span class="number">0.199724</span>, Obj: <span class="number">0.884315</span>, No Obj: <span class="number">0.000286</span>, <span class="number">.5</span>R: <span class="number">1.000000</span>, <span class="number">.75</span>R: <span class="number">0.000000</span>, count: <span class="number">1</span> </span><br><span class="line">Region <span class="number">106</span> Avg IOU: -nan, Class: -nan, Obj: -nan, No Obj: <span class="number">0.000015</span>, <span class="number">.5</span>R: -nan, <span class="number">.75</span>R: -nan, count:</span><br></pre></td></tr></table></figure><ul><li>（1）以上输出显示了所有训练图片的一个批次（batch），批次大小的划分根据我们在 .cfg 文件中设置的subdivisions参数。在我使用的 .cfg 文件中 batch &#x3D; 64 ，subdivision &#x3D; 16，所以在训练输出中，训练迭代包含了16组，每组又包含了4张图片，跟设定的batch和subdivision的值一致。<br>但是此处有16*3条信息，每组包含三条信息，分别是：<br>Region 82 Avg IOU:<br>Region 94 Avg IOU:<br>Region 106 Avg IOU:<br>三个尺度上预测不同大小的框 82卷积层 为最大的预测尺度，使用较大的mask，但是可以预测出较小的物体 94卷积层 为中间的预测尺度，使用中等的mask， 106卷积层为最小的预测尺度，使用较小的mask，可以预测出较大的物体</li><li>（2）每个batch都会有这样一个输出：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2706: 1.350835, 1.386559 avg, 0.001000 rate, 3.323842 seconds, 173184 images</span><br></pre></td></tr></table></figure></li></ul><p>2706：batch是第几组。<br>1.350835：总损失<br>1.386559 avg ： 平均损失<br>0.001000 rate：当前的学习率<br>3.323842 seconds： 当前batch训练所花的时间<br>173184 images ： 目前为止参与训练的图片总数 &#x3D; 2706 * 64 </p><ul><li>（3）<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Region 82 Avg IOU: 0.798032, Class: 0.559781, Obj: 0.515851, No Obj: 0.006533, .5R: 1.000000, .75R: 1.000000,  count: 2</span><br></pre></td></tr></table></figure></li></ul><p>Region Avg IOU: 表示在当前subdivision内的图片的平均IOU，代表预测的矩形框和真实目标的交集与并集之比.<br>Class: 标注物体分类的正确率，期望该值趋近于1。<br>Obj: 越接近1越好。<br>No Obj: 期望该值越来越小，但不为零。<br>count: count后的值是所有的当前subdivision图片（本例中一共4张）中包含正样本的图片的数量。</p><ul><li>参考：<a class="link"   href="https://blog.csdn.net/qq_33444963/article/details/80842179" >https://blog.csdn.net/qq_33444963&#x2F;article&#x2F;details&#x2F;80842179<i class="fas fa-external-link-alt"></i></a></li></ul><hr><h3 id="Training-experience"><a href="#Training-experience" class="headerlink" title="Training experience"></a>Training experience</h3><ul><li><p><strong>YOLO-TINY</strong></p><ul><li>It’s a simple network for feature extraction, fit to the simple circumstances.</li><li>Each class should have more than 500 images</li><li>Training more than 1000 epoches</li><li>Fast but low accurate.</li></ul></li><li><p><strong>YOLO-VOC</strong></p><ul><li>It’s a complicated network training on the Imagenet</li><li>Each class should have more than 300 images</li><li>Traing more than 10000 epoches.</li><li>Slow but accurate</li></ul></li><li><p>Overall, more images, the model will be better. You can try to add images slowly.</p></li></ul><h3 id="How-to-run-your-own-yolov3-model-with-Opencv"><a href="#How-to-run-your-own-yolov3-model-with-Opencv" class="headerlink" title="How to run your own yolov3 model with Opencv"></a>How to run your own yolov3 model with Opencv</h3><ul><li>first you need to install the opencv</li><li>then, you just copy three files from what you have trained<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yourname.name</span><br><span class="line">yourcfg.cfg</span><br><span class="line">yourweights.weights</span><br></pre></td></tr></table></figure></li><li>then set them in the config file<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">class FLAGS:</span><br><span class="line">    # Initialize the parameters</span><br><span class="line">    confThreshold = 0.65  # Confidence threshold</span><br><span class="line">    nmsThreshold = 0.3  # Non-maximum suppression threshold</span><br><span class="line">    inpWidth = 416  # Width of network&#x27;s input image</span><br><span class="line">    inpHeight = 416  # Height of network&#x27;s input image</span><br><span class="line"></span><br><span class="line">    camera_id = 0</span><br><span class="line"></span><br><span class="line">    # Load names of classes</span><br><span class="line">    classesFile = &quot;./shelves_od_300/shelves_od.names&quot;</span><br><span class="line">    classes = None</span><br><span class="line">    with open(classesFile, &#x27;rt&#x27;) as f:</span><br><span class="line">        classes = f.read().rstrip(&#x27;\n&#x27;).split(&#x27;\n&#x27;)</span><br><span class="line"></span><br><span class="line">    # Give the configuration and weight files for the model and load the network using them</span><br><span class="line">    modelConfiguration = &quot;./shelves_od_300/yolov3-voc.cfg&quot;</span><br><span class="line">    modelWeights = &quot;./shelves_od_300/yolov3-voc_latest.weights&quot;</span><br></pre></td></tr></table></figure></li><li>Finally, run the script below<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br></pre></td><td class="code"><pre><span class="line"># This code is written at BigVision LLC. It is based on the OpenCV project. It is subject to the license terms in the LICENSE file found in this distribution and at http://opencv.org/license.html</span><br><span class="line"></span><br><span class="line"># Usage example:  python3 object_detection_yolo.py --video=run.mp4</span><br><span class="line">#                 python3 object_detection_yolo.py --image=bird.jpg</span><br><span class="line"></span><br><span class="line">import cv2 as cv</span><br><span class="line">import argparse</span><br><span class="line">import sys</span><br><span class="line">import numpy as np</span><br><span class="line">import os.path</span><br><span class="line">import uuid</span><br><span class="line"></span><br><span class="line">from config import FLAGS</span><br><span class="line"></span><br><span class="line"># Initialize the parameters</span><br><span class="line">confThreshold = FLAGS.confThreshold  #Confidence threshold</span><br><span class="line">nmsThreshold = FLAGS.nmsThreshold   #Non-maximum suppression threshold</span><br><span class="line">inpWidth = FLAGS.inpWidth       #Width of network&#x27;s input image</span><br><span class="line">inpHeight = FLAGS.inpHeight      #Height of network&#x27;s input image</span><br><span class="line"></span><br><span class="line">classes = FLAGS.classes</span><br><span class="line">global _i</span><br><span class="line">_i = 1000</span><br><span class="line"># Get the =-.l2 of the output layers</span><br><span class="line">def getOutputsNames(net):</span><br><span class="line">    # Get the names of all the layers in the network</span><br><span class="line">    layersNames = net.getLayerNames()</span><br><span class="line">    # Get the names of the output layers, i.e. the layers with unconnected outputs</span><br><span class="line">    return [layersNames[i[0] - 1] for i in net.getUnconnectedOutLayers()]</span><br><span class="line"></span><br><span class="line"># Draw the predicted bounding box</span><br><span class="line">def drawPred(frame, classId, conf, left, top, right, bottom):</span><br><span class="line">    # Draw a bounding box.</span><br><span class="line">    cv.rectangle(frame, (left, top), (right, bottom), (255, 178, 50), 3)</span><br><span class="line">    </span><br><span class="line">    label = &#x27;%.2f&#x27; % conf</span><br><span class="line">        </span><br><span class="line">    # Get the label for the class name and its confidence</span><br><span class="line">    if classes:</span><br><span class="line">        assert(classId &lt; len(classes))</span><br><span class="line">        label = &#x27;%s:%s&#x27; % (classes[classId], label)</span><br><span class="line"></span><br><span class="line">    #Display the label at the top of the bounding box</span><br><span class="line">    labelSize, baseLine = cv.getTextSize(label, cv.FONT_HERSHEY_SIMPLEX, 0.5, 1)</span><br><span class="line">    top = max(top, labelSize[1])</span><br><span class="line">    cv.rectangle(frame, (left, top - round(1.5*labelSize[1])), (left + round(1.5*labelSize[0]), top + baseLine), (255, 255, 255), cv.FILLED)</span><br><span class="line">    cv.putText(frame, label, (left, top), cv.FONT_HERSHEY_SIMPLEX, 0.75, (0,0,0), 1)</span><br><span class="line"></span><br><span class="line"># Remove the bounding boxes with low confidence using non-maxima suppression</span><br><span class="line">def postprocess(frame, outs):</span><br><span class="line">    frameHeight = frame.shape[0]</span><br><span class="line">    frameWidth = frame.shape[1]</span><br><span class="line"></span><br><span class="line">    # Scan through all the bounding boxes output from the network and keep only the</span><br><span class="line">    # ones with high confidence scores. Assign the box&#x27;s class label as the class with the highest score.</span><br><span class="line">    classIds = []</span><br><span class="line">    confidences = []</span><br><span class="line">    boxes = []</span><br><span class="line">    for out in outs:</span><br><span class="line">        for detection in out:</span><br><span class="line">            scores = detection[5:]</span><br><span class="line">            classId = np.argmax(scores)</span><br><span class="line">            confidence = scores[classId]</span><br><span class="line">            if confidence &gt; confThreshold:</span><br><span class="line">                center_x = int(detection[0] * frameWidth)</span><br><span class="line">                center_y = int(detection[1] * frameHeight)</span><br><span class="line">                width = int(detection[2] * frameWidth)</span><br><span class="line">                height = int(detection[3] * frameHeight)</span><br><span class="line">                left = int(center_x - width / 2)</span><br><span class="line">                top = int(center_y - height / 2)</span><br><span class="line">                classIds.append(classId)</span><br><span class="line">                confidences.append(float(confidence))</span><br><span class="line">                boxes.append([left, top, width, height])</span><br><span class="line">    global _i</span><br><span class="line">    # Perform non maximum suppression to eliminate redundant overlapping boxes with</span><br><span class="line">    # lower confidences.</span><br><span class="line">    indices = cv.dnn.NMSBoxes(boxes, confidences, confThreshold, nmsThreshold)</span><br><span class="line">    for i in indices:</span><br><span class="line">        i = i[0]</span><br><span class="line">        box = boxes[i]</span><br><span class="line">        left = box[0]</span><br><span class="line">        top = box[1]</span><br><span class="line">        width = box[2]</span><br><span class="line">        height = box[3]</span><br><span class="line"></span><br><span class="line">        ## save crop image</span><br><span class="line">        crop_img = frame[top:top+height, left:left+width, ]</span><br><span class="line">        #resized_img = cv.resize(crop_img, (100, 100))</span><br><span class="line">        #if _i % 5 == 0:</span><br><span class="line">        #cv.imwrite(&#x27;save_imgs/&#x27;+str(uuid.uuid1())+&#x27;.jpg&#x27;, crop_img)</span><br><span class="line">        _i = _i + 1</span><br><span class="line">        drawPred(frame, classIds[i], confidences[i], left, top, left + width, top + height)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def processing_yolov3(args):</span><br><span class="line"></span><br><span class="line">    net = cv.dnn.readNetFromDarknet(FLAGS.modelConfiguration, FLAGS.modelWeights)</span><br><span class="line">    net.setPreferableBackend(cv.dnn.DNN_BACKEND_OPENCV)</span><br><span class="line">    net.setPreferableTarget(cv.dnn.DNN_TARGET_CPU)</span><br><span class="line"></span><br><span class="line">    # Process inputs</span><br><span class="line">    winName = &#x27;Deep learning object detection in OpenCV&#x27;</span><br><span class="line">    cv.namedWindow(winName, cv.WINDOW_NORMAL)</span><br><span class="line"></span><br><span class="line">    outputFile = &quot;yolo_out_py.avi&quot;</span><br><span class="line">    if (args.image):</span><br><span class="line">        # Open the image file</span><br><span class="line">        if not os.path.isfile(args.image):</span><br><span class="line">            print(&quot;Input image file &quot;, args.image, &quot; doesn&#x27;t exist&quot;)</span><br><span class="line">            sys.exit(1)</span><br><span class="line">        cap = cv.VideoCapture(args.image)</span><br><span class="line">        outputFile = args.image[:-4]+&#x27;_yolo_out_py.jpg&#x27;</span><br><span class="line">    elif (args.video):</span><br><span class="line">        # Open the video file</span><br><span class="line">        if not os.path.isfile(args.video):</span><br><span class="line">            print(&quot;Input video file &quot;, args.video, &quot; doesn&#x27;t exist&quot;)</span><br><span class="line">            sys.exit(1)</span><br><span class="line">        cap = cv.VideoCapture(args.video)</span><br><span class="line">        outputFile = args.video[:-4]+&#x27;_yolo_out_py.avi&#x27;</span><br><span class="line">    else:</span><br><span class="line">        # Webcam input</span><br><span class="line">        cap = cv.VideoCapture(FLAGS.camera_id)</span><br><span class="line"></span><br><span class="line">        cap.set(3, 720)</span><br><span class="line">        cap.set(4, 1280)</span><br><span class="line"></span><br><span class="line">    # Get the video writer initialized to save the output video</span><br><span class="line">    if (not args.image):</span><br><span class="line">        vid_writer = cv.VideoWriter(outputFile, cv.VideoWriter_fourcc(&#x27;M&#x27;,&#x27;J&#x27;,&#x27;P&#x27;,&#x27;G&#x27;), 30, (round(cap.get(cv.CAP_PROP_FRAME_WIDTH)),round(cap.get(cv.CAP_PROP_FRAME_HEIGHT))))</span><br><span class="line"></span><br><span class="line">    while cv.waitKey(1) &lt; 0:</span><br><span class="line"></span><br><span class="line">        # get frame from the video</span><br><span class="line">        hasFrame, frame = cap.read()</span><br><span class="line"></span><br><span class="line">        # Stop the program if reached end of video</span><br><span class="line">        if not hasFrame:</span><br><span class="line">            print(&quot;Done processing !!!&quot;)</span><br><span class="line">            print(&quot;Output file is stored as &quot;, outputFile)</span><br><span class="line">            cv.waitKey(3000)</span><br><span class="line">            # Release device</span><br><span class="line">            cap.release()</span><br><span class="line">            break</span><br><span class="line"></span><br><span class="line">        # Create a 4D blob from a frame.</span><br><span class="line">        blob = cv.dnn.blobFromImage(frame, 1/255, (inpWidth, inpHeight), [0,0,0], 1, crop=False)</span><br><span class="line"></span><br><span class="line">        # Sets the input to the network</span><br><span class="line">        net.setInput(blob)</span><br><span class="line"></span><br><span class="line">        # Runs the forward pass to get output of the output layers</span><br><span class="line">        outs = net.forward(getOutputsNames(net))</span><br><span class="line"></span><br><span class="line">        # Remove the bounding boxes with low confidence</span><br><span class="line">        postprocess(frame, outs)</span><br><span class="line"></span><br><span class="line">        # Put efficiency information. The function getPerfProfile returns the overall time for inference(t) and the timings for each of the layers(in layersTimes)</span><br><span class="line">        t, _ = net.getPerfProfile()</span><br><span class="line">        label = &#x27;Inference time: %.2f ms&#x27; % (t * 1000.0 / cv.getTickFrequency())</span><br><span class="line">        cv.putText(frame, label, (0, 15), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255))</span><br><span class="line"></span><br><span class="line">        # Write the frame with the detection boxes</span><br><span class="line">        if (args.image):</span><br><span class="line">            cv.imwrite(outputFile, frame.astype(np.uint8))</span><br><span class="line">        else:</span><br><span class="line">            vid_writer.write(frame.astype(np.uint8))</span><br><span class="line"></span><br><span class="line">        cv.imshow(winName, frame)</span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    parser = argparse.ArgumentParser(description=&#x27;Object Detection using YOLO in OPENCV&#x27;)</span><br><span class="line">    parser.add_argument(&#x27;--image&#x27;, help=&#x27;Path to image file.&#x27;)</span><br><span class="line">    parser.add_argument(&#x27;--video&#x27;, help=&#x27;Path to video file.&#x27;)</span><br><span class="line">    args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    processing_yolov3(args)</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;date, 2018-11-07 14:48:57&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Data-collection-amp-labeling&quot;&gt;&lt;a href=&quot;#Data-collection-amp-labeling&quot; class=&quot;headerlin</summary>
      
    
    
    
    <category term="机器学习" scheme="http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="yolov3" scheme="http://example.com/tags/yolov3/"/>
    
    <category term="darknet" scheme="http://example.com/tags/darknet/"/>
    
  </entry>
  
  <entry>
    <title>Training your own data with TF object detection API</title>
    <link href="http://example.com/2021/02/03/Training-your-own-data-with-TF-object-detection-API/"/>
    <id>http://example.com/2021/02/03/Training-your-own-data-with-TF-object-detection-API/</id>
    <published>2021-02-03T06:28:07.000Z</published>
    <updated>2023-07-13T04:10:49.719Z</updated>
    
    <content type="html"><![CDATA[<h2 id="System-Info"><a href="#System-Info" class="headerlink" title="System Info"></a>System Info</h2><ul><li>Ubuntu 16.04</li><li>Git</li><li>TF 2.0</li><li>pillow</li><li>lxml</li><li>protobuf ( &gt; 3.3 , my version, 3.11.2)</li><li><a class="link"   href="https://www.cnblogs.com/gezhuangzhuang/p/10613468.html" >ref1-tensorflow+ssd_mobilenet实现目标检测的训练<i class="fas fa-external-link-alt"></i></a></li><li><a class="link"   href="https://blog.csdn.net/dy_guox/article/details/79111949" >ref2-（更新视频教程）Tensorflow object detection API 搭建属于自己的物体识别模型（2）——训练并使用自己的模型<i class="fas fa-external-link-alt"></i></a></li><li><a class="link"   href="https://blog.csdn.net/linolzhang/article/details/87121875" >ref3-Tensorflow object detection API训练自己的数据<i class="fas fa-external-link-alt"></i></a></li></ul><h2 id="To-dos"><a href="#To-dos" class="headerlink" title="To-dos"></a>To-dos</h2><ul><li><a class="link"   href="https://github.com/tensorflow/models/tree/master/research/object_detection" >TF object detection API<i class="fas fa-external-link-alt"></i></a></li></ul><h3 id="Env-prepare"><a href="#Env-prepare" class="headerlink" title="Env prepare"></a>Env prepare</h3><ul><li>Clone the <a class="link"   href="https://github.com/tensorflow/models" >model repository<i class="fas fa-external-link-alt"></i></a> into local</li><li><a class="link"   href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md" >Guid for installation<i class="fas fa-external-link-alt"></i></a></li></ul><h3 id="Make-your-own-dataset"><a href="#Make-your-own-dataset" class="headerlink" title="Make your own dataset"></a>Make your own dataset</h3><ul><li>For us, we have the yolo format annotaion files(txt files), but TFRecord format data is fit to the tensorlow.</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yolo-2-voc.py</span><br><span class="line">voc-2-csv.py</span><br><span class="line">csv-2-tfrecord.py</span><br></pre></td></tr></table></figure><h4 id="yolo-to-voc"><a href="#yolo-to-voc" class="headerlink" title="yolo to voc"></a>yolo to voc</h4><ul><li>Prepare two folders, one for <strong>annotation files</strong> and the other for the <strong>image files</strong>. VOC format(xml files) will save into the <strong>converted_lanbels</strong> folder.</li><li><strong>manual change your own data label-mappings</strong></li><li>Notice that the value of <strong>(x, y, width, height) are integers</strong> .<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br></pre></td><td class="code"><pre><span class="line"># Script to convert yolo annotations to voc format</span><br><span class="line"></span><br><span class="line"># Sample format</span><br><span class="line"># &lt;annotation&gt;</span><br><span class="line">#     &lt;folder&gt;_image_fashion&lt;/folder&gt;</span><br><span class="line">#     &lt;filename&gt;brooke-cagle-39574.jpg&lt;/filename&gt;</span><br><span class="line">#     &lt;size&gt;</span><br><span class="line">#         &lt;width&gt;1200&lt;/width&gt;</span><br><span class="line">#         &lt;height&gt;800&lt;/height&gt;</span><br><span class="line">#         &lt;depth&gt;3&lt;/depth&gt;</span><br><span class="line">#     &lt;/size&gt;</span><br><span class="line">#     &lt;segmented&gt;0&lt;/segmented&gt;</span><br><span class="line">#     &lt;object&gt;</span><br><span class="line">#         &lt;name&gt;head&lt;/name&gt;</span><br><span class="line">#         &lt;pose&gt;Unspecified&lt;/pose&gt;</span><br><span class="line">#         &lt;truncated&gt;0&lt;/truncated&gt;</span><br><span class="line">#         &lt;difficult&gt;0&lt;/difficult&gt;</span><br><span class="line">#         &lt;bndbox&gt;</span><br><span class="line">#             &lt;xmin&gt;549&lt;/xmin&gt;</span><br><span class="line">#             &lt;ymin&gt;251&lt;/ymin&gt;</span><br><span class="line">#             &lt;xmax&gt;625&lt;/xmax&gt;</span><br><span class="line">#             &lt;ymax&gt;335&lt;/ymax&gt;</span><br><span class="line">#         &lt;/bndbox&gt;</span><br><span class="line">#     &lt;/object&gt;</span><br><span class="line"># &lt;annotation&gt;</span><br><span class="line">import os</span><br><span class="line">import xml.etree.cElementTree as ET</span><br><span class="line">from PIL import Image</span><br><span class="line"></span><br><span class="line">ANNOTATIONS_DIR_PREFIX = &quot;annotations&quot;</span><br><span class="line"></span><br><span class="line">DESTINATION_DIR = &quot;converted_labels&quot;</span><br><span class="line"></span><br><span class="line">CLASS_MAPPING = &#123;</span><br><span class="line">    &#x27;0&#x27;: &#x27;cream_hazelnut&#x27;,</span><br><span class="line">    &#x27;1&#x27;: &#x27;cream_berry&#x27;,</span><br><span class="line">    &#x27;2&#x27;: &#x27;cream_cherry&#x27;,</span><br><span class="line">    &#x27;3&#x27;: &#x27;yida_cool_lemon&#x27;,</span><br><span class="line">    &#x27;4&#x27;: &#x27;box_yogurt_mango&#x27;,</span><br><span class="line">    &#x27;5&#x27;: &#x27;white_strawberry&#x27;,</span><br><span class="line">    &#x27;6&#x27;: &#x27;cookies_lemon&#x27;,</span><br><span class="line">    &#x27;7&#x27;: &#x27;yogurt_cranberry&#x27;,</span><br><span class="line">    &#x27;8&#x27;: &#x27;box_cookies_matcha&#x27;,</span><br><span class="line">    &#x27;9&#x27;: &#x27;cookies_matcha&#x27;,</span><br><span class="line">    &#x27;10&#x27;: &#x27;yogurt_mango&#x27;,</span><br><span class="line">    &#x27;11&#x27;: &#x27;white_passionfruit&#x27;,</span><br><span class="line">    &#x27;12&#x27;: &#x27;yida_cool_litchi&#x27;,</span><br><span class="line">    &#x27;13&#x27;: &#x27;box_white_strawberry&#x27;</span><br><span class="line">    # Add your remaining classes here.</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def create_root(file_prefix, width, height):</span><br><span class="line">    root = ET.Element(&quot;annotations&quot;)</span><br><span class="line">    ET.SubElement(root, &quot;filename&quot;).text = &quot;&#123;&#125;.jpg&quot;.format(file_prefix)</span><br><span class="line">    ET.SubElement(root, &quot;folder&quot;).text = &quot;images&quot;</span><br><span class="line">    size = ET.SubElement(root, &quot;size&quot;)</span><br><span class="line">    ET.SubElement(size, &quot;width&quot;).text = str(width)</span><br><span class="line">    ET.SubElement(size, &quot;height&quot;).text = str(height)</span><br><span class="line">    ET.SubElement(size, &quot;depth&quot;).text = &quot;3&quot;</span><br><span class="line">    return root</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def create_object_annotation(root, voc_labels):</span><br><span class="line">    for voc_label in voc_labels:</span><br><span class="line">        obj = ET.SubElement(root, &quot;object&quot;)</span><br><span class="line">        ET.SubElement(obj, &quot;name&quot;).text = voc_label[0]</span><br><span class="line">        ET.SubElement(obj, &quot;pose&quot;).text = &quot;Unspecified&quot;</span><br><span class="line">        ET.SubElement(obj, &quot;truncated&quot;).text = str(0)</span><br><span class="line">        ET.SubElement(obj, &quot;difficult&quot;).text = str(0)</span><br><span class="line">        bbox = ET.SubElement(obj, &quot;bndbox&quot;)</span><br><span class="line">        ET.SubElement(bbox, &quot;xmin&quot;).text = str(voc_label[1])</span><br><span class="line">        ET.SubElement(bbox, &quot;ymin&quot;).text = str(voc_label[2])</span><br><span class="line">        ET.SubElement(bbox, &quot;xmax&quot;).text = str(voc_label[3])</span><br><span class="line">        ET.SubElement(bbox, &quot;ymax&quot;).text = str(voc_label[4])</span><br><span class="line">    return root</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def create_file(file_prefix, width, height, voc_labels):</span><br><span class="line">    root = create_root(file_prefix, width, height)</span><br><span class="line">    root = create_object_annotation(root, voc_labels)</span><br><span class="line">    tree = ET.ElementTree(root)</span><br><span class="line">    tree.write(&quot;&#123;&#125;/&#123;&#125;.xml&quot;.format(DESTINATION_DIR, file_prefix))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def read_file(file_path):</span><br><span class="line">    file_prefix = file_path.split(&quot;.txt&quot;)[0]</span><br><span class="line">    image_file_name = &quot;&#123;&#125;.jpg&quot;.format(file_prefix)</span><br><span class="line">    img = Image.open(&quot;&#123;&#125;/&#123;&#125;&quot;.format(&quot;images&quot;, image_file_name))</span><br><span class="line">    w, h = img.size</span><br><span class="line">    </span><br><span class="line">    with open(&quot;&#123;&#125;/&#123;&#125;&quot;.format(ANNOTATIONS_DIR_PREFIX, file_path), &#x27;r&#x27;) as file:</span><br><span class="line">        lines = file.readlines()</span><br><span class="line">        voc_labels = []</span><br><span class="line">        for line in lines:</span><br><span class="line">            voc = []</span><br><span class="line">            line = line.strip()</span><br><span class="line">            data = line.split()</span><br><span class="line">            voc.append(CLASS_MAPPING.get(data[0]))</span><br><span class="line">            bbox_width = float(data[3]) * w</span><br><span class="line">            bbox_height = float(data[4]) * h</span><br><span class="line">            center_x = float(data[1]) * w</span><br><span class="line">            center_y = float(data[2]) * h</span><br><span class="line">            voc.append(int(center_x - (bbox_width / 2)))</span><br><span class="line">            voc.append(int(center_y - (bbox_height / 2)))</span><br><span class="line">            voc.append(int(center_x + (bbox_width / 2)))</span><br><span class="line">            voc.append(int(center_y + (bbox_height / 2)))</span><br><span class="line">            voc_labels.append(voc)</span><br><span class="line">        create_file(file_prefix, w, h, voc_labels)</span><br><span class="line">    print(&quot;Processing complete for file: &#123;&#125;/&#123;&#125;&quot;.format(ANNOTATIONS_DIR_PREFIX, file_path))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def start():</span><br><span class="line">    if not os.path.exists(DESTINATION_DIR):</span><br><span class="line">        os.makedirs(DESTINATION_DIR)</span><br><span class="line">    for filename in os.listdir(ANNOTATIONS_DIR_PREFIX):</span><br><span class="line">        if filename.endswith(&#x27;txt&#x27;):</span><br><span class="line">            read_file(filename)</span><br><span class="line">        else:</span><br><span class="line">            print(&quot;Skipping file: &#123;&#125;&quot;.format(filename))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    start()</span><br></pre></td></tr></table></figure></li></ul><h4 id="train-test-split-on-xml-files"><a href="#train-test-split-on-xml-files" class="headerlink" title="train test split on xml files"></a>train test split on xml files</h4><ul><li>You can change the percentage to split the dataset manually.<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">import random</span><br><span class="line">import time</span><br><span class="line">import shutil</span><br><span class="line"></span><br><span class="line">xmlfilepath = r&#x27;./Annotations&#x27;</span><br><span class="line">saveBasePath = r&quot;./&quot;</span><br><span class="line"></span><br><span class="line">trainval_percent = 0.8</span><br><span class="line">train_percent = 0.8</span><br><span class="line">total_xml = os.listdir(xmlfilepath)</span><br><span class="line">num = len(total_xml)</span><br><span class="line">list = range(num)</span><br><span class="line">tv = int(num * trainval_percent)</span><br><span class="line">tr = int(tv * train_percent)</span><br><span class="line">trainval = random.sample(list, tv)</span><br><span class="line">train = random.sample(trainval, tr)</span><br><span class="line">print(&quot;train and val size&quot;, tv)</span><br><span class="line">print(&quot;train size&quot;, tr)</span><br><span class="line"></span><br><span class="line">start = time.time()</span><br><span class="line"></span><br><span class="line">test_num = 0</span><br><span class="line">val_num = 0</span><br><span class="line">train_num = 0</span><br><span class="line">print(&#x27;total xml : &#123;&#125;&#x27;.format(total_xml))</span><br><span class="line"></span><br><span class="line">for i in list:</span><br><span class="line">    name = total_xml[i]</span><br><span class="line">    # print(&#x27;name : &#123;&#125;&#x27;.format(name))</span><br><span class="line">    if i in trainval:  # train and val set</span><br><span class="line">        if i in train:</span><br><span class="line">            directory = &quot;train&quot;</span><br><span class="line">            train_num += 1</span><br><span class="line">            xml_path = os.path.join(os.getcwd(), &#x27;&#123;&#125;&#x27;.format(directory))</span><br><span class="line">            if (not os.path.exists(xml_path)):</span><br><span class="line">                os.mkdir(xml_path)</span><br><span class="line">            filePath = os.path.join(xmlfilepath, name)</span><br><span class="line">            newfile = os.path.join(saveBasePath, os.path.join(directory, name))</span><br><span class="line">            # print(&#x27;newfile : &#123;&#125;&#x27;.format(newfile))</span><br><span class="line">            shutil.copyfile(filePath, newfile)</span><br><span class="line">        else:</span><br><span class="line">            directory = &quot;validation&quot;</span><br><span class="line">            xml_path = os.path.join(os.getcwd(), &#x27;&#123;&#125;&#x27;.format(directory))</span><br><span class="line">            if (not os.path.exists(xml_path)):</span><br><span class="line">                os.mkdir(xml_path)</span><br><span class="line">            val_num += 1</span><br><span class="line">            filePath = os.path.join(xmlfilepath, name)</span><br><span class="line">            newfile = os.path.join(saveBasePath, os.path.join(directory, name))</span><br><span class="line">            # print(&#x27;newfile : &#123;&#125;&#x27;.format(newfile))</span><br><span class="line">            shutil.copyfile(filePath, newfile)</span><br><span class="line">    else:</span><br><span class="line">        directory = &quot;test&quot;</span><br><span class="line">        xml_path = os.path.join(os.getcwd(), &#x27;&#123;&#125;&#x27;.format(directory))</span><br><span class="line">        if (not os.path.exists(xml_path)):</span><br><span class="line">            os.mkdir(xml_path)</span><br><span class="line">        test_num += 1</span><br><span class="line">        filePath = os.path.join(xmlfilepath, name)</span><br><span class="line">        newfile = os.path.join(saveBasePath, os.path.join(directory, name))</span><br><span class="line">        # print(&#x27;name : &#123;&#125;&#x27;.format(name))</span><br><span class="line">        shutil.copyfile(filePath, newfile)</span><br><span class="line"></span><br><span class="line">end = time.time()</span><br><span class="line">seconds = end - start</span><br><span class="line">print(&quot;train total : &quot; + str(train_num))</span><br><span class="line">print(&quot;validation total : &quot; + str(val_num))</span><br><span class="line">print(&quot;test total : &quot; + str(test_num))</span><br><span class="line">total_num = train_num + val_num + test_num</span><br><span class="line">print(&quot;total number : &quot; + str(total_num))</span><br><span class="line">print(&quot;Time taken : &#123;0&#125; seconds&quot;.format(seconds))</span><br></pre></td></tr></table></figure></li></ul><h4 id="voc-to-csv"><a href="#voc-to-csv" class="headerlink" title="voc to csv"></a>voc to csv</h4><ul><li>Transfer the xml files to csv for trian, test and validation folder individually.</li><li>You should change the save path for your own csv files.<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">import glob</span><br><span class="line">import pandas as pd</span><br><span class="line">import xml.etree.ElementTree as ET</span><br><span class="line"></span><br><span class="line">def xml_to_csv(path):</span><br><span class="line">    xml_list = []</span><br><span class="line">    for xml_file in glob.glob(path + &#x27;/*.xml&#x27;):</span><br><span class="line">        tree = ET.parse(xml_file)</span><br><span class="line">        root = tree.getroot()</span><br><span class="line"></span><br><span class="line">        print(root.find(&#x27;filename&#x27;).text)</span><br><span class="line">        for member in root.findall(&#x27;object&#x27;):</span><br><span class="line">            value = (root.find(&#x27;filename&#x27;).text,</span><br><span class="line">                int(root.find(&#x27;size&#x27;)[0].text),   #width</span><br><span class="line">                int(root.find(&#x27;size&#x27;)[1].text),   #height</span><br><span class="line">                member[0].text,</span><br><span class="line">                int(member[4][0].text),</span><br><span class="line">                int(float(member[4][1].text)),</span><br><span class="line">                int(member[4][2].text),</span><br><span class="line">                int(member[4][3].text)</span><br><span class="line">                )</span><br><span class="line">            xml_list.append(value)</span><br><span class="line">    column_name = [&#x27;filename&#x27;, &#x27;width&#x27;, &#x27;height&#x27;, &#x27;class&#x27;, &#x27;xmin&#x27;, &#x27;ymin&#x27;, &#x27;xmax&#x27;, &#x27;ymax&#x27;]</span><br><span class="line">    xml_df = pd.DataFrame(xml_list, columns=column_name)</span><br><span class="line">    return xml_df</span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    for directory in [&#x27;train&#x27;,&#x27;test&#x27;,&#x27;validation&#x27;]:</span><br><span class="line">        xml_path = os.path.join(os.getcwd(), &#x27;./&#123;&#125;&#x27;.format(directory))</span><br><span class="line"></span><br><span class="line">        xml_df = xml_to_csv(xml_path)</span><br><span class="line">        # xml_df.to_csv(&#x27;whsyxt.csv&#x27;, index=None)</span><br><span class="line">        xml_df.to_csv(&#x27;/home/tim/workspace/models/research/object_detection/data/dove_cholo_&#123;&#125;_labels.csv&#x27;.format(directory), index=None)</span><br><span class="line">        print(&#x27;Successfully converted xml to csv.&#x27;)</span><br><span class="line"></span><br><span class="line">main()</span><br></pre></td></tr></table></figure></li></ul><h4 id="csv-to-tfrecord"><a href="#csv-to-tfrecord" class="headerlink" title="csv to tfrecord"></a>csv to tfrecord</h4><ul><li>You should set your JPEGImage path.<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python3</span><br><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">Created on Tue Mar  5 15:28:55 2019</span><br><span class="line"></span><br><span class="line">@author: z</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">Usage:</span><br><span class="line">  # From tensorflow/models/</span><br><span class="line">  # Create train data:</span><br><span class="line">  python generate_tfrecord.py --csv_input=data/tv_vehicle_labels.csv  --output_path=train.record</span><br><span class="line">  # Create test data:</span><br><span class="line">  python generate_tfrecord.py --csv_input=data/test_labels.csv  --output_path=test.record</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">import os</span><br><span class="line">import io</span><br><span class="line">import pandas as pd</span><br><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">from PIL import Image</span><br><span class="line">from object_detection.utils import dataset_util</span><br><span class="line">from collections import namedtuple, OrderedDict</span><br><span class="line"></span><br><span class="line">os.chdir(&#x27;/home/tim/workspace/models/research/&#x27;)</span><br><span class="line"></span><br><span class="line">flags = tf.app.flags</span><br><span class="line">flags.DEFINE_string(&#x27;csv_input&#x27;, &#x27;&#x27;, &#x27;Path to the CSV input&#x27;)</span><br><span class="line">flags.DEFINE_string(&#x27;output_path&#x27;, &#x27;&#x27;, &#x27;Path to output TFRecord&#x27;)</span><br><span class="line">FLAGS = flags.FLAGS</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># TO-DO replace this with label map</span><br><span class="line">def class_text_to_int(row_label):</span><br><span class="line">    # 你的所有类别, 必须从1开始，0被征用作为了背景。</span><br><span class="line">    if row_label == &#x27;cream_berry&#x27;:</span><br><span class="line">        return 1</span><br><span class="line">    elif row_label == &#x27;cream_cherry&#x27;:</span><br><span class="line">        return 2</span><br><span class="line">    elif row_label == &#x27;yida_cool_lemon&#x27;:</span><br><span class="line">        return 3</span><br><span class="line">    elif row_label == &#x27;box_yogurt_mango&#x27;:</span><br><span class="line">        return 4</span><br><span class="line">    elif row_label == &#x27;white_strawberry&#x27;:</span><br><span class="line">        return 5</span><br><span class="line">    elif row_label == &#x27;cookies_lemon&#x27;:</span><br><span class="line">        return 6</span><br><span class="line">    elif row_label == &#x27;yogurt_cranberry&#x27;:</span><br><span class="line">        return 7</span><br><span class="line">    elif row_label == &#x27;box_cookies_matcha&#x27;:</span><br><span class="line">        return 8</span><br><span class="line">    elif row_label == &#x27;cookies_matcha&#x27;:</span><br><span class="line">        return 9</span><br><span class="line">    elif row_label == &#x27;yogurt_mango&#x27;:</span><br><span class="line">        return 10</span><br><span class="line">    elif row_label == &#x27;white_passionfruit&#x27;:</span><br><span class="line">        return 11</span><br><span class="line">    elif row_label == &#x27;yida_cool_litchi&#x27;:</span><br><span class="line">        return 12</span><br><span class="line">    elif row_label == &#x27;box_white_strawberry&#x27;:</span><br><span class="line">        return 13</span><br><span class="line">    elif row_label == &#x27;cream_hazelnut&#x27;:</span><br><span class="line">        return 14</span><br><span class="line">    else:</span><br><span class="line">        return None</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def split(df, group):</span><br><span class="line">    data = namedtuple(&#x27;data&#x27;, [&#x27;filename&#x27;, &#x27;object&#x27;])</span><br><span class="line">    gb = df.groupby(group)</span><br><span class="line">    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def create_tf_example(group, path):</span><br><span class="line">    with tf.gfile.GFile(os.path.join(path, &#x27;&#123;&#125;&#x27;.format(group.filename)), &#x27;rb&#x27;) as fid:</span><br><span class="line">        encoded_jpg = fid.read()</span><br><span class="line">    encoded_jpg_io = io.BytesIO(encoded_jpg)</span><br><span class="line">    image = Image.open(encoded_jpg_io)</span><br><span class="line">    width, height = image.size</span><br><span class="line"></span><br><span class="line">    filename = group.filename.encode(&#x27;utf8&#x27;)</span><br><span class="line">    image_format = b&#x27;jpg&#x27;</span><br><span class="line">    xmins = []</span><br><span class="line">    xmaxs = []</span><br><span class="line">    ymins = []</span><br><span class="line">    ymaxs = []</span><br><span class="line">    classes_text = []</span><br><span class="line">    classes = []</span><br><span class="line"></span><br><span class="line">    for index, row in group.object.iterrows():</span><br><span class="line">        xmins.append(row[&#x27;xmin&#x27;] / width)</span><br><span class="line">        xmaxs.append(row[&#x27;xmax&#x27;] / width)</span><br><span class="line">        ymins.append(row[&#x27;ymin&#x27;] / height)</span><br><span class="line">        ymaxs.append(row[&#x27;ymax&#x27;] / height)</span><br><span class="line">        classes_text.append(row[&#x27;class&#x27;].encode(&#x27;utf8&#x27;))</span><br><span class="line">        classes.append(class_text_to_int(row[&#x27;class&#x27;]))</span><br><span class="line"></span><br><span class="line">    tf_example = tf.train.Example(features=tf.train.Features(feature=&#123;</span><br><span class="line">        &#x27;image/height&#x27;: dataset_util.int64_feature(height),</span><br><span class="line">        &#x27;image/width&#x27;: dataset_util.int64_feature(width),</span><br><span class="line">        &#x27;image/filename&#x27;: dataset_util.bytes_feature(filename),</span><br><span class="line">        &#x27;image/source_id&#x27;: dataset_util.bytes_feature(filename),</span><br><span class="line">        &#x27;image/encoded&#x27;: dataset_util.bytes_feature(encoded_jpg),</span><br><span class="line">        &#x27;image/format&#x27;: dataset_util.bytes_feature(image_format),</span><br><span class="line">        &#x27;image/object/bbox/xmin&#x27;: dataset_util.float_list_feature(xmins),</span><br><span class="line">        &#x27;image/object/bbox/xmax&#x27;: dataset_util.float_list_feature(xmaxs),</span><br><span class="line">        &#x27;image/object/bbox/ymin&#x27;: dataset_util.float_list_feature(ymins),</span><br><span class="line">        &#x27;image/object/bbox/ymax&#x27;: dataset_util.float_list_feature(ymaxs),</span><br><span class="line">        &#x27;image/object/class/text&#x27;: dataset_util.bytes_list_feature(classes_text),</span><br><span class="line">        &#x27;image/object/class/label&#x27;: dataset_util.int64_list_feature(classes),</span><br><span class="line">    &#125;))</span><br><span class="line">    return tf_example</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main(_):</span><br><span class="line">    writer = tf.python_io.TFRecordWriter(FLAGS.output_path)</span><br><span class="line">    path = os.path.join(os.getcwd(), &#x27;object_detection/VOCdevkit/VOC2020_dove_cholo/JPEGImages/&#x27;)</span><br><span class="line">    examples = pd.read_csv(FLAGS.csv_input)</span><br><span class="line">    grouped = split(examples, &#x27;filename&#x27;)</span><br><span class="line">    num = 0</span><br><span class="line">    for group in grouped:</span><br><span class="line">        num += 1</span><br><span class="line">        tf_example = create_tf_example(group, path)</span><br><span class="line">        writer.write(tf_example.SerializeToString())</span><br><span class="line">        if (num % 100 == 0):  # 每完成100个转换，打印一次</span><br><span class="line">            print(num)</span><br><span class="line"></span><br><span class="line">    writer.close()</span><br><span class="line">    output_path = os.path.join(os.getcwd(), FLAGS.output_path)</span><br><span class="line">    print(&#x27;Successfully created the TFRecords: &#123;&#125;&#x27;.format(output_path))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    tf.app.run()</span><br></pre></td></tr></table></figure></li><li>command to generate tfrecord files<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd models/research/</span><br><span class="line"></span><br><span class="line">python generate_tfrecord.py --csv_input=object_detection/data/dove_cholo_test_labels.csv --output_path=dove_test.tfrecord</span><br><span class="line"></span><br><span class="line">python generate_tfrecord.py --csv_input=object_detection/data/dove_cholo_validation_labels.csv --output_path=dove_validation.tfrecord</span><br><span class="line"></span><br><span class="line">python generate_tfrecord.py --csv_input=object_detection/data/dove_cholo_train_labels.csv --output_path=dove_train.tfrecord</span><br></pre></td></tr></table></figure></li></ul><h3 id="Training-model"><a href="#Training-model" class="headerlink" title="Training model"></a>Training model</h3><ul><li>Things to prepare<ul><li>create your own label-map.pbtxt<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">cd models/research/object_detection/data</span><br><span class="line">create label-map.pbtxt</span><br><span class="line">contents are belows</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">item &#123;</span><br><span class="line">  id: 1    # id 从1开始编号</span><br><span class="line">  name: &#x27;red pedestrian&#x27;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">item &#123;</span><br><span class="line">  id: 2</span><br><span class="line">  name: &#x27;green pedestrian&#x27;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>model config file list<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">cd object_detection/samples/config/</span><br><span class="line"></span><br><span class="line">(base) tim@tim-System-Product-Name:~/workspace/models/research/object_detection/samples/configs$ tree</span><br><span class="line">.</span><br><span class="line">├── embedded_ssd_mobilenet_v1_coco.config</span><br><span class="line">├── facessd_mobilenet_v2_quantized_320x320_open_image_v4.config</span><br><span class="line">├── faster_rcnn_inception_resnet_v2_atrous_coco.config</span><br><span class="line">├── faster_rcnn_inception_resnet_v2_atrous_cosine_lr_coco.config</span><br><span class="line">├── faster_rcnn_inception_resnet_v2_atrous_oid.config</span><br><span class="line">├── faster_rcnn_inception_resnet_v2_atrous_oid_v4.config</span><br><span class="line">├── faster_rcnn_inception_resnet_v2_atrous_pets.config</span><br><span class="line">├── faster_rcnn_inception_v2_coco.config</span><br><span class="line">├── faster_rcnn_inception_v2_pets.config</span><br><span class="line">├── faster_rcnn_nas_coco.config</span><br><span class="line">├── faster_rcnn_resnet101_atrous_coco.config</span><br><span class="line">├── faster_rcnn_resnet101_ava_v2.1.config</span><br><span class="line">├── faster_rcnn_resnet101_coco.config</span><br><span class="line">├── faster_rcnn_resnet101_fgvc.config</span><br><span class="line">├── faster_rcnn_resnet101_kitti.config</span><br><span class="line">├── faster_rcnn_resnet101_pets.config</span><br><span class="line">├── faster_rcnn_resnet101_voc07.config</span><br><span class="line">├── faster_rcnn_resnet152_coco.config</span><br><span class="line">├── faster_rcnn_resnet152_pets.config</span><br><span class="line">├── faster_rcnn_resnet50_coco.config</span><br><span class="line">├── faster_rcnn_resnet50_fgvc.config</span><br><span class="line">├── faster_rcnn_resnet50_pets.config</span><br><span class="line">├── mask_rcnn_inception_resnet_v2_atrous_coco.config</span><br><span class="line">├── mask_rcnn_inception_v2_coco.config</span><br><span class="line">├── mask_rcnn_resnet101_atrous_coco.config</span><br><span class="line">├── mask_rcnn_resnet101_pets.config</span><br><span class="line">├── mask_rcnn_resnet50_atrous_coco.config</span><br><span class="line">├── rfcn_resnet101_coco.config</span><br><span class="line">├── rfcn_resnet101_pets.config</span><br><span class="line">├── ssd_inception_v2_coco.config</span><br><span class="line">├── ssd_inception_v2_pets.config</span><br><span class="line">├── ssd_inception_v3_pets.config</span><br><span class="line">├── ssdlite_mobilenet_edgetpu_320x320_coco.config</span><br><span class="line">├── ssdlite_mobilenet_edgetpu_320x320_coco_quant.config</span><br><span class="line">├── ssdlite_mobilenet_v1_coco.config</span><br><span class="line">├── ssdlite_mobilenet_v2_coco.config</span><br><span class="line">├── ssdlite_mobilenet_v3_large_320x320_coco.config</span><br><span class="line">├── ssdlite_mobilenet_v3_small_320x320_coco.config</span><br><span class="line">├── ssd_mobilenet_v1_0.75_depth_300x300_coco14_sync.config</span><br><span class="line">├── ssd_mobilenet_v1_0.75_depth_quantized_300x300_coco14_sync.config</span><br><span class="line">├── ssd_mobilenet_v1_0.75_depth_quantized_300x300_pets_sync.config</span><br><span class="line">├── ssd_mobilenet_v1_300x300_coco14_sync.config</span><br><span class="line">├── ssd_mobilenet_v1_coco.config</span><br><span class="line">├── ssd_mobilenet_v1_focal_loss_pets.config</span><br><span class="line">├── ssd_mobilenet_v1_focal_loss_pets_inference.config</span><br><span class="line">├── ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync.config</span><br><span class="line">├── ssd_mobilenet_v1_pets.config</span><br><span class="line">├── ssd_mobilenet_v1_ppn_shared_box_predictor_300x300_coco14_sync.config</span><br><span class="line">├── ssd_mobilenet_v1_quantized_300x300_coco14_sync.config</span><br><span class="line">├── ssd_mobilenet_v2_coco.config</span><br><span class="line">├── ssd_mobilenet_v2_fpnlite_quantized_shared_box_predictor_256x256_depthmultiplier_75_coco14_sync.config</span><br><span class="line">├── ssd_mobilenet_v2_fullyconv_coco.config</span><br><span class="line">├── ssd_mobilenet_v2_oid_v4.config</span><br><span class="line">├── ssd_mobilenet_v2_pets_keras.config</span><br><span class="line">├── ssd_mobilenet_v2_quantized_300x300_coco.config</span><br><span class="line">├── ssd_resnet101_v1_fpn_shared_box_predictor_oid_512x512_sync.config</span><br><span class="line">└── ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync.config</span><br><span class="line"></span><br><span class="line">0 directories, 57 files</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li>Custom your own model config, ssd_moblienet_v1_coco.config for example</li><li>Open it and change the code.<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br></pre></td><td class="code"><pre><span class="line"># SSD with Mobilenet v1 configuration for MSCOCO Dataset.</span><br><span class="line"># Users should configure the fine_tune_checkpoint field in the train config as</span><br><span class="line"># well as the label_map_path and input_path fields in the train_input_reader and</span><br><span class="line"># eval_input_reader. Search for &quot;PATH_TO_BE_CONFIGURED&quot; to find the fields that</span><br><span class="line"># should be configured.</span><br><span class="line"></span><br><span class="line">model &#123;</span><br><span class="line">  ssd &#123;</span><br><span class="line">    num_classes: 14  ## change here</span><br><span class="line">    box_coder &#123;</span><br><span class="line">      faster_rcnn_box_coder &#123;</span><br><span class="line">        y_scale: 10.0</span><br><span class="line">        x_scale: 10.0</span><br><span class="line">        height_scale: 5.0</span><br><span class="line">        width_scale: 5.0</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    matcher &#123;</span><br><span class="line">      argmax_matcher &#123;</span><br><span class="line">        matched_threshold: 0.5</span><br><span class="line">        unmatched_threshold: 0.5</span><br><span class="line">        ignore_thresholds: false</span><br><span class="line">        negatives_lower_than_unmatched: true</span><br><span class="line">        force_match_for_each_row: true</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    similarity_calculator &#123;</span><br><span class="line">      iou_similarity &#123;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    anchor_generator &#123;</span><br><span class="line">      ssd_anchor_generator &#123;</span><br><span class="line">        num_layers: 6</span><br><span class="line">        min_scale: 0.2</span><br><span class="line">        max_scale: 0.95</span><br><span class="line">        aspect_ratios: 1.0</span><br><span class="line">        aspect_ratios: 2.0</span><br><span class="line">        aspect_ratios: 0.5</span><br><span class="line">        aspect_ratios: 3.0</span><br><span class="line">        aspect_ratios: 0.3333</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    image_resizer &#123;</span><br><span class="line">      fixed_shape_resizer &#123;</span><br><span class="line">        height: 300</span><br><span class="line">        width: 300</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    box_predictor &#123;</span><br><span class="line">      convolutional_box_predictor &#123;</span><br><span class="line">        min_depth: 0</span><br><span class="line">        max_depth: 0</span><br><span class="line">        num_layers_before_predictor: 0</span><br><span class="line">        use_dropout: false</span><br><span class="line">        dropout_keep_probability: 0.8</span><br><span class="line">        kernel_size: 1</span><br><span class="line">        box_code_size: 4</span><br><span class="line">        apply_sigmoid_to_scores: false</span><br><span class="line">        conv_hyperparams &#123;</span><br><span class="line">          activation: RELU_6,</span><br><span class="line">          regularizer &#123;</span><br><span class="line">            l2_regularizer &#123;</span><br><span class="line">              weight: 0.00004</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">          initializer &#123;</span><br><span class="line">            truncated_normal_initializer &#123;</span><br><span class="line">              stddev: 0.03</span><br><span class="line">              mean: 0.0</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">          batch_norm &#123;</span><br><span class="line">            train: true,</span><br><span class="line">            scale: true,</span><br><span class="line">            center: true,</span><br><span class="line">            decay: 0.9997,</span><br><span class="line">            epsilon: 0.001,</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    feature_extractor &#123;</span><br><span class="line">      type: &#x27;ssd_mobilenet_v1&#x27;</span><br><span class="line">      min_depth: 16</span><br><span class="line">      depth_multiplier: 1.0</span><br><span class="line">      conv_hyperparams &#123;</span><br><span class="line">        activation: RELU_6,</span><br><span class="line">        regularizer &#123;</span><br><span class="line">          l2_regularizer &#123;</span><br><span class="line">            weight: 0.00004</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        initializer &#123;</span><br><span class="line">          truncated_normal_initializer &#123;</span><br><span class="line">            stddev: 0.03</span><br><span class="line">            mean: 0.0</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        batch_norm &#123;</span><br><span class="line">          train: true,</span><br><span class="line">          scale: true,</span><br><span class="line">          center: true,</span><br><span class="line">          decay: 0.9997,</span><br><span class="line">          epsilon: 0.001,</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    loss &#123;</span><br><span class="line">      classification_loss &#123;</span><br><span class="line">        weighted_sigmoid &#123;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      localization_loss &#123;</span><br><span class="line">        weighted_smooth_l1 &#123;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      hard_example_miner &#123;</span><br><span class="line">        num_hard_examples: 3000</span><br><span class="line">        iou_threshold: 0.99</span><br><span class="line">        loss_type: CLASSIFICATION</span><br><span class="line">        max_negatives_per_positive: 3</span><br><span class="line">        min_negatives_per_image: 0</span><br><span class="line">      &#125;</span><br><span class="line">      classification_weight: 1.0</span><br><span class="line">      localization_weight: 1.0</span><br><span class="line">    &#125;</span><br><span class="line">    normalize_loss_by_num_matches: true</span><br><span class="line">    post_processing &#123;</span><br><span class="line">      batch_non_max_suppression &#123;</span><br><span class="line">        score_threshold: 1e-8</span><br><span class="line">        iou_threshold: 0.6</span><br><span class="line">        max_detections_per_class: 100</span><br><span class="line">        max_total_detections: 100</span><br><span class="line">      &#125;</span><br><span class="line">      score_converter: SIGMOID</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">train_config: &#123;</span><br><span class="line">  batch_size: 24   ## change here</span><br><span class="line">  optimizer &#123;</span><br><span class="line">    rms_prop_optimizer: &#123;</span><br><span class="line">      learning_rate: &#123;</span><br><span class="line">        exponential_decay_learning_rate &#123;</span><br><span class="line">          initial_learning_rate: 0.0004</span><br><span class="line">          decay_steps: 800720</span><br><span class="line">          decay_factor: 0.95</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      momentum_optimizer_value: 0.9</span><br><span class="line">      decay: 0.9</span><br><span class="line">      epsilon: 1.0</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  fine_tune_checkpoint: &quot;object_detection/finetune_cpkt/ssd_mobilenet_v1_coco_2018_01_28/model.ckpt&quot;   ## change here</span><br><span class="line">  from_detection_checkpoint: true</span><br><span class="line">  # Note: The below line limits the training process to 200K steps, which we</span><br><span class="line">  # empirically found to be sufficient enough to train the pets dataset. This</span><br><span class="line">  # effectively bypasses the learning rate schedule (the learning rate will</span><br><span class="line">  # never decay). Remove the below line to train indefinitely.</span><br><span class="line">  num_steps: 10000    ## change here</span><br><span class="line">  data_augmentation_options &#123;</span><br><span class="line">    random_horizontal_flip &#123;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  data_augmentation_options &#123;</span><br><span class="line">    ssd_random_crop &#123;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">train_input_reader: &#123;</span><br><span class="line">  tf_record_input_reader &#123;</span><br><span class="line">    input_path: &quot;object_detection/data/dove_train.tfrecord&quot;   ## change here</span><br><span class="line">  &#125;</span><br><span class="line">  label_map_path: &quot;object_detection/data/dove_cholo_label_map.pbtxt&quot;   ## change here</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">eval_config: &#123;</span><br><span class="line">  num_examples: 3438    ## change here</span><br><span class="line">  # Note: The below line limits the evaluation process to 10 evaluations.</span><br><span class="line">  # Remove the below line to evaluate indefinitely.</span><br><span class="line">  max_evals: 10</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">eval_input_reader: &#123;</span><br><span class="line">  tf_record_input_reader &#123;</span><br><span class="line">    input_path: &quot;object_detection/data/dove_validation.tfrecord&quot;   ## change here</span><br><span class="line">  &#125;</span><br><span class="line">  label_map_path: &quot;object_detection/data/dove_cholo_label_map.pbtxt&quot;   ## change here</span><br><span class="line">  shuffle: false</span><br><span class="line">  num_readers: 1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>Download the pre-trained model<br>  <a class="link"   href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md" >modle zoo<i class="fas fa-external-link-alt"></i></a></li><li>fine_tune_checkpoint: “object_detection&#x2F;finetune_cpkt&#x2F;ssd_mobilenet_v1_coco_2018_01_28&#x2F;model.ckpt”   ## change here</li></ul></li></ul><h4 id="legacy-training-同时跑train-py和eval-py"><a href="#legacy-training-同时跑train-py和eval-py" class="headerlink" title="legacy training (同时跑train.py和eval.py)"></a>legacy training (同时跑train.py和eval.py)</h4><ul><li><p>旧的训练方法，path,  &#x2F;models&#x2F;research&#x2F;object_detection&#x2F;legacy&#x2F;train.py</p></li><li><p>旧的训练方法，path,  &#x2F;models&#x2F;research&#x2F;object_detection&#x2F;legacy&#x2F;eval.py</p></li><li><p><a class="link"   href="https://blog.csdn.net/zong596568821xp/article/details/84842688" >ref-eval的使用<i class="fas fa-external-link-alt"></i></a></p></li><li><p>–logtostderr, 日志保存</p></li><li><p>–train_dir, 训练模型保存的位置</p></li><li><p>–pipeline_config_path, 模型配置文件的路径</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">## 可用GPU训练，但常常会cuda out of memory</span><br><span class="line">## 先在trian.py和eval.py中加入以下代码控制gpu的内存使用</span><br><span class="line"></span><br><span class="line">import os</span><br><span class="line"> </span><br><span class="line">os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;0&quot;</span><br><span class="line">config = tf.ConfigProto(allow_soft_placement = True)</span><br><span class="line">gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction = 0.35)</span><br><span class="line">config.gpu_options.allow_growth = True</span><br><span class="line"> </span><br><span class="line">sess0 = tf.InteractiveSession(config = config)</span><br><span class="line"></span><br><span class="line"># 原文链接：https://blog.csdn.net/baidu_33597755/article/details/102311000</span><br><span class="line"></span><br><span class="line">cd models/research/</span><br><span class="line"></span><br><span class="line">python object_detection/legacy/train.py \</span><br><span class="line">    --pipeline_config_path=object_detection/dove_cholo_od/config/ssd_mobilenet_v2_coco.config \</span><br><span class="line">    --train_dir=object_detection/dove_cholo_od/dove_train_dir/ssd_m_v2/dove_train  \</span><br><span class="line">    --alsologtostderr</span><br><span class="line">    </span><br><span class="line"># 等train.py跑了一会之后，再运行eval.py</span><br><span class="line"></span><br><span class="line">python object_detection/legacy/eval.py \</span><br><span class="line">    --pipeline_config_path=object_detection/dove_cholo_od/config/ssd_mobilenet_v2_coco.config \</span><br><span class="line">    --checkpoint_dir=object_detection/dove_cholo_od/dove_train_dir/ssd_m_v2/dove_train  \</span><br><span class="line">    --eval_dir=object_detection/dove_cholo_od/dove_train_dir/ssd_m_v2/dove_eval  \</span><br><span class="line">    --logtostderr</span><br><span class="line">    </span><br></pre></td></tr></table></figure></li><li><p>Then open the tensorboard to watch the training and eval progress</p></li><li><p>Open two tensorboard at the same time</p></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensorboard --logdir=object_detection/dove_cholo_od/dove_train_dir/ssd_m_v2/dove_train --port=6005</span><br><span class="line"></span><br><span class="line">tensorboard --logdir=object_detection/dove_cholo_od/dove_train_dir/ssd_m_v2/dove_eval</span><br></pre></td></tr></table></figure><h4 id="modern-training-暂不支持GPU"><a href="#modern-training-暂不支持GPU" class="headerlink" title="modern training(暂不支持GPU)"></a>modern training(暂不支持GPU)</h4><ul><li>新的训练方法，path,   &#x2F;models&#x2F;research&#x2F;object_detection&#x2F;model_main.py<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># From the tensorflow/models/research/ directory</span><br><span class="line">python object_detection/model_main.py \</span><br><span class="line">    --pipeline_config_path=object_detection/training/ssd_mobilenet_v1_coco.config \</span><br><span class="line">    --model_dir=object_detection/training \</span><br><span class="line">    --num_train_steps=50000 \</span><br><span class="line">    --num_eval_steps=2000 \</span><br><span class="line">    --alsologtostderr</span><br></pre></td></tr></table></figure></li></ul><h3 id="Model-evaluation"><a href="#Model-evaluation" class="headerlink" title="Model evaluation"></a>Model evaluation</h3><h3 id="Q-amp-A"><a href="#Q-amp-A" class="headerlink" title="Q&amp;A"></a>Q&amp;A</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1. ImportError: cannot import name &#x27;input_reader_pb2&#x27; from &#x27;object_detection.protos&#x27;</span><br><span class="line">solution:</span><br><span class="line"># From tensorflow/models/research/</span><br><span class="line">protoc object_detection/protos/*.proto --python_out=.</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">2. from nets import inception_resnet_v2 ModuleNotFoundError: No module named &#x27;nets&#x27;</span><br><span class="line">solution:</span><br><span class="line">cd model/research/</span><br><span class="line">python setup.py build</span><br><span class="line">python setup.py install</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cd model/research/slim/</span><br><span class="line">python setup.py build</span><br><span class="line">python setup.py install</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">3. Not found: PATH_TO_BE_CONFIGURED; No such file or directory</span><br><span class="line">solution:</span><br><span class="line">download pre-trained cpkt model</span><br><span class="line">go into the config file and Search for &quot;PATH_TO_BE_CONFIGURED&quot; to find the fields that should be configured.</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">4. No module named &#x27;pycocotools&#x27;</span><br><span class="line">pip install git+https://github.com/philferriere/cocoapi.git#subdirectory=PythonAPI</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;System-Info&quot;&gt;&lt;a href=&quot;#System-Info&quot; class=&quot;headerlink&quot; title=&quot;System Info&quot;&gt;&lt;/a&gt;System Info&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Ubuntu 16.04&lt;/li&gt;
&lt;li&gt;Git&lt;/l</summary>
      
    
    
    
    <category term="机器学习" scheme="http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="tensorflow" scheme="http://example.com/tags/tensorflow/"/>
    
    <category term="object detection" scheme="http://example.com/tags/object-detection/"/>
    
  </entry>
  
  <entry>
    <title>可视化证明：神经网络可以计算任何函数</title>
    <link href="http://example.com/2017/06/14/visual-proof-of-neural-networks/"/>
    <id>http://example.com/2017/06/14/visual-proof-of-neural-networks/</id>
    <published>2017-06-14T09:49:20.000Z</published>
    <updated>2023-07-13T04:04:26.324Z</updated>
    
    <content type="html"><![CDATA[<ul><li><p><a class="link"   href="http://neuralnetworksanddeeplearning.com/chap4.html" >Original Post<i class="fas fa-external-link-alt"></i></a></p></li><li><p>神经网络当中一个最显著的事实是：神经网络能够计算任何的函数。也就是说，假如有人给你一个复杂的，波形弯弯曲曲的函数，$f(x):$</p><img src="/img/visual_proof_of_neural_networks/1_function.png" class="[class names]" title="[Function $f(x)$ []]"></li><li><p>无论是什么的函数，我们都可以保证能找到一个网络，对于所有可能的输入，$x$，$f(x)$的值(或者其他的逼近)就是网络的输出，譬如：</p><img src="/img/visual_proof_of_neural_networks/2_network.png" class="[class names]" title="[Neural Network []]"></li><li><p>这个网络即使是网络的输入很多的时候也是成立的。$f&#x3D;f(x_1,…,x_m)$，然后还有很多的输出。譬如，以下就是一个网络，计算的函数，输入$m&#x3D;3$和输出$n&#x3D;2$：</p><img src="/img/visual_proof_of_neural_networks/3_network.png" class="[class names]" title="[Neural Network []]"></li><li><p>以上的网络告诉我们神经网络是有一种泛化性的。无论我们想要计算任何的函数，肯定存在一个网络可以满足我们的需求。</p></li><li><p>另外，更进一步，即使这个网络限制到只有一层隐含层，这个泛化理论也是成立的。这个网络就是所谓的单层隐含层。所以，即使是很简单的网络也是很厉害的。</p></li><li><p>搞神经网络的人都应该熟知这个泛化性理论，可是事实上它并没有让很多人能理解。大多数的解释都是偏技术性的。譬如，其中一篇原始的论文利用$Hahn-Banach$理论，$Riesz Representation$理论和一些傅里叶分析来证明这个泛化性理论。如果你不是一个数学家的话，你很难读懂里面的解释。很遗憾，这样很多人就很难懂这个泛化性理论了。但是其实背后的原理是非常简单和美好的。</p></li><li><p>在本章中，我会给出一个关于泛化性理论的简单的和非常可视化的解释。我们会循序渐进，一步一步来理解这个idea。你将会明白为什么神经网络能够计算任意的函数。你也会理解到这个理论的一些限制的地方。你会理解到这个理论和深度学习之间的关系。</p></li><li><p>要理解这章的内容，你并不需要读前面的内容。反而这一章是一个结构乐见和完整的文章。我会给你们讲一些神经网络的基本知识，这样你们会更容易看懂解释。我会提供一些临时的链接，以防填补你某一部分知识的缺口。</p></li><li><p>泛化性理论是计算机科学中一个老生常谈的东西，以至于我们有时候都忘记了它到底有多厉害了。但是我们应该时刻提醒自己：有能力去计算任意的函数真的是一件很厉害的事情。几乎你可以想象得到的任何进程都可以被认为是一个函数的计算。譬如，根据一些短的音乐片段去给一段音乐命名。这也是看作计算一个函数。又或者把中文翻译成英文，又或者给计算机一个mp4视频资料，它会生成一个关于视频的描绘图还有这个视频的拍摄质量。泛化性意味着，原则上，神经网络可以做任何的事情而且更多。</p></li><li><p>当然，仅仅因为我们知道存在一个网络能够把中文翻译成英文，那不意味着我们就很容易构造甚至识别出这个网络。这样的约束对于模型的传统的泛化性理论，譬如布尔回路，都是适用的。但是，像这本书前面所说的，神经网络对于学习函数有非常强的算法。学习算法和泛化性是一个绝妙的结合。直到现在，这本书还是关注在学习算法。在这一章，我们关注在泛化性理论，和它所代表的意思。</p></li></ul><h2 id="两个说明"><a href="#两个说明" class="headerlink" title="两个说明"></a>两个说明</h2><ul><li><p>在我们解释为什么泛化性理论成立之前，我想要提两个关于“一个神经网络能够计算任何的函数”的说明。</p></li><li><p>首先，并不是说一个神经网络被用来准确地计算任何的函数。而是，我们能够得到一个关于这个函数的一个很好的逼近。通过增加隐层神经元的个数，我们可以不断改进逼近的程度。譬如，前面我们谈到的神经网络，包含一个隐层。对于很多函数，只有3个隐层神经元的神经网络是一个并不好的逼近。通过增加隐层的神经元(假如，增加到5)，我们可以得到更好的逼近：</p><img src="/img/visual_proof_of_neural_networks/4_network.png" class="[class names]" title="[Neural Network []]"></li><li><p>如果我们继续增加神经元的个数，这个逼近就能做得更好。</p></li><li><p>更精确的说，假如给定我们一个函数$f(x)$，我们想要计算它的误差$\epsilon &gt; 0$。只要我们增加足够的隐层神经元，我们就能找到一个神经网络，它的输出$g(x)$满足$g(x)-f(x) &lt; \epsilon$,对于所有的输入$x$。换句话说，这个逼近函数$g(x)$对于所有可能的输入都在可预计的准确度范围之内。</p></li><li><p>第二个说明是能够用逼近的方式的函数类型是连续函数。如果一个函数是不连续的，譬如，突然断开的，或者跳动的函数，然后是没法用神经网络来进行逼近的。这并没有什么奇怪的，因为我们的网络计算输入的连续函数。然而，即使我们想要计算不连续的函数，但是利用连续的逼近来的效果更好。既然这样，那么我们就可以用神经网络。实际上，这并不是一个很重要的限制。</p></li><li><p>总结一下，关于泛化性理论的一个精确的说法是一个单隐层的神经网络能够用来逼近任何的连续函数到任何想要的精度。在本章中，我们实际上证明了一个微弱版本的理论，用两个隐层的神经网络代替单隐层的神经网络。在以下的我们将要解释的问题中，利用一些小技巧，适合的给出了单隐层的神经网络的证明。</p></li></ul><h2 id="一个输入和一个输出的泛化理论"><a href="#一个输入和一个输出的泛化理论" class="headerlink" title="一个输入和一个输出的泛化理论"></a>一个输入和一个输出的泛化理论</h2><ul><li><p>要理解为什么泛化性理论是可行的，让我们从理解如何构造一个能够逼近函数的只包含一个输入和一个输出的神经网络说起：</p><img src="/img/visual_proof_of_neural_networks/5_network.png" class="[class names]" title="[Neural Network []]"></li><li><p>其实最简单的神经网络(包含一个输入和一个输出)就是泛化性理论的核心。一旦我们能够理解这个简单的网络，那么我们也很容易扩展到其他的(包含多个输入和输出)复杂网络了。</p></li><li><p>想要深入理解如果构造能够计算函数$f$的网络，我们先来构造一个简单的神经网络，包含单个输入，一个包含2个神经元的隐层，单个输出的神经网络：</p></li></ul><img src="/img/visual_proof_of_neural_networks/6_network.png" class="[class names]" title="[Neural Network []]"><ul><li>为了感受一下神经网络中的组件是如何工作的，让我们先看上面的隐层神经元。在下面的图中，用鼠标点击然后拖动来改变权重$w$的值。你就可以立刻看到右边的函数图是如何变化的(原网页才能操作)：<img src="/img/visual_proof_of_neural_networks/7_gif_pic.gif" class="[class names]" title="[Neural Network []]"></li><li>本书的前面讲过，$\sigma(wx+b)$是怎么计算的，其中$\sigma(z)&#x3D;1&#x2F;(1+e^{-z})$就是sigmoid函数。到现在，我们一直频繁的使用这种代数形式进行计算。但是要证明泛化性理论，我们应该忽视这种数学形式，然后通过通过操作和观察以上的图来获得更深的理解。</li><li>要开始证明这个理论，请试着用鼠标点击偏置$b$，然后往右拉来增加它的数值。你会看到增加偏置$b$只会把图像往左移动，而不会改变图像的形状。</li><li>接下来，你试着鼠标往左拉，偏置$b$的数值减小，你会看到图像是往右边移动的，同样的，图像的形状并没有改变。</li><li>然后，我们来改变权重$w$的数值，把它的值改变到2或者3。你会看到减小权重$w$，曲线变得更宽了。你可能需要同时改变一下偏置$b$，以免图像跑出了框内。</li><li>最后，把权重$w$的数值增加到100。你会发现，曲线变得更陡峭了，直到它看起来像一个step函数。可以观察一下下面的小视频：</li></ul><img src="/img/visual_proof_of_neural_networks/8_gif_pic.gif" class="[class names]" title="[Neural Network []]"><ul><li>我们可以通过增加权重$w$直到它变成了一个step函数(逼近的精度越来越高)来简化我们的分析。下面右边的图像是当$w&#x3D;999$时的函数图。</li></ul><img src="/img/visual_proof_of_neural_networks/9_network.png" class="[class names]" title="[Neural Network []]"><ul><li><p>其实step函数比一般的sigmoid函数表现更好。原因是输出层是前面所有的隐层的神经元计算来决定的。去分析一堆step函数的总和是件更容易的事，但是去分析一堆sigmoid函数的曲线计算后的结果就不是一件易事了。而且，把隐层的神经元输出step函数是一件更容易的事情。更确切的说，我们把权重$w$的值调得非常大，这样就可以得到了step函数了。然后通过调整偏置$b$来改变step(跃阶)的位置。当然，把输出当成一个step函数也是一种逼近，而且是一个很好的逼近，而现在我们正是这样做的。我稍后会再讨论这种逼近的求导的影响。</p></li><li><p>当$x$的数值是多少时达到跃阶(step)呢？换一种说法，step的位置是如何由权重$w$和偏置$b$来决定的？</p></li><li><p>要回答这个问题，我们再来试一下改变权重$w$和偏置$b$的数值。你可以弄清楚跃阶(step)和权重$w$与偏置$b$的关系吗？通过不断的观察图像的变化，你可能就会发现，跃阶(step)的位置是和偏置$b$成正比的，和权重$w$成反比的。</p></li><li><p>事实上，跃阶(step)的位置$s$满足$s&#x3D;-b&#x2F;w$.</p><img src="/img/visual_proof_of_neural_networks/10_gif_pic.gif" class="[class names]" title="[Neural Network []]"></li><li><p>这会大大简化了我们的生活，如果我们只是单单利用一个参数$s$来描述隐层的神经元的话。$s$就是跃阶(step)的位置，$s&#x3D;-b&#x2F;w$。</p><img src="/img/visual_proof_of_neural_networks/11_gif_pic.gif" class="[class names]" title="[Neural Network []]"></li><li><p>上面有提到，我们可以偷偷地把输入的权重$w$调到非常大，大到出来的step函数是一个很好的逼近。我们就可以很容易的在传统的模型当中把神经元参数按这样子来调整，偏置$b&#x3D;-ws$.</p></li><li><p>以上我们都是讨论上层神经元。现在我们来讨论一下整个网络。我们假设上层神经元通过step函数参数化跃阶(step)为$s_1$，下层神经元通过step函数参数化跃阶(step)为$s_2$.他们分别有输出权重$w_1$和$w_2$。以下就是网络：</p><img src="/img/visual_proof_of_neural_networks/12_gif_pic.gif" class="[class names]" title="[Neural Network []]"></li><li><p>右上方的图像是输出权重$(w_1a_1+w_2a_2)$的结果。其中$a_1$和$a_2$分别是上层神经元和下层神经元的输出。输出用$a$来表示是因为神经元通常包含一个激活函数(activation)。</p></li><li><p>让我们来看一下$s_1$和$s_2$相遇时会发生什么情况呢？看图：</p><img src="/img/visual_proof_of_neural_networks/13_gif_pic.gif" class="[class names]" title="[Neural Network []]"></li><li><p>可以看到，当我们操作$s_1$时，$S_1$和$s_2$相遇时，$S_1$就会带动$s_2$走。所以，图像的变动，我们也要分是$s_1$先动还是$s_2$先动。</p></li><li><p>$h_t$</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a class=&quot;link&quot;   href=&quot;http://neuralnetworksanddeeplearning.com/chap4.html&quot; &gt;Original Post&lt;i class=&quot;fas fa-external-link-alt&quot;&gt;&lt;</summary>
      
    
    
    
    <category term="机器学习" scheme="http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="Translation" scheme="http://example.com/tags/Translation/"/>
    
  </entry>
  
  <entry>
    <title>循环神经网络 Part 1-简介</title>
    <link href="http://example.com/2017/03/29/RNN-tutorial-Part-1-Introduction/"/>
    <id>http://example.com/2017/03/29/RNN-tutorial-Part-1-Introduction/</id>
    <published>2017-03-29T13:02:30.000Z</published>
    <updated>2023-07-13T04:04:53.593Z</updated>
    
    <content type="html"><![CDATA[<ul><li><p>本文翻自<a class="link"   href="http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/" >WILDML<i class="fas fa-external-link-alt"></i></a></p></li><li><p>循环神经网络(RNNs)是一个目前在许多的自然语言处理(NLP)任务当中表现了出色的性能的模型。但是，除了它最近的火热之外，我能找到的关于RNNs模型的工作原理和实现的资源非常的有限。所以我才着手写了这个tutorial。我分了几个部分来写RNN的tutorial：</p><ol><li>RNNs简介(本tutorial)</li><li>用Python和Theano实现RNN</li><li>理解定时后向传播算法和梯度消失的问题</li><li>实现一个GRU&#x2F;LSTM RNN</li></ol></li><li><p>在本tutorial中我们实现了一个基于语言模型的RNN。这个语言模型应用包括两个部分：第一，它允许我们对一个可能出现在现实当中的抽象句子做一个评分，这个分数可以用来评判句子的语法和语义的准确性。这样的模型是典型的机器翻译系统当中的一个部分。第二，一个语言模型允许我们生成一个新的文本(我认为这是一个非常cool的应用)。在Shakespeare(莎士比亚)文章上训练一个语言模型，它可以生成一个新的类莎士比亚的文本。<a class="link"   href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" >Andrej Karpathy写的贴子<i class="fas fa-external-link-alt"></i></a>很好地阐明了基于RNN的字符level的语言模型能够干什么。</p></li><li><p>我假设你们对于基本的神经网络都熟悉了。如果你们并不熟悉的话，你可以先去看一下这个贴子,<a class="link"   href="http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/" >从零开始实现一个神经网络<i class="fas fa-external-link-alt"></i></a>，它会指导你非RNN背后神经网络的思想和实现。</p></li></ul><h2 id="什么是RNNs"><a href="#什么是RNNs" class="headerlink" title="什么是RNNs?"></a>什么是RNNs?</h2><ul><li><p>RNN的核心思想是利用序列信息。在传统的神经网络中，我们假设所有的inputs和outputs都是彼此独立的。但是在很多的任务当中，这是一个非常不合理的想法。如果你想预测一个句子当中的下一个单词，你最好能知道它前面跟着的是什么单词。RNNs当中的”recurrent”，递归，是因为它对于序列当中的每一个元素都执行了同样的任务，当前的output和之前的计算有依赖关系。RNNs的另一种理解就是它有一个“记忆体”记住了到目前为止所计算的信息。理论上RNNs能够利用任意长序列上的信息，但是实际上它们只是局限于能回看前面几步上的信息(以后会更多)。这就是一个典型的RNN模型图：</p></li><li><p><img src="/img/tf_tutorial/05_RNN/rnn.jpg" title="http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/09/rnn.jpg"></p></li><li><p>上面这张图就是RNN展开成全连接的网络图。展开的意思就是我们把所有的序列写出来。譬如，如果我们关注的序列是包含5个单词的，那么展开的网络图就是5层的网络，每一层对应一个单词。图中的公式参数意义如下：</p><ul><li>$x_t$是在时间$t$时的输入。譬如，$x_1$可以是序列中对应到第二个单词的one_hot向量。($X_0$是第一个)</li><li>$s_t$是在时间$t$时的隐层状态。它是网络的“记忆体”。$s_t$是基于前一个隐层状态和当前的输入计算出来的:</li><li><img src="/img/tf_tutorial/05_RNN/eq1.jpg"> 这个函数f通常是一个非线性函数，如tanh或者ReLU。$s_{-1}$是用来计算第一个隐层的，通常初始化为全0。</li><li>$o_t$是在步骤$t$时的输出。譬如，如果我们想去预测句子当中的下一个单词，结果会是一个概率向量，它对应着我们字典中的每一个单词。$o_t&#x3D;softmax(V*s_t)$</li></ul></li><li><p>以下是一些我们需要注意的地方：</p><ul><li>你可以把$s_t$看作是网络的记忆体。$s_t$捕获了前一步所发生的信息。输出$o_t$是单独基于时间$t$时的记忆算出来的。像以上简单提到的，实际上它有点复杂，因为$s_t$一般不能够捕获太多次之前的信息。</li><li>不想传统的深度学习网络，每一层都用了不同的参数，RNN当中的每一层是共享一组参数的($U,V,W$)。这也说明了我们每一层都是做了相同的操作的，只是每次的inputs不同了。这就大大减少了我们要学习的参数的数量。</li><li>上面的图当中每一层都有一个输出，但是有些任务当中这些输出并不是必须的。譬如，在做句子的情感分析当中，我们可能就是需要最后一个输出而已，而不是每一层的outputs。简单来说，我们不是每一层都需要输入。RNN的主要特点是它的的隐层状态，它捕获了序列当中的一些信息。</li></ul></li></ul><h2 id="RNN能够干什么？"><a href="#RNN能够干什么？" class="headerlink" title="RNN能够干什么？"></a>RNN能够干什么？</h2><ul><li>RNN在许多的自然语言处理(NLP)任务中当中获得非常好的结果。这里我不得不提到的一个常用到的RNN模型就是<a class="link"   href="https://en.wikipedia.org/wiki/Long_short_term_memory" >LSTMs<i class="fas fa-external-link-alt"></i></a>。相比普通的RNN模型，它能更好的捕获到长期的依赖信息。但是不要担心，LSTMs也是我们这个tutorial中的RNN差不多，只是它的隐层状态的计算会有所不同。我们会在下一个贴子当中详解LSTMs。这里我们只是列举一些RNN在NLP当中应用的例子。</li></ul><h2 id="语言建模和生成文本"><a href="#语言建模和生成文本" class="headerlink" title="语言建模和生成文本"></a>语言建模和生成文本</h2><ul><li>给定一个序列的单词，我们要预测当给定前一个单词时，下一个单词会出现的概率。语言模型会让我们评判一个什么序列的单词如何才可能是一个句子。这也是机器翻译当中的一个重要的输入(通常概率高的句子都是正确的)。预测下一个单词的另一个作用是我们会得到一个生成模型，这个模型可以通过从输出概率当中进行采样来生成新的文本。利用我们的训练数据，我们可以生成各种各样的单词序列。在语言模型当中，我们的输入通常是一个单词的序列(譬如加密成一个one-hot向量)，然后我们的输出就是预测的单词的序列。当我们训练网络时，我们把$o_t&#x3D;x_{t+1}$，因为我们希望时间$t$时的输出是真实的下一个单词。</li><li>语言模型和生成文本的相关论文：<ul><li><a class="link"   href="http://www.fit.vutbr.cz/research/groups/speech/publi/2010/mikolov_interspeech2010_IS100722.pdf" >Recurrent neural network based language model<i class="fas fa-external-link-alt"></i></a></li><li><a class="link"   href="http://www.fit.vutbr.cz/research/groups/speech/publi/2011/mikolov_icassp2011_5528.pdf" >Extensions of Recurrent neural network based language model<i class="fas fa-external-link-alt"></i></a></li><li><a class="link"   href="http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Sutskever_524.pdf" >Generating Text with Recurrent Neural Networks<i class="fas fa-external-link-alt"></i></a></li></ul></li></ul><h2 id="机器翻译"><a href="#机器翻译" class="headerlink" title="机器翻译"></a>机器翻译</h2><ul><li>机器模型和语言模型非常的相似，它的输入也是一种语种的单词序列(譬如德语)。我们想要输出的是目标语种的单词序列(譬如英语)。一个主要的不同就是我们的输出是当所有的输入都计算过了才开始的，因为我们翻译的句子中的第一个单词是需要所有的输入序列的信息才能确定的。</li><li><img src="/img/tf_tutorial/05_RNN/RNN_for_machine_translation.png" title="RNN for Machine Translation. Image Source: http://cs224d.stanford.edu/lectures/CS224d-Lecture8.pdf"></li><li>机器翻译的相关论文：<ul><li><a class="link"   href="http://www.aclweb.org/anthology/P14-1140.pdf" >A Recursive Recurrent Neural Network for Statistical Machine Translation<i class="fas fa-external-link-alt"></i></a></li><li><a class="link"   href="http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf" >Sequence to Sequence Learning with Neural Networks<i class="fas fa-external-link-alt"></i></a></li><li><a class="link"   href="http://research.microsoft.com/en-us/um/people/gzweig/Pubs/EMNLP2013RNNMT.pdf" >Joint Language and Translation Modeling with Recurrent Neural Networks<i class="fas fa-external-link-alt"></i></a></li></ul></li></ul><h2 id="语音识别"><a href="#语音识别" class="headerlink" title="语音识别"></a>语音识别</h2><ul><li>给定一个从声波中得到的声学信号的输入序列，我们能够利用它们的概率来预测一个序列的语音片段。</li><li>语音识别的相关论文：<ul><li><a class="link"   href="http://www.jmlr.org/proceedings/papers/v32/graves14.pdf" >Towards End-to-End Speech Recognition with Recurrent Neural Networks<i class="fas fa-external-link-alt"></i></a></li></ul></li></ul><h2 id="生成图片描述"><a href="#生成图片描述" class="headerlink" title="生成图片描述"></a>生成图片描述</h2><ul><li>结合卷积神经网络(CNN)和RNN的模型能够对没标签的图片生成描述。这是一个非常惊人的工作。这个组合模型还能把图片当中找到的特征和生成的单词一一对应。</li><li><img src="/img/tf_tutorial/05_RNN/cnn-rnn.png" title="Deep Visual-Semantic Alignments for Generating Image Descriptions. Source: http://cs.stanford.edu/people/karpathy/deepimagesent/"></li></ul><h2 id="训练RNNs"><a href="#训练RNNs" class="headerlink" title="训练RNNs"></a>训练RNNs</h2><ul><li>训练RNN和训练传统的神经网络很相似。我们也用到后向传播(backpropagtion)算法，但是有小小不同。因为参数在整个网络中的每一层是共享的，而每一层输出的梯度不仅仅依赖于当前这一步的计算，还依赖前一步的计算。譬如，为了计算$t&#x3D;4$时的梯度，我们需要往后传播3层，并且把它们的梯度加起来。这就是定时后向传播(BPTT)。如果这还是没有那么清晰的话，不要担心，我们之后还会有更多的详情。现在，我们要注意到用BPTT来训练普通的RNNs，因为梯度消失的问题，所以很难学习到长期的依赖信息(譬如，每一层之间的信息相差甚远)。但还是有一些模型来解决这个问题的，像特定的RNNs模型(LSTMs)就是特别设计用来解决这些问题的。</li></ul><h2 id="RNNs扩展"><a href="#RNNs扩展" class="headerlink" title="RNNs扩展"></a>RNNs扩展</h2><ul><li>经过研究者们那么多年的研究，他们已经发展了更为复杂的RNNs模型来解决普通的RNN模型的一些不足。我们接下来的贴子会讲到更多的细节，但是我想在本部分中做一个简单的总结，这样我们才能对RNNs模型的分类更为熟悉。</li><li>**双向RNNs(Bidirectional RNNs)**就是基于这样的思想：时间$t$的输出可能不仅仅依赖鱼序列当中的前面的元素，还包括了未来的元素。譬如，预测一个序列当中的缺失的单词，你可能要看到前面和后边的内容。双向RNNs非常容易。他们就是把两个RNNs堆叠在一起。输出是基于两个RNNs模型的隐层计算得到的。</li><li><img src="/img/tf_tutorial/05_RNN/bidirectional-rnn.png"></li><li><strong>深度(Bidirectional)RNNs</strong>和双向RNNs很相似，就是我们现在每一个时间点有多层。实际上这给了我们一个更高的学习容量(但是我们也需要大量的训练数据)。</li><li><img src="/img/tf_tutorial/05_RNN/deep-bi-rnn.png"></li><li><strong>LSTM网络</strong>现在非常流行。LSTMs和RNNs在架构上没什么大的不同，但是它们利用了不同的函数来计算隐层状态。LSTMs中的记忆体叫做<strong>cells</strong>，你可以把它们当成一个黑盒子，它吃进了前一个状态$h_{t-1}$和当前的输入$x_t$。这些cells内部决定哪些应该保持，哪些应该删除。然后它们就会合并前一个状态，当前状态和当前的输入。结果证明了这类型的units非常有效地捕获了长期的依赖信息。LSTMs一开始可能很疑惑，但是如果你感兴趣的话，可以读一下<a class="link"   href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" >这篇详细的解释<i class="fas fa-external-link-alt"></i></a>。</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>目前还是理解的不错的。我希望你现在对RNNs已有了一个基本的理解。在下一个贴子中我们会利用Python和Theano实现我们RNN语言模型的第一个版本，请在留言区留下你的问题。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;&lt;p&gt;本文翻自&lt;a class=&quot;link&quot;   href=&quot;http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/&quot; &gt;WILD</summary>
      
    
    
    
    <category term="机器学习" scheme="http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="Translation" scheme="http://example.com/tags/Translation/"/>
    
    <category term="ML" scheme="http://example.com/tags/ML/"/>
    
    <category term="DL" scheme="http://example.com/tags/DL/"/>
    
  </entry>
  
  <entry>
    <title>40 道ML/Data Science的初创公司(可能)的面试题</title>
    <link href="http://example.com/2016/10/03/40/"/>
    <id>http://example.com/2016/10/03/40/</id>
    <published>2016-10-03T08:19:38.000Z</published>
    <updated>2023-07-13T03:47:55.242Z</updated>
    
    <content type="html"><![CDATA[<ul><li>By Manish Saraswat, <a class="link"   href="https://www.analyticsvidhya.com/blog/2016/09/40-interview-questions-asked-at-startups-in-machine-learning-data-science/" >Original Link<i class="fas fa-external-link-alt"></i></a></li><li>09&#x2F;16&#x2F;2016</li></ul><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><blockquote><p><b><font color="red">留心，这些问题你要三思！</font></b></p></blockquote><ul><li>在今天，机器学习和数据科学家被认为是下一代工业改革的驱动力。这也意味着有很多新进的初创公司在寻找数据科学家。那么，该如何给你振奋人心的职业生涯一个更好的开始呢？</li><li>当然，想进入这个行业并不容易。显然你必须要对公司的理念，团队和远景感兴趣。你可能在你的职业之路上遇到一写很棘手的技术问题。本题集和初创公司做的东西有紧密联系。他们会不会提供咨询？他们会不会创建ML产品？你在面试之前就该提前考虑这个问题？</li><li>为了帮助你准备下一场面试，我整理了40个看似可信但是其中暗藏端倪的问题，它们都有可能出现在你的面试当中。如果你能够轻松应对并且深刻理解问题，那么请放心，你可以在面试中打一场硬仗。</li><li>备注：轻松应对这些问题的核心是你对ML有实际操作经验和了解相关的统计概念。</li></ul><h2 id="机器学习的面试问题"><a href="#机器学习的面试问题" class="headerlink" title="机器学习的面试问题"></a>机器学习的面试问题</h2><ul><li><p><b><font color="blue"> Q1，给你一个1000列，100万行的数据集。这个数据集是一个分类问题。你经理要求你减少这个数据集的维度以减少模型计算所花的时间。你的机器有内存限制。你会怎么做？(你可以做出实际的假设)</font></b></p></li><li><p><b>答：</b>在一台内存有限的机器上处理高纬度的数据是一个很费力的任务，你的面试官肯定意识到这一点。以下是你可以拿来应对的方法：</p><ol><li>由于我们的内存有限，我们首先应该关闭所有不需要的程序，包括浏览器，这样我们才能把内存的利用最大化。</li><li>我们可以随机对数据集进行抽样。这就意味着我们可以创建一个更小的数据集，假如，1000个变量，30万行的数据集，然后做计算。</li><li>要减少维度，我们可以把数值型和分类型的变量分开，然后去掉相关的变量。对于数值型数据，我们利用相关性分析，对于分类型数据，我们利用卡方检验。</li><li>另外，我们可以做PCA，然后挑出数据集中能够解释最大方差的变量。</li><li>利用在线学习算法，像Vowpal Wabbit (Python提供)，也是一个选择。</li><li>利用随机梯度下降来创建一个线性模型也是有帮助的。</li><li>我们也可以把数据集的商业理解考虑进去，然后估计哪些predictors能够影响respone variable。但是这是一个凭直觉的方法，如果分析错误就会造成信息的损失。</li></ol></li><li><p><b>备注：</b>对于第4，5点，请务必了解在线算法和随机梯度下降算法。另外还有更高级的算法。</p></li><li><p><b><font color="blue"> Q2， PCA中的旋转是必须的吗？如果是，那么你没有旋转的话，会发生什么？</font></b></p></li><li><p><b>答：</b>是的，旋转(正交直线)是必须的，因为它能最大化捕捉到的变量之间的差异。这会使变量更容易解释。不要忘记，这确切是PCA的动机所在，我们的目标是选择更少的components，这些变量能够解释数据集的最大方差。通过旋转，components的相关位置不会改变，她仅仅改变这些点的实际坐标。</p></li><li><p>如果我们没有进行旋转，PCA的作用就会减少，而我们需要选择更多的components来解释数据集的方差。</p></li><li><p>了解更多：<a class="link"   href="https://www.analyticsvidhya.com/blog/2016/03/practical-guide-principal-component-analysis-python/" >PCA<i class="fas fa-external-link-alt"></i></a></p></li><li><p><b><font color="blue"> Q3，给你一个数据集，这个数据集包含这样的缺失值，它的分布是沿着中位数，标准差是1。那么，有百分之几的数据不受影响？为什么呢？</font></b></p></li><li><p><b>答：</b>这道题有足够的提示让你思考。由于数据是沿着中位数分布的，我们假设它是一个正态分布。我们知道在一个正态分布中，68%的数据包含在均值(或者众数，中位数)为中心1为标准差的范围内，那么就有32%的数据是不受影响的。所以，32%的数据将会不受缺失值的影响。</p></li><li><p><b><font color="blue"> Q4，给你一个癌症检测的数据，你建了一个分类模型并且模型的准确率达到了96%。为什么你不能对你模型的表现感到满意？你会怎么做？</font></b></p></li><li><p><b>答：</b>如果你处理了足够多的数据集，你可以推断癌症检测造成了不平衡的数据。在一个不平衡的数据集中，准确率不应该被当作表现的衡量标准，因为96%仅仅是预测对了大多数的类别，但是我们感兴趣的类别是小部分的4%，它恰恰是被用来用作癌症的诊断。所以，为了评估模型的表现，我们应该利用Sensitivity(True Positive Rate)，Specificity(True Negative Rate)，F measure用来诊断分类器的性能。如果小部分的分类性能是很无力的，我们可以采取一下的措施：</p><ol><li>我们可以利用欠采样，过采样或者SMOTE(一种采样技术)使得数据平衡。</li><li>我们可以通过概率校正来改变预测阈值，然后利用AUC-ROC曲线找到一个最优的阈值。</li><li>我们可以给类别赋予权重，让小部分的类别得到更大的权重。</li><li>我们可以做异常检测。</li></ol></li><li><p><b>了解更多：</b><a class="link"   href="https://www.analyticsvidhya.com/blog/2016/03/practical-guide-deal-imbalanced-classification-problems/" >Imbalanced Classification<i class="fas fa-external-link-alt"></i></a></p></li><li><p><b><font color="blue"> Q5，为什么朴素贝叶斯那么“朴素”？</font></b></p></li><li><p><b>答：</b>朴素贝叶斯“朴素”是因为它假设了数据集中的特征都是平等重要且相互独立的。我们知道，这些假设在现实生活中存在的几率是很小的。</p></li><li><p><b><font color="blue"> Q6，解释朴素贝叶斯中的概念：先验概率，似然和边缘似然。</font></b></p></li><li><p><b>答：</b>先验概率就是数据集中独立(二分类)变量的比重，就是一个最简单的分类。譬如，一个数据集中，独立变量是二分类的(0或者1)。1(垃圾邮件)的比重是70%，0(正常邮件)的比重是30%。所以，我们可以估计新邮件有70%的几率被分作垃圾邮件。</p></li><li><p>似然就是给定的观测量在其他变量的条件下被分作1的概率。譬如，在之前的垃圾邮件中“FREE”这个词的概率就是似然。边缘似然就是，“FREE”这个词被用在任何信息当中的概率。</p></li><li><p><b><font color="blue"> Q7，你正在处理一个时间序列的数据集。你经理要求你创建一个高准确率的模型。你一开始就用决策树算法，因为你知道它对任意类型的数据都处理得不错。然后，你试了一个时间序列的回归模型并且得到了更高的准确率。这会发生吗？为什么呢？</font></b></p></li><li><p><b>答：</b>时间序列数据是受线性限制的。另一方面，我们知道决策树算法是适用于检测非线性的交互。决策树不能很好地提供robust的预测是因为它没有像线性模型那样能很好地map到数据的线性关系。所以，我们知道，线性回归模型可以对给定的线性数据提供更robust的预测。</p></li><li><p><b><font color="blue"> Q8，你被分配了一个新的project，这个project是帮助某公司的食物派送减低成本的。问题是：公司的派送团队没能及时地派送食物，结果，顾客就不开心。然后为了让驳回顾客的芳心，公司最后决定免派送费。你认为哪一个机器学习方法能够拯救他们呢？</font></b></p></li><li><p><b>答：</b>你可能很快的在脑海中扫描了一遍机器学习算法。但是，请放松一下，这个问题考的是你的机器学习的基础。</p></li><li><p>这不是一个机器学习的问题。这是一个路径优化的问题。一个机器学习的算法包括三个基本要素：</p><ol><li>问题中存在一个模式</li><li>你不能通过数学计算来解决它(即使是写指数方程)</li><li>你要有数据</li></ol></li><li><p>我们通常找出这三个要素来决定是否能把机器学习当成一个解决实际问题的工具。</p></li><li><p><b><font color="blue"> Q9，你发现你的模型出现了低偏差高方差的问题，你应该怎么解决？为什么呢？</font></b></p></li><li><p><b>答：</b>低偏差说明模型的预测值非常接近真实值。换句话说，这个模型能够很灵活地模仿到训练数据分布。看似这是很成功，但是不要忘记，一个灵活的模型往往没有泛化能力。这意味着，当模型对新数据进行预测时，它可能会给出很差的结果。</p></li><li><p>这样的话，我们可以利用bagging算法(譬如随机森林)来解决高方差的问题。Bagging算法通过重复的随机采样把数据集分成很多个子集。然后，用这些样本来做不同的算法得到一个模型的集合。之后，最终的预测是对模型集中的模型进行不同的组合，分类的话就用投票的方式，回归的话就用求均值的方式。</p></li><li><p>另外，为了防止高方差，我们可以：</p><ol><li>利用正则化技术，对模型的高系数进行惩罚，从而降低模型的复杂度</li><li>对特征的重要性进行排序然后利用前n个。因为，如果全部的特征都用上，算法可能没办法很好地找到有意义的信号。</li></ol></li><li><p><b><font color="blue"> Q10，给你一个数据集，它包含了很多变量，但是你已经知道其中的一些有很高的关联性变量了。你的经理要求你利用PCA进行处理。你会先把有关联性的变量删掉吗？为什么呢？</font></b></p></li><li><p><b>答：</b>可能你会说NO，但是这是不对的。抛开有关联性的数据对PCA有实质的影响不说，如果没有删掉有关联性的变量，那么一个特定的成分的方差就会膨胀。</p></li><li><p>譬如，你有3个变量的数据集，其中2个是有关联性的。如果你对数据进行PCA处理，那么第一个主要的成分就会展示2倍的方差，比没有关联性变量存在的时候。另外，添加有关联性的变量会使得PCA把更多的重要性给以它们，这恰恰是误导的。</p></li><li><p><b><font color="blue"> Q11，运行了几个小时之后，你很焦急想要创建一个准确率高的模型。结果，你建了一个5GB的模型集合，考虑到一个boosting算法会产生奇迹。但是，很不幸的，没有一个模型的表现能比基准分(benchmark score)更好。最后，你决定组合这些模型。我们都知道ensemble模型都会得到很高的准确率，但是你的却没有。请问到底是哪里出了问题呢？</font></b></p></li><li><p><b>答：</b>总所周知，ensemble learners的核心思想是通过组合简单的弱模型来得到一个强模型。但是当模型之间是独立的时候，组合出来的模型才会表现得很好。所以，我们建立了5GB的模型集合，但是准确率却没有提升，这就暗示着模型之间是有关联性的。有关联性的模型的问题是它们都提供了相同的信息。</p></li><li><p>譬如，如果模型1，2，3都是关联的，那么当模型1把User122分类为1时，模型2和模型3也会得到同样的分类结果，即使它的真实值是0。所以，ensemble learners是建立在没有关联性的弱模型集合的基础上，这样的组合才能得到更好的predictions。</p></li><li><p><b><font color="blue"> Q12，kNN和kmeans聚类有什么不同？</font></b></p></li><li><p><b>答：</b>不要给名字中的k误导了。你应该知道这两个算法之间最基本的不同是：kmeans是一个无监督学习方法而kNN是一个有监督的学习方法。kNN是一个分类(或者回归)的方法。</p></li><li><p>kmeans算法是对一个数据集进行划分以至于组成有同质性族群，其中的点与点之间的距离是相近的。这个算法尽量保持这些族群之间的可划分性。而无监督的学习方法中的族群是没有标签的。</p></li><li><p>kNN算法试着对没有标签的数据按临近的距离进行k(k可以是任何小于sample的数)分类。它又被称作懒惰学习方法因为它涉及到模型的最小训练集。所以，它不会用训练数据对新的数据进行泛化。</p></li><li><p><b><font color="blue"> Q13，True Positive Rate和Recall是什么关系？写出公式。</font></b></p></li><li><p><b>答：</b>True Positive Rate &#x3D; Recall。是的，它们有相同的公式(TP&#x2F;(TP+FN))。</p></li><li><p><b>了解更多：</b><a class="link"   href="https://www.analyticsvidhya.com/blog/2016/02/7-important-model-evaluation-error-metrics/" >Evaluation Metrics<i class="fas fa-external-link-alt"></i></a></p></li><li><p><b><font color="blue"> Q14，你建立了一个多重回归模型。模型的R方并没有你预期的那么好。为了改进，你去掉了截距，模型的R方由原来的0.3升到了0.8。请问这是可能的吗？是如何做到的？</font></b></p></li><li><p><b>答：</b>是的，是有可能的。我们需要理解截距在回归模型中的重要性。截距说明模型的预测是没有任何的独立变量的，如预测的均值。公式：R² &#x3D; 1 – ∑(y – y´)²&#x2F;∑(y – ymean)²，其中y´ 是预测值。</p></li><li><p>当截距存在的时候，R方值把模型的wrt评估到均值模型当中。当截距不存在的时候，模型就不会这样做。巨大的分母∑(y - y´)²&#x2F;∑(y)²就把等式的值变得比实际的要小，然后造成了高的R方。</p></li><li><p><b><font color="blue"> Q15，分析了模型之后，你的经理得知你的模型有多重共线性。你会怎么验证模型？没有信息的流失，你可以建立一个更好的模型吗？</font></b></p></li><li><p><b>答：</b>要检查多重共线性，我们可以创建一个相关系数矩阵来辨识或者删除相关系数达到75%的变量(这个阈值的设置是主观的)。另外，我们可以计算方差膨胀因子(Variance Inflation Factor)来检查多重共线性。 VIF的值&lt;&#x3D;4意味着没有多重共线性，VIF的值&gt;&#x3D;10预示着有严重的多重共线性。最后，我们还可以利用公差来判断多重共线性的出现与否。</p></li><li><p>但是删除相关变量可能导致信息流失。为了保持变量，我们可以用惩罚性回归模型，像lasso回归或者ridge回归。还有，我们可以加入一些随机噪声变量到相关变量当中，这样变量间就会变得不同。但是，加入噪声可能影响预测准确率。所以，这个方法也要小心使用。</p></li><li><p><b>了解更多：</b><a class="link"   href="https://www.analyticsvidhya.com/blog/2016/07/deeper-regression-analysis-assumptions-plots-solutions/" >Regression<i class="fas fa-external-link-alt"></i></a></p></li><li><p><b><font color="blue"> Q16，什么时候Ridge回归比Lasso回归更好用？</font></b></p></li><li><p><b>答：</b>你可以引用ISLR这本书的作者Hastie Tibshirani的话，他说：In presence of few variables with medium&#x2F; large sized effect, use lasso regression. In presence of many variables with small&#x2F; medium size effect, use ridge regression.</p></li><li><p>理论上说，lasso回归(L1)既做了变量选择也做了参数的收缩，而Ridge回归(L2)只是做了参数的收缩，最后把所有的系数都会算进了模型中。当存在相关变量时，ridge回归回事更好的选择。而且，ridge回归在最小二乘因子有比较高的方差时表现最好。所以，她取决于模型的客观性。</p></li><li><p><b>了解更多：</b><a class="link"   href="https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-ridge-lasso-regression-python/" >Ridge and Lasso Regression<i class="fas fa-external-link-alt"></i></a></p></li><li><p><b><font color="blue"> Q17，全球平均气温的提升导致了海盗数量的减少。那么我们可以说海盗数量的减少造成了全球气温的变化吗？</font></b></p></li><li><p><b>答：</b>读完题目后，你应该这就是典型的“因果与相关”的问题。不，我们不能得出海盗数量的减少造成了气温的改变，因为可能是其他因素(潜伏或者混淆的变量)影响着气候。</p></li><li><p>所以，或许全球平均气温和海盗数量有一定的关系，但是基于这样的信息我们不能说海盗减少是因为全球平均气温的升高。</p></li><li><p><b>了解更多：</b><a class="link"   href="https://www.analyticsvidhya.com/blog/2015/06/establish-causality-events/" >Causation and Correlation<i class="fas fa-external-link-alt"></i></a></p></li><li><p><b><font color="blue"> Q18，在处理数据的时候，如何选择重要的变量？请解释你的方法。</font></b></p></li><li><p><b>答：</b>以下是一些常用的变量选择方法：</p><ol><li>在选择重要变量之前，先把有相关性的变量删掉</li><li>利用线性回归基于P值选择变量</li><li>利用前向选择，后向选择和逐步选择法</li><li>利用随机森林，Xgboost或者对变量的重要性列表</li><li>利用Lasso回归</li><li>对所有变量做信息增益，然后选择前n个特征</li></ol></li><li><p><b><font color="blue"> Q19，相关性系数和方差有什么不同？</font></b></p></li><li><p><b>答：</b>相关性系数是协方差的标准形式。</p></li><li><p>协方差不容易进行比较。譬如，如果我们计算了工资和年龄的协方差，我们不能把他们进行比较，因为他们之间的scales不一样。为了解决这个情况，我们计算相关性系数，得到一个在-1和1之间的数值，就不用考虑它们之间不同的scales了。</p></li><li><p><b><font color="blue"> Q20，有没有可能求连续变量和分类变量之间的相关性系数吗？如果可以，怎么做？</font></b></p></li><li><p><b>答：</b>是的，我们可以利用ANCOVA(协方差分析)技术来获得连续性和分类变量之间的相关性系数。</p></li><li><p><b><font color="blue"> Q21，同样是基于树的算法，随机森林和梯度提升算法(GBM)之间有什么不同？</font></b></p></li><li><p><b>答：</b>最基本的不同是，随机森林利用bagging技术来做预测，GBM是用boosting技术来做预测。</p></li><li><p>在bagging技术当中，一个额数据集被随机抽样法分成了n个样本。之后利用单个学习方法对所有的样本进行建模。之后，最终的预测结果是通过对多个模型的预测值进行投票或者求均值的方法得到的。bagging是并行化的。在boosting当中，在第一轮的模型进行预测之后，这个算法就会把误分类模型的权值加大，这样就可以在随后的建模过程中对模型进行修正。这种顺序性的过程直到最后的预测值满足停止标准值为止。</p></li><li><p>随机森林通过减低方差改善了模型的准确率。树的生长和最大化方差的降幅没有关系。另外，GBM同时减低了bias和方差来改善模型的准确率。</p></li><li><p><b>了解更多：</b><a class="link"   href="https://www.analyticsvidhya.com/blog/2016/04/complete-tutorial-tree-based-modeling-scratch-in-python/" >Tree based modeling<i class="fas fa-external-link-alt"></i></a></p></li><li><p><b><font color="blue"> Q22，运行一个二分类树算法并不难。那你知道树是如何分割的吗？譬如，树是如何决定哪一个结点作为根节点，哪一个结点作为后继节点的吗？</font></b></p></li><li><p><b>答：</b>一个分类树的生成是基于基尼系数和结点的熵。简单的说，树算法会找到最适合把数据集划分成子节点的变量。</p></li><li><p>基尼系数是说，如果我们随机选择了两个群体，那么它们必须是属于同一类的，然后概率和为1。我们可以这样来计算基尼系数：</p><ol><li>计算子节点的基尼系数，用概率的成功和失败的平方和公式： (p^2+q^2)。</li><li>利用每个分割节点的权重基尼得分计算它们的基尼系数</li></ol></li><li><p>熵是衡量混乱程度的标准，即是否更适合分割：</p></li><li><p>这里的p和q分别代表节点成功和失败的概率。熵是0当一个节点是同质的时候。它最大的时候是当一个节点的两个分类各占50%。我们要求小的熵。</p></li><li><p><b><font color="blue"> Q23，你利用1000棵树建立了一个随机森林。你非常高兴因为你得到了训练错误率是0。但是，验证错误率是34.23。发生了什么事了？你训练的模型完美吗？</font></b></p></li><li><p><b>答：</b>这个模型是过拟合了。训练错误率是0意味着分类器在某程度上很好的拟合了你的训练数据，但是它对未知数据的预测性很差。所以，当我们用这个分类器来预测新数据时，它找不到新数据的模式并且返回了很高的错误率。在随机森林中，当我们用了超过了我们所需要的树时就会发生这种情况。所以，为了避免这种问题，我们就要用交叉验证来调节树的数量。</p></li><li><p><b><font color="blue"> Q24，你得到了一个数据集，他的变量数p&gt;样本数n。为什么OLS是一个不好的方法？你应该用什么技术来解决，为什么呢？</font></b></p></li><li><p><b>答：</b>在如此高纬度的数据集中，我们不可以利用经典的回归技术，因为假设都会失败。当p&gt;n时，我们不能计算一个最小二乘系数了，变量是非常大的时候，OSL就不可行了。</p></li><li><p>为了解决这种情况，我们可以利用惩罚性回归方法，像lasso，LARS，ridge这些能够收缩系数的方法来减少变量。更准确的说，ridge回归表现最好，当最小二乘因子有高方差的时候。</p></li><li><p>其它的方法还有取子集回归，前向逐步回归。</p></li><li><p><b><font color="blue"> Q25，什么是凸多边形(convex hull)？(思考一下SVM)</font></b></p></li><li><p><b>答：</b>在可分割的数据中，convex hull就是两组数据点的边界部分。一旦convex hull创建了，我们就可以得到最大边界超平面(MMH)，它是两个convex hulls之间的垂直平分线。MMH是一条能最大化的分割两组数据的直线。</p></li><li><p><b><font color="blue"> Q26，我们知道一位热编码会增加数据集的维度。但是，标签编码却不会，为什么呢？</font></b></p></li><li><p><b>答：</b>不要给这个问题给搞混了。它只是问你两个编码之间的差别。</p></li><li><p>利用一位热编码，数据集的维度(变量)就会增加因为它为分类变量的每一个level表现创建了一个新的变量。譬如，一个变量叫“颜色”。这个变量有3个level，红，蓝和绿。一位热编码就会产生3个新的变量<b>Color.Red, Color.Blue, Color.Green</b>，然后它们的值包含0和1。</p></li><li><p>在类标签编码中，分类变量被编成0和1，所以没有产生新的变量。类标签编码通常用在二分类变量当中。</p></li><li><p><b><font color="blue"> Q27，在时间序列的数据集中，你会用哪一种交叉验证方法，k折叠还是留一验证？</font></b></p></li><li><p><b>答：</b>都不是。</p></li><li><p>在时间序列问题中，k折叠会产生问题，因为可能有些模式在第4年和第5年中，但是没有在第3年中。重采样会分离这些，然后我们可以用去年来做验证，这是不对的。但是我们可以用5-fold的正向推理策略：</p><ul><li>fold 1: training [1], test[2]</li><li>fold 2: training[1,2], test[3]</li><li>fold 3: training[1,2,3], test[4]</li><li>fold 4: training[1,2,3,4], test[5]</li><li>fold 5: training[1,2,3,4,5], test[6]</li></ul></li><li><p>1,2,3,4,5,6代表年。</p></li><li><p><b><font color="blue"> Q28，给你一个数据集，但是它包含了缺失值的变量，且缺失值占了超过30%，譬如，50个变量，有8个变量的缺失值超过了30%。你会怎么处理？</font></b></p></li><li><p><b>答：</b>我们可以做以下处理：</p><ol><li>给缺失值赋一个唯一分类值，谁知道缺失值会不会破译一些趋势呢</li><li>我们可以直接删掉它们</li><li>或者，我们可以根据目标变量检查它们的分布，如果我们能找到模式，那么我们就赋于缺失值一个新的分类，否则就删掉它们。</li></ol></li><li><p><b><font color="blue"> Q29，亚马逊上的“浏览此商品的顾客也同时浏览。。。”这个推荐系统是什么算法的结果？</font></b></p></li><li><p><b>答：</b>推荐系统的核心思想是协同过滤。</p></li><li><p>协同过滤算法是通过用户行为来推荐物品。它是通过物品的交易记录，评价，选择以及购买信息来挖掘其他用户的行为。其他用户对物品的行为和爱好被用来当作给新用户推荐的依据。这个例子中，物品的特征是不知道的。</p></li><li><p><b>了解更多：</b><a class="link"   href="https://www.analyticsvidhya.com/blog/2015/10/recommendation-engines/" >Recommender System<i class="fas fa-external-link-alt"></i></a></p></li><li><p><b><font color="blue"> Q30，你怎么理解Type one and Type two error ?</font></b></p></li><li><p><b>答：</b>Type I error 是指统计学中的一类错误，意思是本来是错误的结论却被接受了。TypeII error 是指统计学中的二类错误，也就是本来是正确的错误却被拒绝了。简而言之，就是存伪和弃真。</p></li><li><p>在混淆矩阵当中，我们可以说Type I error就是当我们把实际的0预测分类为1，Type II error就是当我们把实际的1预测分类为0.</p></li><li><p><b><font color="blue"> Q31，你正在做一个分类的问题。为了达到验证的目标，你随机的从训练集抽样分为训练集和验证集。你对你的模型的泛化能力很有信心因为它的验证错误率非常高。但是，结果却是十分失望，你的测试准确率很低。到底是怎么了？</font></b></p></li><li><p><b>答：</b>在分类问题当中，我们应该常常用分层抽样而不是随机抽样。因为随机抽样并没有考虑到目标类别的比例。相反，分层抽样就会保证目标变量的分布也会保证样本的分布。</p></li><li><p><b><font color="blue"> Q32，你被要求利用R², adjusted R² 和tolerance来对回归模型进行评价。你会用哪一个作为标准？</font></b></p></li><li><p><b>答：</b>Tolerance(1 &#x2F; VIF)是用作多重共线性的预示。它是衡量一个预测中的变量的百分比不能给另一个预测占据的程度。Tolerance越大越好。</p></li><li><p>我们认为adjusted R² 和R² 来评估模型是截然不同的，因为当我们增加变量的时候，无论预测准确率有没有改进，R²都会增加 。但是adjusted R²仅仅是在增加变量而提高了模型的准确率的时候才会增加。很难去确定adjusted R²的通常值，因为它会随着数据的不同而不同。譬如，基因变异数据集中，低的adjusted R²值的模型依然会有比较不错的预测能力，但是对比于股票数据，低的adjusted R²值就会得到不好的模型。</p></li><li><p><b><font color="blue"> Q33，在k-means或者kNN中，我们计算相近点之间的距离是用欧几里得距离，为什么我们不用曼哈顿距离呢？</font></b></p></li><li><p><b>答：</b>我们不用曼哈顿距离是因为它真能垂直计算或者平行计算距离，它有维度限制。另外，欧几里得距离是用在任意空间当中计算的。因为，数据是可以表示在任何的维度空间当中的，所以欧几里得距离是更好的选择。</p></li><li><p>譬如，在一个棋盘上，象和车的移动就是通过曼哈顿距离来计算的，因为他们只能垂直做或者平行的移动。</p></li><li><p><b><font color="blue"> Q34，像一个5岁的孩子来介绍一下机器学习。</font></b></p></li><li><p><b>答：</b>非常简单。就像宝宝学走路一样。每一次的跌倒，他们都会无意识地学习并且意识到他们下一次就应该挺直的走而不是弯下来走。当下一次他们跌倒，他们会感到疼，他们会哭，但是，他们就不会再那样走了。为了避免疼痛，他们会更努力尝试。为了成功，他们会借助门后或者墙的力量或者任何接近他们的东西，这样他们就会站的更稳。</p></li><li><p>这是机器如何从它的周围环境学习和发展直觉的过程。</p></li><li><p>注：这道面试题就是考你能不能很好把复杂的文件简单化解释一下。</p></li><li><p><b><font color="blue"> Q35，我知道一个线性回归通常是用adjusted R²或者F值来评估的。那你如何评估一个罗吉斯特回归模型呢？</font></b></p></li><li><p><b>答：</b>我们可以用以下方法：</p><ol><li>因为逻辑斯特回归是用来预测概率的，我们可以用混淆矩阵的AUC-ROC曲线来评估它的性能。</li><li>另外，逻辑斯特回归当中类似adjusted R²的评估标准是AIC。AIC是通过模型系数的数量来惩罚模型的拟合标准。所以，我们要的是有最小AIC值的模型。</li><li>空异常(Null Deviance)说明模型仅仅通过截距来预测。数值越小，模型越好。残差(Residual deviance)说明模型添加了独立变量来进行预测的。数值越小，模型越好。</li></ol></li><li><p><b>了解更多：</b><a class="link"   href="https://www.analyticsvidhya.com/blog/2015/11/beginners-guide-on-logistic-regression-in-r/" >Logistic Regression<i class="fas fa-external-link-alt"></i></a></p></li><li><p><b><font color="blue"> Q36，有那么多的机器学习方法，给你一个数据集，你会决定用什么方法呢？</font></b></p></li><li><p><b>答：</b>你应该说，选择用哪一种机器学习方法取决于数据的类型。如果给你的数据集是一个线性的，那么线性回归算法最适合。如果你处理的是图像，语音数据，那么神经网络可以建一个更稳固的模型。</p></li><li><p>如果数据包含一些非线性的关系，那么boosting或者bagging算法就是一个选择。如果商业需求是建一个能够发布的模型，那么我们会用回归或者决策树模型(容易解释)而不是一些黑箱的方法，像SVM，GBM等等。</p></li><li><p>简单来说，没有绝对的方法，我们应该要认真的理解我们要用的算法。</p></li><li><p><b><font color="blue"> Q37，你认为把分类变量当成连续的变量来处理，会使得预测模型更好吗？</font></b></p></li><li><p><b>答：</b>为了得到更准确的预测，分类变量只有在它是有序的时候才被当成连续的变量，这样才合理。</p></li><li><p><b><font color="blue"> Q38，在机器学习当中，什么时候用到规则化技术(regularization)？</font></b></p></li><li><p><b>答：</b>当模型变得过拟合或者欠拟合时，规则化(Regularization)变得越来越重要了。这个技术在很多特征的模型中加入了一个惩罚项。所以，它试着把很多的变量的系数变成0以至于减少成本。这样可以帮助降低模型的复杂度从而可以提高模型的泛化能力。</p></li><li><p><b><font color="blue"> Q39，你怎么理解bias variance权衡？</font></b></p></li><li><p><b>答：</b>当模型能在数学上表示成3个成分的时候，这个错误就会出现。以下就是这些成分：</p></li><li><p>偏差错误是将预测的均值和真实值的差异程度量化了。一个高的偏差错误意味着我们得到的是一个欠拟合模型，它总是偏离了真实的趋势。而方差则是模型预测值和真实值的分散程度。高方差说明模型在训练数据上过拟合了，然后在新数据上预测很差。</p></li><li><p><b><font color="blue"> Q40，OLS(最小二乘法)对应线性回归，最大似然对应逻辑斯特回归。请解释这句话。</font></b></p></li><li><p><b>答：</b>简单来说，最小二乘法和最大似然都是对回归方法进行未知参数的预估的方法。</p></li><li><p>最小二乘法(Ordinary least square)用在线性回归中估计参数，目的是要真实值和预测值之间的距离最小。最大似然是帮助选择一个参数值，使得模型能够最大化产生观测数据。</p></li></ul><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><ul><li>你可能很轻松地回答了所有问题，但是我们的目标是要理解它们并且可以举一反三，理解透相关的问题。如果你没能很好应对这些问题，也不用担心，从现在开始学习，从现在开始关注学习的问题。</li><li>这些问题是为大家提供了初创公司的面试问题的概况。我相信这些问题引起了你深入学习机器学习的欲望，现在开始计划吧。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;By Manish Saraswat, &lt;a class=&quot;link&quot;   href=&quot;https://www.analyticsvidhya.com/blog/2016/09/40-interview-questions-asked-at-startups-i</summary>
      
    
    
    
    <category term="面试题" scheme="http://example.com/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
    
    
    <category term="数据科学，机器学习" scheme="http://example.com/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%EF%BC%8C%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>支持向量网络论文原文-Vapnik-论文翻译</title>
    <link href="http://example.com/2015/03/13/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E7%BD%91%E7%BB%9C%E8%AE%BA%E6%96%87%E5%8E%9F%E6%96%87-Vapnik-%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/"/>
    <id>http://example.com/2015/03/13/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E7%BD%91%E7%BB%9C%E8%AE%BA%E6%96%87%E5%8E%9F%E6%96%87-Vapnik-%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/</id>
    <published>2015-03-13T10:58:23.000Z</published>
    <updated>2023-07-13T04:02:43.358Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/img/paperBlog/Support-Vector-Networks/head.png"></p><ul><li><strong>摘要</strong>：<ul><li>支持向量网络是一种新的用于二类分类问题的学习机。这个机器(方法)概念地实现了以下想法：非线性的输入向量被映射到高维度的特征空间。在这个特征空间中找出一个线性决策超平面。决策超平面的特殊属性可以保证学习机的强泛化能力。这个支持向量网路的思想在训练资料严格线性可分的情况下已被实现。现在我们来谈一下在训练资料非线性可分的情况下的结果。</li><li>支持向量网络的高泛化能力是利用多项式输入转换。我们同样比较了支持向量网络和和其他经典的学习算法在OCR(光学字符识别)这个基准上的表现。</li></ul></li><li><strong>关键字</strong>：<ul><li>模式识别， 有效的学习算法， 神经网络， 径向基函数分类器， 多类分类器</li></ul></li></ul><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><ul><li>60多年前R.A. Fisher(Fisher, 1936)提出了模式识别的第一个算法。有两个服从正态分布的模型，<img src="/img/paperBlog/Support-Vector-Networks/01/01.PNG">和<img src="/img/paperBlog/Support-Vector-Networks/01/02.PNG">，n维向量X，其中均值向量分别是m1和m2，方差分别是<img src="/img/paperBlog/Support-Vector-Networks/01/03.PNG">和<img src="/img/paperBlog/Support-Vector-Networks/01/04.PNG">，最后得到的最优解(贝叶斯)是一个二次规划函数：<br><img src="/img/paperBlog/Support-Vector-Networks/01/05.PNG"></li><li>若果<img src="/img/paperBlog/Support-Vector-Networks/01/06.PNG">，那么上式化简为一个线性函数：<br><img src="/img/paperBlog/Support-Vector-Networks/01/07.PNG"></li><li>要解式子(1)中的二次规划函数，必须有<img src="/img/paperBlog/Support-Vector-Networks/01/08.PNG">个自由参数。要解式子(2)中线性函数仅仅要n个自由参数。观测量的数量小(比如说小于<img src="/img/paperBlog/Support-Vector-Networks/01/09.PNG">个)估算<img src="/img/paperBlog/Support-Vector-Networks/01/10.PNG">个参数是不可靠的。因此Fisher推荐，即使是在<img src="/img/paperBlog/Support-Vector-Networks/01/11.PNG">的情况下，仍然对线性判别函数(2)使用以下<img src="/img/paperBlog/Support-Vector-Networks/01/12.PNG">的形式：<br><img src="/img/paperBlog/Support-Vector-Networks/01/13.PNG"></li><li>上式中的<img src="/img/paperBlog/Support-Vector-Networks/01/14.PNG">是一个常量。Fisher另外推荐了当两个分布不是服从正态的时候，利用一个线性决策函数。</li><li>模式识别的算法最开始就和线性决策超平面的构建有关。</li><li><img src="/img/paperBlog/Support-Vector-Networks/01/15.PNG"></li><li>在1962年Rosenblatt(Rosenblatt, 1962)发明了一种新型的学习机：感知机或者神经网络。感知机包含多个相连的神经元，每个神经元实现一个分离超平面，所以整个感知机实现了分段的线性分离超平面。见图Fig.1。</li><li>在Rosenblatt时期还没有算法通过调整网络的权值来最小化向量集的错误。根据其他权值的固定值，输入向量被非线性地转换到特征空间Z中,在单元的最后一层。在这个空间中一个线性决策函数被构造：<br><img src="/img/paperBlog/Support-Vector-Networks/01/16.PNG"></li><li>通过调节从第i层隐藏层到输出单元的<img src="/img/paperBlog/Support-Vector-Networks/01/17.PNG">的权值以最小化在整个训练资料上的一些误差。根据Rosenblatt的方法的结果来看，决策规则的构造再一次联系到信息超平面的构造，在某些空间上。</li><li>第一次出现一个算法允许通过调整神经网络的权值来最小化属于模式识别问题的向量集的局部误差是在1986年,(Rumelhart, Hinton &amp; Williams, 1986, 1987; Parker, 1985; LeCun 1985)因为那个时候发现了反向传播算法。它的解法是一个轻微修改的神经元的数学模型。所以，神经网络实现了“分段线性类型”的决策函数。</li><li>在本文中，我们构造一个新型的学习机(方法)，所谓的“支持向量网络”。支持向量网络实现了一下想法：它通过一些事先选择好的非线性的映射规则把输入向量映射到高维度的特征空间Z。在这个空间当中，通过一些特殊属性来构造线性决策超平面来保证网络的高泛化能力。</li><li><img src="/img/paperBlog/Support-Vector-Networks/01/18.PNG"></li><li>例子：要求得二次多项式的决策超平面，可以创建一个特征空间Z，它有 N&#x3D; <img src="/img/paperBlog/Support-Vector-Networks/01/08.PNG">个坐标形式：<br><img src="/img/paperBlog/Support-Vector-Networks/01/19.PNG"></li><li>上面的方法中有两个新的问题：一个是概念上的，一个是技术上的。概念上的问题是怎么才能找到一个推广能力较好的分离超平面：特征空间的维数将会很大，而且并不是所有的可分离训练资料的超平面都有很好的推广能力。然后技术上的问题是面对如此高维的空间，怎么简化计算量：在一个200维德空间中构造一个4次方或者5次方的多项式可能需要构造一个数以数以亿计的维数的空间。</li><li>概念上的问题在1965(Vapnik, 1982)被解决了，鉴于<em>为线性可分的类寻找最佳化的分离超平面</em>这个case.这里定义的最佳化的超平面是两个可分的向量中寻找最大的分类间隔，看Fig.2.被证明说要构造这样一个最佳化的超平面只需要很少的训练数据，这些数据就被称为<em>支撑向量</em>，它们是用来决定间隔的。资料表明，如果训练资料被一个最佳化的超平面完美无误地分离，那么在测试例子中预测新数据的误差期望值等于支持向量的数量的期望值和训练向量的数量的比：<br><img src="/img/paperBlog/Support-Vector-Networks/01/20.PNG"></li><li>注意到这个约束并没有明显的包含可分空间的维数。这个约束遵循这个规则的：如果构造最佳化的超平面包含的支持向量的数量越少，那么这个模型的泛化能力就越高–即使是在无穷的维数空间中。在Section 5我们会通过一个实际生活问题说明上面(5)式子的比值可以低到0.03，而且这个最佳化超平面在数以亿计的维数的特征空间中的推广能力很好。</li><li>让<br><img src="/img/paperBlog/Support-Vector-Networks/01/21.PNG"></li><li>作为空间中最佳化超平面的表示。我们会把特征空间中的最佳化超平面的权值<img src="/img/paperBlog/Support-Vector-Networks/01/22.PNG">写成支持向量的线性组合式<br><img src="/img/paperBlog/Support-Vector-Networks/01/23.PNG"></li><li>特征空间中的线性决策函数<img src="/img/paperBlog/Support-Vector-Networks/01/26.PNG">会相应地变成以下形式：<img src="/img/paperBlog/Support-Vector-Networks/01/24.PNG"></li><li><img src="/img/paperBlog/Support-Vector-Networks/01/27.PNG">表示的是再特征空间中的支持向量zi和z的点积。决策函数能够被描述为一个两层的网络。(Fig.3.)</li><li>然而，即使最佳化超平面的推广能力比较好，但是关于怎样处理高维度空间的技术的问题还没解决。在1992年(Boser, Guyon, &amp; Vapnik, 1992)，构造决策函数的操作顺序是可以互换的：我们可以先比较输入空间中的两个向量(比如，计算它们的点积，或者一些距离测量)对结果的值做非线性转换，而不是拿特征空间中两个点积的向量做非线性的转换。这样促成了更多分类的决策超平面的构造，例如，任意次方的多项式决策超平面。我们把这种类型的学习机叫做支持向量网络。</li><li>支持向量网络的技巧当初是为了毫无误差地找到更精准的分类训练数据的超平面。在这篇文章当中，我们对支持向量网络进行拓展，拓展到当不能毫无误差的进行分类数据的情况下也能使用。在这种情形之下，我们把支持向量网络当成一种新的学习机。一种像神经网络一样更强大更通用的学习机。在Section 5我们会对在一个高维空间(维度256)，多项式次方高达7的情形下，支持向量网络的泛化能力还能有多好进行说明。这种学习机的表现可以与那些经典的学习机(像线性分类器，k邻近分类器和神经网络等)相媲美。Section 2，3和4主要讲算法的推导和它的一些属性的讨论。关于推导的细节请看附录部分。<br><img src="/img/paperBlog/Support-Vector-Networks/01/25.PNG"></li></ul><h2 id="最佳化超平面"><a href="#最佳化超平面" class="headerlink" title="最佳化超平面"></a>最佳化超平面</h2><ul><li>在这个section当中，让我们来回顾一下0误差分离训练资料的最佳化超平面的方法(Vapnik, 1982).而在下一个section，我们介绍软间隔的记号，它允许在分类的过程当中存在误差。</li></ul><h3 id="最佳超平面算法"><a href="#最佳超平面算法" class="headerlink" title="最佳超平面算法"></a>最佳超平面算法</h3><ul><li>训练模式的标签集<br><img src="/img/paperBlog/Support-Vector-Networks/02/01.PNG"></li><li>被认为是线性可分的，如果向量W和标量b满足以下不等式条件：<br><img src="/img/paperBlog/Support-Vector-Networks/02/02.PNG"></li><li>被认为说是对(8)中的所有的训练集都是有效的。然后把(9)中的不等式写成一下形式：<br><img src="/img/paperBlog/Support-Vector-Networks/02/04.PNG"></li><li><img src="/img/paperBlog/Support-Vector-Networks/02/03.PNG"></li><li>最佳化超平面是：<br><img src="/img/paperBlog/Support-Vector-Networks/02/05.PNG"></li><li>它是唯一一个把训练资料分离出最大间隔：它保证了两个不同类别的训练向量映射在<img src="/img/paperBlog/Support-Vector-Networks/02/06.PNG">方向上的距离是最大的。回顾Fig.2.这个距离<img src="/img/paperBlog/Support-Vector-Networks/02/07.PNG">表示如下：<br><img src="/img/paperBlog/Support-Vector-Networks/02/08.PNG"></li><li>最佳化超平面<img src="/img/paperBlog/Support-Vector-Networks/02/09.PNG">是使得(12)中距离最大的参数。它符合(12)和(10)的约束<img src="/img/paperBlog/Support-Vector-Networks/02/10.PNG"></li><li>这就是说最佳化超平面在符合(10)式当中的约束的条件下是唯一一个可以最小化<img src="/img/paperBlog/Support-Vector-Networks/02/11.PNG">的.所以构造最佳化超平面的问题就是一个二次规划问题。</li><li><img src="/img/paperBlog/Support-Vector-Networks/02/13.PNG">当中的向量<img src="/img/paperBlog/Support-Vector-Networks/02/12.PNG">学术上被称为<em>支持向量</em>。在附录A.1中，我们说明了能够决定最佳化超平面的向量<img src="/img/paperBlog/Support-Vector-Networks/02/14.PNG">可以写成一个训练向量的线性组合形式：<img src="/img/paperBlog/Support-Vector-Networks/02/15.PNG"></li><li>(14)中当<img src="/img/paperBlog/Support-Vector-Networks/02/16.PNG">.因为<img src="/img/paperBlog/Support-Vector-Networks/02/17.PNG">仅仅是符合支持向量(看附录)，(14)当中的表达式是<img src="/img/paperBlog/Support-Vector-Networks/02/14.PNG">的简写形式。我们也说明了要找参数<img src="/img/paperBlog/Support-Vector-Networks/02/18.PNG">的向量：<br><img src="/img/paperBlog/Support-Vector-Networks/02/19.PNG"></li><li>必须要解决以下的二次规划问题：<br><img src="/img/paperBlog/Support-Vector-Networks/02/20.PNG"></li><li>其中<img src="/img/paperBlog/Support-Vector-Networks/02/21.PNG">满足的约束条件是：<br><img src="/img/paperBlog/Support-Vector-Networks/02/22.PNG"></li><li>其中<img src="/img/paperBlog/Support-Vector-Networks/02/23.PNG">是一个<img src="/img/paperBlog/Support-Vector-Networks/02/24.PNG">维的单位向量，<img src="/img/paperBlog/Support-Vector-Networks/02/25.PNG">是一个<img src="/img/paperBlog/Support-Vector-Networks/02/24.PNG">维的标签向量，<img src="/img/paperBlog/Support-Vector-Networks/02/26.PNG">是一个带元素的对称的<img src="/img/paperBlog/Support-Vector-Networks/02/27.PNG">矩阵<br><img src="/img/paperBlog/Support-Vector-Networks/02/28.PNG"></li><li>(16)当中的不等式描述的是非负象限。所以我们在(17)的约束条件下最大化(15)中的二次规划式。</li><li>当(8)中的训练资料可以0误差的分离时，我们同样在附录中进行了说明，(15)中的最大值，<img src="/img/paperBlog/Support-Vector-Networks/02/29.PNG">对和(13)中的最大间隔<img src="/img/paperBlog/Support-Vector-Networks/02/35.PNG">的关系：<br><img src="/img/paperBlog/Support-Vector-Networks/02/30.PNG"></li><li>对于某些<img src="/img/paperBlog/Support-Vector-Networks/02/31.PNG">和大的常量<img src="/img/paperBlog/Support-Vector-Networks/02/32.PNG">，不等式<br><img src="/img/paperBlog/Support-Vector-Networks/02/33.PNG"></li><li>是合理的，有一个可以断言的是所有的可分离训练资料(8)的超平面都满足<br><img src="/img/paperBlog/Support-Vector-Networks/02/34.PNG"></li><li>如果(8)中的训练资料不能被一个超平面分离，那么两个模式类别之间的间隔将会非常小，导致函数<img src="/img/paperBlog/Support-Vector-Networks/02/36.PNG">的值非常大。在约束条件(16)和(17)下最大化函数(15)的值，其中一个达到最大值时(这种情况是其中一个通过最大间隔<img src="/img/paperBlog/Support-Vector-Networks/02/35.PNG">构建了一个超平面)，或者其中一个找到了最大值超过了给定的常量<img src="/img/paperBlog/Support-Vector-Networks/02/32.PNG">(这种情况是训练资料的分离超平面比<img src="/img/paperBlog/Support-Vector-Networks/02/37.PNG">还要大是不可能的)。</li><li>在约束条件(16)和(17)下最大化函数(15)的问题很有效地通过以下模式解决。把训练资料合理的分成多个不大的部分。首先利用第一部分的训练资料来解决二次规划的问题。对于这样的处理会有两种可能的结果：这部分的训练资料不能找打一个可分离的超平面(这样的话整个资料也是找不到可分离的超平面的)，或者在第一部分的训练资料中就找到了最佳化的分离超平面。</li><li>如果是在第一部分的训练资料中就找到了分离超平面，我们把它称作向量<img src="/img/paperBlog/Support-Vector-Networks/02/38.PNG">，让它来最大化函数(15).在向量<img src="/img/paperBlog/Support-Vector-Networks/02/38.PNG">当中有一些值是等于0的。它们对应于这部分资料的非支持向量。创建一个新的训练资料集，其中包含第一部分资料的支持向量和第二部分资料的那些不符合约束(10)的向量，其中<img src="/img/paperBlog/Support-Vector-Networks/02/39.PNG">是由<img src="/img/paperBlog/Support-Vector-Networks/02/38.PNG">决定的。在这个新的资料集当中创造了一个新的函数<img src="/img/paperBlog/Support-Vector-Networks/02/40.PNG">和这个函数在<img src="/img/paperBlog/Support-Vector-Networks/02/41.PNG">处达到最大。然后重复这样的做法，覆盖到所有的训练资料中，不断增加新的解法向量<img src="/img/paperBlog/Support-Vector-Networks/02/31.PNG">，如果找不到0误差的分离超平面，或者对所有训练资料可以构造一个最佳化分离超平面<img src="/img/paperBlog/Support-Vector-Networks/02/42.PNG">.请注意，在这个过程当中，函数<img src="/img/paperBlog/Support-Vector-Networks/02/36.PNG">的值是单调递增的，因为越来越多的训练向量被划分为最佳化，导致两个类别之间的分隔越来越小。</li></ul><h2 id="软间隔超平面"><a href="#软间隔超平面" class="headerlink" title="软间隔超平面"></a>软间隔超平面</h2><ul><li>考虑到那种不能0误差的把训练资料分离的情况。这样的话，我们想说要达到误差的最小化来分离资料。要正式地表达这个，让我们先引入一些非负变量<img src="/img/paperBlog/Support-Vector-Networks/03/01.PNG"></li><li>我们现在最小化函数<br><img src="/img/paperBlog/Support-Vector-Networks/03/02.PNG"></li><li>其中<img src="/img/paperBlog/Support-Vector-Networks/03/03.PNG">，约束于<br><img src="/img/paperBlog/Support-Vector-Networks/03/04.PNG"></li><li><img src="/img/paperBlog/Support-Vector-Networks/03/05.PNG">足够小，函数(21)描述的是训练错误的个数。</li><li>最小化(21)，我们要找出一些最小的训练错误的子集：<br><img src="/img/paperBlog/Support-Vector-Networks/03/06.PNG"></li><li>如果这些误差资料不包含在训练资料中，那么训练资料就可以毫无误差的进行分离，并且在两个类别之间找到一个超平面。</li><li>这个想法可以正式的表达为：最小化函数<br><img src="/img/paperBlog/Support-Vector-Networks/03/07.PNG"></li><li>约束条件为(22)和(23)，其中<img src="/img/paperBlog/Support-Vector-Networks/03/08.PNG">是一个单调的凸函数，<img src="/img/paperBlog/Support-Vector-Networks/03/09.PNG">是一个常量。</li><li>足够大的<img src="/img/paperBlog/Support-Vector-Networks/03/09.PNG">和足够小的<img src="/img/paperBlog/Support-Vector-Networks/03/05.PNG">，在约束条件(22)和(23)下的最小化函数(24)的向量<img src="/img/paperBlog/Support-Vector-Networks/03/10.PNG">和常数<img src="/img/paperBlog/Support-Vector-Networks/03/11.PNG">，可以决定一个超平面，这个超平面是最小化在训练集上的错误个数和把剩余的元素利用最大间隔进行分离。</li><li>注意到，在训练集上构造一个能够最小化错误数的超平面是一个正常的NPC问题(因不能用多项式算法而使问题无法解决的；非完全多项式).为避免我们的问题出现NPC问题，我们设定<img src="/img/paperBlog/Support-Vector-Networks/03/12.PNG"></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;img src=&quot;/img/paperBlog/Support-Vector-Networks/head.png&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;摘要&lt;/strong&gt;：&lt;ul&gt;
&lt;li&gt;支持向量网络是一种新的用于二类分类问题的学习机。这个机器(方法)概念地</summary>
      
    
    
    
    <category term="毕业设计系列" scheme="http://example.com/categories/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%E7%B3%BB%E5%88%97/"/>
    
    
    <category term="SVM入门" scheme="http://example.com/tags/SVM%E5%85%A5%E9%97%A8/"/>
    
  </entry>
  
  <entry>
    <title>毕设报告-2015-03-10</title>
    <link href="http://example.com/2015/03/10/%E6%AF%95%E8%AE%BE%E6%8A%A5%E5%91%8A-2015-03-10/"/>
    <id>http://example.com/2015/03/10/%E6%AF%95%E8%AE%BE%E6%8A%A5%E5%91%8A-2015-03-10/</id>
    <published>2015-03-10T03:58:21.000Z</published>
    <updated>2023-07-13T04:09:46.831Z</updated>
    
    <content type="html"><![CDATA[<h2 id="毕业设计完成情况"><a href="#毕业设计完成情况" class="headerlink" title="毕业设计完成情况"></a>毕业设计完成情况</h2><h3 id="我的感受"><a href="#我的感受" class="headerlink" title="我的感受"></a>我的感受</h3><ul><li>写论文绝不是一件轻松的工作，特别是如果你选的题目和你现在的水平相差甚远时。自从<a class="link"   href="http://chenyuqing.github.io/2015/12/30/%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB-%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%E5%8D%9A%E5%AE%A2%E7%B3%BB%E5%88%97-%E8%BF%9E%E8%BD%BD" >上一次的毕业论文中期检查<i class="fas fa-external-link-alt"></i></a>之后，我实习了一个月，然后回家过了个年，所以把时间分配到做毕设的也不多，而且我现在明白到了做理论这一块的论文，特别是面对一连串关数学的推导，一大片难懂的公式，那就更是不知所云。不过就像我的指导老师易老师说的那样，写论文不是简单的拼凑文章，而是需要大量的去阅读前人在你的这个领域范围内的文章，去慢慢吸收里面的知识，然后可以通过自己的话来描述清楚一个问题。“读书千遍，其义自见”这句谚语的个中滋味我也终有领会。特别是偏理论的问题，读第一遍，不知所云，读第二遍，不知所云，读第三遍，不知所云。。。然后突然再读下一遍，就发现自己找到了头绪，那感觉就好像身陷死角里摸不着头了好久，然后突然看到了一线光明一样，整个人都开朗了起来。</li></ul><h3 id="完成情况概述"><a href="#完成情况概述" class="headerlink" title="完成情况概述"></a>完成情况概述</h3><ul><li>我的毕设规划是分两个路线进行，一个是理论学习路线，一个是系统实现路线。<br><img src="/img/paperBlog/plan-routine.png"></li><li>上次的完成情况如下图：<br><img src="/img/paperBlog/plan-routine-00.png"></li><li>现在的完成进度则如下：<br><img src="/img/paperBlog/plan-routine-01.png"></li><li>所以到目前为止，还是注重于理论这一块的学习，因为这一块的难度比重是占的比较大的。</li></ul><h2 id="做了哪些工作"><a href="#做了哪些工作" class="headerlink" title="做了哪些工作"></a>做了哪些工作</h2><h3 id="阅读了以下优秀的博客文章："><a href="#阅读了以下优秀的博客文章：" class="headerlink" title="阅读了以下优秀的博客文章："></a>阅读了以下优秀的博客文章：</h3><ul><li><a class="link"   href="http://blog.csdn.net/v_july_v/article/details/7624837" >支持向量机通俗导论（理解SVM的三层境界）<i class="fas fa-external-link-alt"></i></a></li><li><a class="link"   href="http://chenyuqing.github.io/2015/01/08/SVM%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%97%E5%8D%9A%E6%96%87-%E8%BD%AC%E8%87%AAJasper-s-Java-Jacal-%E5%A4%87%E4%BB%BD-%E6%AF%95%E8%AE%BE%E7%B3%BB%E5%88%97/" >SVM入门系列博文-转自Jasper’s Java Jacal<i class="fas fa-external-link-alt"></i></a></li><li><a class="link"   href="http://www.cnblogs.com/jerrylead/archive/2011/03/13/1982639.html" >支持向量机SVM（一）<i class="fas fa-external-link-alt"></i></a></li></ul><h3 id="翻译了一下国外优秀的文章："><a href="#翻译了一下国外优秀的文章：" class="headerlink" title="翻译了一下国外优秀的文章："></a>翻译了一下国外优秀的文章：</h3><ul><li><a class="link"   href="http://chenyuqing.github.io/2015/01/12/Support-Vector-Machines-scikielearn/" >Support Vector Machines-scikielearn-翻译-毕设系列<i class="fas fa-external-link-alt"></i></a></li><li><a class="link"   href="http://chenyuqing.github.io/2015/01/13/%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB-Kernel%20Support%20Vector%20Machine-%E5%8D%9A%E5%AE%A2%E7%BF%BB%E8%AF%91-%E6%AF%95%E8%AE%BE%E7%B3%BB%E5%88%97/" >手写数字识别-Kernel Support Vector Machine-论文翻译-毕设系列<i class="fas fa-external-link-alt"></i></a></li><li><a class="link"   href="http://chenyuqing.github.io/2015/01/01/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91-%E6%AF%95%E8%AE%BE%E7%B3%BB%E5%88%97" >最小二乘法论文翻译-毕设系列<i class="fas fa-external-link-alt"></i></a></li></ul><h3 id="草拟了论文目录框架"><a href="#草拟了论文目录框架" class="headerlink" title="草拟了论文目录框架"></a>草拟了论文目录框架</h3><ul><li><img src="/img/paperBlog/%E6%AF%95%E8%AE%BE%E8%AE%BA%E6%96%87%E7%9B%AE%E5%BD%95%E6%8B%9F%E7%A8%BF.png"></li></ul><h3 id="利用pygame实现系统的UI，完成了模块的划分"><a href="#利用pygame实现系统的UI，完成了模块的划分" class="headerlink" title="利用pygame实现系统的UI，完成了模块的划分"></a>利用pygame实现系统的UI，完成了模块的划分</h3><ul><li><img src="/img/paperBlog/%E7%A8%8B%E5%BA%8F%E6%A8%A1%E5%9D%97%E8%AE%BE%E8%AE%A1.png"></li></ul><h3 id="利用scikit-learn软件包实现了SVM算法"><a href="#利用scikit-learn软件包实现了SVM算法" class="headerlink" title="利用scikit-learn软件包实现了SVM算法"></a>利用scikit-learn软件包实现了SVM算法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment">### Support Vector Machine for Handwritten Digit Recognition</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm, datasets, cross_validation</span><br><span class="line"><span class="keyword">from</span> sklearn.grid_search <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> gmtime, strftime</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;1- Start 载入训练数据&quot;</span></span><br><span class="line"><span class="built_in">print</span> strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>, gmtime())</span><br><span class="line"></span><br><span class="line"><span class="comment">### Load Training data</span></span><br><span class="line">trainTargetArray = []</span><br><span class="line">trainDataArray = []</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./train.csv&#x27;</span>, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> trainFile:</span><br><span class="line">    trainReader = csv.reader(trainFile, delimiter = <span class="string">&#x27;,&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> trainReader:</span><br><span class="line">        trainTargetArray.append(row[<span class="number">0</span>])</span><br><span class="line">        trainDataArray.append(row[<span class="number">1</span>:])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;1- End 载入训练数据&quot;</span></span><br><span class="line"><span class="built_in">print</span> strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>, gmtime())</span><br><span class="line">    </span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;2- Start 删除列头&quot;</span></span><br><span class="line"><span class="built_in">print</span> strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>, gmtime())</span><br><span class="line">    </span><br><span class="line"><span class="comment">### Delete Column Headers</span></span><br><span class="line"><span class="keyword">del</span> trainTargetArray[<span class="number">0</span>]</span><br><span class="line"><span class="keyword">del</span> trainDataArray[<span class="number">0</span>]</span><br><span class="line">trainData = np.array(trainDataArray)</span><br><span class="line">trainTarget = np.array(trainTargetArray)</span><br><span class="line">trainData = trainData.astype(np.<span class="built_in">float</span>)/<span class="number">255.0</span></span><br><span class="line">trainTarget = trainTarget.astype(np.<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;2- End 删除列头&quot;</span></span><br><span class="line"><span class="built_in">print</span> strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>, gmtime())</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;3-Start  载入测试数据&quot;</span></span><br><span class="line"><span class="built_in">print</span> strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>, gmtime())</span><br><span class="line"><span class="comment">### Load Testing data</span></span><br><span class="line">testDataArray = []</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./test.csv&#x27;</span>, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> testFile:</span><br><span class="line">    testReader = csv.reader(testFile, delimiter = <span class="string">&#x27;,&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> testReader:</span><br><span class="line">        testDataArray.append(row)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;3- End  载入测试数据&quot;</span></span><br><span class="line"><span class="built_in">print</span> strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>, gmtime())</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;4 -Start 删除列头&quot;</span></span><br><span class="line"><span class="built_in">print</span> strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>, gmtime())</span><br><span class="line"><span class="comment"># Delete column Headers</span></span><br><span class="line"><span class="keyword">del</span> testDataArray[<span class="number">0</span>]</span><br><span class="line">testData = np.array(testDataArray)</span><br><span class="line">testData = testData.astype(np.<span class="built_in">float</span>)/<span class="number">255.0</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;4-End 删除列头&quot;</span></span><br><span class="line"><span class="built_in">print</span> strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>, gmtime())</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;5-Start 设置分类器并训练模型&quot;</span></span><br><span class="line"><span class="built_in">print</span> strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>, gmtime())</span><br><span class="line"><span class="comment"># Set up classification and fit he model data</span></span><br><span class="line">svc = svm.SVC(gamma=<span class="number">0.128</span>, C=<span class="number">1</span>)</span><br><span class="line">svc.fit(trainData, trainTarget)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;5-End 模型训练完成&quot;</span></span><br><span class="line"><span class="built_in">print</span> strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>, gmtime())</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;6- Start 利用模型预测测试数据中的手写数字&quot;</span></span><br><span class="line"><span class="built_in">print</span> strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>, gmtime())</span><br><span class="line"><span class="comment"># Predict / Determine Value of New images</span></span><br><span class="line">prediction = svc.predict(testData)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;6-End 预测&quot;</span></span><br><span class="line"><span class="built_in">print</span> strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>, gmtime())</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;7- Start  保存输出文件&quot;</span></span><br><span class="line"><span class="built_in">print</span> strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>, gmtime())</span><br><span class="line"><span class="comment"># Save output to file</span></span><br><span class="line">output = <span class="built_in">open</span>(<span class="string">&#x27;./output.csv&#x27;</span>, <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> x, value <span class="keyword">in</span> np.ndenumerate(prediction):</span><br><span class="line">    output.write(<span class="built_in">str</span>(<span class="built_in">int</span>(value)))</span><br><span class="line">    output.write(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">output.close()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;7- End  结束！&quot;</span></span><br><span class="line"><span class="built_in">print</span> strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>, gmtime())</span><br></pre></td></tr></table></figure><ul><li>本次SVM的实现是利用了网上比较健全的开源机器学习工具—<a class="link"   href="http://scikit-learn.org/stable/" >scikit-learn<i class="fas fa-external-link-alt"></i></a>,Scikit-Learn是基于python的机器学习模块，基于BSD开源许可证。这个项目最早由DavidCournapeau 在2007 年发起的，目前也是由社区自愿者进行维护。</li><li>scikit-learn的SVM说明，也是我翻译了一篇文章<a class="link"   href="http://chenyuqing.github.io/2015/01/12/Support-Vector-Machines-scikielearn/" >Support Vector Machines-scikielearn-翻译-毕设系列<i class="fas fa-external-link-alt"></i></a></li><li>然后本次的数据是Kaggle上的数字识别的数据<a class="link"   href="http://www.kaggle.com/c/digit-recognizer" >Digit Recognizer<i class="fas fa-external-link-alt"></i></a>。<a class="link"   href="http://www.kaggle.com/" >Kaggle<i class="fas fa-external-link-alt"></i></a>是一个数据建模和数据分析竞赛平台。企业和研究者可在其上发布数据，统计学者和数据挖掘专家可在其上进行竞赛以产生最好的模型。这一众包模式依赖于这一事实，即有众多策略可以用于解决几乎所有预测建模的问题，而研究者不可能在一开始就了解什么方法对于特定问题是最为有效的。Kaggle的目标则是试图通过众包的形式来解决这一难题，进而使数据科学成为一场运动。<a class="link"   href="http://zh.wikipedia.org/wiki/Kaggle" >Kaggle的Wiki简介<i class="fas fa-external-link-alt"></i></a></li><li>SVM的训练日志：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">log-<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="number">1</span>- Start Load Training data</span><br><span class="line"><span class="number">2015</span>-03-09 <span class="number">14</span>:<span class="number">15</span>:<span class="number">33</span></span><br><span class="line"><span class="number">1</span>- End Load Training data</span><br><span class="line"><span class="number">2015</span>-03-09 <span class="number">14</span>:<span class="number">15</span>:<span class="number">37</span></span><br><span class="line"></span><br><span class="line"><span class="number">2</span>- Start Delete Column Headers</span><br><span class="line"><span class="number">2015</span>-03-09 <span class="number">14</span>:<span class="number">15</span>:<span class="number">37</span></span><br><span class="line"><span class="number">2</span>- End Delete Column Headers</span><br><span class="line"><span class="number">2015</span>-03-09 <span class="number">14</span>:<span class="number">15</span>:<span class="number">51</span></span><br><span class="line"></span><br><span class="line"><span class="number">3</span>-Start  Load Testing data</span><br><span class="line"><span class="number">2015</span>-03-09 <span class="number">14</span>:<span class="number">15</span>:<span class="number">51</span></span><br><span class="line"><span class="number">3</span>- End  Load Testing data</span><br><span class="line"><span class="number">2015</span>-03-09 <span class="number">14</span>:<span class="number">15</span>:<span class="number">55</span></span><br><span class="line"></span><br><span class="line"><span class="number">4</span> -Start Delete column Headers</span><br><span class="line"><span class="number">2015</span>-03-09 <span class="number">14</span>:<span class="number">15</span>:<span class="number">55</span></span><br><span class="line"><span class="number">4</span>-End Delete column Headers</span><br><span class="line"><span class="number">2015</span>-03-09 <span class="number">14</span>:<span class="number">16</span>:05</span><br><span class="line"></span><br><span class="line"><span class="number">5</span>-Start <span class="type">Set</span> up classification <span class="keyword">and</span> fit he model data</span><br><span class="line"><span class="number">2015</span>-03-09 <span class="number">14</span>:<span class="number">16</span>:05</span><br><span class="line"><span class="number">5</span>-End <span class="type">Set</span> up classification <span class="keyword">and</span> fit he model data</span><br><span class="line"><span class="number">2015</span>-03-09 <span class="number">15</span>:<span class="number">40</span>:<span class="number">12</span></span><br><span class="line"></span><br><span class="line"><span class="number">6</span>- Start Predict / Determine Value of New images</span><br><span class="line"><span class="number">2015</span>-03-09 <span class="number">15</span>:<span class="number">40</span>:<span class="number">12</span></span><br><span class="line"><span class="number">6</span>-End Predict / Determine Value of New images</span><br><span class="line"><span class="number">2015</span>-03-09 <span class="number">15</span>:<span class="number">57</span>:<span class="number">34</span></span><br><span class="line"></span><br><span class="line"><span class="number">7</span>- Start  Save output to file</span><br><span class="line"><span class="number">2015</span>-03-09 <span class="number">15</span>:<span class="number">57</span>:<span class="number">34</span></span><br><span class="line"><span class="number">7</span>- End  Save output to file</span><br><span class="line"><span class="number">2015</span>-03-09 <span class="number">15</span>:<span class="number">57</span>:<span class="number">34</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li>由日志可以看出，用时最长的是在第5步，有开始到结束共用时1小时10秒。这一步是利用训练数据训练SVM模型，也即是通过支持向量机训练出一个手写数字识别的分类器模型的过程。</li><li>第七步是利用生成的模型来对新的数据进行预测，即是对新的手写数字进行识别。用时17分22秒。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">log-<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="number">1</span>- Start 载入训练数据</span><br><span class="line"><span class="number">2015</span>-03-<span class="number">10</span> 02:<span class="number">43</span>:<span class="number">27</span></span><br><span class="line"><span class="number">1</span>- End 载入训练数据</span><br><span class="line"><span class="number">2015</span>-03-<span class="number">10</span> 02:<span class="number">43</span>:<span class="number">45</span></span><br><span class="line"></span><br><span class="line"><span class="number">2</span>- Start 删除列头</span><br><span class="line"><span class="number">2015</span>-03-<span class="number">10</span> 02:<span class="number">43</span>:<span class="number">45</span></span><br><span class="line"><span class="number">2</span>- End 删除列头</span><br><span class="line"><span class="number">2015</span>-03-<span class="number">10</span> 02:<span class="number">43</span>:<span class="number">59</span></span><br><span class="line"></span><br><span class="line"><span class="number">3</span>-Start  载入测试数据</span><br><span class="line"><span class="number">2015</span>-03-<span class="number">10</span> 02:<span class="number">43</span>:<span class="number">59</span></span><br><span class="line"><span class="number">3</span>- End  载入测试数据</span><br><span class="line"><span class="number">2015</span>-03-<span class="number">10</span> 02:<span class="number">44</span>:<span class="number">21</span></span><br><span class="line"></span><br><span class="line"><span class="number">4</span> -Start 删除列头</span><br><span class="line"><span class="number">2015</span>-03-<span class="number">10</span> 02:<span class="number">44</span>:<span class="number">21</span></span><br><span class="line"><span class="number">4</span>-End 删除列头</span><br><span class="line"><span class="number">2015</span>-03-<span class="number">10</span> 02:<span class="number">44</span>:<span class="number">30</span></span><br><span class="line"></span><br><span class="line"><span class="number">5</span>-Start 设置分类器并训练模型</span><br><span class="line"><span class="number">2015</span>-03-<span class="number">10</span> 02:<span class="number">44</span>:<span class="number">30</span></span><br><span class="line"><span class="number">5</span>-End 模型训练完成</span><br><span class="line"><span class="number">2015</span>-03-<span class="number">10</span> 04:04:<span class="number">19</span></span><br><span class="line"></span><br><span class="line"><span class="number">6</span>- Start 利用模型预测测试数据中的手写数字</span><br><span class="line"><span class="number">2015</span>-03-<span class="number">10</span> 04:04:<span class="number">19</span></span><br><span class="line"><span class="number">6</span>-End 预测</span><br><span class="line"><span class="number">2015</span>-03-<span class="number">10</span> 04:<span class="number">21</span>:<span class="number">18</span></span><br><span class="line"></span><br><span class="line"><span class="number">7</span>- Start  保存输出文件</span><br><span class="line"><span class="number">2015</span>-03-<span class="number">10</span> 04:<span class="number">21</span>:<span class="number">18</span></span><br><span class="line"><span class="number">7</span>- End  结束！</span><br><span class="line"><span class="number">2015</span>-03-<span class="number">10</span> 04:<span class="number">21</span>:<span class="number">18</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>第二次训练，模型生成的时间是1小时19分39秒。预测用时16分59秒。</li></ul><h2 id="遇到了那些问题？那些问题已经解决了，哪些没有解决？"><a href="#遇到了那些问题？那些问题已经解决了，哪些没有解决？" class="headerlink" title="遇到了那些问题？那些问题已经解决了，哪些没有解决？"></a>遇到了那些问题？那些问题已经解决了，哪些没有解决？</h2><ul><li>梳理SVM流程如下<br><img src="/img/paperBlog/svm-route.png"></li><li>上图中涉及的理论较繁，而且理解难度不小。对于各方面还需要多加理解。</li></ul><h2 id="下一步的计划"><a href="#下一步的计划" class="headerlink" title="下一步的计划"></a>下一步的计划</h2><ul><li>下一步的计划从以下三个路线出发<ul><li>手写数字识别这个问题的描述</li><li>SVM如何应用到手写数字识别</li><li>pygame实现手写数字识别系统</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;毕业设计完成情况&quot;&gt;&lt;a href=&quot;#毕业设计完成情况&quot; class=&quot;headerlink&quot; title=&quot;毕业设计完成情况&quot;&gt;&lt;/a&gt;毕业设计完成情况&lt;/h2&gt;&lt;h3 id=&quot;我的感受&quot;&gt;&lt;a href=&quot;#我的感受&quot; class=&quot;headerlink&quot; </summary>
      
    
    
    
    <category term="毕业设计系列" scheme="http://example.com/categories/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%E7%B3%BB%E5%88%97/"/>
    
    
    <category term="SVM入门" scheme="http://example.com/tags/SVM%E5%85%A5%E9%97%A8/"/>
    
  </entry>
  
  <entry>
    <title>程序员必须知道的10大基础实用算法及其讲解-@慕可网制作</title>
    <link href="http://example.com/2015/02/08/%E7%A8%8B%E5%BA%8F%E5%91%98%E5%BF%85%E9%A1%BB%E7%9F%A5%E9%81%93%E7%9A%8410%E5%A4%A7%E5%9F%BA%E7%A1%80%E5%AE%9E%E7%94%A8%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E8%AE%B2%E8%A7%A3-%E6%85%95%E5%8F%AF%E7%BD%91%E5%88%B6%E4%BD%9C/"/>
    <id>http://example.com/2015/02/08/%E7%A8%8B%E5%BA%8F%E5%91%98%E5%BF%85%E9%A1%BB%E7%9F%A5%E9%81%93%E7%9A%8410%E5%A4%A7%E5%9F%BA%E7%A1%80%E5%AE%9E%E7%94%A8%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E8%AE%B2%E8%A7%A3-%E6%85%95%E5%8F%AF%E7%BD%91%E5%88%B6%E4%BD%9C/</id>
    <published>2015-02-08T03:24:07.000Z</published>
    <updated>2015-02-11T13:49:30.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="算法一：快速排序算法"><a href="#算法一：快速排序算法" class="headerlink" title="算法一：快速排序算法"></a>算法一：快速排序算法</h2><ul><li>快速排序算法是由东尼.霍尔所发展的一种排序算法。在平均状况下，排序n个项目要O(nlog n)次比较。在最坏状况下则需要O(n2)次比较，但这种状况并不常见。事实上，快速排序O(n log n)通常明显比其他算法更快，因为它的内部循环结构(inner loop)可以在大部分的架构上很有效率地被实现出来。</li><li>快速排序使用分治法(Divide and conquer)策略来把一个串行(list)分为两个子串行(sub-lists)。</li><li>gif动图</li><li>算法步骤：<ol><li>从数列中挑出一个元素，称为“基准”(pivot)。</li><li>重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆放基准的后面(相同的数可以到任一边)。在这个分区退出之后，该基准就处在数列的中间位置。这个称为分区(partition)操作。</li><li>递归地(recursive)把小于基准值元素的子数列和大于基准值元素的子数列排序。</li></ol></li><li>递归的最底部情形，数列的大小是零或者一，也就是永远都已经被排序好了。虽然一直递归下去，但是这个算法总会退出，因为在每次的迭代(iteration)中，它至少会把一个元素摆到它最后的位置去。</li></ul><h2 id="算法二：堆排序算法"><a href="#算法二：堆排序算法" class="headerlink" title="算法二：堆排序算法"></a>算法二：堆排序算法</h2><ul><li>堆排序(Heapsort)是指利用堆这种数据结构所设计的一种排序算法。堆积是一个近似完全二叉树的结构，并同时满足堆积的性质：即子节点的键值或索引总是小于(或者大于)它的父节点。</li><li>堆排序的平均时间复杂度为O(nlog n)。</li><li>gif动图</li><li>算法步骤：<ol><li>创建一个堆H[0…n-1]。</li><li>把堆首(最大值)和堆尾互换。</li><li>把堆的尺寸缩小1，并调用shift_down(0)，目的是把新的数组顶端数据调整到相应位置。</li><li>重复步骤2，直到堆的尺寸为1。</li></ol></li></ul><h2 id="算法三：归并排序"><a href="#算法三：归并排序" class="headerlink" title="算法三：归并排序"></a>算法三：归并排序</h2><ul><li>归并排序(Merge sort，台湾译作：合并排序)是建立在归并操作上的一种有限的排序算法。该算法是采用分治法(Divide and conquer)的一个非常典型的应用。</li><li>算法步骤：<ol><li>申请空间，使其大小为两个已经排序序列之和，该空间用来存放合并后的序列。</li><li>设定两个指针，最初位置分别为两个已经排序序列的起始位置。</li><li>比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置。</li><li>重复步骤3直到某一指针达到序列尾。</li><li>将另一序列剩下的所有元素直接复制到合并序列尾。</li></ol></li><li>gif动图</li></ul><h2 id="算法四：二分查找算法"><a href="#算法四：二分查找算法" class="headerlink" title="算法四：二分查找算法"></a>算法四：二分查找算法</h2><ul><li>二分查找算法是一种在有序数组中查找某一特定元素的搜索算法。搜索过程从数组的中间元素开始，如果中间元素正好是要查找的元素，则搜索过程结束；如果某一特定元素大于或小于中间元素，则在数组大于或者小于中间元素的那一半查找，而且跟开始一样从中间元素开始比较。如果在某一步骤数组为空，则代表找不到。这种搜索算法每一次比较都使搜索范围缩小一半。折半搜索每次把搜索区域减少一半，时间复杂度为O(log n)。</li></ul><h2 id="算法五：BFPRT-线性查找算法"><a href="#算法五：BFPRT-线性查找算法" class="headerlink" title="算法五：BFPRT(线性查找算法)"></a>算法五：BFPRT(线性查找算法)</h2><ul><li>BFPRT算法解决的问题十分经典，即从某n个元素的序列中选出第k大(第k小)的元素，通过巧妙的分析，BFPRT可以保证在最坏情况下仍为线性时间复杂度。该算法的思想与快速排序思想相似，当然，为使得算法在最坏情况下，依然能达到O(n)的时间复杂度，五位算法作者做了精妙的处理。</li><li>算法步骤：<ol><li>将n个元素每5个一组，分成n&#x2F;5(上界)组。</li><li>取出每一组的中位数，任意排序方法，比如插入排序。</li><li>递归地调用selection算法查找上一步中所有中位数的中位数，设为x，偶数个中位数的情况下设定为选取中间小的一个。</li><li>用x来分割数组，设小于等于x的个数为k，大于x的个数即为n-k。</li><li>用i &#x3D;&#x3D; k， 返回x;若i&gt;k，在大于x的元素中递归查找第i-k的元素。终止条件：n &#x3D; 1时，返回的即使i小元素。</li></ol></li></ul><h2 id="算法六：DES-深度优先搜索"><a href="#算法六：DES-深度优先搜索" class="headerlink" title="算法六：DES(深度优先搜索)"></a>算法六：DES(深度优先搜索)</h2><ul><li>深度优先搜索算法(Depth-First-Search)，是搜索算法的一种。它沿着树的深度遍历 树的节点，尽可能深的搜索树的分支。当节点v的所有边都已被探寻过，搜索将回溯到发现节点v的那条边的起始节点。这一过程一直进行到已发现从源节点可达的所有节点为止。如果还存在未被发现的节点，则选择其中一个作为源节点并重复以上过程，整个进程反复进行直到所有节点都被访问为止。DFS属于盲目搜索。</li><li>深度优先搜索是图论中的经典算法，利用深度优先搜索算法可以产生目标图的相应拓扑排序表，利用拓扑排序表可以方便的解决很多相关的图论问题，如最大路径问题等等。一般用堆数据结构来辅助实现DFS算法。</li><li>深度优先遍历图算法步骤：<ol><li>访问顶点v。</li><li>依次从v的未被访问的临接点出发，对图进行深度优先遍历；直至图中和v有路径相通的顶点都被访问。</li><li>若此时图中尚有顶点未被访问，则从一个未被访问的顶点出发，重新进行深度优先遍历，直到图中所有顶点均被访问过为止。</li></ol></li><li>上述描述可能比较抽象，举个例子：<ul><li>DFS在访问途中某一起始顶点v后，由v出发，访问它的任一邻接顶点w1;再从w1出发，访问与w1邻接但还没有访问过的顶点w2；然后再从w2出发，进行类似的访问，。。。如此进行下去，直至到达所有的邻接顶点都被访问过的顶点u为止。</li><li>接着，退回一步，退回前一次刚访问过的顶点，看是否还有其他没有被访问的邻接顶点。如果有，则访问此顶点，之后再从此顶点出发，进行与前述类似的访问；如果没有，就再退回一步进行搜索。重复上述过程，直到连通图中所有顶点都被访问过为止。</li></ul></li></ul><h2 id="算法七：BFS-广度优先搜索"><a href="#算法七：BFS-广度优先搜索" class="headerlink" title="算法七：BFS(广度优先搜索)"></a>算法七：BFS(广度优先搜索)</h2><ul><li>广度优先搜索算法(Breadth-First-Search),是一种图形搜索算法。简单的说，BFS是从跟节点开始，沿着树(图)的宽度遍历树(图)的节点。如果所有节点均未被访问，则算法终止。BFS同样属于盲目搜索。一般用队列数据结构来辅助实现BFS算法。</li><li>算法步骤：<ol><li>首先将根节点放入队列中。</li><li>从队列中取出第一个节点，并检验它是否为目标。如果找到目标，则结束搜寻并回传结果，否则将它所有尚未检验过的直接子节点加入队列中。</li><li>若队列为空，表示整张图都检查过了–亦即图中没有欲搜寻的目标。结束搜寻并回传“找不到目标”。</li><li>重复步骤2.</li></ol></li><li>gif动图。</li></ul><h2 id="算法八：Dijkstra算法"><a href="#算法八：Dijkstra算法" class="headerlink" title="算法八：Dijkstra算法"></a>算法八：Dijkstra算法</h2><ul><li>戴克斯特拉算法(Dijkstra’s algorithm)是有荷兰计算机科学家艾兹赫尔.戴克斯特拉提出。迪克斯切算法使用了广度优先搜索解决非负权有向图的单源最短路径问题，算法最终得到了一个最短路径树。该算法常用于路由算法或者作为其他图算法的一个子模块。</li><li>该算法的输入包含了一个有权重的有向图G，以及G中的一个来源顶点S。我们以V表示G中所有顶点的集合。每一个图中的边，都是两个顶点所形成的有序元素树。(u, v)表示从顶点u到v有路径相连。我们以E表示G中所有边的集合，而边的权重则由权重函数w: E –&gt; [0, 无穷大]定义。因此，w(u, v)就是从顶点u到顶点v的非负权重(weight)。边的权重可以想象成两个顶点之间的距离。任何两点间的路径的权重，就是该路径上所有边的权重总和。已知有V中有顶点s及t,Dijkstra算法可以找到s到t的最低权重路径(例如，最短路径)。这个路径也可以在一个图中，找到从一个顶点s到任何其他顶点的最短路径。对于不含负权的有向图，Dijkstra算法是目前已知的最快的单源最短路径算法。</li><li>算法步骤：<ol><li>初始时令 S&#x3D;{V0}，T&#x3D;{其他顶点}，T中为顶点对应的距离值，若存在，d(V0,Vi)为弧上的权值，若不存在，d(V0,Vi)为无穷大。</li><li>从T中选取一个其距离值为最小的顶点W且其不再S中，加入S。</li><li>对其余T中顶点的距离值进行修改：若加进W作中间顶点，从V0到Vi的距离值缩短，则修改此距离值。</li><li>重复上述步骤2，3，直到S中包含所有顶点，即W&#x3D;Vi为止。</li></ol></li><li>图片</li></ul><h2 id="算法九：动态规划算法"><a href="#算法九：动态规划算法" class="headerlink" title="算法九：动态规划算法"></a>算法九：动态规划算法</h2><ul><li>动态规划(Dynamic Programming)是一种在数学，计算机科学和经济学中使用的，通过把原问题分解为相对简单的子问题求解复杂问题的方法。动态规划常常适用于重叠子问题和最优子结构性质的问题，动态规划方法所耗时间往往少于朴素解法。</li><li>动态规划背后的基本思想非常简单。大致上，若要了解一个给定问题，我们需要解其不同的部分(即子问题)，再合并子问题的解以得出原问题的解。通常许多子问题非常相似，为此动态规划试图仅仅解决每个子问题一次，从而减少计算量：一旦某个给定子问题的解已经算出，则将其记忆化存储，以便下次需要同一个子问题解之时直接查表。这种做法在重复子问题的数目关于输入的规模呈指数增长时特别有用。</li><li>关于动态规划最经典的问题当属背包问题。</li><li>算法步骤：<ol><li>最优子结构性质。如果问题的最优解所包含的子问题也是最优的，我们就称该问题具有最优子结构性质(即满足最优化原理)。最优子结构性质为动态规划算法解决问题提供了重要线索。</li><li>子问题重叠性质。子问题重叠性质是指在用递归算法自顶向下对问题进行求解时，每次产生的子问题并不总是新问题，有些子问题会被重复计算多次。动态规划算法正是利用了这种子问题的重叠性质，对美一个子问题只计算一次，然后将子问题时，只是在表格中简单地查看一下结果，从而获得较高的效率。</li></ol></li></ul><h2 id="算法十：朴素贝叶斯分类算法"><a href="#算法十：朴素贝叶斯分类算法" class="headerlink" title="算法十：朴素贝叶斯分类算法"></a>算法十：朴素贝叶斯分类算法</h2><ul><li>朴素贝叶斯分类算法是一种基于贝叶斯定理的简单概率分类算法。贝叶斯分类的基础是概率推理，就是在各种条件的存在不确定，仅知其出现概率的情况下，如何完成推理和决策任务。概率推理是与确定性推理相对应的。而朴素贝叶斯分类器是基于独立假设的，即假设样本每个特征与其他特征都不相关。</li><li>朴素贝叶斯分类器依靠精确的自然概率模型，在有监督学习的样本集中能获得非常好的分类效果。在许多实际应用中，朴素贝叶斯模型参数估计使用最大似然估计方法，换言之朴素贝叶斯模型能工作并没有用到贝叶斯概率或者任何贝叶斯模型。</li><li>尽管是带着这些朴素思想和过于简单化的假设，但朴素贝叶斯分类器在很多复杂的现实情形中仍能够取得相当好的效果。</li><li>文章来源：36大数据</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;算法一：快速排序算法&quot;&gt;&lt;a href=&quot;#算法一：快速排序算法&quot; class=&quot;headerlink&quot; title=&quot;算法一：快速排序算法&quot;&gt;&lt;/a&gt;算法一：快速排序算法&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;快速排序算法是由东尼.霍尔所发展的一种排序算法。在平均状况下，排</summary>
      
    
    
    
    <category term="算法" scheme="http://example.com/categories/%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="10大基础实用算法" scheme="http://example.com/tags/10%E5%A4%A7%E5%9F%BA%E7%A1%80%E5%AE%9E%E7%94%A8%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>Django-1-7-3-Tutorial-Part-3-视图和模板</title>
    <link href="http://example.com/2015/01/27/Django-1-7-3-Tutorial-Part-3-%E8%A7%86%E5%9B%BE%E5%92%8C%E6%A8%A1%E6%9D%BF/"/>
    <id>http://example.com/2015/01/27/Django-1-7-3-Tutorial-Part-3-%E8%A7%86%E5%9B%BE%E5%92%8C%E6%A8%A1%E6%9D%BF/</id>
    <published>2015-01-27T08:46:50.000Z</published>
    <updated>2015-10-26T07:43:52.000Z</updated>
    
    <content type="html"><![CDATA[<ul><li>本教程是接着上一节教程继续的。我们继续讨论网页投票(Web-poll)应用程序，然后关注与创建公共接口–“视图”。</li></ul><h2 id="哲学"><a href="#哲学" class="headerlink" title="哲学"></a>哲学</h2><ul><li><p>一个视图是在你的Django应用中一种有特定应用功能和有一个模板的网页的“类型”。譬如，在一个博客应用中，你可能需要以下视图：</p><ul><li>博客首页–显示最新的博客</li><li>“具体”页面的入口–单独入口的固定链接</li><li>把博客按照年排序的架构页面–给定年份，按月列出所有的文章</li><li>把博客按照月排序的架构页面–给定月份，按日列出所有的文章</li><li>把博客按照日排序的架构页面–给定日期，列出所有的文章</li><li>评论操作–给指定的文章下评论</li></ul></li><li><p>在我们的投票应用中(poll)，我们已经有了以下四个页面：</p><ul><li>问题“首页”–显示最新的问题</li><li>问题“具体页”–显示一个问题文本，不能显示结果，但是提供投票表格</li><li>问题“结果页”–为指定的问题显示投票结果</li><li>投票操作–在给定的问题中投给定的选项</li></ul></li><li><p>在Django中，网页和其他的内容页是通过视图展示的。每一个视图是通过一个简单的Python功能展示的(或者方法，如果在基于类的视图下)。Django通过测试请求的URL而选择视图(更准确的说，是跟在域名后面的URL部分)。</p></li><li><p>现在你在浏览网页的时候可能看过这样的网页链接：<strong>“ME2&#x2F;Sites&#x2F;dirmod.asp?sid&#x3D;&amp;type&#x3D;gen&amp;mod&#x3D;Core+Pages&amp;gid&#x3D;A6CD4967199A42D9B65B1B”</strong>。但是更值得我们高兴的是，Django允许我们使用比以上更优雅的链接模式。</p></li><li><p>一个URL模式是一个简单的URL通常格式–譬如：<img src="/img/Django-1-7-3-tutorial/url-01.png"></p></li><li><p>要从一个URL得到一个视图，Django利用了我们熟知的’URLconfs’。一个URLconf把一个URL模式(通常被描述为正则表达式)映射到一个视图。</p></li><li><p>本节教程提供了URLconfs的基本用法，然后你可以参考<strong>django.core.urlresolvers</strong>得到更多信息。</p></li></ul><h2 id="写你的第一个视图"><a href="#写你的第一个视图" class="headerlink" title="写你的第一个视图"></a>写你的第一个视图</h2><ul><li><p>让我们开始写第一个视图吧。打开文件<strong>polls&#x2F;views.py</strong>然后写入以下python代码：</p></li><li><p><font color="green"><strong>polls&#x2F;views.py</strong></font></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> django.http <span class="keyword">import</span> HttpResponse</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">index</span>(<span class="params">request</span>):</span><br><span class="line"><span class="keyword">return</span> HttpResponse(<span class="string">&quot;Hello, world. You&#x27;re at the polls index.&quot;</span>)</span><br></pre></td></tr></table></figure></li><li><p>这可能是Django中最简单的视图了。要调用这个视图，我们需要把它映射到一个URL–然后我们就需要一个URLconf。</p></li><li><p>在polls目录下创建一个URLconf，创建一个<strong>urls.py</strong>文件。你的app目录应该看起来是这样：<br><img src="/img/Django-1-7-3-tutorial/polls-urls.png"></p></li><li><p>在<strong>polls&#x2F;urls.py</strong>文件中加入以下代码：</p></li><li><p><font color="green"><strong>polls&#x2F;urls.py</strong></font></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> django.conf.urls <span class="keyword">import</span> patterns, url</span><br><span class="line"><span class="keyword">from</span> polls <span class="keyword">import</span> views</span><br><span class="line"></span><br><span class="line">urlpatterns = patterns(<span class="string">&#x27;&#x27;</span>,</span><br><span class="line">url(<span class="string">r&#x27;^$&#x27;</span>, views.index, name=<span class="string">&#x27;index&#x27;</span>),</span><br><span class="line">)</span><br></pre></td></tr></table></figure></li><li><p>下一步就是在<strong>polls.urls</strong>模块中指定根URLconf。在<strong>mysite&#x2F;urls.py</strong>中插入一个**include()**，像这样：</p></li><li><p><font color="green"><strong>mysite&#x2F;urls.py</strong></font></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> django.conf.urls <span class="keyword">import</span> patterns, include, url</span><br><span class="line"><span class="keyword">from</span> django.contrib <span class="keyword">import</span> admin</span><br><span class="line"></span><br><span class="line">urlpatterns = patterns(<span class="string">&#x27;&#x27;</span>, </span><br><span class="line">url(<span class="string">r&#x27;^polls/&#x27;</span>, include(<span class="string">&#x27;polls.urls&#x27;</span>)),</span><br><span class="line">url(<span class="string">r&#x27;^admin/&#x27;</span>, include(admin.site.urls)),</span><br><span class="line">)</span><br></pre></td></tr></table></figure><blockquote><p><strong>和你所见的不匹配吗？</strong><br>如果你在<strong>urlpatterns</strong>定义之前就看见了**admin.autodiscover()**，你可能是在用一个和本教程不匹配的版本，你应该更改Django的版本。</p></blockquote></li><li><p>你现在可以把**首页(index)<strong>视图转换为URLconf。在你的浏览器中输入<a class="link"   href="http://localhost:8000/polls/" >http://localhost:8000/polls/<i class="fas fa-external-link-alt"></i></a>，按下Enter键，你应该可以看到文本“Hello, world. You’re at the polls index.”，它是在</strong>首页(index)**视图所定义的。</p></li><li><p><strong>url()<strong>函数有四个参数，其中两个是必须的：</strong>regex(正则表达式)<strong>和</strong>view(视图)</strong>,两个是可选的：<strong>kwargs</strong>和**name(名字)**。现在，让我们来了解一下这些参数具体是什么来的。</p></li></ul><h3 id="url-参数：regex"><a href="#url-参数：regex" class="headerlink" title="url()参数：regex"></a><strong>url()参数：regex</strong></h3><ul><li>术语<strong>regex</strong>通常是**regular expression(正则表达式)**的缩写，它是一个字符串匹配的语法规则，在这里，它是url模式的匹配。Django从第一个正则表达式开始，然后把它们造一个列表，把请求的URL和每一个正则表达式单元进行比较，然后找到匹配的那一个。</li><li>请注意，这些正则表达式不会搜寻GET和POST的参数或者域名。譬如，在请求URL<strong><a class="link"   href="http://www.example.com/myapp/**%E4%B8%AD%EF%BC%8CURLconf%E4%BC%9A%E5%AF%BB%E6%89%BE**myapp/**%E3%80%82%E8%80%8C%E5%9C%A8%E8%AF%B7%E6%B1%82URL**http://www.example.com/myapp/?page=3" >http://www.example.com/myapp/**中，URLconf会寻找**myapp/**。而在请求URL**http://www.example.com/myapp/?page=3<i class="fas fa-external-link-alt"></i></a></strong>中，URLconf也会寻找**myapp&#x2F;**。</li><li>如果你不了解正则表达式，请看<a class="link"   href="http://en.wikipedia.org/wiki/Regular_expression" >Wikipedia’s entry<i class="fas fa-external-link-alt"></i></a>或者<a href="http://docs.python.org/3/library/re.html#module-re"><strong>re</strong></a>模块的文档。另外，O’Reilly的书–Jeffrey Friedl著的《Mastering Regular Expressions》非常不错。实际上，你不需要成为<strong>正则表达式</strong>方面的专家，如果你仅仅需要知道一些简单的模式匹配的话。事实上，复杂的正则表达式有比较弱的检查能力，所以，你不太可能依赖正则表达式。</li><li>最后，性能笔记：这些正则表达式在URLconf模块加载时会被首次编译。它们非常快(只要查找的不是太复杂的正则表达式)。</li></ul><h3 id="url-参数：view"><a href="#url-参数：view" class="headerlink" title="url()参数：view"></a><strong>url()参数：view</strong></h3><ul><li>当Django匹配到了正则表达式时，Django调用指定的视图函数，第一个参数是一个<strong>HttpRequest</strong>对象，其他的参数是根据需要从正则表达式中捕捉的任意值。如果正则表达式是用简单的捕捉，值就会当成位置参数来传递；如果正则表达式是用命名捕捉，值就会被当成关键字参数来传递。我们稍后会给出例子进行说明。</li></ul><h3 id="url-参数：kwargs"><a href="#url-参数：kwargs" class="headerlink" title="url()参数：kwargs"></a><strong>url()参数：kwargs</strong></h3><ul><li>任意的关键字参数都可以传递到目标视图中的字典。在这个教程中我们不会讨论这个特性。</li></ul><h3 id="url-参数：name"><a href="#url-参数：name" class="headerlink" title="url()参数：name"></a><strong>url()参数：name</strong></h3><ul><li>对你的URL命名可以让你清楚地从Django中的任何地方中引用，特别是在模板中。这个有力的特性让你对项目中的url模式做全局的修改，当你仅仅创建了单个文件时。</li></ul><h2 id="写更多的视图"><a href="#写更多的视图" class="headerlink" title="写更多的视图"></a>写更多的视图</h2><ul><li><p>现在让我们在<strong>polls&#x2F;views.py</strong>文件中添加更多的视图。这些视图可能有小小的不同，因为它们有一个参数。</p></li><li><p><font color="green"><strong>polls&#x2F;views.py</strong></font></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">detail</span>(<span class="params">request, question_id</span>):</span><br><span class="line"><span class="keyword">return</span> HttpResponse(<span class="string">&quot;You&#x27;re looking at question %s.&quot;</span> % question_id)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">results</span>(<span class="params">request, question_id</span>):</span><br><span class="line">response = <span class="string">&quot;You&#x27;re looking at the results of question %s.&quot;</span></span><br><span class="line"><span class="keyword">return</span> HttpResponse(response % question_id)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vote</span>(<span class="params">request, question_id</span>):</span><br><span class="line"><span class="keyword">return</span> HttpResponse(<span class="string">&quot;You&#x27;re voting on question %s.&quot;</span> % question_id)</span><br></pre></td></tr></table></figure></li><li><p>把这些新的视图通过添加以下的<strong>url()<strong>调用写进</strong>polls.urls</strong>模块：</p></li><li><p><font color="green"><strong>polls&#x2F;urls.py</strong></font></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> django.conf.urls <span class="keyword">import</span> patterns, url</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> polls <span class="keyword">import</span> views</span><br><span class="line"></span><br><span class="line">urlpatterns = patterns(<span class="string">&#x27;&#x27;</span>,</span><br><span class="line"><span class="comment"># ex: /polls/</span></span><br><span class="line">url(<span class="string">r&#x27;^$&#x27;</span>, views.index, name=<span class="string">&#x27;index&#x27;</span>),</span><br><span class="line"><span class="comment"># ex: /polls/5/</span></span><br><span class="line">url(<span class="string">r&#x27;^(?P&lt;question_id&gt;\d+)/$&#x27;</span>, views.detail, name=<span class="string">&#x27;detail&#x27;</span>),</span><br><span class="line"><span class="comment"># ex: /polls/5/results/</span></span><br><span class="line">url(<span class="string">r&#x27;^(?P&lt;question_id&gt;\d+)/results/$&#x27;</span>, views.results, name=<span class="string">&#x27;results&#x27;</span>),</span><br><span class="line"><span class="comment"># ex: /polls/5/vote/</span></span><br><span class="line">url(<span class="string">r&#x27;^(?P&lt;question_id&gt;\d+)/vote/$&#x27;</span>, views.vote, name=<span class="string">&#x27;vote&#x27;</span>),</span><br><span class="line">)</span><br></pre></td></tr></table></figure></li><li><p>在浏览器中打开**”&#x2F;polls&#x2F;34&#x2F;“<strong>浏览一下。它运行</strong>detail()<strong>方法并且根据你的URL提供的ID显示你的东西。试一下</strong>“&#x2F;polls&#x2F;34&#x2F;results&#x2F;”<strong>和</strong>&#x2F;polls&#x2F;34&#x2F;vote&#x2F;**–这些会显示占位符结果和投票页面。</p></li><li><p>当某人从你的网站请求网页时–譬如，**&#x2F;polls&#x2F;34&#x2F;<strong>,Django将会加载</strong>mysite.urls<strong>模块，因为它是被</strong>ROOT_URLCONF<strong>设置所指向的。它找到名叫</strong>urlpatterns<strong>的变量然后遍历正则表达式。</strong>include()<strong>函数只是引用了其他的URLconfs。注意到关于</strong>include()<strong>方法的正则表达式没有</strong>$<strong>(字符串匹配的结束符)而只有末尾斜杠。无论何时Django遇上了</strong>include()**方法，它会发送剩余的字符串到包含的URLconf给下一步做准备，而砍掉其他的部分。</p></li><li><p>**include()<strong>背后的思想是使得URLs即插即用，用起来非常简单。由于polls在它们自己的URLconf(<strong>polls&#x2F;urls.py</strong>)中，它们可以被放在</strong>&#x2F;polls&#x2F;<strong>或者</strong>&#x2F;fun_polls&#x2F;<strong>或者</strong>&#x2F;content&#x2F;polls&#x2F;**或者其它的根路径后面，应用还是可以运行的。</p></li><li><p>如果用户去到系统中的**&#x2F;polls&#x2F;34&#x2F;**，它会发生以下事情：</p><ul><li>Django会对**^polls&#x2F;**进行匹配</li><li>然后，Django会去掉匹配的文本(<strong>“polls&#x2F;”</strong>)并且把剩下的文本<strong>34&#x2F;<strong>发送到</strong>polls.urls</strong>URLconf作进一步的操作，**34&#x2F;<strong>是匹配<img src="/img/Django-1-7-3-tutorial/reg-1.png">,然后对</strong>detail()**视图进行调用：</li><li><img src="/img/Django-1-7-3-tutorial/reg-4.png"></li></ul></li><li><p>**question_id&#x3D;’34’<strong>是来自<img src="/img/Django-1-7-3-tutorial/reg-2.png">。用圆括号把匹配到的模式文本括起来当成一个参数传到视图函数；<img src="/img/Django-1-7-3-tutorial/reg-3.png">定义了将要确定匹配模式的名字；而</strong>\d+**是一个匹配一串数字的正则表达式。</p></li><li><p>因为URL模式是一个正则表达式，它们没有任何限制。没必要添加URL烂尾，譬如**.html**,除非你想要加，然后你可以这样做：</p></li><li><p><img src="/img/Django-1-7-3-tutorial/reg-5.png"></p></li><li><p>但是不要这样做，它看起来傻傻的。</p></li></ul><h2 id="写一些起作用的视图"><a href="#写一些起作用的视图" class="headerlink" title="写一些起作用的视图"></a>写一些起作用的视图</h2><ul><li>每一个视图都应该做一到两样事情：返回一个包含请求页的内容的<strong>HttpResponse</strong>对象，或者产生一个像<strong>Http404</strong>这样的异常。剩下的就由你决定。</li><li>你的视图能够从数据库中读取记录，或者不读。它能够使用一个像Django这样的模板系统，或者第三方模板系统，又或者不用。它能够生成一个PDF文件，输出XML，飞速创建一个ZIP文件，或者任何你想要的文件，使用任何你想要的Python库。</li><li>Django想做的就是一个<strong>HttpResponse</strong>，或者一个异常。</li><li>由于方便，我们使用Django默认的数据库API，就是我们在教程1当中介绍的。下面是我们在**index()**视图中插入新的东西，它显示了系统中最新的5个投票问题，根据发布日期通过逗号隔开：</li><li><font color="green"><strong>polls&#x2F;views.py</strong></font><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> django.http <span class="keyword">import</span> HttpResponse</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> polls.models <span class="keyword">import</span> Question</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">index</span>(<span class="params">request</span>):</span><br><span class="line">latest_question_list = Question.objects.order_by(<span class="string">&#x27;-pub_date&#x27;</span>)[:<span class="number">5</span>]</span><br><span class="line">output = <span class="string">&#x27;,&#x27;</span>.join([p.question_text <span class="keyword">for</span> p <span class="keyword">in</span> latest_question_list])</span><br><span class="line"></span><br><span class="line"><span class="comment"># leave the rest of views (detail, results, vote) unchanged</span></span><br></pre></td></tr></table></figure></li><li>但还有一个问题：页面的设计是在视图硬性写定了。如果你像更改页面的设计，你需要重新编辑Python 代码。所以让我们使用Django的模板系统把设计和Python代码通过创建一个视图可调用的模板来分开。</li><li>首先，在你的<strong>polls</strong>目录下创建一个名为<strong>templates</strong>的文件。Django会在那里进行搜寻的。</li><li>Django的<strong>TEMPLATE_LOADERS</strong>设置包含一系列知道如何从不同资源中导入模板的可调用方法。其中默认的方法是<strong>django.template.loaders.app_directories.Loader</strong>，它在每一个<strong>INSTALLED_APPS</strong>中寻找一个“模板”子目录。这就是为什么Django在没有修改<strong>TEMPLATE_DIRS</strong>的情况下知道怎么找到poll模板的原因。</li></ul><blockquote><p><strong>组织模板</strong><br>我们可以把所有的模板放在一起，在一个大的模板目录中，而且它可以工作的很顺利。但是，这个模板是属于polls应用的，所以不像上一个教程中我们介绍的管理员模板那样，我们把它放在程序的模板目录而不是项目的模板目录。我们会讨论更多关于这个更多的可重用的app教程，并对其进行解释。</p></blockquote><ul><li>在你刚刚创建的<strong>template</strong>模板目录中，创建另外一个叫做<strong>polls</strong>的目录，然后再里面创建一个<strong>index.html</strong>文件。换句话说，你的模板应该是在<strong>polls&#x2F;templates&#x2F;polls&#x2F;index.html</strong>目录中。正是由于上面我们讨论的关于<strong>app_directories</strong>模板加载器是如何工作的，你可以像<strong>polls&#x2F;index.html</strong>一样通过Django简单的找到模板文件。</li></ul><blockquote><p><strong>模板命名空间</strong><br>现在我们可能不需要把我们的模板放进<strong>polls&#x2F;templates</strong>目录(而不是在<strong>polls</strong>的子目录下新建一个)，但这确实是一个坏主意。Django会选择它第一个匹配到的模板名字，如果你在不同的目录下有相同的名字的应用，Django就不会对它们进行分辨。我们应该要为Django正确指定哪一个模板，最简单的方法来保证这样的事情就是通过给它们创建命名空间。也就是说，把那些模板放进另一个为本应用命名的目录。</p></blockquote><ul><li>在模板中写进以下代码：</li><li><font color="green"><strong>polls&#x2F;templates&#x2F;polls&#x2F;index.html</strong></font><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#123;% <span class="keyword">if</span> latest_question_list %&#125;</span><br><span class="line">&lt;ul&gt;</span><br><span class="line">&#123;% <span class="keyword">for</span> question <span class="keyword">in</span> latest_question_list %&#125;</span><br><span class="line">&lt;li&gt;&lt;a href=<span class="string">&quot;/polls.&#123;&#123; question.id &#125;&#125;/&quot;</span>&gt;&#123;&#123; question.question_text &#125;&#125;&lt;/a&gt;&lt;/li&gt;</span><br><span class="line">&#123;% endfor %&#125;</span><br><span class="line">&lt;/ul&gt;</span><br><span class="line">&#123;% <span class="keyword">else</span> %&#125;</span><br><span class="line">&lt;p&gt;No polls are available.&lt;/p&gt;</span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure></li><li>现在让我们更新<strong>polls&#x2F;views.py</strong>中的视图来使用模板：</li><li><font color="green"><strong>polls&#x2F;views.py</strong></font><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> django.http <span class="keyword">import</span> HttpResponse</span><br><span class="line"><span class="keyword">from</span> django.template <span class="keyword">import</span> RequestContext, loader</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> polls.models <span class="keyword">import</span> Question</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">index</span>(<span class="params">request</span>):</span><br><span class="line">latest_question_list = Question.objects.order_by(<span class="string">&#x27;-pub_date&#x27;</span>)[:<span class="number">5</span>]</span><br><span class="line">template = loader.get_template(<span class="string">&#x27;polls/index.html&#x27;</span>)</span><br><span class="line">context = RequestionContext(request, &#123;</span><br><span class="line"><span class="string">&#x27;latest_question_list&#x27;</span>: latest_question_list,</span><br><span class="line">&#125;)</span><br><span class="line"><span class="keyword">return</span> HttpResponse(template.render(context))</span><br></pre></td></tr></table></figure></li><li>上面的代码加载了<strong>polls&#x2F;index.html</strong>模板，然后传递了一个context。context是一个匹配模板变量名到Python对象的字典。</li><li>在你的浏览器里点击**”&#x2F;polls&#x2F;“<strong>加载页面，你会看到包含Tutorial_1中的</strong>“What’s up”**问题的无序列表。这个链接指向问题详细内容页。</li></ul><h2 id="一个快捷键-render"><a href="#一个快捷键-render" class="headerlink" title="一个快捷键:render()"></a>一个快捷键:render()</h2><ul><li>这是一种常用的语法：加载一个模板，传递一个context，然后返回一个对显示模板结果的<strong>HttpResponse</strong>对象。Django提供一个快捷键。下面是完整的**index()**视图，重写：</li><li><font color="green"><strong>polls&#x2F;views.py</strong></font><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> django.shortcuts <span class="keyword">import</span> render</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> polls.models <span class="keyword">import</span> Question</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">index</span>(<span class="params">request</span>):</span><br><span class="line">lastest_question_list = Question.objects.order_by(<span class="string">&#x27;-pub_date&#x27;</span>)[:<span class="number">5</span>]</span><br><span class="line">context = &#123;<span class="string">&#x27;lastest_question_list&#x27;</span>: lastest_question_list&#125;</span><br><span class="line"><span class="keyword">return</span> render(request, <span class="string">&#x27;polls/index.html&#x27;</span>, context)</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li>既然我们搞好了所有的视图，我们不需要去导入<strong>loader,RequestContext</strong>和<strong>HttpResponse</strong>(如果你需要<strong>detail</strong>和<strong>results</strong>，<strong>vote</strong>的根方法，你需要保留<strong>HttpResponse</strong>对象)。</li><li><strong>render()<strong>方法的第一个参数是</strong>Request</strong>对象，第二个参数是一个模板名，然后第三参数是可选的，它是一个字典类型。方法返回的是一个带根据给定的context而呈现的给定的模板的<strong>HttpResponse</strong>对象。</li></ul><h2 id="报告404错误"><a href="#报告404错误" class="headerlink" title="报告404错误"></a>报告404错误</h2><ul><li>现在，让我们浏览一下问题详细视图-根据给定的poll显示问题文本的页面。这就是视图：</li><li><font color="green"><strong>polls&#x2F;views.py</strong></font><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> django.http <span class="keyword">import</span> Http404</span><br><span class="line"><span class="keyword">from</span> djang.shortcuts <span class="keyword">import</span> render</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> polls.models <span class="keyword">import</span> Question</span><br><span class="line"><span class="comment"># ...</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">detail</span>(<span class="params">request, question_id</span>):</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">question = Question.objects.get(pk = question_id)</span><br><span class="line"><span class="keyword">except</span> Question.DoesNotExist:</span><br><span class="line"><span class="keyword">raise</span> Http404(<span class="string">&quot;Question does not exist&quot;</span>)</span><br><span class="line"><span class="keyword">return</span> render(request, <span class="string">&#x27;polls/detail.html&#x27;</span>, &#123;<span class="string">&#x27;question&#x27;</span>: question&#125;)</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li>新的概念：如果问题的请求ID不存在，那么视图就会产生要给404异常。</li><li>我们会在稍后讨论你能够在<strong>polls&#x2F;detail.html</strong>模板中放入什么，但是如果你想快速地运行上面的例子，文件应该包含如下：</li><li><font color="green"><strong>polls&#x2F;templates&#x2F;polls&#x2F;detail.html</strong></font><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#123; question &#125;&#125;</span><br></pre></td></tr></table></figure></li><li>会让你现在开始。</li></ul><h3 id="快捷键：get-object-or-404"><a href="#快捷键：get-object-or-404" class="headerlink" title="快捷键：get_object_or_404()"></a>快捷键：get_object_or_404()</h3><ul><li>这是一种常用的语法：如果对象不存在，利用<strong>get()<strong>方法报告一个</strong>Http404</strong>异常。Django提供一个快捷键。下面是<strong>detial</strong>视图，重写：</li><li><font color="green"><strong>polls&#x2F;views.py</strong></font><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> django.shortcuts <span class="keyword">import</span> get_object_or_404, render</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> polls.models <span class="keyword">import</span> Question</span><br><span class="line"><span class="comment"># ...</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">detail</span>(<span class="params">request, question_id</span>):</span><br><span class="line">question = get_object_or_404(Question, pk = question_id)</span><br><span class="line"><span class="keyword">return</span> render(request, <span class="string">&#x27;polls/detail.html&#x27;</span>, &#123;<span class="string">&#x27;question&#x27;</span>:question&#125;)</span><br></pre></td></tr></table></figure></li><li><strong>get_object_or_404()<strong>函数的第一个参数是要给Django模型，然后有数个关键字参数，它们是被传递到模型管理的</strong>get()<strong>函数。如果对象不存在，它会报告</strong>Http404</strong>异常。</li></ul><blockquote><p><strong>Philosophy</strong><br>为什么我们在更高的水平上使用帮助函数<strong>get_object_or_404()<strong>而不是自动获取</strong>ObjectDoesNotExist</strong>异常，或者通过模型API报告<strong>Http404</strong>异常而不是<strong>ObjectDoesNotExist</strong>异常。<br>因为这样会把模型层结合视图层。Django的一个最重要的设计目标是保持低耦合。在Django.shortcuts模型中引入了一些强耦合。</p></blockquote><ul><li>还有一个<strong>get_list_or_404()<strong>函数，它就像</strong>get_object_or_404()<strong>函数一样工作。用</strong>filter()<strong>而不是</strong>get()<strong>方法。它会报告</strong>Http404</strong>异常，如果列表是空的话。</li></ul><h2 id="使用模板系统"><a href="#使用模板系统" class="headerlink" title="使用模板系统"></a>使用模板系统</h2><ul><li>回到我们的poll应用的<strong>detail()<strong>视图。给定context变量</strong>question</strong>，这就是<strong>polls&#x2F;detail.html</strong>模板的代码：<br> <img src="/img/Django-1-7-3-tutorial/detail-01.png"></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;本教程是接着上一节教程继续的。我们继续讨论网页投票(Web-poll)应用程序，然后关注与创建公共接口–“视图”。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;哲学&quot;&gt;&lt;a href=&quot;#哲学&quot; class=&quot;headerlink&quot; title=&quot;哲学&quot;&gt;&lt;/a&gt;哲学</summary>
      
    
    
    
    <category term="Django" scheme="http://example.com/categories/Django/"/>
    
    
    <category term="Django-Models" scheme="http://example.com/tags/Django-Models/"/>
    
  </entry>
  
  <entry>
    <title>Django-1-7-3-Tutorial-Part-2-管理站点</title>
    <link href="http://example.com/2015/01/19/Django-1-7-3-Tutorial-Part-2-%E7%AE%A1%E7%90%86%E7%AB%99%E7%82%B9/"/>
    <id>http://example.com/2015/01/19/Django-1-7-3-Tutorial-Part-2-%E7%AE%A1%E7%90%86%E7%AB%99%E7%82%B9/</id>
    <published>2015-01-19T01:27:02.000Z</published>
    <updated>2015-10-26T07:38:30.000Z</updated>
    
    <content type="html"><![CDATA[<ul><li>本节教程接着<a href="">Part-1-模型</a>继续，我们继续网络民意调查(Web-poll)应用，然后把焦点放在Django的自生成的管理员站点。<blockquote><p><strong>哲学</strong><br>为你的员工或客户自动生成管理员站点，让它可以很方便的对内容进行增删改是一件不需要太多创新的比较乏味的事情。<br>Django是在一个新闻工作室的环境下编写的，“内容出版商”站点和“公共”站点之间有比较清晰的界限。站点管理员利用系统添加新闻故事，事件，体育等等，然后内容会显示在公共站点。Django为站点管理员编辑内容创建了统一的接口。</p></blockquote></li></ul><h2 id="新建一个管理用户"><a href="#新建一个管理用户" class="headerlink" title="新建一个管理用户"></a>新建一个管理用户</h2><ul><li>首先我们需要创建一个能够登入管理站点的用户。运行以下命令：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ python manage.py createsuperuser</span><br></pre></td></tr></table></figure></li><li>然后输入你想要的用户名：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Username: admin</span><br></pre></td></tr></table></figure></li><li>然后继续输入你的邮箱地址：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Email address: admin@example.com</span><br></pre></td></tr></table></figure></li><li>最后一步就是输入你的密码。你需要输入2次来确认你的密码：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Password: **********</span><br><span class="line">Password (again): *********</span><br><span class="line">Superuser created successfully.</span><br></pre></td></tr></table></figure></li><li>我的截图：<br><img src="/img/Django-1-7-3-tutorial/createUser.png"></li></ul><h2 id="打开开发者服务器"><a href="#打开开发者服务器" class="headerlink" title="打开开发者服务器"></a>打开开发者服务器</h2><ul><li>Django管理站点默认是激活的。让我们开启开发者服务器对它一探究竟吧。</li><li>回想一下<a href="">Part-1-模型</a>，你是怎么开始服务器的：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ python manage.py runserver</span><br></pre></td></tr></table></figure></li><li>现在，打开浏览器，然后再输入以下地址<a class="link"   href="http://127.0.0.1:8000/admin/" >http://127.0.0.1:8000/admin/<i class="fas fa-external-link-alt"></i></a>。你就可以看到管理员登陆界面了：<br><img src="/img/Django-1-7-3-tutorial/admin-login.png"></li><li>由于页面是自动<a class="link"   href="https://docs.djangoproject.com/en/1.7/topics/i18n/translation/" >翻译<i class="fas fa-external-link-alt"></i></a>的，所以可能登陆页面是以你的语言显示的，取决于你的浏览器的设置了。<blockquote><p><strong>和你的不同吗？</strong><br>如果你的登陆界面打不开，而是出现了这样的错误：</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ImportError at/admin/</span><br><span class="line">cannot <span class="keyword">import</span> name patterns</span><br><span class="line">...</span><br></pre></td></tr></table></figure></li></ul><h2 id="进入管理站点"><a href="#进入管理站点" class="headerlink" title="进入管理站点"></a>进入管理站点</h2><ul><li>现在，利用你刚才设置的账户和密码登录管理员站点，你应该看到这样的页面：<br><img src="/img/Django-1-7-3-tutorial/welcome-page.png"></li><li>你应该会看到两种可编辑的内容：<strong>Groups</strong>和<strong>Users</strong>。它们是由<strong>django.contrib.auth</strong>提供的，这个认证框架是由Django支持的。</li></ul><h2 id="使投票-poll-应用在管理站点中被修改"><a href="#使投票-poll-应用在管理站点中被修改" class="headerlink" title="使投票(poll)应用在管理站点中被修改"></a>使投票(poll)应用在管理站点中被修改</h2><ul><li>但是我们的投票(poll)应用在哪里？它并不再管理首页上展示。</li><li>只需要做一件事情：我们需要告知管理站点<strong>Question</strong>对象有一个管理接口。打开<strong>polls&#x2F;admin.py</strong>文件，然后对它们进行以以下编辑：</li><li><font color = "green"><strong>polls&#x2F;admin.py</strong></font><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> django.contrib <span class="keyword">import</span> admin</span><br><span class="line"><span class="keyword">from</span> polls.models <span class="keyword">import</span> Question</span><br><span class="line"></span><br><span class="line">admin.site.register(Question)</span><br></pre></td></tr></table></figure></li></ul><h2 id="探索免费的管理功能"><a href="#探索免费的管理功能" class="headerlink" title="探索免费的管理功能"></a>探索免费的管理功能</h2><ul><li>既然我们注册了<strong>Question</strong>，那么Django就会在管理首页进行显示了。<br><img src="/img/Django-1-7-3-tutorial/poll-resigster.png"></li><li>点击<strong>Question</strong>。你就进入了question的修改列表。这个页面显示了数据库中的所有的问题，然后让你选择哪个进行修改。这里显示了问题“What’s up?”在上一部分教程中：<br><img src="/img/Django-1-7-3-tutorial/question-01.png"></li><li>点击“What’s up?”，然后编辑它：<br><img src="/img/Django-1-7-3-tutorial/question-02.png"></li><li>这里要注意的是：<ul><li>这个表格是根据<strong>Question</strong>模型自动生成的。</li><li>这个不同的模型的域类型(<strong>DateTimeField,CharField</strong>)对应到合适的HTML输入小部件。每一个字段类型明白自己在Django的管理站点中如何展示。</li><li>每一个<strong>DateTimeField</strong>都有一个免费的Javascript快捷方式。日期(Date)会有一个“今天(today)”的快捷方式和日历弹框选择，然后时间(Time)会有一个“现在(now)”的快捷方式和一个便利的弹框，它有常用时间的输入。</li></ul></li><li>页面的底部给你一些选项：<ul><li>保存(save)—保存修改和返回当前对象类型的修改列表页面。</li><li>保存并且继续编辑(Save and continue editing)—保存修改并且重载当前对象的管理页面。</li><li>保存并且继续添加(Save and add another)—保存修改并且为当前对象加载一个新的空白的表格。</li><li>删除(Detele)—显示一个删除确认页面。</li></ul></li><li>如果发布日期(“Date published”)的值和你在第一部分创建的时间不相同，那很有可能你没有设置正确的时区。修改时区，然后重载当前页面看看是否准确。</li><li>通过点击“今天”和“现在”快捷键来修改“发布日期”，然后点击“保存并且继续编辑”。点击上方的“历史记录”，你会看到一个通过Django管理对当前对象做的所有修改的列表页面，有时间戳和修改者的用户名：<br><img src="/img/Django-1-7-3-tutorial/history.png"></li></ul><h2 id="添加相关的对象"><a href="#添加相关的对象" class="headerlink" title="添加相关的对象"></a>添加相关的对象</h2><ul><li>OK，我们有了<strong>Question</strong>管理页面。但是一个<strong>Question</strong>有多个<strong>Choices</strong>，而管理页面不显示choices.</li><li>但是。</li><li>有两种方法可以解决这个问题。第一个通过用户admin注册<strong>Choice</strong>就像我们注册<strong>Question</strong>一样。非常简单：</li><li><font color="green"><strong>polls&#x2F;admin.py</strong></font><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> django.contrib <span class="keyword">import</span> admin</span><br><span class="line"><span class="keyword">from</span> polls.models <span class="keyword">import</span> Choice, Question</span><br><span class="line"><span class="comment">#...</span></span><br><span class="line">admin.site.register(Choice)</span><br></pre></td></tr></table></figure></li><li>现在，<strong>Choices</strong>在Django中是一个可用的选项。<strong>添加choice（Add choice）</strong>的页面应该像这样：<br><img src="/img/Django-1-7-3-tutorial/choice-01.png"></li><li>在这个表格当中，<strong>Question</strong>属性是一个选择框(select box)，它包含了数据库当中的每一个问题(question)。Django知道**外键(ForeignKey)<strong>在管理页面中应该是一个</strong><select>**框。在我们的例子中，只有一个问题。</li><li>注意到”Add Another”这个链接到下一个“Question”。每一个带<strong>外键</strong>的对象都会自动生成这个链接。当你点击”Add Another”这个链接时，你可以得到一个带有“Add question”表格的弹出窗口。如果你在那个窗口中添加一个问题，然后点击“保存”按钮，Django会把问题保存到数据库，并且动态把它添加为一个你所见到的在“Add choice”表格中可选的选项。</li><li>但实际上，这并不是一个有效的添加<strong>Choice</strong>对象到系统的方法。如果能在创建<strong>Question</strong>的同时直接添加多个<strong>Choice</strong>，那样更好。让我们来试试吧。</li><li>为<strong>Choice</strong>模型删除<strong>register()<strong>方法。然后，编辑</strong>Question</strong>注册代码如下：</li><li><font color="green"><strong>polls&#x2F;admin.py</strong></font><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> django.contrib <span class="keyword">import</span> admin</span><br><span class="line"></span><br><span class="line"><span class="comment"># Register your models here.</span></span><br><span class="line"><span class="keyword">from</span> polls.models <span class="keyword">import</span> Question, Choice</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChoiceInline</span>(admin.StackedInline):</span><br><span class="line"><span class="string">&quot;&quot;&quot;docstring for ChoiceInline&quot;&quot;&quot;</span></span><br><span class="line">model = Choice</span><br><span class="line">extra = <span class="number">3</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">QuestionAdmin</span>(admin.ModelAdmin):</span><br><span class="line">fieldsets = [</span><br><span class="line">(<span class="literal">None</span>, &#123;<span class="string">&#x27;fields&#x27;</span>:[<span class="string">&#x27;question_text&#x27;</span>]&#125;),</span><br><span class="line">(<span class="string">&#x27;Date information&#x27;</span>, &#123;<span class="string">&#x27;fields&#x27;</span>:[<span class="string">&#x27;pub_date&#x27;</span>], <span class="string">&#x27;classes&#x27;</span>:[<span class="string">&#x27;collapse&#x27;</span>]&#125;),</span><br><span class="line">]</span><br><span class="line">inlines = [ChoiceInline]</span><br><span class="line"></span><br><span class="line">admin.site.register(Question,QuestionAdmin)</span><br></pre></td></tr></table></figure></li><li>它告诉Django：<strong>Choice</strong>对象在<strong>Question</strong>管理页面上边界。默认情况下，提供3个choice填写属性。</li><li>加载“Add question”页面来看一下：<br><img src="/img/Django-1-7-3-tutorial/choice-02.png"></li><li>它是这样子工作的：相关的Choice有三个可填—由<strong>Extra</strong>指定的，每一次你返回一个已经创建好的对象的<strong>Change</strong>页面，你又可以得到3个额外的choice可填。</li><li>在3个choice的底部，你可以找到一个“Add another Choice”链接。如果你点击它，一个新增的choice就可诞生。如果你像删除新增的choice，那么你可以点击这个choice的右上角的X。注意原来的3个choice是不可删除的。<br><img src="/img/Django-1-7-3-tutorial/choice-03.png"></li><li>但是有一个小问题，它占用了太多的屏幕空间。所以，Django提供了一个列表的形式显示相关的行内对象，你只需要修改<strong>ChoiceInline</strong>代码：</li><li><font color="green"><strong>polls&#x2F;admin.py</strong></font><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ChoiceInline</span>(admin.TabularInline):</span><br><span class="line"><span class="comment">#....</span></span><br></pre></td></tr></table></figure></li><li>用<strong>TabularInline</strong>而非<strong>StackedInline</strong>，相关的对象就会以表格的形式显示得更简洁。<br><img src="/img/Django-1-7-3-tutorial/choice-04.png"></li><li>注意到以上还有一个删除的按钮，它可以删除新增的行。</li></ul><h2 id="自定义管理表格"><a href="#自定义管理表格" class="headerlink" title="自定义管理表格"></a>自定义管理表格</h2><ul><li>对你还没写的代码感到惊叹吧。通过<strong>admin.site.register(Question)<strong>来注册</strong>Question</strong>模型，Django能够构建一个默认的表格表现形式。通常，你会想自定义自己的管理表单，你只要通过注册告知Django你想怎么注册这个对象就OK了。</li><li>通过重新排序表格中字段，我们来看看效果。修改**admin.site.register(Question)**这一行：</li><li><font color="green"><strong>polls&#x2F;admin.py</strong></font><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> django.contrib <span class="keyword">import</span> admin</span><br><span class="line"><span class="keyword">from</span> polls.models <span class="keyword">import</span> Question</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">QuestionAdmin</span>(admin.ModelAdmin):</span><br><span class="line">    fields = [<span class="string">&#x27;pub_date&#x27;</span>, <span class="string">&#x27;question_text&#x27;</span>]</span><br><span class="line"></span><br><span class="line">admin.site.register(Question, QuestionAdmin)</span><br></pre></td></tr></table></figure></li><li>你遵循这种模式—创建一个模型管理对象，然后把它当成第二参数传给<strong>admin.site.register()</strong>—任何时候都可以修改。</li><li>以上的修改是把“发布日期”(Date published)放在了“问题”(Question)这个字段的前面：<br><img src="/img/Django-1-7-3-tutorial/question-03.png"></li><li>虽然两个字段看起来不够酷，但是对于数十个字段的表格来说，选择一个符合直觉的排序是一个非常重要的实用细节。</li><li>说到数十个字段的表格，你可能想到把一个表格分离成多个属性(字段).</li><li><font color="green"><strong>polls&#x2F;admin.py</strong></font><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> django.contrib <span class="keyword">import</span> admin</span><br><span class="line"><span class="keyword">from</span> polls.models <span class="keyword">import</span> Question</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">QuestionAdmin</span>(admiin.ModelAdmin):</span><br><span class="line">fieldsets = [</span><br><span class="line">(Node, &#123;<span class="string">&#x27;fields&#x27;</span>:[<span class="string">&#x27;Question_text&#x27;</span>]&#125;),</span><br><span class="line">(<span class="string">&#x27;Date information&#x27;</span>, &#123;<span class="string">&#x27;fields&#x27;</span>:[<span class="string">&#x27;pub_date&#x27;</span>]&#125;),</span><br><span class="line">]</span><br><span class="line">admin.site.register(Question, QuestionAdmin)</span><br></pre></td></tr></table></figure></li><li>在**属性(fieldsets)**中的每一个元组的第一个元素是这个属性的标题。以上的表格就是这样：<br><img src="/img/Django-1-7-3-tutorial/question-04.png"></li><li>你可以为属性(fieldsets)注入任意的HTML类。Django提供了一个**折叠(collapse)**类用于展示默认是折叠的特定的属性。如果你有一个包含了许多个不常用的属性的很长的表格，那么这个类是非常有用的：</li><li><font color="green"><strong>polls&#x2F;admin.py</strong></font><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> django.contrib <span class="keyword">import</span> admin</span><br><span class="line"><span class="keyword">from</span> polls.models <span class="keyword">import</span> Question</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">QuestionAdmin</span>(admin.ModelAdmin):</span><br><span class="line">fieldsets = [</span><br><span class="line">(<span class="literal">None</span>, &#123;<span class="string">&#x27;fields&#x27;</span>:[<span class="string">&#x27;question_text&#x27;</span>]&#125;),</span><br><span class="line">(<span class="string">&#x27;Date information&#x27;</span>, &#123;<span class="string">&#x27;fields&#x27;</span>:[<span class="string">&#x27;pub_date&#x27;</span>], <span class="string">&#x27;classes&#x27;</span>:[<span class="string">&#x27;collapse&#x27;</span>]&#125;),</span><br><span class="line">]</span><br><span class="line">admin.site.register(Question, QuestionAdmin)</span><br></pre></td></tr></table></figure><br><img src="/img/Django-1-7-3-tutorial/question-05.png"></li></ul><h2 id="添加相关的对象-1"><a href="#添加相关的对象-1" class="headerlink" title="添加相关的对象"></a>添加相关的对象</h2><ul><li>OK，我们有了<strong>Question</strong>管理页面。但是一个<strong>Question</strong>有多个<strong>Choices</strong>，而管理页面不显示choices.</li><li>但是。</li><li>有两种方法可以解决这个问题。第一个通过用户admin注册<strong>Choice</strong>就像我们注册<strong>Question</strong>一样。非常简单：</li><li><font color="green"><strong>polls&#x2F;admin.py</strong></font><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> django.contrib <span class="keyword">import</span> admin</span><br><span class="line"><span class="keyword">from</span> polls.models <span class="keyword">import</span> Choice, Question</span><br><span class="line"><span class="comment">#...</span></span><br><span class="line">admin.site.register(Choice)</span><br></pre></td></tr></table></figure></li><li>现在，<strong>Choices</strong>在Django中是一个可用的选项。<strong>添加choice（Add choice）</strong>的页面应该像这样：<br><img src="/img/Django-1-7-3-tutorial/choice-01.png"></li><li>在这个表格当中，<strong>Question</strong>属性是一个选择框(select box)，它包含了数据库当中的每一个问题(question)。Django知道**外键(ForeignKey)<strong>在管理页面中应该是一个</strong><select>**框。在我们的例子中，只有一个问题。</li><li>注意到”Add Another”这个链接到下一个“Question”。每一个带<strong>外键</strong>的对象都会自动生成这个链接。当你点击”Add Another”这个链接时，你可以得到一个带有“Add question”表格的弹出窗口。如果你在那个窗口中添加一个问题，然后点击“保存”按钮，Django会把问题保存到数据库，并且动态把它添加为一个你所见到的在“Add choice”表格中可选的选项。</li><li>但实际上，这并不是一个有效的添加<strong>Choice</strong>对象到系统的方法。如果能在创建<strong>Question</strong>的同时直接添加多个<strong>Choice</strong>，那样更好。让我们来试试吧。</li><li>为<strong>Choice</strong>模型删除<strong>register()<strong>方法。然后，编辑</strong>Question</strong>注册代码如下：</li><li><font color="green"><strong>polls&#x2F;admin.py</strong></font><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> django.contrib <span class="keyword">import</span> admin</span><br><span class="line"></span><br><span class="line"><span class="comment"># Register your models here.</span></span><br><span class="line"><span class="keyword">from</span> polls.models <span class="keyword">import</span> Question, Choice</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChoiceInline</span>(admin.StackedInline):</span><br><span class="line"><span class="string">&quot;&quot;&quot;docstring for ChoiceInline&quot;&quot;&quot;</span></span><br><span class="line">model = Choice</span><br><span class="line">extra = <span class="number">3</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">QuestionAdmin</span>(admin.ModelAdmin):</span><br><span class="line">fieldsets = [</span><br><span class="line">(<span class="literal">None</span>, &#123;<span class="string">&#x27;fields&#x27;</span>:[<span class="string">&#x27;question_text&#x27;</span>]&#125;),</span><br><span class="line">(<span class="string">&#x27;Date information&#x27;</span>, &#123;<span class="string">&#x27;fields&#x27;</span>:[<span class="string">&#x27;pub_date&#x27;</span>], <span class="string">&#x27;classes&#x27;</span>:[<span class="string">&#x27;collapse&#x27;</span>]&#125;),</span><br><span class="line">]</span><br><span class="line">inlines = [ChoiceInline]</span><br><span class="line"></span><br><span class="line">admin.site.register(Question,QuestionAdmin)</span><br></pre></td></tr></table></figure></li><li>它告诉Django：<strong>Choice</strong>对象在<strong>Question</strong>管理页面上边界。默认情况下，提供3个choice填写属性。</li><li>加载“Add question”页面来看一下：<br><img src="/img/Django-1-7-3-tutorial/choice-02.png"></li><li>它是这样子工作的：相关的Choice有三个可填—由<strong>Extra</strong>指定的，每一次你返回一个已经创建好的对象的<strong>Change</strong>页面，你又可以得到3个额外的choice可填。</li><li>在3个choice的底部，你可以找到一个“Add another Choice”链接。如果你点击它，一个新增的choice就可诞生。如果你像删除新增的choice，那么你可以点击这个choice的右上角的X。注意原来的3个choice是不可删除的。<br><img src="/img/Django-1-7-3-tutorial/choice-03.png"></li><li>但是有一个小问题，它占用了太多的屏幕空间。所以，Django提供了一个列表的形式显示相关的行内对象，你只需要修改<strong>ChoiceInline</strong>代码：</li><li><font color="green"><strong>polls&#x2F;admin.py</strong></font><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ChoiceInline</span>(admin.TabularInline):</span><br><span class="line"><span class="comment">#....</span></span><br></pre></td></tr></table></figure></li><li>用<strong>TabularInline</strong>而非<strong>StackedInline</strong>，相关的对象就会以表格的形式显示得更简洁。<br><img src="/img/Django-1-7-3-tutorial/choice-04.png"></li><li>注意到以上还有一个删除的按钮，它可以删除新增的行。</li></ul><h2 id="自定义管理修改列表"><a href="#自定义管理修改列表" class="headerlink" title="自定义管理修改列表"></a>自定义管理修改列表</h2><ul><li>既然Question管理页面开启来不错，让我们对“修改列表”页面做一些更改–让一页显示系统中的所有问题。</li><li>现在的页面是：<br><img src="/img/Django-1-7-3-tutorial/choice-05.png"></li><li>默认情况下，Django显示每个对象的<strong>str()<strong>内容。但是有时候我们想显示单独的每个属性。这样做的话，就要用到</strong>list_display</strong>管理选项，它是一个可显示为列的属性的元组：</li><li><font color="green"><strong>polls&#x2F;admin.py</strong></font><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">QuestionAdmin</span>(admin.ModelAdmin):</span><br><span class="line"><span class="comment">#...</span></span><br><span class="line">list_display = (<span class="string">&#x27;question_text&#x27;</span>,<span class="string">&#x27;pub_date&#x27;</span>)</span><br></pre></td></tr></table></figure></li><li>为了更好的展示，让我们在自定义的方法表格中添加<strong>was_published_recently</strong>:</li><li><font color="green"><strong>polls&#x2F;admin.py</strong></font><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">QuestionAdmin</span>(admin.ModelAdmin):</span><br><span class="line"><span class="comment">#...</span></span><br><span class="line">list_display = (<span class="string">&#x27;question_text&#x27;</span>, <span class="string">&#x27;pub_date&#x27;</span>, <span class="string">&#x27;was_published_recently&#x27;</span>)</span><br></pre></td></tr></table></figure></li><li>现在问题修改页面变成这样子了：<br><img src="/img/Django-1-7-3-tutorial/choice-06.png"></li><li>你可以点击列头来对这些值进行排序–出了<strong>was_published_recently</strong>列头，因为通过武断的方法输出来进行排序是不支持的。还有注意到<strong>was_published_recently</strong>列头，默认的，是方法的名字(通过空格来强调)，每一行都包含输出的字符串的表示。</li><li>你可以通过给这个方法加一些属性来改善它(在<strong>polls&#x2F;models.py</strong>文件中)，如下：</li><li><font color="green"><strong>polls&#x2F;models.py</strong></font><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Question</span>(models.Model):</span><br><span class="line"><span class="comment">#...</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">was_publised_recently</span>(<span class="params">self</span>):</span><br><span class="line"><span class="keyword">return</span> self.pub_date &gt;= timezone.now() - datetime.timedelta(days=<span class="number">1</span>)</span><br><span class="line">was_published_recently.admin_order_field = <span class="string">&#x27;pub_date&#x27;</span></span><br><span class="line">was_published_recently.boolean = <span class="literal">True</span></span><br><span class="line">was_published_recently.short_description = <span class="string">&#x27;Published recently ?&#x27;</span></span><br></pre></td></tr></table></figure></li><li>参考更多消息，请看<a class="link"   href="https://docs.djangoproject.com/en/1.7/ref/contrib/admin/#django.contrib.admin.ModelAdmin.list_display" >list_display<i class="fas fa-external-link-alt"></i></a></li><li>再次编辑你的<strong>polls&#x2F;admin.py</strong>文件，为<strong>Question</strong>修改列表页面添加一个改进：用<strong>list_filter</strong>过滤，添加以下行道<strong>QuestioAdmin</strong>文件中：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">list_filter = [<span class="string">&#x27;pub_date&#x27;</span>]</span><br></pre></td></tr></table></figure></li><li>过滤显示的类型取决于你在过滤的属性的类型。因为<strong>pub_date</strong>是一个<strong>DateTimeField</strong>类型，Django自动给出合适的过滤选项：“Any date”,”Today”,”Past 7 days”,”This month”,”This year”.</li><li>这些看起来不错，让我们添加一些查找功能：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">search_field = [<span class="string">&#x27;question_text&#x27;</span>]</span><br></pre></td></tr></table></figure></li><li>这个会在修改页面的上方添加一个查询框。当输入一些关键字时，Django会查询<strong>question_text</strong>域。你还可以添加其他的任意域–因为在数据库中用到了<strong>LIKE</strong>查询，将查询的数量减少了，这样查询的速度更快。</li><li>现在是时候给你的修改列表来个分页显示的功能。默认是每一页显示100条。<strong>Change list pagination, search boxes, filters, date-hierarchies</strong>和<strong>column-header-ordering</strong>都可以工作。</li></ul><h2 id="自定义管理look和feel"><a href="#自定义管理look和feel" class="headerlink" title="自定义管理look和feel"></a>自定义管理look和feel</h2><ul><li>明显的，把“Django administration”放在每一个管理页面的头部是不合理的。它只是文本占位而已。</li><li>用Django的模板核能修改，但是，Django管理只是供Django自身支持，而且它的接口也是使用Django自身你的模板系统。</li></ul><h3 id="自定义你的项目模板"><a href="#自定义你的项目模板" class="headerlink" title="自定义你的项目模板"></a>自定义你的项目模板</h3><ul><li><p>在你的项目目录中创建一个模板(<strong>templates</strong>)目录。模板能够在Django可使用的任何的文件系统中。(你的服务器运行什么，Django就运行什么）。但是，把你的模板文件夹放在项目目录下是一个很方便的选择。</p></li><li><p>打开你的设置文件(<strong>mysite&#x2F;settings.py</strong>文件，记住)，然后添加一个TEMPLATE_DIRS设置。</p></li><li><p><font color="green"><strong>mysite&#x2F;settings.py</strong></font><br><br><img src="/img/Django-1-7-3-tutorial/1.png"></p><blockquote><p><strong>Django的源代码在哪？</strong><br>如果你在你的硬盘上找不到你的Django的源代码，运行一下口令：<br><img src="/img/Django-1-7-3-tutorial/django-source.png"></p></blockquote></li><li><p>然后，编辑文件，换掉，包括花括号，换成自己应用的名字。如下：<br><br><img src="/img/Django-1-7-3-tutorial/poll-admin.png"></p></li><li><p>我们用这种方法向你们传授了怎么覆盖模板。在实际的项目中，你可能更喜欢用<strong>django.contrib.admin.AdminSite.site_header</strong>的属性来进行定制，因为它更容易。</p></li><li><p><img src="http://res.cloudinary.com/djqbxphzo/image/upload/v1445845066/django-part2_zbt9g1.png"></p></li></ul><h3 id="自定义你的应用模板"><a href="#自定义你的应用模板" class="headerlink" title="自定义你的应用模板"></a>自定义你的应用模板</h3><ul><li>聪明的读者可能会问：如果<strong>TEMPLATE_DIRS</strong>默认是空的，Django是怎么找到默认的管理模板的？答案是：默认情况下，作为后备，Django自动在每个应用程序包中查找<strong>templates&#x2F;<strong>子目录。(不要忘记</strong>django.contrib.admin</strong>也是一个应用程序)。</li><li>我们的投票(poll)应用并不复杂，而且不需要自定义的管理模板。但是当它变得复杂而且需要对Django的标准管理模板做一些修改以适应新的功能时，修改应用程序模板就会比修改项目中的其他文件要更加小心了。这样，你可以把Poll应用程序添加到任何新的项目中，并且假设它会找到需要的自定义模板。</li><li>关于Django怎么找到它的模板文件的更多信息，请参考<a class="link"   href="https://docs.djangoproject.com/en/1.7/ref/templates/api/#template-loaders" >template loader documentation<i class="fas fa-external-link-alt"></i></a>。</li></ul><h2 id="自定管理首页"><a href="#自定管理首页" class="headerlink" title="自定管理首页"></a>自定管理首页</h2><ul><li>在一个类似的笔记中，你可能想要自定义Django首页的外观和感觉。</li><li>默认情况下，它会根据<strong>INSTALLED_APPS</strong>文件中所注册的程序进行展示，以字母的排序。你可能想要对布局进行重要的修改。毕竟，首页可能是最重要的管理页面，而且它应该很容易被使用的。</li><li>要修改的模板是<strong>admin&#x2F;index.html</strong>文件。(和上面对<strong>admin&#x2F;base_site.html</strong>文件做的一样—把它从默认路径复制到你所在的路径。)编辑文件，你可以看到一个额模板变量<strong>app_list</strong>。这个变量包含了所有安装在Django中的app。你可以不用它，但你可以对它进行重新编码，把链接指向你最想要的特定对象的管理页面。还有，如果你现在看不懂模板语言，不要担心，我们将在下一节中讨论模板语言。</li><li>当你熟悉了管理站点，请读下一小节，在投票程序的页面设计上下功夫。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;本节教程接着&lt;a href=&quot;&quot;&gt;Part-1-模型&lt;/a&gt;继续，我们继续网络民意调查(Web-poll)应用，然后把焦点放在Django的自生成的管理员站点。&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;哲学&lt;/strong&gt;&lt;br&gt;为你的员工或客户自动生成</summary>
      
    
    
    
    <category term="Django" scheme="http://example.com/categories/Django/"/>
    
    
    <category term="Django-Models" scheme="http://example.com/tags/Django-Models/"/>
    
  </entry>
  
  <entry>
    <title>Django-1.7.3-Tutorial-Part-1-模型</title>
    <link href="http://example.com/2015/01/16/Django-1-7-3-Tutorial-Part-1-%E6%A8%A1%E5%9E%8B/"/>
    <id>http://example.com/2015/01/16/Django-1-7-3-Tutorial-Part-1-%E6%A8%A1%E5%9E%8B/</id>
    <published>2015-01-16T02:46:52.000Z</published>
    <updated>2015-01-18T05:38:44.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="创建你的第一个Django-app-Part-1"><a href="#创建你的第一个Django-app-Part-1" class="headerlink" title="创建你的第一个Django app-Part 1"></a>创建你的第一个Django app-Part 1</h1><ul><li>让我们从简单的例子开始吧。</li><li>通过这个教程，我们将快速学习投票(poll)应用的创建。</li><li>环境：windows 8 32 bits + Python 2.7.5 + Django 1.7.3</li><li>它包含两个部分：<ul><li>一个供人们查看和进行投票的公开的站点。</li><li>一个管理员站点，可以让你进行添加，修改和查询投票。</li></ul></li><li>我们假设你已经装好了Django.你可以通过以下命令查看你安装的版本。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ python -c <span class="string">&quot;import django; print(django.get_version())&quot;</span></span><br></pre></td></tr></table></figure></li><li>如果你成功安装了Django，你就会看到版本号，否则，你就会得到一个错误信息：”No module named django”.</li><li>我的Django信息如下：<br><img src="/img/Django-1-7-3-tutorial/get_version.png"></li></ul><h2 id="创建项目"><a href="#创建项目" class="headerlink" title="创建项目"></a>创建项目</h2><ul><li>如果你是第一次使用Django，那么你应该注意一些初始化的设置。也就是说，你需要一些自生成的代码来构建一个Django项目，包括Django实例的设置文件，譬如数据库配置文件，Django指定选项和应用指定的设置。</li><li>从命令行中切换到你想把项目存储的目录，然后输入以下命令:<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ django-admin.py startproject mysite</span><br></pre></td></tr></table></figure></li><li>在当前目录下就会生成一个mysite的目录。如果没有，请查看<a class="link"   href="https://docs.djangoproject.com/en/1.7/faq/troubleshooting/#troubleshooting-django-admin-py" >问题反馈<i class="fas fa-external-link-alt"></i></a></li></ul><blockquote><p><strong>笔记</strong><br>请注意命名，不能和Python或者Django组件中的关键字重名，特别的，你不能使用django或者test。</p></blockquote><ul><li>通过startproject命令创建的目录如下：<br><img src="/img/Django-1-7-3-tutorial/dir-startproject.png"></li></ul><blockquote><p><strong>和你建的目录不同？</strong><br>默认项目布局最近有所改变。如果你看到一个’flat’布局(里面没有mysite&#x2F;目录)，你可能使用的Django和本教程的版本不同。请移步。</p></blockquote><ul><li>目录路径解释：<ul><li>外层mysite&#x2F;：你的项目的根目录。它的名字可以随意更改。</li><li>manage.py文件：它是一个和Django进行多样化交互的命令行工具。你可以从以下链接查看详细内容<a class="link"   href="https://docs.djangoproject.com/en/1.7/ref/django-admin/" >django-admin.py and manage.py<i class="fas fa-external-link-alt"></i></a></li><li>内层mysite&#x2F;：它是项目的真正的python包。名字不可随意更改，因为它是在其他地方可供导入的(例如：mysite.urls)</li><li>mysite&#x2F;<strong>init</strong>.py：一个空文件，它的作用是标注自己是一个python包。</li><li>mysite&#x2F;settings.py：Django项目的设置或配置。详细可查看<a class="link"   href="https://docs.djangoproject.com/en/1.7/topics/settings/" >Django settings<i class="fas fa-external-link-alt"></i></a></li><li>mysite&#x2F;urls.py：对Django项目的URL声明，就像是你的Django网站的目录列表。详细可查看<a class="link"   href="https://docs.djangoproject.com/en/1.7/topics/http/urls/" >URL dispatcher<i class="fas fa-external-link-alt"></i></a></li><li>mysite&#x2F;wsgi.py：它是配置WSGI服务器的入口点。详细可见：<a class="link"   href="https://docs.djangoproject.com/en/1.7/howto/deployment/wsgi/" >How to deploy with WSGI<i class="fas fa-external-link-alt"></i></a></li></ul></li></ul><h2 id="数据库配置"><a href="#数据库配置" class="headerlink" title="数据库配置"></a>数据库配置</h2><ul><li><p>现在，编辑mysite&#x2F;settings.py文件。它是一个普通的Python模块，用模块级变量表示Django设置。</p></li><li><p>默认情况下，配置是用SQLite。如果你不熟悉数据库，或者你只想玩玩Django,这是最快捷的选择。SQLite包含在Python中，所以不需要你安装。</p></li><li><p>如果你想用其他数据库，安装相应<a class="link"   href="https://docs.djangoproject.com/en/1.7/topics/install/#database-installation" >数据库绑定<i class="fas fa-external-link-alt"></i></a>,然后修改DATABASES中的默认选项来匹配你的数据库连接设置：</p><ul><li><strong>ENGINE</strong>-数据库引擎，SQLite(默认)：**’django.db.backends.sqlite3’<strong>;postgresql：</strong>‘django.db.backends.postgresql_psycopg2’<strong>；mysql：</strong>‘django.db.backends.mysql’**；Oracle： **’django.db.backends.oracle’**，或其他。</li><li><strong>NAME</strong>-数据库名称。如果你用SQLite,那么他是电脑上的一个文件，这样的话，<strong>NAME</strong>应该是一个绝对路径，包括文件名。默认值是**os.path.join(BASE_DIR, ‘db.sqlite3’)**，它是存储在项目路径下的文件。</li></ul></li><li><p>如果你不用SQLite，那么你需要添加<strong>USER</strong>,<strong>PASSWORD</strong>,<strong>HOST</strong>。详细可见：<a class="link"   href="https://docs.djangoproject.com/en/1.7/ref/settings/#std:setting-DATABASES" >DATABASES<i class="fas fa-external-link-alt"></i></a>。</p></li></ul><blockquote><p><strong>笔记</strong><br>如果你在使用PostgreSQL或者MySQL，你必须要创建好数据库。通过命令**CREATE DATABASE database_name;**。<br>如果你在使用SQLite,那么它会自动创建，必须手动创建。</p></blockquote><ul><li><p>当你在编辑mysite&#x2F;settings.py时，请把<strong>TIME_ZONE</strong>设置为自己的时区。</p></li><li><p>另外，文件开头的<strong>INSTALLED_APPS</strong>配置，它Django实例中被激活的Django应用的名字。Apps可以被多个项目使用，你可以把Apps打包和发布给其他项目使用。</p></li><li><p>默认情况下，<strong>INSTALLED_APPS</strong>配置包含Django中的apps，如下：</p><ul><li><strong>django.contrib.admin</strong>-管理员站点，你在Part2中会用到。</li><li><strong>django.contrib.auth</strong>-认证系统</li><li><strong>django.contrib.contenttypes</strong>-一个内容类型的框架</li><li><strong>django.contrib.sessions</strong>-session框架</li><li><strong>django.contrib.messages</strong>-messaging框架</li><li><strong>django.contrib.staticfiles</strong>-管理静态文件的框架</li></ul></li><li><p>这些apps默认添加的，你可以根据自己需求修改。</p></li><li><p>这些apps中可能要用到数据库表，所以，我们应该先要在数据库中创建表，然后再使用。命令如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ python manage.py migrate</span><br></pre></td></tr></table></figure></li><li><p><strong>migrate</strong>命令会查看<strong>INSTALLED_APPS</strong>配置，然后根据<strong>mysite&#x2F;settings.py</strong>文件创建一些需要的数据库表，并把数据库迁移到相应的应用中。n你可以查看信息：运行数据库客户端，在命令行中输入\dt (PostgreSQL), SHOW TABLES; (MySQL), or .schema (SQLite)。</p></li></ul><h2 id="发布到服务器"><a href="#发布到服务器" class="headerlink" title="发布到服务器"></a>发布到服务器</h2><ul><li>验证你的项目是否可运行，在外层mysite目录下，运行一下命令：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ python manage.py runserver</span><br></pre></td></tr></table></figure></li><li>你可以看到以下输出(我的版本如下)：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">January 16, 2015 - 14:18:47</span><br><span class="line">Django version 1.7.3, using settings &#x27;mysite.settings&#x27;</span><br><span class="line">Starting development server at http://127.0.0.1:8000/</span><br><span class="line">Quit the server with CTRL-BREAK.</span><br></pre></td></tr></table></figure></li><li>你已经把项目成功发布到服务器上了，它是一个用纯python实现的轻量级的Web server。它已经被包含到Django当中，方便我们进行快速的开发。</li><li>它不可以用于商用，因为能力有限。我们是开发框架而不是服务器。</li><li>现在打开浏览器，输入”127.0.0.1:8000&#x2F;“，你就可以访问到你的项目页面了。效果如下：<br><img src="/img/Django-1-7-3-tutorial/worked.png"></li></ul><blockquote><p><strong>修改端口</strong><br>默认端口是8000，如果你想修改，可以按如下格式发布项目</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ python mange.py runserver <span class="number">8080</span></span><br></pre></td></tr></table></figure><blockquote><p>如果你想修改服务器的IP，如下格式：</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ python manage.py runserver <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>:<span class="number">8000</span></span><br></pre></td></tr></table></figure><blockquote><p>详细文档参考<a class="link"   href="https://docs.djangoproject.com/en/1.7/ref/django-admin/#django-admin-runserver" >runserver<i class="fas fa-external-link-alt"></i></a></p></blockquote><blockquote><p>服务器自动加载，不用重新发布项目。</p></blockquote><h2 id="创建模型-models"><a href="#创建模型-models" class="headerlink" title="创建模型(models)"></a>创建模型(models)</h2><ul><li><p>现在你项目的基本环境已经搭建好，你可以开始做事了。</p></li><li><p>在Django中创建的app都有相同的目录结构，但是Django已经用过工具自动生成了，而不必你操心，你只要专注于写代码就好了。</p><blockquote><p>Projects VS apps<br>项目和app之间有什么不同呢？一个app表示网站程序中的一个功能，譬如，一个网路博客系统，一个公开记录或公共投票的数据库应用。而一个项目(project)往往是app的集合，几个app组成一个project，另外，一个app可以被多个项目包含。</p></blockquote></li><li><p>如果你的python环境已经配置好，那么你的app可以在任何地方创建。这里我们把polls应用创建在manage.py的旁边，所以，它可以被当成自己的顶级模块导入，而不是mysite的子模块。</p></li><li><p>创建app,请到manage.py所在目录下，执行命令：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ python manage.py startapp polls</span><br></pre></td></tr></table></figure></li><li><p>创建了一个polls目录，结构如下：<br><img src="/img/Django-1-7-3-tutorial/dir-polls.png"></p></li><li><p>这个目录包含polls应用。</p></li><li><p>通过Django写数据库网页应用的第一步是定义自己的模块(models)-主要的是，你的数据库布局，加上额外的元数据。</p></li></ul><blockquote><p>哲学<br>一个模型是一个独立的，明确的数据资源。它包含主要的字段和你存储的数据的行为。Django遵循<a class="link"   href="https://docs.djangoproject.com/en/1.7/misc/design-philosophies/#dry" >DRY原则<i class="fas fa-external-link-alt"></i></a>。目的是从一个地方定义和导出数据。<br>还包括迁移，不像Ruby On Rails，例如，模型中的数据可以全部迁移，但它只不过是Django中的一个历史记录，可以随时回滚到当前适应的模型。</p></blockquote><ul><li>在简单的投票(polls)应用中，我们创建2个模型：<strong>Question</strong>和<strong>Choice</strong>。<strong>Question</strong>有一个问题和发表日期。<strong>Choice</strong>有两个域：选择文本和投票计数器。每一个<strong>Choice</strong>关联一个<strong>Question</strong>。</li><li>这些概念都能通过简单的Python类实现。编辑<strong>polls&#x2F;models.py</strong>文件，如下：</li><li><font color="green">polls&#x2F;models.py</font><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> django.db <span class="keyword">import</span> models</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Question</span>(models.Model):</span><br><span class="line">    question_text = models.CharField(max_length=<span class="number">200</span>)</span><br><span class="line">    pub_date = models.DateTimeField(<span class="string">&#x27;date published&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Choice</span>(models.Model):</span><br><span class="line">    question = models.ForeignKey(Question)</span><br><span class="line">    choice_text = models.CharField(max_length=<span class="number">200</span>)</span><br><span class="line">    votes = models.IntegerField(default=<span class="number">0</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li>代码非常简单明了。每个<strong>模型</strong>都是继承类**<a class="link"   href="https://docs.djangoproject.com/en/1.7/ref/models/instances/#django.db.models.Model" >django.db.models.Model<i class="fas fa-external-link-alt"></i></a><strong>。每个</strong>模型<strong>都有一些类变量，其中每个变量都代表数据库中的一个</strong>字段**。</li><li>每个<strong>字段</strong>都是一个<strong>字段<a class="link"   href="https://docs.djangoproject.com/en/1.7/ref/models/fields/#django.db.models.Field" >(Field)<i class="fas fa-external-link-alt"></i></a>类</strong>的实例–譬如，<a class="link"   href="https://docs.djangoproject.com/en/1.7/ref/models/fields/#django.db.models.CharField" >CharField<i class="fas fa-external-link-alt"></i></a>代表字符域，<a class="link"   href="https://docs.djangoproject.com/en/1.7/ref/models/fields/#django.db.models.DateTimeField" >DateTimeField<i class="fas fa-external-link-alt"></i></a>代表数据库实时间。这样Django就知道每个字段是什么类型的。</li><li>每个域实例的名字(譬如<strong>question_text</strong>或者<strong>pub_date</strong>)就是字段名称，它是机器能够识别的形式。字段的值会用python代码表示，数据库就会把字段名称当成一个列名。</li><li>你还可以为每个字段起一个易于让人读懂的名字。在Django中是支持的，而且也可以记录到文档中。如果你美誉定义这个名字，那么Django就会用机器识别的名字。例如，我们只为<strong>Question.pub_date</strong>定义一个易于让人都懂的名字。对于模型中的其他字段，机读和人读的名字是一样的。</li><li>一些字段类中有写必需的参数，例如<strong>CharField</strong>，我们必须给它指定一个最大长度**(max_length)**。它不仅仅需要数据库模式，还需要验证的，后面我们就会将到。</li><li>一个字段还可以有多个可选的参数，譬如，我们把vote的默认值设为0.</li><li>最后，要定义一个关系，用<strong>ForeignKey</strong>，即是外键。它向Django表明每个<strong>Choice</strong>关联一个<strong>Question</strong>。Django支持多种数据库映射关系：多对一，多对多，一对一。</li></ul><h2 id="激活模型-Activating-models"><a href="#激活模型-Activating-models" class="headerlink" title="激活模型(Activating models)"></a>激活模型(Activating models)</h2><ul><li><p>上面一小段代码给了Django很多的信息。通过代码，Django可以做到：</p><ul><li>为这个app创建一个数据库模式(<strong>CREATE TABLE 语句</strong>)</li><li>创建一个Python数据库可用API，用于使用<strong>Question</strong>和<strong>Choice</strong>对象。</li></ul></li><li><p>但是我们先要告知项目polls已经安装了。</p><blockquote><p><strong>哲学</strong><br>Django的app是可插的(像USB一样，适配多台电脑)：你的app可以插入到多个项目当中，你也可以发布app，这样它(app)就不用绑定到Django中用于安装了。</p></blockquote></li><li><p>再一次编辑<strong>mysite&#x2F;settings.py</strong>文件，然后修改<strong>INSTALLED_APPS</strong>的内容，让它包含’<strong>polls</strong>‘，修改后的文件是：</p></li><li><p><font color="green">mysite&#x2F;settings.py</font></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">INSTALLED_APPS = (</span><br><span class="line">    <span class="string">&#x27;django.contrib.admin&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;django.contrib.auth&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;django.contrib.contenttypes&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;django.contrib.sessions&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;django.contrib.messages&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;django.contrib.staticfiles&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;polls&#x27;</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure></li><li><p>现在Django知道应该包含polls这个app了。让我们运行另外一个命令：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ python manage.py makemigrations polls</span><br></pre></td></tr></table></figure></li><li><p>你应该看到以下的输出：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Migrations for &#x27;polls&#x27;:</span><br><span class="line">  0001_initial.py:</span><br><span class="line">    - Create model Choice</span><br><span class="line">    - Create model Question</span><br><span class="line">    - Add field question to choice</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>通过<strong>makemigrations</strong>口令，你在告诉Django你的模型有了修改(这样，你就新建了一个模型)，你希望修改转存的过程当成迁移。</p></li><li><p>Migrations记录着你对模型做了什么修改(也即是数据库模式)-它们只是硬盘上的文件。你可以读取你新模型的migration如果你喜欢，它保存在<strong>polls&#x2F;migrations&#x2F;0001_initial.py</strong>文件当中。不要担心，你不需要每当Django创建一个的时候就读取一次，但它还是可编辑的，当你想对它进行修改的时候。</p></li><li><p>有一个口令可以帮你运行migration并且自动管理你的数据库模式，它是<strong>migrate</strong>，我们就要将到它了，但首先，让我们看一下migration会运行什么样的SQL代码。<strong>sqlmigrate</strong>口令得到migration的名字并且返回它们的SQL。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ python manage.py sqlmigrate polls 0001</span><br></pre></td></tr></table></figure></li><li><p>你应该会看到以下相似的代码：(我们已经把代码格式化了，为了让我们更易读懂它)</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">BEGIN</span>;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> polls_question (</span><br><span class="line">    &quot;id&quot; serial <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">PRIMARY</span> KEY,</span><br><span class="line">    &quot;question_text&quot; <span class="type">varchar</span>(<span class="number">200</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    &quot;pub_date&quot; <span class="type">timestamp</span> <span class="keyword">with</span> <span class="type">time</span> zone <span class="keyword">NOT</span> <span class="keyword">NULL</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> polls_choice (</span><br><span class="line">    &quot;id&quot; serial <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">PRIMARY</span> KEY,</span><br><span class="line">    &quot;question_id&quot; <span class="type">integer</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    &quot;choice_text&quot; <span class="type">varchar</span>(<span class="number">200</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    &quot;votes&quot; <span class="type">integer</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> INDEX polls_choice_7aa0f6ee <span class="keyword">ON</span> &quot;polls_choice&quot; (&quot;question_id&quot;);</span><br><span class="line"></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> &quot;polls_choice&quot;</span><br><span class="line">  <span class="keyword">ADD</span> <span class="keyword">CONSTRAINT</span> polls_choice_question_id_246c99a640fbbd72_fk_polls_question_id</span><br><span class="line">    <span class="keyword">FOREIGN</span> KEY (&quot;question_id&quot;)</span><br><span class="line">    <span class="keyword">REFERENCES</span> &quot;polls_question&quot; (&quot;id&quot;)</span><br><span class="line">    DEFERRABLE INITIALLY DEFERRED;</span><br><span class="line"><span class="keyword">COMMIT</span>;</span><br></pre></td></tr></table></figure></li><li><p>注意一下内容：</p><ul><li>确切的输出会和你用的数据库而有所不同。上面的例子是用PostgreSQL生成的。</li><li>表名是自动取app的名字加上模型的名字(小写格式)，如polls_question和polls_choice。(你可以自己更改)</li><li>主见(IDs)是自增长的，你也可以自行修改。</li><li>按照惯例，Django会在外键字段名字后面加上**_id**,(当然这个你也可以修改)。</li><li>外键关系是通过<strong>FOREIGN KEY</strong>这个约束来清晰定义的。不要担心不同的部分，它仅仅是告知PostgreSQL在结束事务之前不要强行实施外键。</li><li>它是根据你用的数据库来适配的，所以数据库指定的域类型，好像，自动适配<strong>auto_increment</strong>(MySQL),<strong>serial</strong>(PostgreSQL)，或者<strong>integer primary key autoincrement</strong>(SQLite)，给字段名加引号是一样的，加单引号或双引号。</li><li><strong>sqlmigrate</strong>口令并不会真正在你的数据库上运行migtaration-只是把它打印到屏幕上，让你知道Django需要什么SQL。知道Django正在做什么或者你拥有可以修改SQL资格的数据库管理员是非常有用的。</li></ul></li><li><p>如果你有兴趣，你也可以运行<strong>python manage.py check</strong>口令，它会检测你的项目是否有问题或者创建数据库是否顺利。</p></li><li><p>现在，再次运行<strong>migrate</strong>来创建你数据库上的模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Operations to perform:</span><br><span class="line">  Apply <span class="built_in">all</span> migrations: admin, contenttypes, polls, auth, sessions</span><br><span class="line">Running migrations:</span><br><span class="line">  Applying polls<span class="number">.0001</span>_initial... OK</span><br></pre></td></tr></table></figure></li><li><p><strong>migrate</strong>口令处理所有那些没被处理的migrations。(Django通过你数据库当中的特殊表<strong>django_migrations</strong>来跟踪那些被处理了或者那些没有处理)</p></li><li><p><strong>migrations</strong>非常强大，而且当你在开发你的项目时，它可以让你随着时间变化修改你的模型，而不需要删除当前的数据库去创建一个新的。我们稍后再对这部分做深入研究，现在，请记住以下三步来对你的模型进行修改：</p><ul><li>修改模型(在<strong>models.py</strong>文件中)</li><li>运行<strong>python manage.py makemigrations</strong>来为这些修改创建migrations</li><li>运行<strong>python manage.py migrate</strong>把这些修改应用(apply)到数据库</li></ul></li><li><p>为什么make和apply这两步要分开执行呢？原因是你要首先提交migrations到你的版本控制系统，然后在把它们和你的app一起执行。这样会不仅会令你的开发更容易，还便于其他的开发者使用和再次开发。</p></li><li><p>阅读<a class="link"   href="https://docs.djangoproject.com/en/1.7/ref/django-admin/" >django-admin.py documentation<i class="fas fa-external-link-alt"></i></a>得到<strong>manage.py</strong>工具类的更详细的信息。</p></li></ul><h2 id="玩转API"><a href="#玩转API" class="headerlink" title="玩转API"></a>玩转API</h2><ul><li>现在，让我们投进可交互的Python shell，玩一下Django提供给我们的免费的API。进入Python Shell，用这个命令：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ python manage.py shell</span><br></pre></td></tr></table></figure></li><li>我们用python manage.py而不用python的原因是<strong>manage.py</strong>设置了<strong>DJANGO_SETTINGS_MODULE</strong>的环境变量，也就是说，Django和python的路径都加入了你的<strong>mysite&#x2F;settings.py</strong>文件中。</li></ul><blockquote><p><strong>跳过manage.py(Bypassing manage.py)</strong><br>如果你不想使用<strong>manage.py</strong>，没问题，只需要把<strong>DJANGO_SETTINGS_MODULE</strong>的环境变量设置到<strong>mysite.settings</strong>中，新开一个纯净的Python shell，然后设置Django：</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> django</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>django.setup()</span><br></pre></td></tr></table></figure><blockquote><p>如果这样报了一个<strong>AttributeError</strong>错误，那么你现在使用的是一个不匹配的Django版本。请更换不同的Django版本。<br>你必须在manage.py的目录下运行<strong>python</strong>，或者确保你的目录加入了Python路径，这样<strong>import mysite</strong>才起作用。<br>更多详情，请看<a class="link"   href="https://docs.djangoproject.com/en/1.7/ref/django-admin/" >django-admin.py documentation<i class="fas fa-external-link-alt"></i></a></p></blockquote><ul><li><p>当你进入了shell，可以探索[database API](database API:)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">In [<span class="number">1</span>]: <span class="keyword">from</span> polls.models <span class="keyword">import</span> Question, Choice <span class="comment"># Import the model classes we just wrote</span></span><br><span class="line"><span class="comment"># No questions are in the system yet.</span></span><br><span class="line">In [<span class="number">2</span>]: Question.objects.<span class="built_in">all</span>()</span><br><span class="line">Out[<span class="number">2</span>]: []</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a new Question.</span></span><br><span class="line"><span class="comment"># Support for time zones is enabled in the default settings file, so Django experts a datatime with tzinfo for </span></span><br><span class="line"><span class="comment"># pub_date.Use timezone.now()</span></span><br><span class="line"><span class="comment"># Instead of datatime.datetime.now() and it will do the right thing. </span></span><br><span class="line">In [<span class="number">3</span>]: <span class="keyword">from</span> django.utils <span class="keyword">import</span> timezone</span><br><span class="line"></span><br><span class="line">In [<span class="number">4</span>]: q = Question(question_text=<span class="string">&quot;What&#x27;s new?&quot;</span>, pub_date = timezone.now())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Save the object into the database. You have to call save() explicitly.</span></span><br><span class="line">In [<span class="number">5</span>]: q.save()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now it has an ID. Note that this might say &quot;1L&quot; instead of &quot;1&quot;, depending on which database you&#x27;re using. That&#x27;s no biggie; </span></span><br><span class="line"><span class="comment"># it just means your database backend prefers to returns to return integers as Python long integer objects.</span></span><br><span class="line">In [<span class="number">6</span>]: q.<span class="built_in">id</span></span><br><span class="line">Out[<span class="number">6</span>]: <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Access model field values via Python attributes.</span></span><br><span class="line">In [<span class="number">7</span>]: q.question_text</span><br><span class="line">Out[<span class="number">7</span>]: <span class="string">&quot;What&#x27;s new?&quot;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">8</span>]: q.pub_date</span><br><span class="line">Out[<span class="number">8</span>]: datetime.datetime(<span class="number">2015</span>, <span class="number">1</span>, <span class="number">18</span>, <span class="number">2</span>, <span class="number">22</span>, <span class="number">53</span>, <span class="number">431000</span>, tzinfo=&lt;UTC&gt;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Change values by changing the attributes, then calling save().</span></span><br><span class="line">In [<span class="number">9</span>]: q.question_text = <span class="string">&quot;What&#x27;s up?&quot;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">10</span>]: q.save()</span><br><span class="line"></span><br><span class="line"><span class="comment"># objects.all() displays all the questions in the database.</span></span><br><span class="line">In [<span class="number">11</span>]: Question.objects.<span class="built_in">all</span>()</span><br><span class="line">Out[<span class="number">11</span>]: [&lt;Question: Question <span class="built_in">object</span>&gt;]</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>等一下，**&lt;Question: Question object&gt;<strong>似乎对这个对象来说表现很差。我们可以这样来修正它，修改</strong>Question<strong>模型(在</strong>polls&#x2F;models.py<strong>文件中)，为</strong>Question<strong>和</strong>Choice<strong>分别添加一个</strong><strong>unicode</strong>**方法(就像java中重写toString()方法一样)。</p></li><li><p><font color="green">polls&#x2F;models.py</font></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> django.db <span class="keyword">import</span> models</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Question</span>(models.Model):</span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__unicode__</span>(<span class="params">self</span>):              <span class="comment"># __str__ on Python 3</span></span><br><span class="line">        <span class="keyword">return</span> self.question_text</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Choice</span>(models.Model):</span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__unicode__</span>(<span class="params">self</span>):              <span class="comment"># __str__ on Python 3</span></span><br><span class="line">        <span class="keyword">return</span> self.choice_text</span><br></pre></td></tr></table></figure></li><li><p>为你的模型添加__unicode__()方法非常重要，不仅仅方便于你和Python进行交互，还方便通过Django自动生成的管理员对对象的展现。</p><blockquote><p><strong><strong>str</strong>()方法还是__unicode__()方法</strong><br>在Python 3，就简单的用**<strong>str</strong>()<strong>方法<br>在Python 2中，你应该定义</strong><strong>unicode</strong>()<strong>方法返回的是</strong>unicode<strong>值。Django模型有一个默认的</strong><strong>str</strong>()<strong>方法，它调用了</strong><strong>unicode</strong>()<strong>方法并且把结果转化成了一个UTF-8字节型字符串。也就是说</strong><strong>unicode</strong>(p)<strong>方法返回的是一个Unicode字符串，而</strong>str(p)<strong>返回的是一个字节型的字符串，编码格式是UTF-8。Python刚好相反：</strong>object<strong>有一个</strong><strong>unicode</strong>()<strong>方法，它调用了</strong><strong>str</strong>()**方法，并把结果解释成一个ASCII的字节型的字符串。这些不同很容易混淆。<br>如果你觉得以上内容很混乱，那请直接用Python 3吧。</p></blockquote></li><li><p>看完了一般的Python方法，让我们添加一个自定义的方法，说明一下：</p></li><li><p><font color="green">polls&#x2F;models.py</font></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> django.db <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> django.utils <span class="keyword">import</span> timezone</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Question</span>(models.Model):</span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">was_published_recently</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.pub_date &gt;= timezone.now() - datetime.timedelta(days=<span class="number">1</span>)</span><br></pre></td></tr></table></figure></li><li><p>注意到加入了<strong>import datetime</strong>和<strong>from django.utils import timezone</strong>，请参考Python的标准<strong>datetime</strong>模型和从<strong>django.utils.timezone</strong>中了解到Django相关的时区工具类。如果你还没熟悉控制Python中的时区，你可以参考这里<a class="link"   href="https://docs.djangoproject.com/en/1.7/topics/i18n/timezones/" >time zone support docs<i class="fas fa-external-link-alt"></i></a>。</p></li><li><p>保存修改后，通过<strong>python manage.py shell</strong>打开一个新的Python shell交互:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> polls.models <span class="keyword">import</span> Question, Choice</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make sure our __str__() addition worked.</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Question.objects.<span class="built_in">all</span>()</span><br><span class="line">[&lt;Question: What<span class="string">&#x27;s up?&gt;]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># Django provides a rich database lookup API that&#x27;</span>s entirely driven by</span><br><span class="line"><span class="comment"># keyword arguments.</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Question.objects.<span class="built_in">filter</span>(<span class="built_in">id</span>=<span class="number">1</span>)</span><br><span class="line">[&lt;Question: What<span class="string">&#x27;s up?&gt;]</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; Question.objects.filter(question_text__startswith=&#x27;</span>What<span class="string">&#x27;)</span></span><br><span class="line"><span class="string">[&lt;Question: What&#x27;</span>s up?&gt;]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get the question that was published this year.</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> django.utils <span class="keyword">import</span> timezone</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>current_year = timezone.now().year</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Question.objects.get(pub_date__year=current_year)</span><br><span class="line">&lt;Question: What<span class="string">&#x27;s up?&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># Request an ID that doesn&#x27;</span>t exist, this will <span class="keyword">raise</span> an exception.</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Question.objects.get(<span class="built_in">id</span>=<span class="number">2</span>)</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">    ...</span><br><span class="line">DoesNotExist: Question matching query does <span class="keyword">not</span> exist.</span><br><span class="line"></span><br><span class="line"><span class="comment"># Lookup by a primary key is the most common case, so Django provides a</span></span><br><span class="line"><span class="comment"># shortcut for primary-key exact lookups.</span></span><br><span class="line"><span class="comment"># The following is identical to Question.objects.get(id=1).</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Question.objects.get(pk=<span class="number">1</span>)</span><br><span class="line">&lt;Question: What<span class="string">&#x27;s up?&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># Make sure our custom method worked.</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; q = Question.objects.get(pk=1)</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; q.was_published_recently()</span></span><br><span class="line"><span class="string">True</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># Give the Question a couple of Choices. The create call constructs a new</span></span><br><span class="line"><span class="string"># Choice object, does the INSERT statement, adds the choice to the set</span></span><br><span class="line"><span class="string"># of available choices and returns the new Choice object. Django creates</span></span><br><span class="line"><span class="string"># a set to hold the &quot;other side&quot; of a ForeignKey relation</span></span><br><span class="line"><span class="string"># (e.g. a question&#x27;</span>s choice) which can be accessed via the API.</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>q = Question.objects.get(pk=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Display any choices from the related object set -- none so far.</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>q.choice_set.<span class="built_in">all</span>()</span><br><span class="line">[]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create three choices.</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>q.choice_set.create(choice_text=<span class="string">&#x27;Not much&#x27;</span>, votes=<span class="number">0</span>)</span><br><span class="line">&lt;Choice: Not much&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>q.choice_set.create(choice_text=<span class="string">&#x27;The sky&#x27;</span>, votes=<span class="number">0</span>)</span><br><span class="line">&lt;Choice: The sky&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = q.choice_set.create(choice_text=<span class="string">&#x27;Just hacking again&#x27;</span>, votes=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Choice objects have API access to their related Question objects.</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c.question</span><br><span class="line">&lt;Question: What<span class="string">&#x27;s up?&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># And vice versa: Question objects get access to Choice objects.</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; q.choice_set.all()</span></span><br><span class="line"><span class="string">[&lt;Choice: Not much&gt;, &lt;Choice: The sky&gt;, &lt;Choice: Just hacking again&gt;]</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; q.choice_set.count()</span></span><br><span class="line"><span class="string">3</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># The API automatically follows relationships as far as you need.</span></span><br><span class="line"><span class="string"># Use double underscores to separate relationships.</span></span><br><span class="line"><span class="string"># This works as many levels deep as you want; there&#x27;</span>s no limit.</span><br><span class="line"><span class="comment"># Find all Choices for any question whose pub_date is in this year</span></span><br><span class="line"><span class="comment"># (reusing the &#x27;current_year&#x27; variable we created above).</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Choice.objects.<span class="built_in">filter</span>(question__pub_date__year=current_year)</span><br><span class="line">[&lt;Choice: Not much&gt;, &lt;Choice: The sky&gt;, &lt;Choice: Just hacking again&gt;]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Let&#x27;s delete one of the choices. Use delete() for that.</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = q.choice_set.<span class="built_in">filter</span>(choice_text__startswith=<span class="string">&#x27;Just hacking&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c.delete()</span><br></pre></td></tr></table></figure></li><li><p>关于更多信息，请看</p></li><li><p>[Accessing related objects](Accessing related objects),</p></li><li><p><a class="link"   href="https://docs.djangoproject.com/en/1.7/topics/db/queries/#field-lookups-intro" >Field lookups<i class="fas fa-external-link-alt"></i></a>,</p></li><li><p><a class="link"   href="https://docs.djangoproject.com/en/1.7/topics/db/queries/" >Database API reference<i class="fas fa-external-link-alt"></i></a>.</p></li><li><p>如果你熟悉了API，那么请读下一篇<a href="">Part2-Django’s automatic admin working</a>.</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;创建你的第一个Django-app-Part-1&quot;&gt;&lt;a href=&quot;#创建你的第一个Django-app-Part-1&quot; class=&quot;headerlink&quot; title=&quot;创建你的第一个Django app-Part 1&quot;&gt;&lt;/a&gt;创建你的第一个Django </summary>
      
    
    
    
    <category term="Django" scheme="http://example.com/categories/Django/"/>
    
    
    <category term="Django-Models" scheme="http://example.com/tags/Django-Models/"/>
    
  </entry>
  
  <entry>
    <title>SVM入门系列博文-转自Jasper&#39;s Java Jacal-备份-毕设系列</title>
    <link href="http://example.com/2015/01/08/SVM%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%97%E5%8D%9A%E6%96%87-%E8%BD%AC%E8%87%AAJasper-s-Java-Jacal-%E5%A4%87%E4%BB%BD-%E6%AF%95%E8%AE%BE%E7%B3%BB%E5%88%97/"/>
    <id>http://example.com/2015/01/08/SVM%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%97%E5%8D%9A%E6%96%87-%E8%BD%AC%E8%87%AAJasper-s-Java-Jacal-%E5%A4%87%E4%BB%BD-%E6%AF%95%E8%AE%BE%E7%B3%BB%E5%88%97/</id>
    <published>2015-01-08T03:15:11.000Z</published>
    <updated>2015-01-08T11:05:16.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="写在前面的话"><a href="#写在前面的话" class="headerlink" title="写在前面的话"></a>写在前面的话</h2><ul><li>本文是一个备份，转自：<a class="link"   href="http://www.blogjava.net/zhenandaci/" >Jasper’s Java Jacal<i class="fas fa-external-link-alt"></i></a></li><li>以下是原文。请细赏！</li></ul><h2 id="SVM入门（一）之SVM的八股简介"><a href="#SVM入门（一）之SVM的八股简介" class="headerlink" title="SVM入门（一）之SVM的八股简介"></a>SVM入门（一）之SVM的八股简介</h2><ul><li>支持向量机(Support Vector Machine)是Cortes和Vapnik于1995年首先提出的，它在解决<font color="red"><strong>小样本、非线性及高维模式识别</strong></font>中表现出许多特有的优势，并能够推广应用到函数拟合等其他机器学习问题中[10]。</li><li>支持向量机方法是建立在<font color="red"><strong>统计学习理论的VC维理论和结构风险最小原理</strong></font>基础上的，根据有限的样本信息在模型的复杂性（即对特定训练样本的学习精度，Accuracy）和学习能力（即无错误地识别任意样本的能力）之间寻求最佳折衷，以期获得最好的推广能力[14]（或称泛化能力）。</li><li>以上是经常被有关SVM 的学术文献引用的介绍，有点八股，我来逐一分解并解释一下。</li></ul><h3 id="传统机器学习与统计机器学习"><a href="#传统机器学习与统计机器学习" class="headerlink" title="@传统机器学习与统计机器学习"></a>@传统机器学习与统计机器学习</h3><ul><li>Vapnik是统计机器学习的大牛，这想必都不用说，他出版的《Statistical Learning Theory》是一本完整阐述统计机器学习思想的名著。在该书中详细的论证了统计机器学习之所以区别于传统机器学习的本质，就在于统计机器学习能够精确的给出学习效果，能够解答需要的样本数等等一系列问题。与统计机器学习的精密思维相比，传统的机器学习基本上属于摸着石头过河，用传统的机器学习方法构造分类系统完全成了一种技巧，一个人做的结果可能很好，另一个人差不多的方法做出来却很差，缺乏指导和原则。</li></ul><h3 id="VC维"><a href="#VC维" class="headerlink" title="@VC维"></a>@VC维</h3><ul><li>所谓<font color="red"><strong>VC维是对函数类的一种度量，可以简单的理解为问题的复杂程度，VC维越高，一个问题就越复杂</strong></font>。正是因为SVM关注的是VC维，后面我们可以看到，SVM解决问题的时候，和样本的维数是无关的（甚至样本是上万维的都可以，这使得SVM很适合用来解决文本分类的问题，当然，有这样的能力也因为引入了核函数）。</li></ul><h3 id="结构风险最小"><a href="#结构风险最小" class="headerlink" title="@结构风险最小"></a>@结构风险最小</h3><ul><li><font color="red"><strong>结构风险最小</strong></font>听上去文绉绉，其实说的也无非是下面这回事。</li><li>机器学习本质上就是<font color="red"><strong>一种对问题真实模型的逼近（我们选择一个我们认为比较好的近似模型，这个近似模型就叫做一个假设）</strong></font>，但毫无疑问，真实模型一定是不知道的（如果知道了，我们干吗还要机器学习？直接用真实模型解决问题不就可以了？对吧，哈哈）既然真实模型不知道，那么我们选择的假设与问题真实解之间究竟有多大差距，我们就没法得知。比如说我们认为宇宙诞生于150亿年前的一场大爆炸，这个假设能够描述很多我们观察到的现象，但它与真实的宇宙模型之间还相差多少？谁也说不清，因为我们压根就不知道真实的宇宙模型到底是什么。</li><li>这个与问题真实解之间的误差，就叫做<font color="red"><strong>风险（更严格的说，误差的累积叫做风险）</strong></font>。我们选择了一个假设之后（更直观点说，我们得到了一个分类器以后），真实误差无从得知，但我们可以用某些可以掌握的量来逼近它。最直观的想法就是使用分类器在样本数据上的分类的结果与真实结果（因为样本是已经标注过的数据，是准确的数据）之间的差值来表示。这个差值叫做<font color="red"><strong>经验风险Remp(w)</strong></font>。以前的机器学习方法都把经验风险最小化作为努力的目标，但后来发现很多分类函数能够在样本集上轻易达到100%的正确率，在真实分类时却一塌糊涂（即所谓的推广能力差，或泛化能力差）。此时的情况便是选择了一个足够复杂的分类函数（它的VC维很高），能够精确的记住每一个样本，但对样本之外的数据一律分类错误。回头看看经验风险最小化原则我们就会发现，此原则适用的大前提是经验风险要确实能够逼近真实风险才行（行话叫一致），但实际上能逼近么？答案是不能，因为样本数相对于现实世界要分类的文本数来说简直九牛一毛，<font color="red"><strong>经验风险最小化原则只在这占很小比例的样本上做到没有误差，当然不能保证在更大比例的真实文本上也没有误差。</strong></font></li></ul><h3 id="泛化误差界"><a href="#泛化误差界" class="headerlink" title="@泛化误差界"></a>@泛化误差界</h3><ul><li>统计学习因此而引入了泛化误差界的概念，就是指<font color="red"><strong>真实风险应该由两部分内容刻画，一是经验风险，代表了分类器在给定样本上的误差；二是置信风险，代表了我们在多大程度上可以信任分类器在未知文本上分类的结果。</strong></font>很显然，第二部分是没有办法精确计算的，因此只能给出一个估计的区间，也使得整个误差只能计算上界，而无法计算准确的值（所以叫做泛化误差界，而不叫泛化误差）。 </li><li>置信风险与两个量有关，一是样本数量，显然给定的样本数量越大，我们的学习结果越有可能正确，此时置信风险越小；二是分类函数的VC维，显然VC维越大，推广能力越差，置信风险会变大。</li><li>泛化误差界的公式为：R(w)≤Remp(w)+Ф(n&#x2F;h) </li><li>公式中R(w)就是真实风险，Remp(w)就是经验风险，Ф(n&#x2F;h)就是置信风险。统计学习的目标从经验风险最小化变为了寻求经验风险与置信风险的和最小，即结构风险最小。</li><li>SVM正是这样一种努力最小化结构风险的算法。</li></ul><h3 id="小样本，非线性，高维度识别"><a href="#小样本，非线性，高维度识别" class="headerlink" title="@小样本，非线性，高维度识别"></a>@小样本，非线性，高维度识别</h3><ul><li>SVM其他的特点就比较容易理解了。</li><li><font color="red"><strong>小样本</strong></font>，并不是说样本的绝对数量少（实际上，对任何算法来说，更多的样本几乎总是能带来更好的效果），而是说与问题的复杂度比起来，SVM算法要求的样本数是相对比较少的。</li><li><font color="red"><strong>非线性</strong></font>，是指SVM擅长应付样本数据线性不可分的情况，主要通过松弛变量（也有人叫惩罚变量）和核函数技术来实现，这一部分是SVM的精髓，以后会详细讨论。多说一句，关于文本分类这个问题究竟是不是线性可分的，尚没有定论，因此不能简单的认为它是线性可分的而作简化处理，在水落石出之前，只好先当它是线性不可分的（反正线性可分也不过是线性不可分的一种特例而已，我们向来不怕方法过于通用）。</li><li><font color="red"><strong>高维模式识别</strong></font>是指样本维数很高，例如文本的向量表示，如果没有经过另一系列文章（《文本分类入门》）中提到过的降维处理，出现几万维的情况很正常，其他算法基本就没有能力应付了，SVM却可以，主要是因为SVM 产生的分类器很简洁，用到的样本信息很少（仅仅用到那些称之为“支持向量”的样本，此为后话），使得即使样本维数很高，也不会给存储和计算带来大麻烦（相对照而言，kNN算法在分类时就要用到所有样本，样本数巨大，每个样本维数再一高，这日子就没法过了……）。</li></ul><h3 id="下节预告"><a href="#下节预告" class="headerlink" title="@下节预告"></a>@下节预告</h3><ul><li>下一节开始正式讨论SVM。别嫌我说得太详细哦。</li></ul><h2 id="SVM入门（二）线性分类器Part-1"><a href="#SVM入门（二）线性分类器Part-1" class="headerlink" title="SVM入门（二）线性分类器Part 1"></a>SVM入门（二）线性分类器Part 1</h2><h3 id="线性分类器"><a href="#线性分类器" class="headerlink" title="@线性分类器"></a>@线性分类器</h3><ul><li>线性分类器(一定意义上,也可以叫做<font color="red"><strong>感知机</strong></font>) 是最简单也很有效的分类器形式.在一个线性分类器中,可以看到SVM形成的思路,并接触很多SVM的核心概念。 </li><li>用一个二维空间里仅有两类样本的分类问题来举个小例子。如图所示：<br><img src="/img/paperBlog/intro-SVM-serial/serial02/clip_image002_thumb.gif"></li><li>C1和C2是要区分的两个类别，在二维平面中它们的样本如上图所示。<font color="red"><strong>中间的直线就是一个分类函数</strong></font>，它可以将两类样本完全分开。一般的，如果一个线性函数能够将样本完全正确的分开，就称这些数据是线性可分的，否则称为非线性可分的。</li></ul><h3 id="线性函数"><a href="#线性函数" class="headerlink" title="@线性函数"></a>@线性函数</h3><ul><li><p>什么叫线性函数呢？在一维空间里就是一个点，在二维空间里就是一条直线，三维空间里就是一个平面，可以如此想象下去，如果不关注空间的维数，这种线性函数还有一个统一的名称——<font color="red"><strong>超平面（Hyper Plane）</strong></font>！</p></li><li><p>实际上，一个线性函数是一个实值函数（即函数的值是连续的实数），而我们的分类问题（例如这里的二元分类问题——回答一个样本属于还是不属于一个类别的问题）需要离散的输出值，例如用1表示某个样本属于类别C1，而用0表示不属于（不属于C1也就意味着属于C2），这时候只需要简单的在实值函数的基础上附加一个阈值即可，通过分类函数执行时得到的值大于还是小于这个阈值来确定类别归属。 例如我们有一个线性函数</p><p>  g(x)&#x3D;wx+b</p></li><li><p>我们可以取阈值为0，这样当有一个样本xi需要判别的时候，我们就看g(xi)的值。若g(xi)&gt;0，就判别为类别C1，若g(xi)&lt;0，则判别为类别C2（等于的时候我们就拒绝判断，呵呵）。此时也等价于给函数g(x)附加一个<strong>符号函数</strong>sgn()，即f(x)&#x3D;sgn[g(x)]是我们真正的<strong>判别函数</strong>。</p></li><li><p>关于g(x)&#x3D;wx+b这个表达式要注意三点：</p><ul><li>一，式中的x不是二维坐标系中的横轴，而是样本的向量表示，例如一个样本点的坐标是(3,8)，则xT&#x3D;(3,8) ，而不是x&#x3D;3（一般说向量都是说列向量，因此以行向量形式来表示时，就加上转置）。</li><li>二，这个形式并不局限于二维的情况，在n维空间中仍然可以使用这个表达式，只是式中的w成为了n维向量（在二维的这个例子中，w是二维向量，为了表示起来方便简洁，以下均不区别列向量和它的转置，聪明的读者一看便知）；</li><li>三，g(x)不是中间那条直线的表达式，中间那条直线的表达式是g(x)&#x3D;0，即wx+b&#x3D;0，我们也把这个函数叫做分类面。</li></ul></li><li><p>实际上很容易看出来，中间那条分界线并不是唯一的，我们把它稍微旋转一下，只要不把两类数据分错，仍然可以达到上面说的效果，稍微平移一下，也可以。此时就牵涉到一个问题，对同一个问题存在多个分类函数的时候，哪一个函数更好呢？显然必须要先找一个指标来量化“好”的程度，通常使用的都是叫做<font color="red"><strong>“分类间隔”</strong></font>的指标。</p></li></ul><h3 id="下节预告-1"><a href="#下节预告-1" class="headerlink" title="@下节预告"></a>@下节预告</h3><ul><li>下一节我们就仔细说说<font color="red"><strong>分类间隔</strong></font>，也补一补相关的数学知识。</li></ul><h2 id="SVM入门（三）线性分类器Part-2"><a href="#SVM入门（三）线性分类器Part-2" class="headerlink" title="SVM入门（三）线性分类器Part 2"></a>SVM入门（三）线性分类器Part 2</h2><ul><li>上回说到对于文本分类这样的<strong>不适定问题</strong>（<em>有一个以上解的问题称为不适定问题</em>），需要有一个指标来衡量解决方案（即我们通过训练建立的分类模型）的好坏，而<font color="red"><strong>分类间隔</strong></font>是一个比较好的指标。</li></ul><h3 id="文本分类在计算机中的表示"><a href="#文本分类在计算机中的表示" class="headerlink" title="@文本分类在计算机中的表示"></a>@文本分类在计算机中的表示</h3><ul><li>在进行文本分类的时候，我们可以让计算机这样来看待我们提供给它的训练样本，每一个样本由一个向量（就是那些文本特征所组成的向量）和一个标记（标示出这个样本属于哪个类别）组成。如下：<br>  Di&#x3D;(xi,yi)</li><li>xi就是文本向量（维数很高），yi就是分类标记。</li><li>在二元的线性分类中，这个表示分类的标记只有两个值，1和-1（用来表示属于还是不属于这个类）。有了这种表示法，我们就可以定义一个样本点到某个超平面的间隔：<br>  δi&#x3D;yi(wxi+b)</li><li>这个公式乍一看没什么神秘的，也说不出什么道理，只是个定义而已，但我们做做变换，就能看出一些有意思的东西。</li></ul><h3 id="由分类间隔到几何间隔"><a href="#由分类间隔到几何间隔" class="headerlink" title="@由分类间隔到几何间隔"></a>@由分类间隔到几何间隔</h3><ul><li>首先注意到如果某个样本属于该类别的话，那么wxi+b&gt;0（记得么？这是因为我们所选的g(x)&#x3D;wx+b就通过大于0还是小于0来判断分类），而yi也大于0；若不属于该类别的话，那么wxi+b&lt;0，而yi也小于0，这意味着yi(wxi+b)总是大于0的，而且它的值就等于|wxi+b|！（也就是|g(xi)|） </li><li>现在把w和b进行一下归一化，即用w&#x2F;||w||和b&#x2F;||w||分别代替原来的w和b，那么间隔就可以写成<br><img src="/img/paperBlog/intro-SVM-serial/serial03/formula1.gif"></li><li>这个公式是不是看上去有点眼熟？没错，这不就是解析几何中点xi到直线g(x)&#x3D;0的距离公式嘛！（推广一下，是到超平面g(x)&#x3D;0的距离， g(x)&#x3D;0就是上节中提到的分类超平面） <blockquote><p>小Tips：||w||是什么符号？||w||叫做向量w的范数，范数是对向量长度的一种度量。我们常说的向量长度其实指的是它的2-范数，范数最一般的表示形式为p-范数，可以写成如下表达式<br>      向量w&#x3D;(w1, w2, w3,…… wn)<br>它的p-范数为 <br><img src="/img/paperBlog/intro-SVM-serial/serial03/formula2.gif"></p></blockquote></li><li>看看把p换成2的时候，不就是传统的向量长度么？当我们不指明p的时候，就像||w||这样使用时，就意味着我们不关心p的值，用几范数都可以；或者上文已经提到了p的值，为了叙述方便不再重复指明。 </li><li>当用归一化的w和b代替原值之后的间隔有一个专门的名称，叫做<font color="red"><strong>几何间隔</strong></font>，几何间隔所表示的正是点到超平面的欧氏距离，我们下面就简称几何间隔为“距离”。以上是单个点到某个超平面的距离（就是间隔，后面不再区别这两个词）定义，同样可以定义一个点的集合（就是一组样本）到某个超平面的距离为此集合中离超平面最近的点的距离。下面这张图更加直观的展示出了几何间隔的现实含义： <br><img src="/img/paperBlog/intro-SVM-serial/serial03/p1.png"></li><li>H是分类面，而H1和H2是平行于H，且过离H最近的两类样本的直线，H1与H，H2与H之间的距离就是<font color="red"><strong>几何间隔</strong></font>。 </li><li>之所以如此关心几何间隔这个东西，是因为几何间隔与样本的误分次数间存在关系：<br><img src="/img/paperBlog/intro-SVM-serial/serial03/formula3.gif"></li><li>其中的δ是样本集合到分类面的间隔，R&#x3D;max ||xi||  i&#x3D;1,…,n，即R是所有样本中（xi是以向量表示的第i个样本）向量长度最长的值（也就是说代表样本的分布有多么广）。先不必追究误分次数的具体定义和推导过程，只要记得这个误分次数一定程度上代表分类器的误差。而从上式可以看出，误分次数的上界由几何间隔决定！（当然，是样本已知的时候）</li><li>至此我们就明白为何要选择几何间隔来作为评价一个解优劣的指标了，<font color="red"><strong>原来几何间隔越大的解，它的误差上界越小</strong></font>。因此最大化几何间隔成了我们训练阶段的目标，而且，与二把刀作者所写的不同，最大化分类间隔并不是SVM的专利，而是早在线性分类时期就已有的思想。</li></ul><h2 id="SVM入门（四）线性分类器的求解——问题的描述Part1"><a href="#SVM入门（四）线性分类器的求解——问题的描述Part1" class="headerlink" title="SVM入门（四）线性分类器的求解——问题的描述Part1"></a>SVM入门（四）线性分类器的求解——问题的描述Part1</h2><h3 id="上节回顾-间隔和几何间隔"><a href="#上节回顾-间隔和几何间隔" class="headerlink" title="@上节回顾-间隔和几何间隔"></a>@上节回顾-间隔和几何间隔</h3><ul><li>上节说到我们有了一个线性分类函数，也有了判断解优劣的标准——即有了优化的目标，<font color="red"><strong>这个目标就是最大化几何间隔</strong></font>，但是看过一些关于SVM的论文的人一定记得什么优化的目标是要最小化||w||这样的说法，这是怎么回事呢？回头再看看我们对<strong>间隔</strong>和<strong>几何间隔</strong>的定义： </li><li>间隔：δ&#x3D;y(wx+b)&#x3D;|g(x)| </li><li>几何间隔：<img src="/img/paperBlog/intro-SVM-serial/serial04/formula1.gif"></li><li>可以看出δ&#x3D;||w||δ几何。注意到几何间隔与||w||是成反比的，因此最大化几何间隔与最小化||w||完全是一回事。而我们常用的方法并不是固定||w||的大小而寻求最大几何间隔，而是固定间隔（例如固定为1），寻找最小的||w||。</li></ul><h3 id="寻优问题"><a href="#寻优问题" class="headerlink" title="@寻优问题"></a>@寻优问题</h3><ul><li>而凡是求一个函数的最小值（或最大值）的问题都可以称为寻优问题（也叫作一个<font color="red"><strong>规划问题</strong></font>），又由于找最大值的问题总可以通过加一个负号变为找最小值的问题，因此我们下面讨论的时候都针对找最小值的过程来进行。一个寻优问题最重要的部分是<font color="red"><strong>目标函数</strong></font>，顾名思义，就是指寻优的目标。例如我们想寻找最小的||w||这件事，就可以用下面的式子表示：<br><img src="/img/paperBlog/intro-SVM-serial/serial04/formula2.gif"> </li><li>但实际上对于这个目标，我们常常使用另一个完全等价的目标函数来代替，那就是：<br><img src="/img/paperBlog/intro-SVM-serial/serial04/formula3.gif"> </li><li>不难看出当||w||2达到最小时，||w||也达到最小，反之亦然（前提当然是||w||描述的是向量的长度，因而是非负的）。之所以采用这种形式，是因为后面的求解过程会对目标函数作一系列变换，而式（1）的形式会使变换后的形式更为简洁（正如聪明的读者所料，添加的系数二分之一和平方，皆是为求导数所需）。</li></ul><h3 id="加约束条件"><a href="#加约束条件" class="headerlink" title="@加约束条件"></a>@加约束条件</h3><ul><li>接下来我们自然会问的就是，这个式子是否就描述了我们的问题呢？（回想一下，我们的问题是有一堆点，可以被分成两类，我们要找出最好的分类面） </li><li>如果直接来解这个求最小值问题，很容易看出当||w||&#x3D;0的时候就得到了目标函数的最小值。但是你也会发现，无论你给什么样的数据，都是这个解！反映在图中，就是H1与H2两条直线间的距离无限大，这个时候，所有的样本点（无论正样本还是负样本）都跑到了H1和H2中间，而我们原本的意图是，H1右侧的被分为正类，H2 左侧的被分为负类，位于两类中间的样本则拒绝分类（拒绝分类的另一种理解是分给哪一类都有道理，因而分给哪一类也都没有道理）。这下可好，所有样本点都进入了无法分类的灰色地带。<br><img src="/img/paperBlog/intro-SVM-serial/serial04/p1.gif"> </li><li>造成这种结果的原因是在描述问题的时候只考虑了目标，而没有加入<font color="red"><strong>约束条件</strong></font>，约束条件就是在求解过程中必须满足的条件，体现在我们的问题中就是样本点必须在H1或H2的某一侧（或者至少在H1和H2上），而不能跑到两者中间。我们前文提到过把间隔固定为1，这是指把所有样本点中间隔最小的那一点的间隔定为1（这也是集合的间隔的定义，有点绕嘴），也就意味着集合中的其他点间隔都不会小于1，按照间隔的定义，满足这些条件就相当于让下面的式子总是成立： <ul><li>yi[(w·xi)+b]≥1 (i&#x3D;1,2,…,l) （l是总的样本数）</li></ul></li><li>但我们常常习惯让式子的值和0比较，因而经常用变换过的形式： <ul><li>yi[(w·xi)+b]-1≥0 (i&#x3D;1,2,…,l) （l是总的样本数）</li></ul></li><li>因此我们的两类分类问题也被我们转化成了它的数学形式，一个<font color="red"><strong>带约束的最小值的问题</strong></font>： <br><img src="/img/paperBlog/intro-SVM-serial/serial04/formula4.gif"></li></ul><h3 id="下节预告-2"><a href="#下节预告-2" class="headerlink" title="@下节预告"></a>@下节预告</h3><ul><li>下一节我们从最一般的意义上看看一个求最小值的问题有何特征，以及如何来解。</li></ul><h2 id="SVM入门（五）线性分类器的求解——问题的描述Part2"><a href="#SVM入门（五）线性分类器的求解——问题的描述Part2" class="headerlink" title="SVM入门（五）线性分类器的求解——问题的描述Part2"></a>SVM入门（五）线性分类器的求解——问题的描述Part2</h2><h3 id="规划-Programming"><a href="#规划-Programming" class="headerlink" title="@规划(Programming)"></a>@规划(Programming)</h3><ul><li>从最一般的定义上说，一个求最小值的问题就是一个优化问题（也叫寻优问题，更文绉绉的叫法是<font color="red"><strong>规划</strong></font>——Programming），它同样由两部分组成，目标函数和约束条件，可以用下面的式子表示：<br><img src="/img/paperBlog/intro-SVM-serial/serial05/formula1.gif"> （式1）</li><li>约束条件用函数c来表示，就是constrain的意思啦。你可以看出一共有p+q个约束条件，其中p个是<font color="red"><strong>不等式约束</strong></font>，q个<font color="red"><strong>等式约束</strong></font>。 </li><li>关于这个式子可以这样来理解：式中的x是自变量，但不限定它的维数必须为1（视乎你解决的问题空间维数，对我们的文本分类来说，那可是成千上万啊）。要求f(x)在哪一点上取得最小值（反倒不太关心这个最小值到底是多少，关键是哪一点），但不是在整个空间里找，而是在约束条件所划定的一个有限的空间里找，这个有限的空间就是优化理论里所说的<font color="red"><strong>可行域</strong></font>。注意可行域中的每一个点都要求满足所有p+q个条件，而不是满足其中一条或几条就可以（切记，要满足每个约束），同时可行域边界上的点有一个额外好的特性，它们可以使<font color="red"><strong>不等式约束</strong></font>取得等号！而边界内的点不行。</li></ul><h3 id="凸集"><a href="#凸集" class="headerlink" title="@凸集"></a>@凸集</h3><ul><li>关于可行域还有个概念不得不提，那就是<font color="red"><strong>凸集</strong></font>，凸集是指有这么一个点的集合，其中任取两个点连一条直线，这条线上的点仍然在这个集合内部，因此说“凸”是很形象的（一个反例是，二维平面上，一个月牙形的区域就不是凸集，你随便就可以找到两个点违反了刚才的规定）。</li></ul><h3 id="凸二次规划"><a href="#凸二次规划" class="headerlink" title="@凸二次规划"></a>@凸二次规划</h3><ul><li>回头再来看我们线性分类器问题的描述，可以看出更多的东西。<br><img src="/img/paperBlog/intro-SVM-serial/serial05/formula2.gif"> （式2）</li><li>在这个问题中，自变量就是w，而目标函数是w的二次函数，所有的约束条件都是w的线性函数（哎，千万不要把xi当成变量，它代表样本，是已知的），这种规划问题有个很有名气的称呼——<font color="red"><strong>二次规划</strong></font>（Quadratic Programming，QP），而且可以更进一步的说，由于它的可行域是一个凸集，因此它是一个<font color="red"><strong>凸二次规划</strong></font>。 </li><li>一下子提了这么多术语，实在不是为了让大家以后能向别人炫耀学识的渊博，这其实是我们继续下去的一个重要前提，因为在动手求一个问题的解之前（好吧，我承认，是动计算机求……），我们必须先问自己：<strong>这个问题是不是有解？如果有解，是否能找到？</strong></li></ul><h3 id="问题可解吗"><a href="#问题可解吗" class="headerlink" title="@问题可解吗"></a>@问题可解吗</h3><ul><li>对于一般意义上的规划问题，两个问题的答案都是不一定，<strong>但凸二次规划让人喜欢的地方就在于，它有解（教科书里面为了严谨，常常加限定成分，说它有全局最优解，由于我们想找的本来就是全局最优的解，所以不加也罢），而且可以找到！</strong>（当然，依据你使用的算法不同，找到这个解的速度，行话叫收敛速度，会有所不同）</li><li>对比（式2）和（式1）还可以发现，我们的线性分类器问题只有不等式约束，因此形式上看似乎比一般意义上的规划问题要简单，但解起来却并非如此。 </li><li>因为我们实际上并不知道该怎么解一个带约束的优化问题。如果你仔细回忆一下高等数学的知识，会记得我们可以轻松的解一个不带任何约束的优化问题（实际上就是当年背得烂熟的函数求极值嘛，求导再找0点呗，谁不会啊？笑），我们甚至还会解一个只带等式约束的优化问题，也是背得烂熟的，求条件极值，记得么，通过添加拉格朗日乘子，构造拉格朗日函数，来把这个问题转化为无约束的优化问题云云（如果你一时没想通，我提醒一下，构造出的拉格朗日函数就是转化之后的问题形式，它显然没有带任何条件）。</li></ul><h3 id="读者问"><a href="#读者问" class="headerlink" title="@读者问"></a>@读者问</h3><ul><li>读者问：如果只带等式约束的问题可以转化为无约束的问题而得以求解，那么可不可以把带不等式约束的问题向只带等式约束的问题转化一下而得以求解呢？ </li><li>聪明，可以，实际上我们也正是这么做的。下一节就来说说如何做这个转化，一旦转化完成，求解对任何学过高等数学的人来说，都是小菜一碟啦。</li></ul><h2 id="SVM入门（六）线性分类器的求解——问题的转化，直观角度"><a href="#SVM入门（六）线性分类器的求解——问题的转化，直观角度" class="headerlink" title="SVM入门（六）线性分类器的求解——问题的转化，直观角度"></a>SVM入门（六）线性分类器的求解——问题的转化，直观角度</h2><h3 id="回到问题"><a href="#回到问题" class="headerlink" title="@回到问题"></a>@回到问题</h3><ul><li>让我再一次比较完整的重复一下我们要解决的问题：我们有属于两个类别的样本点（并不限定这些点在二维空间中）若干，如图，<br><img src="/img/paperBlog/intro-SVM-serial/serial06/p1.png"> </li><li>圆形的样本点定为正样本（连带着，我们可以把正样本所属的类叫做正类），方形的点定为负例。我们想求得这样一个线性函数（在n维空间中的线性函数）： <ul><li>g(x)&#x3D;wx+b</li></ul></li><li>使得所有属于正类的点x+代入以后有g(x+)≥1，而所有属于负类的点x-代入后有g(x-)≤-1（之所以总跟1比较，无论正一还是负一，都是因为我们固定了间隔为1，注意间隔和几何间隔的区别）。代入g(x)后的值如果在1和-1之间，我们就拒绝判断。</li></ul><h3 id="问题实际上就是求解w和b"><a href="#问题实际上就是求解w和b" class="headerlink" title="@问题实际上就是求解w和b"></a>@问题实际上就是求解w和b</h3><ul><li>求这样的g(x)的过程就是求w（一个n维向量）和b（一个实数）两个参数的过程（但实际上只需要求w，求得以后找某些样本点代入就可以求得b）。因此在求g(x)的时候，w才是变量。 </li><li>你肯定能看出来，一旦求出了w（也就求出了b），那么中间的直线H就知道了（因为它就是wx+b&#x3D;0嘛，哈哈），那么H1和H2也就知道了（因为三者是平行的，而且相隔的距离还是||w||决定的）。那么w是谁决定的？显然是你给的样本决定的，一旦你在空间中给出了那些个样本点，三条直线的位置实际上就唯一确定了（因为我们求的是最优的那三条，当然是唯一的），我们解优化问题的过程也只不过是把这个确定了的东西算出来而已。</li></ul><h3 id="w的数学表示"><a href="#w的数学表示" class="headerlink" title="@w的数学表示"></a>@w的数学表示</h3><ul><li>样本确定了w，用数学的语言描述，就是w可以表示为样本的某种组合： <ul><li>w&#x3D;α1x1+α2x2+…+αnxn</li></ul></li><li>式子中的αi是一个一个的数（在严格的证明过程中，这些α被称为<font color="red"><strong>拉格朗日乘子</strong></font>），而xi是样本点，因而是向量，n就是总样本点的个数。为了方便描述，以下开始严格区别数字与向量的乘积和向量间的乘积，我会用α1x1表示数字和向量的乘积，而用&lt;x1,x2&gt;表示向量x1,x2的内积（也叫点积，注意与向量叉积的区别）。因此g(x)的表达式严格的形式应该是： <br><img src="/img/paperBlog/intro-SVM-serial/serial06/f1.png"></li></ul><h3 id="式子转换"><a href="#式子转换" class="headerlink" title="@式子转换"></a>@式子转换</h3><ul><li>但是上面的式子还不够好，你回头看看图中正样本和负样本的位置，想像一下，我不动所有点的位置，而只是把其中一个正样本点定为负样本点（也就是把一个点的形状从圆形变为方形），结果怎么样？三条直线都必须移动（因为对这三条直线的要求是必须把方形和圆形的点正确分开）！<strong>这说明w不仅跟样本点的位置有关，还跟样本的类别有关（也就是和样本的“标签”有关）</strong>。因此用下面这个式子表示才算完整： <ul><li>w&#x3D;α1y1x1+α2y2x2+…+αnynxn （式1）</li></ul></li><li>其中的yi就是第i个样本的标签，它等于1或者-1。其实以上式子的那一堆<font color="red"><strong>拉格朗日乘子</strong></font>中，只有很少的一部分不等于0（不等于0才对w起决定作用），这部分不等于0的拉格朗日乘子后面所乘的样本点，其实都落在H1和H2上，也正是这部分样本（而不需要全部样本）唯一的确定了分类函数，当然，更严格的说，这些样本的一部分就可以确定，因为例如确定一条直线，只需要两个点就可以，即便有三五个都落在上面，我们也不是全都需要。这部分我们真正需要的样本点，就叫做<font color="red"><strong>支持（撑）向量</strong></font>！（名字还挺形象吧，他们“撑”起了分界线） </li><li>式子也可以用求和符号简写一下：<br><img src="/img/paperBlog/intro-SVM-serial/serial06/formula1.gif"></li><li>因此原来的g(x)表达式可以写为：<br><img src="/img/paperBlog/intro-SVM-serial/serial06/formula2.gif"></li><li>注意式子中x才是变量，也就是你要分类哪篇文档，就把该文档的向量表示代入到 x的位置，而所有的xi统统都是已知的样本。还注意到式子中只有xi和x是向量，因此一部分可以从内积符号中拿出来，得到g(x)的式子为：<br><img src="/img/paperBlog/intro-SVM-serial/serial06/formula3.gif"></li><li>发现了什么？<strong>w不见啦！从求w变成了求α。</strong></li><li>但肯定有人会说，这并没有把原问题简化呀。嘿嘿，其实简化了，只不过在你看不见的地方，以这样的形式描述问题以后，我们的优化问题少了很大一部分不等式约束（记得这是我们解不了极值问题的万恶之源）。但是接下来先跳过线性分类器求解的部分，来看看 SVM在线性分类器上所做的重大改进——<font color="red"><strong>核函数</strong></font>。</li></ul><h2 id="SVM入门（七）为何需要核函数"><a href="#SVM入门（七）为何需要核函数" class="headerlink" title="SVM入门（七）为何需要核函数"></a>SVM入门（七）为何需要核函数</h2><ul><li>生存？还是毁灭？——哈姆雷特</li><li>可分？还是不可分？——支持向量机</li></ul><h3 id="线性不可分到线性可分，可能吗？"><a href="#线性不可分到线性可分，可能吗？" class="headerlink" title="@线性不可分到线性可分，可能吗？"></a>@线性不可分到线性可分，可能吗？</h3><ul><li>之前一直在讨论的线性分类器,器如其名（汗，这是什么说法啊），只能对线性可分的样本做处理。如果提供的样本线性不可分，结果很简单，线性分类器的求解程序会无限循环，永远也解不出来。这必然使得它的适用范围大大缩小，而它的很多优点我们实在不原意放弃，怎么办呢？<strong>是否有某种方法，让线性不可分的数据变得线性可分呢？</strong> </li><li>有！其思想说来也简单，来用一个二维平面中的分类问题作例子，你一看就会明白。事先声明，下面这个例子是网络早就有的，我一时找不到原作者的正确信息，在此借用，并加进了我自己的解说而已。 </li><li>例子是下面这张图： <br><img src="/img/paperBlog/intro-SVM-serial/serial07/p1.jpg"></li><li>我们把横轴上端点a和b之间红色部分里的所有点定为正类，两边的黑色部分里的点定为负类。试问能找到一个线性函数把两类正确分开么？不能，因为二维空间里的线性函数就是指直线，显然找不到符合条件的直线。 </li><li>但我们可以找到一条曲线，例如下面这一条：<br><img src="/img/paperBlog/intro-SVM-serial/serial07/p2.gif"> </li><li>显然通过点在这条曲线的上方还是下方就可以判断点所属的类别（你在横轴上随便找一点，算算这一点的函数值，会发现负类的点函数值一定比0大，而正类的一定比0小）。这条曲线就是我们熟知的二次曲线，它的函数表达式可以写为： <br><img src="/img/paperBlog/intro-SVM-serial/serial07/f1.gif"> </li><li>问题只是它不是一个线性函数，但是，下面要注意看了，新建一个向量y和a： <br><img src="/img/paperBlog/intro-SVM-serial/serial07/f2.gif"> </li><li>这样g(x)就可以转化为<img src="/img/paperBlog/intro-SVM-serial/serial07/f5.png"> ，你可以把y和a分别回带一下，看看等不等于原来的g(x)。用内积的形式写你可能看不太清楚，实际上f(y)的形式就是：<blockquote><p>g(x)&#x3D;f(y)&#x3D;ay </p></blockquote></li><li><strong>在任意维度的空间中，这种形式的函数都是一个线性函数（只不过其中的a和y都是多维向量罢了），因为自变量y的次数不大于1</strong>。</li></ul><h3 id="妙！高维度空间可分了！"><a href="#妙！高维度空间可分了！" class="headerlink" title="@妙！高维度空间可分了！"></a>@妙！高维度空间可分了！</h3><ul><li>看出妙在哪了么？原来在二维空间中一个线性不可分的问题，映射到四维空间后，变成了线性可分的！因此这也形成了我们最初想解决线性不可分问题的基本思路——<font color="red"><strong>向高维空间转化，使其变得线性可分</strong></font>。 </li><li>而转化最关键的部分就在于找到x到y的映射方法。遗憾的是，如何找到这个映射，没有系统性的方法（也就是说，纯靠猜和凑）。具体到我们的文本分类问题，文本被表示为上千维的向量，即使维数已经如此之高，也常常是线性不可分的，还要向更高的空间转化。其中的难度可想而知。<blockquote><p><strong>小Tips</strong>:为什么说f(y)&#x3D;ay是四维空间里的函数?<br>大家可能一时没看明白。回想一下我们二维空间里的函数定义<br>        g(x)&#x3D;ax+b<br>  变量x是一维的，为什么说它是二维空间里的函数呢？因为还有一个变量我们没写出来，它的完整形式其实是<br>        y&#x3D;g(x)&#x3D;ax+b<br>  即<br>        y&#x3D;ax+b<br>  看看，有几个变量？两个。那是几维空间的函数？（作者五岁的弟弟答：五维的。作者：……）<br>  再看看<br>      f(y)&#x3D;ay<br>  里面的y是三维的变量，那f(y)是几维空间里的函数？（作者五岁的弟弟答：还是五维的。作者：……）</p></blockquote></li></ul><h3 id="文本分类例子又来了"><a href="#文本分类例子又来了" class="headerlink" title="@文本分类例子又来了"></a>@文本分类例子又来了</h3><ul><li>用一个具体文本分类的例子来看看这种向高维空间映射从而分类的方法如何运作，想象一下，我们文本分类问题的原始空间是1000维的（即每个要被分类的文档被表示为一个1000维的向量），在这个维度上问题是线性不可分的。现在我们有一个2000维空间里的线性函数<br><img src="/img/paperBlog/intro-SVM-serial/serial07/f6.png"> </li><li>注意向量的右上角有个 ’哦。它能够将原问题变得可分。式中的 w’和x’都是2000维的向量，只不过w’是定值，而x’是变量（好吧,严格说来这个函数是2001维的,哈哈），现在我们的输入呢，是一个1000维的向量x，分类的过程是先把x变换为2000维的向量x’，然后求这个变换后的向量x’与向量w’的内积，再把这个内积的值和b相加，就得到了结果，看结果大于阈值还是小于阈值就得到了分类结果。 </li><li>你发现了什么？我们其实只关心那个高维空间里内积的值，那个值算出来了，分类结果就算出来了。而从理论上说， x’是经由x变换来的，因此广义上可以把它叫做x的函数（有一个x，就确定了一个x’，对吧，确定不出第二个），而w’是常量，它是一个低维空间里的常量w经过变换得到的，所以给了一个w 和x的值，就有一个确定的f(x’)值与其对应。<font color="red"><strong>这让我们幻想，是否能有这样一种函数K(w,x),他接受低维空间的输入值，却能算出高维空间的内积值&lt;w’,x’&gt;？</strong></font> </li><li>如果有这样的函数，那么当给了一个低维空间的输入x以后，<br><img src="/img/paperBlog/intro-SVM-serial/serial07/f7.png">  </li><li>这两个函数的计算结果就完全一样，我们也就用不着费力找那个映射关系，直接拿低维的输入往g(x)里面代就可以了（再次提醒，这回的g(x)就不是线性函数啦，因为你不能保证K(w,x)这个表达式里的x次数不高于1哦）。</li></ul><h3 id="核函数大神出来了"><a href="#核函数大神出来了" class="headerlink" title="@核函数大神出来了"></a>@核函数大神出来了</h3><ul><li>万幸的是，这样的K(w,x)确实存在（发现凡是我们人类能解决的问题，大都是巧得不能再巧，特殊得不能再特殊的问题，总是恰好有些能投机取巧的地方才能解决，由此感到人类的渺小），它被称作<font color="red"><strong>核函数（核，kernel）</strong></font>，而且还不止一个，事实上，只要是满足了Mercer条件的函数，都可以作为核函数。<font color="red"><strong>核函数的基本作用就是接受两个低维空间里的向量，能够计算出经过某个变换后在高维空间里的向量内积值</strong></font>。几个比较常用的核函数，线性核函数，高斯核函数，径向基核函数,教课书里都列过，我就不敲了（懒！）。</li></ul><h3 id="让核函数来拯救线性不可分吧-其实是简化了高维度中向量的内积计算"><a href="#让核函数来拯救线性不可分吧-其实是简化了高维度中向量的内积计算" class="headerlink" title="@让核函数来拯救线性不可分吧(其实是简化了高维度中向量的内积计算$_$)"></a>@让核函数来拯救线性不可分吧(其实是简化了高维度中向量的内积计算$_$)</h3><ul><li>回想我们上节说的求一个线性分类器，它的形式应该是： <br><img src="/img/paperBlog/intro-SVM-serial/serial07/f3.gif"></li><li>现在这个就是高维空间里的线性函数（为了区别低维和高维空间里的函数和向量，我改了函数的名字，并且给w和x都加上了 ’），我们就可以用一个低维空间里的函数（再一次的，这个低维空间里的函数就不再是线性的啦）来代替， <br><img src="/img/paperBlog/intro-SVM-serial/serial07/f4.gif"> </li><li>又发现什么了？<font color="red"><strong>f(x’) 和g(x)里的α，y，b全都是一样一样的！这就是说，尽管给的问题是线性不可分的，但是我们就硬当它是线性问题来求解，只不过求解过程中，凡是要求内积的时候就用你选定的核函数来算</strong></font>。这样求出来的α再和你选定的核函数一组合，就得到分类器啦！</li></ul><h3 id="问题来了"><a href="#问题来了" class="headerlink" title="@问题来了"></a>@问题来了</h3><ul><li>明白了以上这些，会自然的问接下来两个问题： <ul><li><strong>1． 既然有很多的核函数，针对具体问题该怎么选择？</strong> </li><li><strong>2． 如果使用核函数向高维空间映射后，问题仍然是线性不可分的，那怎么办？</strong></li></ul></li><li>第一个问题现在就可以回答你：对核函数的选择，现在还缺乏指导原则！各种实验的观察结果（不光是文本分类）的确表明，某些问题用某些核函数效果很好，用另一些就很差，但是一般来讲，<strong>径向基核函数</strong>是不会出太大偏差的一种，首选。（我做文本分类系统的时候，使用径向基核函数，没有参数调优的情况下，绝大部分类别的准确和召回都在85%以上，可见。虽然libSVM的作者林智仁认为文本分类用线性核函数效果更佳，待考证）</li></ul><h3 id="下节预告-3"><a href="#下节预告-3" class="headerlink" title="@下节预告"></a>@下节预告</h3><p>对第二个问题的解决则引出了我们下一节的主题：<strong>松弛变量</strong>。 </p><h2 id="SVM入门（八）松弛变量"><a href="#SVM入门（八）松弛变量" class="headerlink" title="SVM入门（八）松弛变量"></a>SVM入门（八）松弛变量</h2><h3 id="“近似线性可分”与“硬间隔”"><a href="#“近似线性可分”与“硬间隔”" class="headerlink" title="@“近似线性可分”与“硬间隔”"></a>@“近似线性可分”与“硬间隔”</h3><ul><li>现在我们已经把一个本来线性不可分的文本分类问题，通过映射到高维空间而变成了线性可分的。就像下图这样：<br><img src="/img/paperBlog/intro-SVM-serial/serial08/p1.png"> </li><li>圆形和方形的点各有成千上万个（毕竟，这就是我们训练集中文档的数量嘛，当然很大了）。现在想象我们有另一个训练集，只比原先这个训练集多了一篇文章，映射到高维空间以后（当然，也使用了相同的核函数），也就多了一个样本点，但是这个样本的位置是这样的：<br><img src="/img/paperBlog/intro-SVM-serial/serial08/p2.png"> </li><li>就是图中黄色那个点，它是方形的，因而它是负类的一个样本，这单独的一个样本，使得原本线性可分的问题变成了线性不可分的。这样类似的问题（仅有少数点线性不可分）叫做<font color="red"><strong>“近似线性可分”</strong></font>的问题。 </li><li>以我们人类的常识来判断，说有一万个点都符合某种规律（因而线性可分），有一个点不符合，那这一个点是否就代表了分类规则中我们没有考虑到的方面呢（因而规则应该为它而做出修改）？ </li><li>其实我们会觉得，更有可能的是，这个样本点压根就是错误，是噪声，是提供训练集的同学人工分类时一打瞌睡错放进去的。所以我们会简单的忽略这个样本点，仍然使用原来的分类器，其效果丝毫不受影响。 </li><li>但这种对噪声的容错性是人的思维带来的，我们的程序可没有。由于我们原本的优化问题的表达式中，确实要考虑所有的样本点（不能忽略某一个，因为程序它怎么知道该忽略哪一个呢？），在此基础上寻找正负类之间的最大几何间隔，而几何间隔本身代表的是距离，是非负的，像上面这种有噪声的情况会使得整个问题无解。这种解法其实也叫做<font color="red"><strong>“硬间隔”</strong></font>分类法，因为他硬性的要求所有样本点都满足和分类平面间的距离必须大于某个值。 </li><li>因此由上面的例子中也可以看出，硬间隔的分类法其结果容易受少数点的控制，这是很危险的（尽管有句话说真理总是掌握在少数人手中，但那不过是那一小撮人聊以自慰的词句罢了，咱还是得民主）。</li></ul><h3 id="要容错啊，变软间隔吧–松弛变量来帮你"><a href="#要容错啊，变软间隔吧–松弛变量来帮你" class="headerlink" title="@要容错啊，变软间隔吧–松弛变量来帮你"></a>@要容错啊，变软间隔吧–松弛变量来帮你</h3><ul><li>但解决方法也很明显，就是仿照人的思路，允许一些点到分类平面的距离不满足原先的要求。由于不同的训练集各点的间距尺度不太一样，因此用间隔（而不是几何间隔）来衡量有利于我们表达形式的简洁。我们原先对样本点的要求是：<br><img src="/img/paperBlog/intro-SVM-serial/serial08/f1.gif"> </li><li>意思是说离分类面最近的样本点函数间隔也要比1大。如果要引入容错性，就给1这个硬性的阈值加一个<font color="red"><strong>松弛变量</strong></font>，即允许<br><img src="/img/paperBlog/intro-SVM-serial/serial08/f2.gif"></li><li>因为<font color="red"><strong>松弛变量</strong></font>是非负的，因此最终的结果是要求间隔可以比1小。但是当某些点出现这种间隔比1小的情况时（这些点也叫<font color="red"><strong>离群点</strong></font>），意味着我们放弃了对这些点的精确分类，而这对我们的分类器来说是种损失。但是放弃这些点也带来了好处，那就是使分类面不必向这些点的方向移动，因而可以得到更大的几何间隔（在低维空间看来，分类边界也更平滑）。显然我们必须权衡这种损失和好处。好处很明显，我们得到的分类间隔越大，好处就越多。回顾我们原始的<font color="red"><strong>硬间隔分类</strong></font>对应的优化问题：<br><img src="/img/paperBlog/intro-SVM-serial/serial08/f3.gif"></li><li>||w||2就是我们的目标函数（当然系数可有可无），希望它越小越好，因而损失就必然是一个能使之变大的量（能使它变小就不叫损失了，我们本来就希望目标函数值越小越好）。那如何来衡量损失，有两种常用的方式，有人喜欢用<br><img src="/img/paperBlog/intro-SVM-serial/serial08/f4.gif"></li><li>而有人喜欢用<br><img src="/img/paperBlog/intro-SVM-serial/serial08/f5.gif"></li><li>其中l都是样本的数目。两种方法没有大的区别。如果选择了第一种，得到的方法的就叫做<font color="red"><strong>二阶软间隔分类器</strong></font>，第二种就叫做<font color="red"><strong>一阶软间隔分类器</strong></font>。把损失加入到<strong>目标函数</strong>里的时候，就需要一个<font color="red"><strong>惩罚因子</strong></font>（cost，也就是libSVM的诸多参数中的C），原来的优化问题就变成了下面这样：<br><img src="/img/paperBlog/intro-SVM-serial/serial08/f6.gif"></li><li>这个式子有这么几点要注意：<ul><li>一是并非所有的样本点都有一个<font color="red"><strong>松弛变量</strong></font>与其对应。实际上只有<strong>“离群点”</strong>才有，或者也可以这么看，所有没离群的点<font color="red"><strong>松弛变量</strong></font>都等于0（对负类来说，离群点就是在前面图中，跑到H2右侧的那些负样本点，对正类来说，就是跑到H1左侧的那些正样本点）。 </li><li>二是<font color="red"><strong>松弛变量</strong></font>的值实际上<strong>标示出了对应的点到底离群有多远，值越大，点就越远</strong>。 </li><li>三是<font color="red"><strong>惩罚因子C</strong></font>决定了你有多重视离群点带来的损失，显然当所有离群点的<font color="red"><strong>松弛变量</strong></font>的和一定时，你定的C越大，对目标函数的损失也越大，此时就暗示着你非常不愿意放弃这些离群点，最极端的情况是你把C定为无限大，这样只要稍有一个点离群，目标函数的值马上变成无限大，马上让问题变成无解，这就退化成了硬间隔问题。</li><li>四是<font color="red"><strong>惩罚因子C</strong></font>不是一个变量，整个优化问题在解的时候，C是一个你必须事先指定的值，指定这个值以后，解一下，得到一个分类器，然后用测试数据看看结果怎么样，如果不够好，换一个C的值，再解一次优化问题，得到另一个分类器，再看看效果，如此就是一个参数寻优的过程，但这和优化问题本身决不是一回事，优化问题在解的过程中，C一直是定值，要记住。</li><li>五是尽管加了<font color="red"><strong>松弛变量</strong></font>这么一说，但这个优化问题仍然是一个优化问题（汗，这不废话么），解它的过程比起原始的硬间隔问题来说，没有任何更加特殊的地方。</li></ul></li><li>从大的方面说优化问题解的过程，就是先试着确定一下w，也就是确定了前面图中的三条直线，这时看看间隔有多大，又有多少点离群，把目标函数的值算一算，再换一组三条直线（你可以看到，分类的直线位置如果移动了，有些原来离群的点会变得不再离群，而有的本来不离群的点会变成离群点），再把目标函数的值算一算，如此往复（迭代），直到最终找到目标函数最小时的w。</li></ul><h3 id="＠读者又提问了–松弛变量和核函数都是解决线性不可分问题"><a href="#＠读者又提问了–松弛变量和核函数都是解决线性不可分问题" class="headerlink" title="＠读者又提问了–松弛变量和核函数都是解决线性不可分问题"></a>＠读者又提问了–松弛变量和核函数都是解决线性不可分问题</h3><ul><li>啰嗦了这么多，读者一定可以马上自己总结出来，松弛变量也就是个解决线性不可分问题的方法罢了，但是回想一下，核函数的引入不也是为了解决线性不可分的问题么？为什么要为了一个问题使用两种方法呢？ </li><li>其实两者还有微妙的不同。一般的过程应该是这样，还以文本分类为例。在原始的低维空间中，样本相当的不可分，无论你怎么找分类平面，总会有大量的离群点，此时用核函数向高维空间映射一下，虽然结果仍然是不可分的，但比原始空间里的要更加接近线性可分的状态（就是达到了近似线性可分的状态），此时再用松弛变量处理那些少数“冥顽不化”的离群点，就简单有效得多啦。 </li><li>本节中的（式1）也确实是支持向量机最最常用的形式。至此一个比较完整的支持向量机框架就有了，简单说来，<font color="red"><strong>支持向量机就是使用了核函数的软间隔线性分类法</strong></font>。</li></ul><h3 id="下节预告-4"><a href="#下节预告-4" class="headerlink" title="@下节预告"></a>@下节预告</h3><ul><li>下一节会说说松弛变量剩下的一点点东西，顺便搞个读者调查，看看大家还想侃侃SVM的哪些方面。</li></ul><h2 id="SVM入门（九）松弛变量（续）"><a href="#SVM入门（九）松弛变量（续）" class="headerlink" title="SVM入门（九）松弛变量（续）"></a>SVM入门（九）松弛变量（续）</h2><h3 id="惩罚因子C的权值"><a href="#惩罚因子C的权值" class="headerlink" title="@惩罚因子C的权值"></a>@惩罚因子C的权值</h3><ul><li>接下来要说的东西其实不是松弛变量本身，但由于是为了使用松弛变量才引入的，因此放在这里也算合适，那就是<font color="red"><strong>惩罚因子C</strong></font>。回头看一眼引入了松弛变量以后的优化问题：<br><img src="/img/paperBlog/intro-SVM-serial/serial09/f1.gif"></li><li>注意其中C的位置，也可以回想一下C所起的作用<font color="red"><strong>（表征你有多么重视离群点，C越大越重视，越不想丢掉它们）</strong></font>。这个式子是以前做SVM的人写的，大家也就这么用，但没有任何规定说必须对所有的松弛变量都使用同一个惩罚因子，我们完全可以给每一个离群点都使用不同的C，这时就意味着你对每个样本的重视程度都不一样，有些样本丢了也就丢了，错了也就错了，这些就给一个比较小的C；而有些样本很重要，决不能分类错误（比如中央下达的文件啥的，笑），就给一个很大的C。</li></ul><h3 id="数据集偏斜问题"><a href="#数据集偏斜问题" class="headerlink" title="@数据集偏斜问题"></a>@数据集偏斜问题</h3><ul><li>当然实际使用的时候并没有这么极端，但一种很常用的变形可以用来解决分类问题中样本的<strong>“偏斜”</strong>问题。</li><li>先来说说样本的偏斜问题，也叫<font color="red"><strong>数据集偏斜（unbalanced）</strong></font>，它指的是参与分类的两个类别（也可以指多个类别）样本数量差异很大。比如说正类有10，000个样本，而负类只给了100个，这会引起的问题显而易见，可以看看下面的图：<br><img src="/img/paperBlog/intro-SVM-serial/serial09/p1.png"></li><li>方形的点是负类。H，H1，H2是根据给的样本算出来的分类面，由于负类的样本很少很少，所以有一些本来是负类的样本点没有提供，比如图中两个灰色的方形点，如果这两个点有提供的话，那算出来的分类面应该是H’，H2’和H1，他们显然和之前的结果有出入，实际上负类给的样本点越多，就越容易出现在灰色点附近的点，我们算出的结果也就越接近于真实的分类面。但现在由于偏斜的现象存在，使得数量多的正类可以把分类面向负类的方向“推”，因而影响了结果的准确性。</li></ul><h3 id="惩罚因子C，数量越少越重视"><a href="#惩罚因子C，数量越少越重视" class="headerlink" title="@惩罚因子C，数量越少越重视"></a>@惩罚因子C，数量越少越重视</h3><ul><li>对付数据集偏斜问题的方法之一就是在惩罚因子上作文章，想必大家也猜到了，那就是给样本数量少的负类更大的惩罚因子，表示我们重视这部分样本（本来数量就少，再抛弃一些，那人家负类还活不活了），因此我们的目标函数中因<font color="red"><strong>松弛变量</strong></font>而损失的部分就变成了：<br><img src="/img/paperBlog/intro-SVM-serial/serial09/f2.gif"></li><li>其中i&#x3D;1…p都是正样本，j&#x3D;p+1…p+q都是负样本。libSVM这个算法包在解决偏斜问题的时候用的就是这种方法。</li></ul><h3 id="怎么比较正类多，还是负类多？"><a href="#怎么比较正类多，还是负类多？" class="headerlink" title="@怎么比较正类多，还是负类多？"></a>@怎么比较正类多，还是负类多？</h3><ul><li>那C+和C-怎么确定呢？它们的大小是试出来的（参数调优），但是他们的比例可以有些方法来确定。咱们先假定说C+是5这么大，那确定C-的一个很直观的方法就是<font color="red"><strong>使用两类样本数的比来算</strong></font>，对应到刚才举的例子，C-就可以定为500这么大（因为10，000：100&#x3D;100：1嘛）。 </li><li>但是这样并不够好，回看刚才的图，你会发现正类之所以可以“欺负”负类，其实并不是因为负类样本少，真实的原因是负类的样本分布的不够广（没扩充到负类本应该有的区域）。说一个具体点的例子，现在想给政治类和体育类的文章做分类，政治类文章很多，而体育类只提供了几篇关于篮球的文章，这时分类会明显偏向于政治类，如果要给体育类文章增加样本，但增加的样本仍然全都是关于篮球的（也就是说，没有足球，排球，赛车，游泳等等），那结果会怎样呢？虽然体育类文章在数量上可以达到与政治类一样多，但过于集中了，结果仍会偏向于政治类！<font color="red"><strong>所以给C+和C-确定比例更好的方法应该是衡量他们分布的程度</strong></font>。比如可以算算他们在空间中占据了多大的体积，例如给负类找一个超球——就是高维空间里的球啦——它可以包含所有负类的样本，再给正类找一个，比比两个球的半径，就可以大致确定分布的情况。显然半径大的分布就比较广，就给小一点的惩罚因子。 </li><li>但是这样还不够好，<font color="red"><strong>因为有的类别样本确实很集中，这不是提供的样本数量多少的问题，这是类别本身的特征</strong></font>（就是某些话题涉及的面很窄，例如计算机类的文章就明显不如文化类的文章那么“天马行空”），这个时候即便超球的半径差异很大，也不应该赋予两个类别不同的惩罚因子。</li><li>看到这里读者一定疯了，因为说来说去，这岂不成了一个解决不了的问题？然而事实如此，完全的方法是没有的，根据需要，选择实现简单又合用的就好（<font color="red"><strong>例如libSVM就直接使用样本数量的比</strong></font>）。</li></ul><h2 id="SVM入门（十）将SVM用于多类分类"><a href="#SVM入门（十）将SVM用于多类分类" class="headerlink" title="SVM入门（十）将SVM用于多类分类"></a>SVM入门（十）将SVM用于多类分类</h2><h3 id="SVM只是个两类分类器"><a href="#SVM只是个两类分类器" class="headerlink" title="@SVM只是个两类分类器"></a>@SVM只是个两类分类器</h3><ul><li>从SVM的那几张图可以看出来，<strong>SVM是一种典型的两类分类器</strong>，即它只回答属于正类还是负类的问题。而现实中要解决的问题，往往是多类的问题（少部分例外，例如垃圾邮件过滤，就只需要确定“是”还是“不是”垃圾邮件），比如文本分类，比如数字识别。如何由两类分类器得到多类分类器，就是一个值得研究的问题。</li></ul><h3 id="穷举法？行不通！"><a href="#穷举法？行不通！" class="headerlink" title="@穷举法？行不通！"></a>@穷举法？行不通！</h3><ul><li>还以文本分类为例，现成的方法有很多，其中一种一劳永逸的方法，就是真的一次性考虑所有样本，并求解一个多目标函数的优化问题，一次性得到多个分类面，就像下图这样：<br><img src="/img/paperBlog/intro-SVM-serial/serial10/p1.jpg">  </li><li>多个超平面把空间划分为多个区域，每个区域对应一个类别，给一篇文章，看它落在哪个区域就知道了它的分类。 </li><li>看起来很美对不对？只可惜这种算法还基本停留在纸面上，因为一次性求解的方法计算量实在太大，大到无法实用的地步。</li></ul><h3 id="一对其余"><a href="#一对其余" class="headerlink" title="@一对其余"></a>@一对其余</h3><ul><li>稍稍退一步，我们就会想到所谓<font color="red"><strong>“一类对其余”</strong></font>的方法，就是每次仍然解一个两类分类的问题。比如我们有5个类别，第一次就把类别1的样本定为正样本，其余2，3，4，5的样本合起来定为负样本，这样得到一个两类分类器，它能够指出一篇文章是还是不是第1类的；第二次我们把类别2 的样本定为正样本，把1，3，4，5的样本合起来定为负样本，得到一个分类器，如此下去，我们可以得到5个这样的两类分类器（总是和类别的数目一致）。到了有文章需要分类的时候，我们就拿着这篇文章挨个分类器的问：是属于你的么？是属于你的么？哪个分类器点头说是了，文章的类别就确定了。</li><li>这种方法的<font color="red"><strong>好处是每个优化问题的规模比较小，而且分类的时候速度很快（只需要调用5个分类器就知道了结果）</strong></font>。但有时也会出现两种很尴尬的情况，例如拿一篇文章问了一圈，每一个分类器都说它是属于它那一类的，或者每一个分类器都说它不是它那一类的，前者叫<font color="red"><strong>分类重叠现象</strong></font>，后者叫<font color="red"><strong>不可分类现象</strong></font>。分类重叠倒还好办，随便选一个结果都不至于太离谱，或者看看这篇文章到各个超平面的距离，哪个远就判给哪个。不可分类现象就着实难办了，只能把它分给第6个类别了……更要命的是，本来各个类别的样本数目是差不多的，但“其余”的那一类样本数总是要数倍于正类（因为它是除正类以外其他类别的样本之和嘛），这就人为的造成了上一节所说的<strong>“数据集偏斜”问题</strong>。</li></ul><h3 id="一对一"><a href="#一对一" class="headerlink" title="@一对一"></a>@一对一</h3><ul><li>因此我们还得再退一步，还是解两类分类问题，还是每次选一个类的样本作正类样本，而负类样本则变成只选一个类（称为<font color="red"><strong>“一对一单挑”</strong></font>的方法，哦，不对，没有单挑，就是<font color="red"><strong>“一对一”</strong></font>的方法，呵呵），这就避免了偏斜。因此过程就是算出这样一些分类器，第一个只回答“是第1类还是第2类”，第二个只回答“是第1类还是第3类”，第三个只回答“是第1类还是第4类”，如此下去，你也可以马上得出，这样的分类器应该有5 X 4&#x2F;2&#x3D;10个（通式是，如果有k个类别，则总的两类分类器数目为k(k-1)&#x2F;2）。虽然分类器的数目多了，但是在训练阶段（也就是算出这些分类器的分类平面时）所用的总时间却比“一类对其余”方法少很多，在真正用来分类的时候，把一篇文章扔给所有分类器，第一个分类器会投票说它是“1”或者“2”，第二个会说它是“1”或者“3”，让每一个都投上自己的一票，最后统计票数，如果类别“1”得票最多，就判这篇文章属于第1类。这种方法显然也会有分类重叠的现象，但不会有不可分类现象，因为总不可能所有类别的票数都是0。看起来够好么？其实不然，想想分类一篇文章，我们调用了多少个分类器？10个，这还是类别数为5的时候，类别数如果是1000，要调用的分类器数目会上升至约500,000个（类别数的平方量级）。这如何是好？</li></ul><h3 id="有向无环图-DAG-SVM"><a href="#有向无环图-DAG-SVM" class="headerlink" title="@有向无环图-DAG SVM"></a>@有向无环图-DAG SVM</h3><ul><li>看来我们必须再退一步，在分类的时候下功夫，我们还是像一对一方法那样来训练，只是在对一篇文章进行分类之前，我们先按照下面图的样子来组织分类器（如你所见，这是一个<font color="red"><strong>有向无环图</strong></font>，因此这种方法也叫做<font color="red"><strong>DAG SVM</strong></font>）<br><img src="/img/paperBlog/intro-SVM-serial/serial10/p2.png"> </li><li>这样在分类时,我们就可以先问分类器“1对5”（意思是它能够回答“是第1类还是第5类”），如果它回答5，我们就往左走，再问“2对5”这个分类器，如果它还说是“5”，我们就继续往左走，这样一直问下去，就可以得到分类结果。<font color="red"><strong>好处在哪？我们其实只调用了4个分类器（如果类别数是k，则只调用k-1个），分类速度飞快，且没有分类重叠和不可分类现象！</strong></font><font color="green"><strong>缺点在哪？假如最一开始的分类器回答错误（明明是类别1的文章，它说成了5），那么后面的分类器是无论如何也无法纠正它的错误的（因为后面的分类器压根没有出现“1”这个类别标签），其实对下面每一层的分类器都存在这种错误向下累积的现象</strong></font>。</li><li>不过不要被DAG方法的错误累积吓倒，错误累积在一对其余和一对一方法中也都存在，DAG方法好于它们的地方就在于，累积的上限，不管是大是小，总是有定论的，有理论证明。而一对其余和一对一方法中，尽管每一个两类分类器的泛化误差限是知道的，但是合起来做多类分类的时候，误差上界是多少，没人知道，这意味着准确率低到0也是有可能的，这多让人郁闷。</li><li>而且现在DAG方法根节点的选取（也就是如何选第一个参与分类的分类器），也有一些方法可以改善整体效果，我们总希望根节点少犯错误为好，因此参与第一次分类的两个类别，最好是差别特别特别大，大到以至于不太可能把他们分错；或者我们就总取在两类分类中正确率最高的那个分类器作根节点，或者我们让两类分类器在分类的时候，不光输出类别的标签，还输出一个类似“置信度”的东东，当它对自己的结果不太自信的时候，我们就不光按照它的输出走，把它旁边的那条路也走一走，等等。</li></ul><h3 id="大Tips：SVM的计算复杂度"><a href="#大Tips：SVM的计算复杂度" class="headerlink" title="@大Tips：SVM的计算复杂度"></a>@大Tips：SVM的计算复杂度</h3><ul><li>使用SVM进行分类的时候，实际上是<font color="red"><strong>训练和分类</strong></font>两个完全不同的过程，因而讨论复杂度就不能一概而论，我们这里所说的主要是训练阶段的复杂度，即解那个二次规划问题的复杂度。对这个问题的解，基本上要划分为两大块，<font color="red"><strong>解析解和数值解</strong></font>。</li><li><font color="red"><strong>解析解就是理论上的解</strong></font>，它的形式是表达式，因此它是精确的，一个问题只要有解（无解的问题还跟着掺和什么呀，哈哈），那它的解析解是一定存在的。当然存在是一回事，能够解出来，或者可以在可以承受的时间范围内解出来，就是另一回事了。对SVM来说，求得解析解的时间复杂度最坏可以达到O(Nsv3)，其中Nsv是支持向量的个数，而虽然没有固定的比例，但支持向量的个数多少也和训练集的大小有关。</li><li><font color="red"><strong>数值解就是可以使用的解</strong></font>，是一个一个的数，往往都是近似解。求数值解的过程非常像穷举法，从一个数开始，试一试它当解效果怎样，不满足一定条件（叫做停机条件，就是满足这个以后就认为解足够精确了，不需要继续算下去了）就试下一个，当然下一个数不是乱选的，也有一定章法可循。有的算法，每次只尝试一个数，有的就尝试多个，而且找下一个数字（或下一组数）的方法也各不相同，停机条件也各不相同，最终得到的解精度也各不相同，可见对求数值解的复杂度的讨论不能脱开具体的算法。</li><li>一个具体的算法，<font color="red"><strong>Bunch-Kaufman训练算法</strong></font>，典型的时间复杂度在O(Nsv3+LNsv2+dLNsv)和O(dL2)之间，其中Nsv是支持向量的个数，L是训练集样本的个数，d是每个样本的维数（原始的维数，没有经过向高维空间映射之前的维数）。复杂度会有变化，是因为它不光跟输入问题的规模有关（不光和样本的数量，维数有关），也和问题最终的解有关（即支持向量有关），如果支持向量比较少，过程会快很多，如果支持向量很多，接近于样本的数量，就会产生O(dL2)这个十分糟糕的结果（给10，000个样本，每个样本1000维，基本就不用算了，算不出来，呵呵，而这种输入规模对文本分类来说太正常了）。 </li><li>这样再回头看就会明白为什么一对一方法尽管要训练的两类分类器数量多，但总时间实际上比一对其余方法要少了，因为一对其余方法每次训练都考虑了所有样本（只是每次把不同的部分划分为正类或者负类而已），自然慢上很多。</li></ul><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><ul><li>这篇文章真的写的不错，不要漏了。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;写在前面的话&quot;&gt;&lt;a href=&quot;#写在前面的话&quot; class=&quot;headerlink&quot; title=&quot;写在前面的话&quot;&gt;&lt;/a&gt;写在前面的话&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;本文是一个备份，转自：&lt;a class=&quot;link&quot;   href=&quot;http://www.bl</summary>
      
    
    
    
    <category term="毕业设计系列" scheme="http://example.com/categories/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%E7%B3%BB%E5%88%97/"/>
    
    
    <category term="SVM入门" scheme="http://example.com/tags/SVM%E5%85%A5%E9%97%A8/"/>
    
  </entry>
  
  <entry>
    <title>【基础】常用的机器学习&amp;数据挖掘知识点</title>
    <link href="http://example.com/2015/01/04/%E3%80%90%E5%9F%BA%E7%A1%80%E3%80%91%E5%B8%B8%E7%94%A8%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%9F%A5%E8%AF%86%E7%82%B9/"/>
    <id>http://example.com/2015/01/04/%E3%80%90%E5%9F%BA%E7%A1%80%E3%80%91%E5%B8%B8%E7%94%A8%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%9F%A5%E8%AF%86%E7%82%B9/</id>
    <published>2015-01-04T11:04:41.000Z</published>
    <updated>2015-08-03T00:31:40.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h1><ul><li><img src="/img/repost/ml-basic.png"></li><li>转自：<a class="link"   href="http://www.36dsj.com/archives/20135#rd" >36大数据<i class="fas fa-external-link-alt"></i></a></li><li>本文总结了机器学习入门的基础知识的<font color="red"><strong>标题</strong></font>。相当于给我们入门者一个学习的架构。</li></ul><h2 id="Basis-基础"><a href="#Basis-基础" class="headerlink" title="Basis(基础)"></a>Basis(基础)</h2><ul><li>MSE(Mean Square Error (均方误差)</li><li>LMS(LeastMean Square (最小均方)</li><li>LSM(Least Square Methods (最小二乘法)</li><li>MLE(MaximumLikelihood Estimation (最大似然估计)</li><li>QP(Quadratic Programming (二次规划) </li><li>CP(Conditional Probability (条件概率)</li><li>JP(Joint Probability (联合概率)</li><li>MP(Marginal Probability (边缘概率)</li><li>Bayesian Formula (贝叶斯公式)</li><li>L1 &#x2F;L2Regularization (L1&#x2F;L2正则，以及更多的，现在比较火的L2.5正则等)</li><li>GD (GradientDescent 梯度下降)</li><li>SGD (Stochastic Gradient Descent 随机梯度下降)</li><li>Eigenvalue (特征值)</li><li>Eigenvector (特征向量)</li><li>QR-decomposition (QR分解)</li><li>Quantile (分位数)</li><li>Covariance (协方差矩阵)</li></ul><h2 id="Common-Distribution-常见分布"><a href="#Common-Distribution-常见分布" class="headerlink" title="Common Distribution(常见分布)"></a>Common Distribution(常见分布)</h2><h3 id="Discrete-Distribution-离散型分布"><a href="#Discrete-Distribution-离散型分布" class="headerlink" title="Discrete Distribution(离散型分布)"></a>Discrete Distribution(离散型分布)</h3><ul><li>BernoulliDistribution&#x2F;Binomial(贝努利分布&#x2F;二项分布)</li><li>Negative BinomialDistribution(负二项分布)</li><li>MultinomialDistribution(多项式分布)</li><li>Geometric Distribution(几何分布)</li><li>HypergeometricDistribution(超几何分布)</li><li>Poisson Distribution (泊松分布)</li></ul><h3 id="Continuous-Distribution-连续型分布"><a href="#Continuous-Distribution-连续型分布" class="headerlink" title="Continuous Distribution (连续型分布)"></a>Continuous Distribution (连续型分布)</h3><ul><li>UniformDistribution(均匀分布)</li><li>Normal Distribution &#x2F;Guassian Distribution(正态分布&#x2F;高斯分布)</li><li>ExponentialDistribution(指数分布)</li><li>Lognormal Distribution(对数正态分布)</li><li>GammaDistribution(Gamma分布)</li><li>Beta Distribution(Beta分布)</li><li>Dirichlet Distribution(狄利克雷分布)</li><li>Rayleigh Distribution(瑞利分布)</li><li>Cauchy Distribution(柯西分布)</li><li>Weibull Distribution (韦伯分布)</li></ul><h3 id="Three-Sampling-Distribution-三大抽样分布"><a href="#Three-Sampling-Distribution-三大抽样分布" class="headerlink" title="Three Sampling Distribution(三大抽样分布)"></a>Three Sampling Distribution(三大抽样分布)</h3><ul><li>Chi-squareDistribution(卡方分布)</li><li>t-distribution(t-分布)</li><li>F-distribution(F-分布)</li></ul><h2 id="Data-Pre-processing-数据预处理"><a href="#Data-Pre-processing-数据预处理" class="headerlink" title="Data Pre-processing(数据预处理)"></a>Data Pre-processing(数据预处理)</h2><ul><li>Missing Value Imputation(缺失值填充)</li><li>Discretization(离散化)</li><li>Mapping(映射)</li><li>Normalization(归一化&#x2F;标准化)</li></ul><h2 id="Sampling-采样"><a href="#Sampling-采样" class="headerlink" title="Sampling(采样)"></a>Sampling(采样)</h2><ul><li>Simple Random Sampling(简单随机采样)</li><li>OfflineSampling(离线等可能K采样)</li><li>Online Sampling(在线等可能K采样)</li><li>Ratio-based Sampling(等比例随机采样)</li><li>Acceptance-RejectionSampling(接受-拒绝采样)</li><li>Importance Sampling(重要性采样)</li><li>MCMC(MarkovChain Monte Carlo 马尔科夫蒙特卡罗采样算法：Metropolis-Hasting&amp; Gibbs)</li></ul><h2 id="Clustering-聚类"><a href="#Clustering-聚类" class="headerlink" title="Clustering(聚类)"></a>Clustering(聚类)</h2><ul><li>K-Means</li><li>K-Mediods</li><li>二分K-Means</li><li>FK-Means</li><li>Canopy</li><li>Spectral-KMeans(谱聚类)</li><li>GMM-EM(混合高斯模型-期望最大化算法解决)</li><li>K-Pototypes</li><li>CLARANS(基于划分)</li><li>BIRCH(基于层次)</li><li>CURE(基于层次)</li><li>DBSCAN(基于密度)</li><li>CLIQUE(基于密度和基于网格)</li></ul><h2 id="Classification-amp-Regression-分类-amp-回归"><a href="#Classification-amp-Regression-分类-amp-回归" class="headerlink" title="Classification&amp;Regression(分类&amp;回归)"></a>Classification&amp;Regression(分类&amp;回归)</h2><ul><li>LR(Linear Regression 线性回归)</li><li>LR(LogisticRegression逻辑回归)</li><li>SR(Softmax Regression 多分类逻辑回归)</li><li>GLM(GeneralizedLinear Model 广义线性模型)</li><li>RR(Ridge Regression 岭回归&#x2F;L2正则最小二乘回归)</li><li>LASSO(Least Absolute Shrinkage andSelectionator Operator L1正则最小二乘回归)</li><li>RF(随机森林)</li><li>DT(DecisionTree决策树)</li><li>GBDT(Gradient BoostingDecision Tree 梯度下降决策树)</li><li>CART(ClassificationAnd Regression Tree 分类回归树)</li><li>KNN(K-Nearest Neighbor K近邻)</li><li>SVM(Support VectorMachine)</li><li>KF(KernelFunction 核函数)</li><li>PolynomialKernel Function 多项式核函数</li><li>Guassian KernelFunction 高斯核函数</li><li>Radial BasisFunction RBF径向基函数</li><li>String KernelFunction (字符串核函数)</li><li>NB(Naive Bayes 朴素贝叶斯)</li><li>BN(Bayesian Network&#x2F;Bayesian Belief Network&#x2F; Belief Network 贝叶斯网络&#x2F;贝叶斯信度网络&#x2F;信念网络)</li><li>LDA(Linear Discriminant Analysis&#x2F;FisherLinear Discriminant 线性判别分析&#x2F;Fisher线性判别)</li><li>EL(Ensemble Learning集成学习Boosting，Bagging，Stacking)</li><li>AdaBoost(Adaptive Boosting 自适应增强)</li><li>MEM(MaximumEntropy Model最大熵模型)</li></ul><h2 id="Effectiveness-Evaluation-分类效果评估"><a href="#Effectiveness-Evaluation-分类效果评估" class="headerlink" title="Effectiveness Evaluation(分类效果评估)"></a>Effectiveness Evaluation(分类效果评估)</h2><ul><li>Confusion Matrix(混淆矩阵)</li><li>Precision(精确度)</li><li>Recall(召回率)</li><li>Accuracy(准确率)</li><li>F-score(F得分)</li><li>ROC Curve(ROC曲线)</li><li>AUC(AUC面积)</li><li>LiftCurve(Lift曲线) </li><li>KS Curve(KS曲线)</li></ul><h2 id="PGM-Probabilistic-Graphical-Models概率图模型"><a href="#PGM-Probabilistic-Graphical-Models概率图模型" class="headerlink" title="PGM(Probabilistic Graphical Models概率图模型)"></a>PGM(Probabilistic Graphical Models概率图模型)</h2><ul><li>BN(Bayesian Network&#x2F;Bayesian Belief Network&#x2F; BeliefNetwork 贝叶斯网络&#x2F;贝叶斯信度网络&#x2F;信念网络)</li><li>MC(Markov Chain 马尔科夫链)</li><li>HMM(HiddenMarkov Model 马尔科夫模型)</li><li>MEMM(Maximum Entropy Markov Model 最大熵马尔科夫模型)</li><li>CRF(ConditionalRandom Field 条件随机场)</li><li>MRF(MarkovRandom Field 马尔科夫随机场)</li></ul><h2 id="NN-Neural-Network神经网络"><a href="#NN-Neural-Network神经网络" class="headerlink" title="NN(Neural Network神经网络)"></a>NN(Neural Network神经网络)</h2><ul><li>ANN(Artificial Neural Network 人工神经网络)</li><li>BP(Error BackPropagation 误差反向传播)</li></ul><h2 id="Deep-Learning-深度学习"><a href="#Deep-Learning-深度学习" class="headerlink" title="Deep Learning(深度学习)"></a>Deep Learning(深度学习)</h2><ul><li>Auto-encoder(自动编码器)</li><li>SAE(Stacked Auto-encoders堆叠自动编码器：Sparse Auto-encoders稀疏自动编码器、Denoising Auto-encoders去噪自动编码器、Contractive Auto-encoders 收缩自动编码器)</li><li>RBM(RestrictedBoltzmann Machine 受限玻尔兹曼机)</li><li>DBN(Deep Belief Network 深度信念网络)</li><li>CNN(ConvolutionalNeural Network 卷积神经网络)</li><li>Word2Vec(词向量学习模型)</li></ul><h2 id="DimensionalityReduction-降维"><a href="#DimensionalityReduction-降维" class="headerlink" title="DimensionalityReduction(降维)"></a>DimensionalityReduction(降维)</h2><ul><li>LDA LinearDiscriminant Analysis&#x2F;Fisher Linear Discriminant 线性判别分析&#x2F;Fisher线性判别</li><li>PCA(Principal Component Analysis 主成分分析)</li><li>ICA(IndependentComponent Analysis 独立成分分析)</li><li>SVD(Singular Value Decomposition 奇异值分解)</li><li>FA(FactorAnalysis 因子分析法)</li></ul><h2 id="Text-Mining-文本挖掘"><a href="#Text-Mining-文本挖掘" class="headerlink" title="Text Mining(文本挖掘)"></a>Text Mining(文本挖掘)</h2><ul><li>VSM(Vector Space Model向量空间模型)</li><li>Word2Vec(词向量学习模型)</li><li>TF(Term Frequency词频)</li><li>TF-IDF(Term Frequency-Inverse DocumentFrequency 词频-逆向文档频率)</li><li>MI(MutualInformation 互信息)</li><li>ECE(Expected Cross Entropy 期望交叉熵)</li><li>QEMI(二次信息熵)</li><li>IG(InformationGain 信息增益)</li><li>IGR(Information Gain Ratio 信息增益率)</li><li>Gini(基尼系数)，x2 Statistic(x2统计量)</li><li>TEW(TextEvidence Weight文本证据权)</li><li>OR(Odds Ratio 优势率)</li><li>N-Gram Model，LSA(Latent Semantic Analysis 潜在语义分析)</li><li>PLSA(ProbabilisticLatent Semantic Analysis 基于概率的潜在语义分析)</li><li>LDA(Latent DirichletAllocation 潜在狄利克雷模型)</li></ul><h2 id="Association-Mining-关联挖掘"><a href="#Association-Mining-关联挖掘" class="headerlink" title="Association Mining(关联挖掘)"></a>Association Mining(关联挖掘)</h2><ul><li>Apriori</li><li>FP-growth(Frequency Pattern Tree Growth 频繁模式树生长算法)</li><li>AprioriAll</li><li>Spade</li></ul><h2 id="Recommendation-Engine-推荐引擎"><a href="#Recommendation-Engine-推荐引擎" class="headerlink" title="Recommendation Engine(推荐引擎)"></a>Recommendation Engine(推荐引擎)</h2><ul><li>DBR(Demographic-based Recommendation 基于人口统计学的推荐)</li><li>CBR(Context-basedRecommendation 基于内容的推荐)</li><li>CF(Collaborative Filtering协同过滤)</li><li>UCF(User-basedCollaborative Filtering Recommendation 基于用户的协同过滤推荐)</li><li>ICF(Item-basedCollaborative Filtering Recommendation 基于项目的协同过滤推荐)</li></ul><h2 id="Similarity-Measure-amp-Distance-Measure-相似性与距离度量-："><a href="#Similarity-Measure-amp-Distance-Measure-相似性与距离度量-：" class="headerlink" title="Similarity Measure&amp;Distance Measure(相似性与距离度量)："></a>Similarity Measure&amp;Distance Measure(相似性与距离度量)：</h2><ul><li>Euclidean Distance(欧式距离)</li><li>ManhattanDistance(曼哈顿距离)</li><li>Chebyshev Distance(切比雪夫距离)</li><li>MinkowskiDistance(闵可夫斯基距离)</li><li>Standardized Euclidean Distance(标准化欧氏距离)</li><li>MahalanobisDistance(马氏距离)</li><li>Cos(Cosine 余弦)</li><li>HammingDistance&#x2F;Edit Distance(汉明距离&#x2F;编辑距离)</li><li>JaccardDistance(杰卡德距离)</li><li>Correlation Coefficient Distance(相关系数距离)</li><li>InformationEntropy(信息熵)</li><li>KL(Kullback-Leibler Divergence KL散度&#x2F;Relative Entropy 相对熵)</li></ul><h2 id="Optimization-最优化"><a href="#Optimization-最优化" class="headerlink" title="Optimization(最优化)"></a>Optimization(最优化)</h2><ul><li>Heuristic Algorithm(启发式算法)</li><li>SA(SimulatedAnnealing，模拟退火算法)</li><li>GA(genetic algorithm遗传算法)</li></ul><h3 id="Non-constrainedOptimization-无约束优化"><a href="#Non-constrainedOptimization-无约束优化" class="headerlink" title="Non-constrainedOptimization(无约束优化)"></a>Non-constrainedOptimization(无约束优化)</h3><ul><li>Cyclic VariableMethods(变量轮换法)</li><li>Pattern Search Methods(模式搜索法)</li><li>VariableSimplex Methods(可变单纯形法)</li><li>Gradient Descent Methods(梯度下降法)</li><li>Newton Methods(牛顿法)</li><li>Quasi-NewtonMethods(拟牛顿法)</li><li>Conjugate Gradient Methods(共轭梯度法)</li></ul><h3 id="ConstrainedOptimization-有约束优化"><a href="#ConstrainedOptimization-有约束优化" class="headerlink" title="ConstrainedOptimization(有约束优化)"></a>ConstrainedOptimization(有约束优化)</h3><ul><li>Approximation Programming Methods(近似规划法)</li><li>FeasibleDirection Methods(可行方向法)</li><li>Penalty Function Methods(罚函数法)</li><li>Multiplier Methods(乘子法)</li></ul><h2 id="Feature-Selection-特征选择算法"><a href="#Feature-Selection-特征选择算法" class="headerlink" title="Feature Selection(特征选择算法)"></a>Feature Selection(特征选择算法)</h2><ul><li>Mutual Information(互信息)</li><li>DocumentFrequence(文档频率)</li><li>Information Gain(信息增益)</li><li>Chi-squared Test(卡方检验)</li><li>Gini(基尼系数)</li></ul><h2 id="Outlier-Detection-异常点检测算法"><a href="#Outlier-Detection-异常点检测算法" class="headerlink" title="Outlier Detection(异常点检测算法)"></a>Outlier Detection(异常点检测算法)</h2><ul><li>Statistic-based(基于统计)</li><li>Distance-based(基于距离)</li><li>Density-based(基于密度)</li><li>Clustering-based(基于聚类)</li></ul><h2 id="Learning-to-Rank-基于学习的排序"><a href="#Learning-to-Rank-基于学习的排序" class="headerlink" title="Learning to Rank(基于学习的排序)"></a>Learning to Rank(基于学习的排序)</h2><ul><li>Pointwise：McRank；</li><li>Pairwise：RankingSVM，RankNet，Frank，RankBoost；</li><li>Listwise：AdaRank，SoftRank，LamdaMART；</li></ul><h2 id="Tool-工具"><a href="#Tool-工具" class="headerlink" title="Tool(工具)"></a>Tool(工具)</h2><ul><li>MPI，Hadoop生态圈，Spark，BSP，Weka，Mahout，Scikit-learn，PyBrain…</li></ul><h1 id="End"><a href="#End" class="headerlink" title="End"></a>End</h1>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;说明&quot;&gt;&lt;a href=&quot;#说明&quot; class=&quot;headerlink&quot; title=&quot;说明&quot;&gt;&lt;/a&gt;说明&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;img src=&quot;/img/repost/ml-basic.png&quot;&gt;&lt;/li&gt;
&lt;li&gt;转自：&lt;a class=&quot;link&quot;</summary>
      
    
    
    
    <category term="机器学习" scheme="http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="机器学习基础" scheme="http://example.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>手写数字识别-Kernel Support Vector Machine-论文翻译-毕设系列</title>
    <link href="http://example.com/2015/01/03/%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB-Kernel%20Support%20Vector%20Machine-%E5%8D%9A%E5%AE%A2%E7%BF%BB%E8%AF%91-%E6%AF%95%E8%AE%BE%E7%B3%BB%E5%88%97/"/>
    <id>http://example.com/2015/01/03/%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB-Kernel%20Support%20Vector%20Machine-%E5%8D%9A%E5%AE%A2%E7%BF%BB%E8%AF%91-%E6%AF%95%E8%AE%BE%E7%B3%BB%E5%88%97/</id>
    <published>2015-01-03T06:29:02.000Z</published>
    <updated>2015-01-03T13:30:58.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="写在前面的话"><a href="#写在前面的话" class="headerlink" title="写在前面的话"></a>写在前面的话</h1><ul><li>本篇博文是翻译自Code Project上的<a class="link"   href="http://www.codeproject.com/script/Membership/View.aspx?mid=1841592" >César de Souza<i class="fas fa-external-link-alt"></i></a>教授的关于用Kernel Support Vector Machine手写数字识别的博客。认真学习借鉴一下。</li><li>出处：<a class="link"   href="http://www.codeproject.com/Articles/106583/Handwriting-Recognition-Revisited-Kernel-Support-V" >Handwriting Recognition Revisited: Kernel Support Vector Machines<i class="fas fa-external-link-alt"></i></a></li></ul><h1 id="博文正文"><a href="#博文正文" class="headerlink" title="博文正文"></a>博文正文</h1><ul><li>在上一篇文章中，我们讨论了怎么利用基于核函数的辨别分析(Kernel Discriminant Analysis)的方法来解决手写数字识别的问题。在这里，我们将要讨论如何利用基于核函数的支持向量机(Kernel Support Vector Machine)的一些技巧来解决手写数字的识别问题。</li><li><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/download.png"><a class="link"   href="http://www.codeproject.com/KB/recipes/handwriting-svm/accord-handwritting-svm-src.zip" >Download source code - 584 KB <i class="fas fa-external-link-alt"></i></a></li><li><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/download.png"><a class="link"   href="http://www.codeproject.com/KB/recipes/handwriting-svm/accord-handwritting-svm-bin.zip" >Download sample application - 522 KB<i class="fas fa-external-link-alt"></i></a></li><li><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/download.png">Download the <a class="link"   href="http://accord-framework.net/" >Accord.NET Machine Learning Framework.<i class="fas fa-external-link-alt"></i></a></li><li>由于在最新的代码库中，它通常包含了最新的功能增强和修正，所以请下载  最新的<a class="link"   href="http://accord-framework.net/" >Accord.NET Framework<i class="fas fa-external-link-alt"></i></a>.</li><li><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/font.png"></li></ul><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><ul><li>在上一篇文章中，我想向大家展示怎么用<a class="link"   href="http://crsouza.blogspot.com/2010/01/kernel-discriminant-analysis-in-c.html" >核判别分析法<i class="fas fa-external-link-alt"></i></a>来解决手写数字识别的问题。但是，我发现自己并没有更多的关注手写数字识别的问题，因为我把焦点都放在了KDA方法上了，而不是识别问题本身。在本篇文章中，我会给大家展示一个更好的方法来解决数字识别的问题。</li><li>核判别分析方法有自己的问题集。尽管它在处理高维度的数据是没有任何问题，但当样本的数量达到O(n³)，它就显得有些无能为力了。另外一个更严重的问题是在模型评估过程中核判别分析方法需要载入全部数据集，这样令它很难推广(例如嵌入式系统)。</li><li>在上一篇文章的最后，我提到了SVM其实是一种解决数字识别的更好的方法。SVM的一个优点是它们的解决问题的方法比较单一，不像KDA,它们在数据评估的过程中不需要载入全部数据集，而只是需要非常小部分的数据。这部分数据就是我们所通常称的”支持向量”。</li></ul><h3 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h3><ul><li><a class="link"   href="http://en.wikipedia.org/wiki/Support_vector_machine" >支持向量机<i class="fas fa-external-link-alt"></i></a>是属于<a class="link"   href="http://en.wikipedia.org/wiki/Supervised_learning" >监督学习<i class="fas fa-external-link-alt"></i></a>方法中的一种，它既可以用作<a class="link"   href="http://en.wikipedia.org/wiki/Statistical_classification" >分类<i class="fas fa-external-link-alt"></i></a>，也可以用做<a class="link"   href="http://en.wikipedia.org/wiki/Regression_analysis" >回归<i class="fas fa-external-link-alt"></i></a>。简单的说，给定一个训练数据样本，其中的每条记录都有一个标记变量，它标记着本条记录是属于哪一个分类的(现在讨论的是二类分类器)，然后数据集通过SVM分类器进行训练得到一个<a class="link"   href="http://en.wikipedia.org/wiki/Classifier_(mathematics)" >决策模型<i class="fas fa-external-link-alt"></i></a>，这个模型可以预测新进来的一条记录是属于两个分类中的哪一种。如果样本中的每条记录是落在空间上的某个点，那么一个SVM的线性分类器可以看做是空间中的一个分界，把空间分成两类，这样我们希望把样本分成两类的清晰的间隔，它越宽越好。新的样本点看它落在间隔的那一边上就可以预测它属于那一类的了。<br><br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/SVM-1.png"></li><li>一个线性SVM是由给定的支持向量<strong>z</strong>集合和权重<strong>w</strong>集合组成。由N个支持向量z1,z2…zN和w1,w2…wN构成的支持向量机输出的计算公式是：<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/SVM-fornular-1.png"></li><li>一个决策函数通常把这个作为输入变量，然后转化为一个二类分类器。通常地，我们用sign(.)函数，就是符号函数，输入变量大于0的作为一类，输入变量小于0的作为另外一类。</li></ul><h3 id="基于核函数的支持向量机"><a href="#基于核函数的支持向量机" class="headerlink" title="基于核函数的支持向量机"></a>基于核函数的支持向量机</h3><ul><li>如上所述，原始的SVM的最优化平面是一个<a class="link"   href="http://en.wikipedia.org/wiki/Linear_classifier" >线性分类器<i class="fas fa-external-link-alt"></i></a>。然而，从它在1963年提出的30年后，一些研究者(包括原提出者自己)建议把<a class="link"   href="http://en.wikipedia.org/wiki/Kernel_trick" >核技巧<i class="fas fa-external-link-alt"></i></a>应用到那些最大边界超平面来创建一个非线性分类器。结果引起了研究<a class="link"   href="http://www.kernel-machines.org/" >“核方法”<i class="fas fa-external-link-alt"></i></a>的一片浪潮，而核方法开始成为一个最有力的而且最受欢迎的分类方法。</li><li>不容置疑的是，核技巧是一种非常有力的工具，它提供了一种仅仅依赖于求两个向量的点积的算法来打通了线性和非线性的之间的桥梁。事实上，我们首先把输入数据映射到一个高维空间，然后一个线性的算法就可以在这个空间上操作在原始空间中的非线性的输入数据。</li><li>这个“技巧”的厉害之处在于它根本就不用计算映射后的点积；我们所需要做的是找到一个适合的核函数来代替所有的点积(这样便可以简化了计算)。核函数标记特征空间中的一个内积，它通常记为：<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/kernel-function-form.png"><br>(其中Ψ()代表映射函数)。</li><li>利用核函数，算法能被带入到高维空间而不需要明确的把输入点映射到这个空间上。这是非常取巧的，特别是当高维的特征空间是无穷多维的，它是不可以计算的时候。正是由于原始的SVM的公式中包含点积运算，它是可以直接应用核技巧的。即使结果分类器在高维特征空间中是个超平面，但在原始空间中它还是非线性的。核技巧的应用同样为不同的视野去进行比较的分类器提供了非常有力的理论支持，例如，生物。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/kernel-transform.png"></li><li>可以很明显的看出，通过核函数(of the form K(z,x) &#x3D; &lt;z,x&gt; &#x3D; zTx)，我们又得到了原始线性SVM的相似公式。想了解更详细的关于核技巧的资料和核函数应用的例子，可以参考<a class="link"   href="http://www.codeproject.com/KB/recipes/handwriting-kda.aspx" >previous article about Kernel Discriminant Analysis<i class="fas fa-external-link-alt"></i></a>，或者<a class="link"   href="http://crsouza.blogspot.com/2010/03/kernel-functions-for-machine-learning.html" >Kernel Functions for Machine Learning Applications<i class="fas fa-external-link-alt"></i></a>。</li></ul><h3 id="多分类的支持向量机"><a href="#多分类的支持向量机" class="headerlink" title="多分类的支持向量机"></a>多分类的支持向量机</h3><ul><li>很不幸的，不像<a class="link"   href="http://www.codeproject.com/KB/recipes/handwriting-kda.aspx" >KDA<i class="fas fa-external-link-alt"></i></a>，支持向量机并没有很自然的推广到多分类的问题。原始的SVM是一个<a class="link"   href="http://en.wikipedia.org/wiki/Binary_classification" >二类分类器<i class="fas fa-external-link-alt"></i></a>，它一次只可以在两个分类中进行预测。然而，<a class="link"   href="http://en.wikipedia.org/wiki/Support_vector_machines#Multiclass_SVM" >现实问题需要更多的是可以用SVM解决多分类问题<i class="fas fa-external-link-alt"></i></a>，下面我们就来举一个例子。</li><li>假设我们有三个分类A,B,C。现在，假设我们只有二类分类器，那么我们怎么把二类分类器去解决一个多分类器的问题呢？其中一个可行的方法就是把我们的多分类问问题拆成多个二类分类器的集合。下面左边的矩阵是泳衣解决三个分类的分类器的二类分类器的所有组合：<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/binary-conbination.png"></li><li>然而，注意到上面左边的矩阵中有一些多余的情况。譬如，计算AxA是没有意义的。还有，计算AxB之后再计算BxA是很低效率的，我们计算了AxB后，可以通过取反就得到了BxA。丢弃了多余的选项后，我们只剩下右边的(半透明的，除了AxA,BxB,CxC)矩阵。观察可知，一个n类的分类问题可以拆分成n(n-1)&#x2F;2个二类分类器的组合组成的小的子集合。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/n-binary.png"></li><li>现在我们得到了3个二类分类的问题，所以，我们需要创建3个SVM来解决每一个子问题。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/3-SVM.png"></li><li>要确定一个分类，我们就看3个SVM当中谁的投票最多。譬如，A在第一个SVM中胜出，而C在其他的两个SVM中都胜出。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/3-SVM-2.png"></li><li>如果我们把胜出次数最多的作为赢家，那么我们应该把它归为C类。这种方法通常称作多分类器中的”一对一”策略。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/table-one-against-one.png"></li><li>另外一种方法是利用“一对多”的策略，把输入放到所有的SVM中，然后选择最高的输出的那个SVM。很不幸的，我们不能保证有最高的输出就是最好的SVM。这个不作本文讨论的范畴。</li></ul><h2 id="源代码"><a href="#源代码" class="headerlink" title="源代码"></a>源代码</h2><ul><li>基于核方法的支持向量机的代码也是属于<a class="link"   href="http://accord-framework.net/" >Accord.NET<i class="fas fa-external-link-alt"></i></a>的一部分，这个框架我做了数年。它是在<a class="link"   href="http://code.google.com/p/aforge/" >AForge.NET<i class="fas fa-external-link-alt"></i></a>的顶层建立的,<a class="link"   href="http://code.google.com/p/aforge/" >AForge.NET<i class="fas fa-external-link-alt"></i></a>是计算机视觉，机器学习中非常受欢迎的框架，它集合了我过去的研究中的多个主题。目前，它有了<a class="link"   href="http://crsouza.blogspot.com/2009/09/principal-component-analysis-in-c.html" >PCA<i class="fas fa-external-link-alt"></i></a>, <a class="link"   href="http://crsouza.blogspot.com/2010/01/kernel-principal-component-analysis-in.html" >KPCA<i class="fas fa-external-link-alt"></i></a>, <a class="link"   href="http://crsouza.blogspot.com/2010/01/linear-discriminant-analysis-in-c.html" >LDA<i class="fas fa-external-link-alt"></i></a>, <a class="link"   href="http://crsouza.blogspot.com/2010/01/kernel-discriminant-analysis-in-c.html" >KDA<i class="fas fa-external-link-alt"></i></a>, <a class="link"   href="http://crsouza.blogspot.com/2010/02/logistic-regression-in-c.html" >LR<i class="fas fa-external-link-alt"></i></a>, <a class="link"   href="http://crsouza.blogspot.com/2010/04/partial-least-squares-analysis-and.html" >PLS<i class="fas fa-external-link-alt"></i></a>, <a class="link"   href="http://crsouza.blogspot.com/2010/04/kernel-support-vector-machines-for.html" >SVMs<i class="fas fa-external-link-alt"></i></a>, <a class="link"   href="http://www.codeproject.com/Articles/69647/Hidden-Markov-Models-in-Csharp.aspx" >HMMs<i class="fas fa-external-link-alt"></i></a>, <a class="link"   href="http://www.codeproject.com/Articles/55691/Neural-Network-Learning-by-the-Levenberg-Marquardt.aspx" >LM-ANN<i class="fas fa-external-link-alt"></i></a>和其他的缩写。这个项目在Github上举办，地址是：<a class="link"   href="https://github.com/accord-net/framework/" >https://github.com/accord-net/framework/<i class="fas fa-external-link-alt"></i></a>。最小的版本中包含了最小的bug修正，完善和功能加强，新特征等，我强烈推荐大家直接从Github上下载最新的版本库。</li></ul><h3 id="支持向量机-1"><a href="#支持向量机-1" class="headerlink" title="支持向量机"></a>支持向量机</h3><ul><li>支持向量机类结构如下：(C#和VB实现)<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/svm-class-structure.png"></li><li><a class="link"   href="http://accord-framework.net/docs/html/T_Accord_MachineLearning_VectorMachines_KernelSupportVectorMachine.htm" >KernelSupportVectorMachine<i class="fas fa-external-link-alt"></i></a>类继承SupportVectorMachine类，加了kernel方法。MulticlassSupportVectorMachine类集合了一堆实现了“一对一”策略的KernelSupportVectorMachines类来实现多分类器。框架的API在此：<a class="link"   href="http://accord-framework.net/docs/html/N_Accord_Statistics_Kernels.htm" >extensive list of machine learning kernel functions to chose from<i class="fas fa-external-link-alt"></i></a>.</li></ul><h3 id="训练算法"><a href="#训练算法" class="headerlink" title="训练算法"></a>训练算法</h3><ul><li>训练算法既可以实现分类也可以实现回归。它们是<a class="link"   href="http://research.microsoft.com/apps/pubs/default.aspx?id=69644" >Platt的序列最优化(SMO)算法<i class="fas fa-external-link-alt"></i></a>的直接实现。MulticlassSupportVectorLearning类提供了一个回调函数，名字是Configure，它可以被任何的算法选择并进行配置。这个方法并没有强加需要利用哪一种算法，而且还允许用户利用自定义的算法来进行训练。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/svm-class-structure-2.png"></li><li>因为MulticlassSupportVectorLearning算法一次可以训练一堆独立的机器，所以它容易实现并行运算。事实上，这些实现方法在单台机器中可以充分利用剩下的核。<figure class="highlight c#"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"><span class="doctag">///</span> <span class="doctag">&lt;summary&gt;</span></span></span><br><span class="line"><span class="comment"><span class="doctag">///</span>   Runs the one-against-one learning algorithm.</span></span><br><span class="line"><span class="comment"><span class="doctag">///</span> <span class="doctag">&lt;/summary&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="built_in">double</span> <span class="title">Run</span>(<span class="params"><span class="built_in">bool</span> computeError</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">// For each class i</span></span><br><span class="line">    AForge.Parallel.For(<span class="number">0</span>, msvm.Classes, <span class="built_in">delegate</span>(<span class="built_in">int</span> i)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// For each class j</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="built_in">int</span> j = <span class="number">0</span>; j &lt; i; j++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// Retrieve the associated machine</span></span><br><span class="line">            <span class="keyword">var</span> machine = msvm[i,j];</span><br><span class="line"></span><br><span class="line">            <span class="comment">// Retrieve the associated classes</span></span><br><span class="line">            <span class="built_in">int</span>[] idx = outputs.Find(x =&gt; x == i || x == j);</span><br><span class="line">            <span class="built_in">double</span>[][] subInputs = inputs.Submatrix(idx);</span><br><span class="line">            <span class="built_in">int</span>[] subOutputs = outputs.Submatrix(idx);</span><br><span class="line">   </span><br><span class="line">            <span class="comment">// Transform in a two-class problem</span></span><br><span class="line">            subOutputs.ApplyInPlace(x =&gt; x = (x == i) ? <span class="number">-1</span> : <span class="number">1</span>);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// Train the machine on the two-class problem.</span></span><br><span class="line">            configure(machine, subInputs, subOutputs).Run(<span class="literal">false</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>上面的代码利用了<a class="link"   href="http://www.codeproject.com/KB/cs/aforge_parallel.aspx" >AForge.NET Parallel<i class="fas fa-external-link-alt"></i></a>的构造器和<a class="link"   href="http://crsouza.blogspot.com/2010/08/matrix-manipulation-using-accordnet.html" >Accord.NET matrix extensions<i class="fas fa-external-link-alt"></i></a>。我决定不用最新加的 .NET 4.0 Parallel Extensions,所以这个框架还是兼容.NET 3.5 applications的应用的。</li></ul><h2 id="数字识别"><a href="#数字识别" class="headerlink" title="数字识别"></a>数字识别</h2><h3 id="UCI的光学数字数据集"><a href="#UCI的光学数字数据集" class="headerlink" title="UCI的光学数字数据集"></a>UCI的光学数字数据集</h3><ul><li>如果你读了上一篇文章<a class="link"   href="http://crsouza.blogspot.com/2010/01/kernel-discriminant-analysis-in-c.html" >Kernel Discriminant Analysis for Handwritten Digit Recognition<i class="fas fa-external-link-alt"></i></a>，那么请跳过本小节。本小节只是对UCI机器学习的光学数字数据库的介绍。</li><li><a class="link"   href="http://archive.ics.uci.edu/ml/" >UCI机器学习库<i class="fas fa-external-link-alt"></i></a>是一个被机器学习社区用于做机器学习算法实践分析的数据库，域理论，数据生成器的集合。其中一个就是<a class="link"   href="http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits" >光学识别的手写数字数据集<i class="fas fa-external-link-alt"></i></a>，又叫Optdigits Dataset.</li><li>原始的光学数字数据是一个个32x32的矩阵。它们提供经过预处理的数字形式，数字被分成非重叠的4x4块，每一块上像素都合计了。这就生成了8x8输入矩阵，每一个元素都是0到16的整数。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/digit.png"></li></ul><h3 id="基于多分类的SVM的数字分类器"><a href="#基于多分类的SVM的数字分类器" class="headerlink" title="基于多分类的SVM的数字分类器"></a>基于多分类的SVM的数字分类器</h3><ul><li>核方法引起了很大的兴趣，因为它可以应用到那些需要进行预处理的(例如，数据降维)数据的问题上和被模型化的数据结构的扩展知识上。即使我们对数据知之甚少，核方法的直接应用往往得到令人感兴趣的结果。利用核方法实现最佳化是一个非常难的任务，因为我们用无穷多的核函数可供选择，而每个核函数也有无穷多的参数可供调整。</li><li>下面的代码向我们展示了基于核函数的支持向量机是怎么实现的。输入的是一个1024的全向量。这个对神经网络来说是不切实际的，例如，通常的核方法处理高维数的问题是没问题的，因为它不会遭受维数灾难。<figure class="highlight c#"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Extract inputs and outputs</span></span><br><span class="line"><span class="built_in">int</span> samples = <span class="number">500</span>;</span><br><span class="line"><span class="built_in">double</span>[][] input = <span class="keyword">new</span> <span class="built_in">double</span>[samples][];</span><br><span class="line"><span class="built_in">int</span>[] output = <span class="keyword">new</span> <span class="built_in">int</span>[samples];</span><br><span class="line"><span class="keyword">for</span> (<span class="built_in">int</span> i = <span class="number">0</span>; i &lt; samples; i++)</span><br><span class="line">&#123;</span><br><span class="line">   ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Create the chosen Kernel with given parameters</span></span><br><span class="line">IKernel kernel = <span class="keyword">new</span> Polynomial((<span class="built_in">int</span>)numDegree.Value, (<span class="built_in">double</span>)numConstant.Value);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Create the Multi-class Support Vector Machine using the selected Kernel</span></span><br><span class="line">ksvm = <span class="keyword">new</span> MulticlassSupportVectorMachine(<span class="number">1024</span>, kernel, <span class="number">10</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Create the learning algorithm using the machine and the training data</span></span><br><span class="line"><span class="keyword">var</span> ml = <span class="keyword">new</span> MulticlassSupportVectorLearning(ksvm, input, output);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Extract training parameters from the interface</span></span><br><span class="line"><span class="built_in">double</span> complexity = (<span class="built_in">double</span>)numComplexity.Value;</span><br><span class="line"><span class="built_in">double</span> epsilon = (<span class="built_in">double</span>)numEpsilon.Value;</span><br><span class="line"><span class="built_in">double</span> tolerance = (<span class="built_in">double</span>)numTolerance.Value;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Configure the learning algorithm</span></span><br><span class="line">ml.Configure = <span class="built_in">delegate</span>(KernelSupportVectorMachine svm, </span><br><span class="line">                        <span class="built_in">double</span>[][] cinput, <span class="built_in">int</span>[] coutput)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">var</span> smo = <span class="keyword">new</span> SequentialMinimalOptimization(svm, cinput, coutput);</span><br><span class="line">    smo.Complexity = complexity;</span><br><span class="line">    smo.Epsilon    = epsilon;</span><br><span class="line">    smo.Tolerance  = tolerance;</span><br><span class="line">    <span class="keyword">return</span> smo;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Train the machines. It should take a while.</span></span><br><span class="line"><span class="built_in">double</span> error = ml.Run();</span><br></pre></td></tr></table></figure></li></ul><h2 id="应用例子"><a href="#应用例子" class="headerlink" title="应用例子"></a>应用例子</h2><h3 id="学习"><a href="#学习" class="headerlink" title="学习"></a>学习</h3><ul><li>样例应用附带源代码，它实现了基于核函数的多分类支持向量机的手写数字识别。下载了应用后，打开并点击菜单，然后选择”Open”。它就会载入数据。</li><li>要开始训练数据，点击“Start training”。利用默认设置，应该不会太长时间。因为代码是用了并行运算，核数越多，训练越快。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/app-1.png"></li><li>训练完成后，点击“Classify”开始分类测试数据集。利用默认值，它应该可以得到95%的正确率，大概是500个数据中有475个分类正确。识别率的大小会随着每次训练的不同而有小小的波动。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/app-2.png"></li><li>相同的集合和相同的训练和测试样本已经在上一篇中的基于核方法的判别分析方法中使用。而SVM却得到更高的运行效率和更少的内存，更多的样本数可能得到更高的正确率。</li><li>训练后，创建的SVM可以在“Machine”这个tab中看到。每次的SVM的支持向量和临界值可以在第一个数据格视图中通过选择一个数据入口而看到。向量越暗，在决策过程中它的权值就越大。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/app-3.png"></li></ul><h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><ul><li>即使识别率刚刚超过3%，但是识别的正确率已经比KDA大大的提升了。点击“Classification”tab，我们可以手动地为用户手写的数字测试多分类支持向量机。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/app-4.png"></li><li>我们看到SVM方法产生了更强壮的结果，即使手写很差的数字也能识别正确：<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/app-5.png"></li><li>最后，有一个视频演示：</li></ul><iframe height=498 width=610 src="http://player.youku.com/embed/XODYzNjk3NzMy" frameborder=0 allowfullscreen></iframe><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>在本文中，我们详细叙述和探索了基于核方法的SVM来解决手写数字识别的问题，并且可以得到更好的结果。</li><li>SVM适合小样本的数据训练。</li></ul><h2 id="继续阅读"><a href="#继续阅读" class="headerlink" title="继续阅读"></a>继续阅读</h2><ul><li><a class="link"   href="http://www.codeproject.com/KB/recipes/handwriting-kda.aspx" >Handwriting Recognition using Kernel Discriminant Analysis<i class="fas fa-external-link-alt"></i></a></li><li><a class="link"   href="http://crsouza.blogspot.com/2010/04/kernel-support-vector-machines-for.html" >Kernel Functions for Machine Learning Applications<i class="fas fa-external-link-alt"></i></a></li><li><a class="link"   href="http://crsouza.blogspot.com/2010/04/kernel-support-vector-machines-for.html" >Kernel Support Vector Machines (SVM)<i class="fas fa-external-link-alt"></i></a></li><li><a class="link"   href="http://crsouza.blogspot.com/2009/09/principal-component-analysis-in-c.html" >Principal Component Analysis (PCA)<i class="fas fa-external-link-alt"></i></a></li><li><a class="link"   href="http://crsouza.blogspot.com/2010/01/kernel-principal-component-analysis-in.html" >Kernel Principal Component Analysis (KPCA)<i class="fas fa-external-link-alt"></i></a></li><li><a class="link"   href="http://crsouza.blogspot.com/2010/01/linear-discriminant-analysis-in-c.html" >Linear Discriminant Analysis (LDA)<i class="fas fa-external-link-alt"></i></a></li><li><a class="link"   href="http://crsouza.blogspot.com/2010/01/kernel-discriminant-analysis-in-c.html" >Non-Linear Discriminant Analysis with Kernels (KDA)<i class="fas fa-external-link-alt"></i></a></li><li><a class="link"   href="http://crsouza.blogspot.com/2010/02/logistic-regression-in-c.html" >Logistic Regression Analysis<i class="fas fa-external-link-alt"></i></a></li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>Wikipedia contributors,<a class="link"   href="http://en.wikipedia.org/wiki/Sequential_Minimal_Optimization" >“Sequential Minimal Optimization”<i class="fas fa-external-link-alt"></i></a>, Wikipedia, The Free Encyclopedia,<a class="link"   href="http://en.wikipedia.org/wiki/Sequential_Minimal_Optimization" >http://en.wikipedia.org/wiki/Sequential_Minimal_Optimization<i class="fas fa-external-link-alt"></i></a> (accessed April 24, 2010).</li><li>Wikipedia contributors, <a class="link"   href="http://en.wikipedia.org/wiki/Support_vector_machine" >“Support Vector Machine”<i class="fas fa-external-link-alt"></i></a>, Wikipedia, The Free Encyclopedia,<a class="link"   href="http://en.wikipedia.org/wiki/Support_vector_machine" >http://en.wikipedia.org/wiki/Support_vector_machine<i class="fas fa-external-link-alt"></i></a>,(accessed April 24, 2010).</li><li>John C. Platt,<a class="link"   href="http://research.microsoft.com/en-us/um/people/jplatt/smoTR.pdf" >Sequential Minimal Optimization: A Fast Algorithm for Training Support Vector Machines<i class="fas fa-external-link-alt"></i></a> , Microsoft Research, 1998.</li><li>J. P. Lewis,<a class="link"   href="http://www.idiom.com/~zilla/Work/Notes/svmtutorial.pdf" >A Short SVM (Support Vector Machine) Tutorial.<i class="fas fa-external-link-alt"></i></a>,CGIT Lab &#x2F; IMSC, University of Southern California.</li><li>A. J. Smola and B. Scholkopf,<a class="link"   href="http://www.kernel-machines.org/publications/SmoSch98c" >A Tutorial on Support Vector Regression.<i class="fas fa-external-link-alt"></i></a>,NeuroCOLT2 Technical Report Series, 1998.</li><li>S. K. Shevade et al.<a class="link"   href="http://drona.csa.iisc.ernet.in/~chiru/papers/ieee_smo_reg.ps.gz" >Improvements to SMO Algorithm for SVM Regression<i class="fas fa-external-link-alt"></i></a>,1999.</li><li>G. W. Flake, S. Lawrence<a class="link"   href="http://www.keerthis.com/smoreg_ieee_shevade_00.pdf" >Efficient SVM Regression Training with SMO<i class="fas fa-external-link-alt"></i></a></li><li>A. Asuncion &amp; D.J. Newman,<a class="link"   href="http://archive.ics.uci.edu/ml/index.html" >UCI Machine Learning Repository.<i class="fas fa-external-link-alt"></i></a>Irvine, CA: University of California, School of Information and Computer Science (2007).</li><li>Andrew Kirillov,<a class="link"   href="http://aforgenet.com/framework" >The AForge.NET Framework<i class="fas fa-external-link-alt"></i></a>.The AForge.NET Computer Vision, Artificial Intelligence and Robotics Website, 2010.</li><li>C. R. Souza, <a class="link"   href="http://crsouza.blogspot.com/2010/03/kernel-functions-for-machine-learning.html" >Kernel Functions for Machine Learning Applications.<i class="fas fa-external-link-alt"></i></a> 17 Mar. 2010. Web.</li></ul><h1 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h1><ul><li>翻译这篇文章后，除了对翻译的难度有了更深一层的认知之后，本次只要是对SVM进行多分类问题的解决有了更深的认识。SVM本来是一个二类分类器，那么要解决多分类问题，应该要什么思路呢？就是用二类分类器进行组合，然后通过“一对一”策略来解决多分类分类器。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;写在前面的话&quot;&gt;&lt;a href=&quot;#写在前面的话&quot; class=&quot;headerlink&quot; title=&quot;写在前面的话&quot;&gt;&lt;/a&gt;写在前面的话&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;本篇博文是翻译自Code Project上的&lt;a class=&quot;link&quot;   href=&quot;ht</summary>
      
    
    
    
    <category term="毕业设计系列" scheme="http://example.com/categories/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%E7%B3%BB%E5%88%97/"/>
    
    
    <category term="手写数字识别 Kernel Support Vector Machine" scheme="http://example.com/tags/%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB-Kernel-Support-Vector-Machine/"/>
    
  </entry>
  
  <entry>
    <title>最小二乘法论文翻译-毕设系列</title>
    <link href="http://example.com/2015/01/01/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91-%E6%AF%95%E8%AE%BE%E7%B3%BB%E5%88%97/"/>
    <id>http://example.com/2015/01/01/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91-%E6%AF%95%E8%AE%BE%E7%B3%BB%E5%88%97/</id>
    <published>2015-01-01T11:57:02.000Z</published>
    <updated>2015-01-02T05:01:18.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="写在前面的话"><a href="#写在前面的话" class="headerlink" title="写在前面的话"></a>写在前面的话</h1><ul><li>本篇论文是布朗大学数学系Steven J. Miller∗教授的论文翻译。</li><li>出处：<a class="link"   href="http://web.williams.edu/Mathematics/sjmiller/public_html/BrownClasses/54/handouts/MethodLeastSquares.pdf" >The Method of Least Squares-Steven J. Miller∗<i class="fas fa-external-link-alt"></i></a></li></ul><h1 id="最小二乘法"><a href="#最小二乘法" class="headerlink" title="最小二乘法"></a>最小二乘法</h1><ul><li>Steven J. Miller*</li><li>布朗大学，数学系</li><li>普罗维登斯（美国罗得岛州的首府），RI 02912</li></ul><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><ul><li>原文<br><img src="/img/paperBlog/LSM-translation/LSM-abstract.png"></li><li>译文</li><li>最小二乘法是求解数据的最佳线性拟合的过程；它可以用简单微积分和线性代数来证明。根本的问题就是根据给定数据集(xn,yn),其中n属于{1,…,N}，然后对这些数据集求解y&#x3D;ax+b最佳拟合直线。这个方法容易推广为求解最佳拟合直线的形式为：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-0.1.png"><br>上式中右边的f(x)不需要对x成线性关系，但等式右边的必须是函数的线性组合。</li></ul><h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ol><li><strong>问题的描述</strong></li><li><strong>概率与统计知识的回顾</strong></li><li><strong>最小二乘法</strong></li></ol><h3 id="1-问题的描述"><a href="#1-问题的描述" class="headerlink" title="1.问题的描述"></a>1.问题的描述</h3><ul><li>现实生活中，我们经常需要找到多个变量之间的线性关系。比如，弹簧的拉力和弹簧的长度成线性关系：y&#x3D;kx(y是拉力，x是弹簧的长度，k是常数)。为了验证以上线性关系，研究者们在实验室测量不同拉力下的不同长度。然后他们按(xn,yn)，其中n属于{1,…,N}的形式收集数据，这里的yn是以牛顿为单位，xn是以米为单位。<img src="/img/paperBlog/LSM-translation/LSM-figure-1.png"></li><li>很不幸的，它很难验证出我们上面那么精确的线性关系。原因有以下两个。第一个是实验误差，第二个是可能弹簧的拉力和长度不是成线性关系的。观察图1，弹簧定长为5的拉力和长度的测量数据集模拟。</li><li>最小二乘法是一个过程，它需要简单的微积分和线性代数，去决定什么是数据的“最佳拟合”线。当然，我们需要衡量“最佳拟合”的标准，那我们就要用上一些概率和统计学的知识了。</li><li>对证明的一个比较谨慎分析表明最小二乘法有很强的泛化能力。虽然求解不出精确的最佳拟合直线，但我们可以求解出给定的特定函数的有限线性组合。所以问题是，给定函数f1,f2…fk，求出以下线性组合中的系数a1,a2…ak的值。<br><img src="/img/paperBlog/LSM-translation/LSM-formula-1.1.png"><br>就是对数据的最好的估计。</li></ul><h3 id="2-概率与统计知识的回顾"><a href="#2-概率与统计知识的回顾" class="headerlink" title="2.概率与统计知识的回顾"></a>2.概率与统计知识的回顾</h3><ul><li>下面我们对最小二乘法需要用到的概率和统计相关的基本元素做一个快速的介绍；详细请看[BD, CaBe, Du, Fe, Kel, LF, MoMc]。</li><li>给定一个数据序列x1,x2…xN,我们定义<strong>平均数</strong>(或<strong>期望值</strong>)为(x1+x2+…+xN)&#x2F;N。我们在x的上面加上一横作为标记：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-2.2.png"><br>平均数就是数据的均值。</li><li>观察下面两个数据序列：{10, 20, 30, 40, 50}和{30, 30, 30, 30, 30}。两个序列有相同的均值；但是，对于各个数和均值的差值，第一个序列有更大的变动。这就导出了方差的概念，方差是验证数据距离均值的波动程度大小的有用的工具。{x1, . . . , xN}的方差记为<img src="/img/paperBlog/LSM-translation/LSM-variance-note.png">，式子如下：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-2.3.png"><br>标准差<img src="/img/paperBlog/LSM-translation/LSM-standard-deviation-note.png">是方差的开平方：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-2.4.png"></li><li>注意到如果x的单位是米，那么方差的单位是平方米，而标准差和平均数的单位还是米。所以，用标准差来测量数据距离均值的波动更合适。</li><li>当然，我们还有另外的方法可用，例如：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-2.5.png"></li><li>但是这是一个带符号的数量，最大的正偏差和最大的负偏差会相互抵消。实际上，由平均数的定义就可以知道上面的式子结果为0！这是一个非常糟糕的数据偏差的测量，因为0对数据来说一点意义都没有。</li><li>我们可以通过绝对值来纠正这个问题，就如下面的式子：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-2.6.png"></li><li>虽然绝对值的好处是消除征服误差相互抵消的问题（而且它也有相同的单位），但绝对值函数并非一个好的函数分析。它是不可微的。这也是我们选用标准差的首要原因–它可以让我们利用微积分工具。</li><li>现在我们可以衡量“最佳拟合”的标准了。如果我们相信y&#x3D;ax+b,那么y-(ax+b)应该等于0.所以，给定观测量<br><img src="/img/paperBlog/LSM-translation/LSM-formula-2.7.png"><br>我们观察：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-2.8.png"></li><li>均值和应该是越小越好，然后求出方差就可以知道我们的数据拟合得好不好了。</li><li>那么这个数据集的方差是：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-2.9.png"></li><li>大误差应该给于大的权值，而小误差应该给于小的权值(因为误差进行了平方)。所以我们的最小二乘法更喜欢中等的误差而不是大误差。如果我们利用绝对值函数求误差(式子2.6)，那么所有的误差的权值都是一样的；而且，绝对值函数是不可微的，也就是用不了微积分工具的。</li></ul><h3 id="3-最小二乘法"><a href="#3-最小二乘法" class="headerlink" title="3.最小二乘法"></a>3.最小二乘法</h3><ul><li><p>给定数据<img src="/img/paperBlog/LSM-translation/LSM-data.png">,我们可以根据y&#x3D;ax+b计算误差：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-3.10.png"></p></li><li><p>这就是数据集<img src="/img/paperBlog/LSM-translation/LSM-data-variance.png">方差的N倍。那么我们研究方差的N倍和方差本身是没有差别的，我们注意到上面的错误是两个变量的函数。</p></li><li><p>我们的目标是求出令误差E(a,b)达到最小的a和b的值。在多变量微积分中我们知道对E(a,b)要分布求a和b的偏导数，并且偏导数等于0：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-3.11.png"></p></li><li><p>我们不需要考虑边界点：因为|a|和|b|值越大，拟合就变得越差。所以，我们不需要考虑边界点。</p></li><li><p>对E(a,b)求偏微分得：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-3.12.png"></p></li><li><p>假设<img src="/img/paperBlog/LSM-translation/LSM-bia-difference.png">(除以2)得到：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-3.13.png"></p></li><li><p>我们可以重写这些等式：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-3.14.png"></p></li><li><p>我们已经得到a和b的值了，它们能令误差最小，满足以下矩阵等式：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-3.15.png"></p></li><li><p>我们会证明矩阵是不可逆的，暗示着：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-3.16.png"></p></li><li><p>记矩阵为M，那么M的行列式是：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-3.17.png"></p></li><li><p>当：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-3.18.png"></p></li><li><p>我们得到：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-3.19.png"></p></li><li><p>上面最后的等式遵循简单的代数。所以，只要所有的Xn都不相等，detM的值就是非0而且是可逆的。</p></li><li><p><strong>结论是，只要所有的x都不相等，那么最好的拟合的a和b的值可以通过求解一个线性方程组而得到；解在式子3.16给出了。</strong></p></li><li><p><strong>标记3.1</strong> 描绘在图1中的点是令xn&#x3D;5+0.2<em>n，然后令yn&#x3D;5</em>xn，再加上一个均值为0，标准差为4(n ∈ {1, . . . , 100})的正态分布的随机误差。利用这些值，我们找到一条最佳拟合直线为：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-3.20.png"><br>所以，a&#x3D;4.99,b&#x3D;0.48.相比我们期望的关系：y&#x3D;5*x,我们期望一个更好的拟合值，a&#x3D;5,b&#x3D;0.</p></li><li><p>当a的值越来越接近真实值，b的值就会越来越小了。我们特地选取数据的这个特性来反映出在使用最小二乘法的问题。我们知道斜率的最佳值是4.99，而截距的最佳值是0.48，但是这并不是最好的估计。理论需要误差评估的技术支持。所以，我们想知道根据给定的数据，a落在(4.96,5.02)之间和b落在(-0.33,1.18)之间有99%的机会；这比我们仅仅知道最佳值更有用。</p></li><li><p>另外，如果我们用绝对值的方法：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-3.21.png"><br>那么算出的a的最佳值是5.03，b的最佳值是小于10的负10次方。这两种方法(绝对值方法和最小二乘法)求解出的不同的a和b是因为它们对错误的权值取值不同。</p></li></ul><h1 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h1><ul><li>这次虽然不是第一次翻译，但还是遇到许多人埋怨的翻译问题，就是由原文翻译到中文是一道很大的坑，真的很多地方不知道如何翻译，你要联系上下文，分析清楚语境，才能准确地翻译出它想表达的意思，而这不是一件很容易的事件，对于那些需要某些领域的专业知识的就是更难了。</li><li>所以，那么老是埋怨翻译人翻译的很差的人，还是不要那么激动的好，毕竟翻译也有翻译的痛。不过，无论怎样，这次翻译无论对我的理论知识的理解还是阅读英文文刊的能力都是有所增进的。</li></ul><h1 id="参考文献列表"><a href="#参考文献列表" class="headerlink" title="参考文献列表"></a>参考文献列表</h1><p><img src="/img/paperBlog/LSM-translation/LSM-reference.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;写在前面的话&quot;&gt;&lt;a href=&quot;#写在前面的话&quot; class=&quot;headerlink&quot; title=&quot;写在前面的话&quot;&gt;&lt;/a&gt;写在前面的话&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;本篇论文是布朗大学数学系Steven J. Miller∗教授的论文翻译。&lt;/li&gt;
&lt;li&gt;出</summary>
      
    
    
    
    <category term="毕业设计系列" scheme="http://example.com/categories/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%E7%B3%BB%E5%88%97/"/>
    
    
    <category term="最小二乘法 论文翻译" scheme="http://example.com/tags/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95-%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/"/>
    
  </entry>
  
  <entry>
    <title>单例设计模式</title>
    <link href="http://example.com/2014/12/25/Singleton-note/"/>
    <id>http://example.com/2014/12/25/Singleton-note/</id>
    <published>2014-12-25T08:30:38.000Z</published>
    <updated>2014-12-26T03:57:58.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="写在前面的话"><a href="#写在前面的话" class="headerlink" title="写在前面的话"></a>写在前面的话</h2><ul><li>本次笔记是在看了《毕向东Java基础》视频之后写的，对于毕老师讲课的优点，我想听过他的课的同学都应该知道的，所以我也不想多说了，但我还是忍不住再说一下，就是幽默风趣，讲课条理清晰，了解学生学习的难点，并能引领大家的思路。</li><li>另外，由于这是基础视频，所以讲的内容还是比较简单的。因此，我在课外进行了补充学习，希望能把这个单例模式问题学得更深更透！</li></ul><h2 id="什么是单例设计模式"><a href="#什么是单例设计模式" class="headerlink" title="什么是单例设计模式"></a>什么是单例设计模式</h2><h3 id="什么是设计模式？"><a href="#什么是设计模式？" class="headerlink" title="什么是设计模式？"></a>什么是设计模式？</h3><ul><li>首先第一个问题就是：什么是单例设计模式？要弄懂这个问题，我们首先要理解什么是<a class="link"   href="http://en.wikipedia.org/wiki/Software_design_pattern" >设计模式<i class="fas fa-external-link-alt"></i></a>。设计模式原本并不是软件开发领域首创的，它是建筑领域的一套理论知识。所谓设计模式，就是解决同一类问题的一种方法，它面向的是高层的抽象理念，和Java中的类和实例之间的关系有相似之处。</li></ul><h3 id="单例设计模式解决的问题"><a href="#单例设计模式解决的问题" class="headerlink" title="单例设计模式解决的问题"></a>单例设计模式解决的问题</h3><ul><li>单例设计模式面向的问题是什么呢？保证内存中某个类的实例的唯一性。即是说，无论什么时候，在内存中只能存在一个实例。</li></ul><h3 id="哪里应用了单例设计模式"><a href="#哪里应用了单例设计模式" class="headerlink" title="哪里应用了单例设计模式"></a>哪里应用了单例设计模式</h3><ul><li>这样的设计需要有哪些呢？举些例子来说吧，操作系统当中的垃圾桶，它在系统运行过程中都只有一个实例存在，无论你在C盘删除文件，还是在D盘删除文件，文件垃圾都是保存到同一个垃圾桶实例当中。这个最简单的验证就是：若果你把文件属性中的隐藏文件选择显示，那么你会在系统的任何地方都有一个垃圾桶文件夹，而这并不是说有多个垃圾桶实例，而是一个垃圾桶实例的多个引用。</li><li>另外的例子还包括软件的配置文件，其实也是应用了单例设计模式。试想下，若果软件的配置的配置有多个，那么软件在下次运行时应该选择哪么配置文件呢？比如eclipse，你在使用时发现没有显示行数，那么狠明显你是修改配置，行号就可以显示出来，而当你下次启动eclipse时，行号还是显示的。所有配置文件只有一个，你任何的修改都是对一个配置文件进行，这样才能保证下次启动软件时持续生效。</li></ul><h2 id="单例设计模式的实现-Java"><a href="#单例设计模式的实现-Java" class="headerlink" title="单例设计模式的实现(Java)"></a>单例设计模式的实现(Java)</h2><h3 id="单例设计模式的思路"><a href="#单例设计模式的思路" class="headerlink" title="单例设计模式的思路"></a>单例设计模式的思路</h3><ul><li>为了避免其他程序过多的建立该类对象。先禁止其他程序建立该类对象</li><li>为了让其他程序可以访问到该类对象，只好在本类中，自定义一个对象。</li><li>为了方便其他程序对自定义对象的访问，可以对外提供一些访问方式。</li></ul><h3 id="单例设计模式的代码实现步骤"><a href="#单例设计模式的代码实现步骤" class="headerlink" title="单例设计模式的代码实现步骤"></a>单例设计模式的代码实现步骤</h3><ul><li>将构造函数私有化</li><li>在类中创造一个本类对象</li><li>提供一个方法可以获取到该对象</li></ul><h3 id="实现代码"><a href="#实现代码" class="headerlink" title="实现代码"></a>实现代码</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SingletonDemo</span> &#123;</span><br><span class="line"><span class="comment">// 将构造函数私有化 </span></span><br><span class="line"><span class="keyword">private</span> <span class="title function_">SingletonDemo</span><span class="params">()</span> &#123;&#125;</span><br><span class="line"><span class="comment">// 在类中创造一个本类对象</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="type">SingletonDemo</span> <span class="variable">s</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SingletonDemo</span>();</span><br><span class="line"><span class="comment">// 提供一个方法可以获取到该对象</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> SingletonDemo <span class="title function_">getInstance</span><span class="params">()</span> &#123;</span><br><span class="line"><span class="keyword">return</span> s;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="单例设计模式就那么简单吗？"><a href="#单例设计模式就那么简单吗？" class="headerlink" title="单例设计模式就那么简单吗？"></a>单例设计模式就那么简单吗？</h2><ul><li>咋看，觉得代码那么简单，其实并不是那么简单，其中的坑还是不少的。让我们逐层逐层揭开它的神秘面纱吧。</li><li>单例设计模式一般有2种形式：懒汉式和饿汉式</li></ul><h3 id="懒汉式单例设计模式"><a href="#懒汉式单例设计模式" class="headerlink" title="懒汉式单例设计模式"></a>懒汉式单例设计模式</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 懒汉式</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Singleton</span> &#123;</span><br><span class="line"><span class="comment">// 私有化构造函数</span></span><br><span class="line"><span class="keyword">private</span> <span class="title function_">Singleton</span><span class="params">()</span> &#123;&#125;</span><br><span class="line"><span class="comment">// 创建空引用</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="type">Singleton</span> <span class="variable">instance</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line"><span class="comment">// 创建实例，并返回对象</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title function_">getInstance</span><span class="params">()</span> &#123;</span><br><span class="line"><span class="keyword">if</span> (instance == <span class="literal">null</span>) &#123;</span><br><span class="line">instance = <span class="keyword">new</span> <span class="title class_">Singleton</span>();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> instance;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>上面的代码看上去似乎没什么问题？但其实暗藏了一个安全问题，因为在getInstance()的方法中包含2个语句，并不是原子操作，存在线程安全的问题，导致可能产生多个实例对象。</li><li>线程安全的懒汉式单例设计模式(只改getInstance方法)<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> Singleton <span class="title function_">getInstance</span><span class="params">()</span> &#123;</span><br><span class="line"><span class="keyword">if</span> (instance == <span class="literal">null</span>) &#123;</span><br><span class="line">instance = <span class="keyword">new</span> <span class="title class_">Singleton</span>();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> instance;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>以上的代码，在方法前面加了synchronized关键字，表示了线程安全。但是把整个方法都同步了之后，程序的运行速度变得更慢了。为了解决慢的问题，又引出了双重检验锁。</li><li>双重检验锁(double checked locking pattern)的懒汉式单例设计模式(只改getInstance方法)<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title function_">getSingleton</span><span class="params">()</span> &#123;</span><br><span class="line"><span class="keyword">if</span> (instance == <span class="literal">null</span>) &#123;<span class="comment">// Single checked</span></span><br><span class="line"><span class="keyword">synchronized</span> (Singleton.class) &#123;</span><br><span class="line"><span class="keyword">if</span> (instance == <span class="literal">null</span>) &#123;<span class="comment">// Double checked</span></span><br><span class="line">instance = <span class="keyword">new</span> <span class="title class_">Singleton</span>();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> instance;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li>这段代码貌似很完美了，但很遗憾地，它还是有问题的。主要是instance &#x3D; new Singleton()这句，这并非是一个原子操作，事实上在JVM中执行这个语句时做了以下3个事情。</li></ul><ol><li>给instance分配内存</li><li>调用Singleton的构造函数来初始化成员变量</li><li>将instance对象指向分配的内存空间(执行完这步instance才是非空)</li></ol><ul><li>但在JVM的即时编译器中存在指令重排序的优化。也就是上面的第2步和第3步的顺序是不能保证的，最终的执行顺序可能是1-2-3，也可能是1-3-2.如果是后者，则在3执行完毕、2未执行前，被线程二抢占了，这时的instance已经是非null(但却没有初始化)，所以线程二会直接返回instance，然后使用，然后顺理成章地报错了。（摘抄自大牛原文）</li><li>那我们应该怎么办呢？我们把instance变量声明为volatile就可以了。<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Singleton</span> &#123;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">static</span> Singleton instance; </span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="title function_">Singleton</span><span class="params">()</span> &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> Singleton <span class="title function_">getSingleton</span><span class="params">()</span> &#123;</span><br><span class="line"><span class="keyword">if</span> (instance == <span class="literal">null</span>) &#123;</span><br><span class="line"><span class="keyword">synchronized</span> (Singleton.class) &#123;</span><br><span class="line"><span class="keyword">if</span> (instance == <span class="literal">null</span>) &#123;</span><br><span class="line">instance = <span class="keyword">new</span> <span class="title class_">Singleton</span>();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> instance;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li>(大牛解释）</li><li>有些人认为使用 volatile 的原因是可见性，也就是可以保证线程在本地不会存有 instance 的副本，每次都是去主内存中读取。但其实是不对的。使用 volatile 的主要原因是其另一个特性：禁止指令重排序优化。也就是说，在 volatile 变量的赋值操作后面会有一个内存屏障（生成的汇编代码上），读操作不会被重排序到内存屏障之前。比如上面的例子，取操作必须在执行完 1-2-3 之后或者 1-3-2 之后，不存在执行到 1-3 然后取到值的情况。从「先行发生原则」的角度理解的话，就是对于一个 volatile 变量的写操作都先行发生于后面对这个变量的读操作（这里的“后面”是时间上的先后顺序）。</li><li>但是特别注意在 Java 5 以前的版本使用了 volatile 的双检锁还是有问题的。其原因是 Java 5 以前的 JMM （Java 内存模型）是存在缺陷的，即时将变量声明成 volatile 也不能完全避免重排序，主要是 volatile 变量前后的代码仍然存在重排序问题。这个 volatile 屏蔽重排序的问题在 Java 5 中才得以修复，所以在这之后才可以放心使用 volatile。</li><li>相信你不会喜欢这种复杂又隐含问题的方式，当然我们有更好的实现线程安全的单例模式的办法。</li></ul><h3 id="饿汉式单例设计模式"><a href="#饿汉式单例设计模式" class="headerlink" title="饿汉式单例设计模式"></a>饿汉式单例设计模式</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 饿汉式</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Singleton</span> &#123;</span><br><span class="line"><span class="comment">// 类加载时就初始化</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">Singleton</span> <span class="variable">instance</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Singleton</span>();</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="title function_">Singleton</span><span class="params">()</span> &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title function_">getInstance</span><span class="params">()</span> &#123;</span><br><span class="line"><span class="keyword">return</span> instance;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>这种方法非常简单，因为单例的实例被声明成static和final变量了，在第一次加载类到内存中时就会初始化，所以创建实例本身是线程安全的。</li><li>但是这种方法还是有问题的，它的缺点是它不是一种懒加载模式(lazy initialization)，单例会在加载类后一开始就被初始化，即使客户端没有调用getInstance()方法。饿汉式的创建方式在一些场景中将无法使用：譬如Singleton实例的创建时依赖参数或者配置文件的，在getInstance()之前必须调用某个方法设置参数给它，那么这种单例写法就无法使用了。</li></ul><h3 id="静态内部类的单例设计模式"><a href="#静态内部类的单例设计模式" class="headerlink" title="静态内部类的单例设计模式"></a>静态内部类的单例设计模式</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Singleton</span> &#123;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">SingletonHolder</span> &#123;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">Singleton</span> <span class="variable">INSTANCE</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Singleton</span>();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">private</span> <span class="title function_">Singleton</span> <span class="params">()</span> &#123;&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Singleton <span class="title function_">getInstance</span><span class="params">()</span> &#123;</span><br><span class="line"><span class="keyword">return</span> SingletonHolder.INSTANCE;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>这种写法仍然使用JVM本身机制保证了线程安全问题；由于SingletonHolder 是私有的，除了getInstance()之外没有办法访问它，因此它是懒汉式的；同时读取实例的时候不会进行同步，没有性能缺陷；也不依赖JDK版本。</li></ul><h3 id="枚举Enum"><a href="#枚举Enum" class="headerlink" title="枚举Enum"></a>枚举Enum</h3><ul><li>用枚举来实现单例真的太简单了！<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">enum</span> <span class="title class_">EasySingleton</span> &#123;</span><br><span class="line">INSTANCE;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>我们可以通过EasySingleton.INSTANCE来访问实例，这比调用getInstance()方法简单多了。创建枚举默认就是线程安全的，所以不需要担心double checked locking，而且还能防止反序列化导致重新创建新的对象。但是还是很少看到有人这样写，可能是因为不太熟悉吧。</li></ul><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><ul><li>一般来说，在开发中常用的是饿汉式的单例模式。</li><li>参考：<a class="link"   href="http://wuchong.me/blog/2014/08/28/how-to-correctly-write-singleton-pattern/" >如何正确地写出单例模式<i class="fas fa-external-link-alt"></i></a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;写在前面的话&quot;&gt;&lt;a href=&quot;#写在前面的话&quot; class=&quot;headerlink&quot; title=&quot;写在前面的话&quot;&gt;&lt;/a&gt;写在前面的话&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;本次笔记是在看了《毕向东Java基础》视频之后写的，对于毕老师讲课的优点，我想听过他的课的同学都</summary>
      
    
    
    
    <category term="黑马程序员" scheme="http://example.com/categories/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98/"/>
    
    
    <category term="单例设计模式" scheme="http://example.com/tags/%E5%8D%95%E4%BE%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>概率论基本概念1</title>
    <link href="http://example.com/2014/11/06/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B51/"/>
    <id>http://example.com/2014/11/06/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B51/</id>
    <published>2014-11-06T14:28:33.000Z</published>
    <updated>2023-07-13T04:12:43.734Z</updated>
    
    <content type="html"><![CDATA[<h1 id="定量数据的统计特征"><a href="#定量数据的统计特征" class="headerlink" title="定量数据的统计特征"></a>定量数据的统计特征</h1><ul><li>在对一组统计数据的分布变化进行深入研究之前，我们首先研究一组数据的特征。为了比较精确地描述一组统计资料的特征，需要使用一些统计指标来描述它。下面我们讨论一下数据统计特征的四个方面。</li></ul><h2 id="集中趋势"><a href="#集中趋势" class="headerlink" title="集中趋势"></a>集中趋势</h2><ul><li>集中趋势，也称做中心位置。即表示一组数据的中心位置的数据是在什么地方，也就是数据集中分布的位置。</li><li>一组数据的集中趋势通常用<strong>平均数</strong>、<strong>中位数</strong>和<strong>众数</strong>等来表示。这些统计量均称为平均指标。平均指标的特点是将一组数据中各个数据之间的差异抽象化，用一个指标来代表各个数据的一般水平，它反映了一组数据中各个数据的代表水平、中心位置或集中趋势。</li></ul><h3 id="均数"><a href="#均数" class="headerlink" title="均数"></a>均数</h3><ul><li>均数是算术均数的简称。常用表示样本均数，表示总体均数。均数用于反映一组同质观测值的平均水平，适用于正态或近似正态分布的数值变量资料。其计算方法有：<ul><li><font color=" #0000FF">直接法</font><ul><li>用于样本含量较少时，其公式为：</li><li><img src="/img/probability-theory-basic-conception/01/01_arithmetic_mean.PNG"></li><li>式中，希腊字母∑（读作sigma）表示求和；X1,X2…,Xn为观察值；n为样本含量，即观测值的个数。</li></ul></li><li><font color=" #0000FF">加权法</font><ul><li>用于频数表资料或样本中相同观察值较多时，其公式为：</li><li><img src="/img/probability-theory-basic-conception/01/02_weighted_mean.PNG"></li><li>式中，X1,X2,…,Xn与f1,f2,…,fk分别为相同观察值与其对应的频数（或频数表资料中个组段的组中值和相应组段的频数）。</li></ul></li></ul></li></ul><h3 id="几何均数"><a href="#几何均数" class="headerlink" title="几何均数"></a>几何均数</h3><ul><li>适用于对数正态分布，即数据经过对数变换后呈正态分布的资料；等比级数资料，即观测值之间呈倍数或近似倍数变化的资料。如抗体滴度、平均效价等。其计算方法有：<ul><li><font color=" #0000FF">直接法</font><ul><li>适用于样本含量n较小时</li><li><img src="/img/probability-theory-basic-conception/01/03_geometric_mean.PNG"><br>  或<br>  <img src="/img/probability-theory-basic-conception/01/04_geometric_mean.PNG"></li></ul></li><li><font color=" #0000FF">加权法</font><ul><li>频数表资料或样本中相同观察值较多时</li><li><img src="/img/probability-theory-basic-conception/01/05_geometric_weighted_mean.PNG"></li></ul></li><li><strong>注意：</strong>计算几何均数时观察值中不能有0，因为0不能取对数；一组观察值中不能同时又正值和负值。</li></ul></li></ul><h3 id="中位数"><a href="#中位数" class="headerlink" title="中位数"></a>中位数</h3><ul><li>一组由小到大按顺序排列的观察值中位次居中的数值。</li><li>中位数可用于描述：<ul><li>非正态分布资料（对数正态分布除外）；</li><li>频数分布的一端或两端无确切数据的资料；</li><li>总体分布不清楚的资料</li></ul></li><li>在全部观察中，小于和大于中位数的观察值个数相等。其计算方法也包括：<ul><li><font color=" #0000FF">直接法</font><ul><li>适用于样本含量n较小的资料</li><li>把数从小到大排成一列</li><li><img src="/img/probability-theory-basic-conception/01/06_median.PNG"></li></ul></li><li><font color=" #0000FF">频数表法</font><ul><li>适用于样本含量n较大的资料</li><li><img src="/img/probability-theory-basic-conception/01/07_median.PNG"></li></ul></li></ul></li></ul><h2 id="离散趋势"><a href="#离散趋势" class="headerlink" title="离散趋势"></a>离散趋势</h2><ul><li>在统计学上描述观察值偏离中心位置的趋势，反映了所有观察值偏离中心的分布情况。</li><li>描述一组计量资料离散趋势的常用指标有极差、四分位数间距、方差、标准差、标准误差和变异系数等，其中方差和标准差最常用。</li></ul><h3 id="极差"><a href="#极差" class="headerlink" title="极差"></a>极差</h3><ul><li>极差(range,简记为R)亦称全距。</li><li>定义：值一组同质观察值中最大值和最小值之差。极差反映了个体差异的范围：极差大，说明变异度大；反之，极差小，说明变异度小。</li><li>公式：R &#x3D; Xmax - Xmin</li><li>不足：<ul><li><ol><li>仅考虑了最大值和最小值之差，不能反映组内其他观察值的变异度；</li></ol></li><li><ol start="2"><li>样本含量越大，抽到较大或较小的观察值的可能性越大，故极差可能越大。因此，样本含量相差悬殊时不宜用极差比较。</li></ol></li></ul></li></ul><h3 id="平均差"><a href="#平均差" class="headerlink" title="平均差"></a>平均差</h3><ul><li>定义：平均差是指一组数据中的各数据对平均数的离差绝对值的平均数。</li><li>一组数据中的各数据对平均数的离差有正有负，其和等于0，因此平均差必须用离差的绝对值来计算。</li><li>平均差越大，表示数据之间的变异程度越大，反之，则变异程度越小。</li><li>公式：<img src="/img/probability-theory-basic-conception/01/08_mean_deviation.PNG"></li></ul><h3 id="百分位数"><a href="#百分位数" class="headerlink" title="百分位数"></a>百分位数</h3><ul><li><p>定义：百分位数(percentile)用Px表示，0&lt;x&lt;100，是描述一组数据某百分位的位置指标。Px将全部观察值分为两部分，理论上有x%的观察值比它小，有(100-x%)的观察值比它大。</p></li><li><p>最常用的百分位数是P50,即中位数。</p></li><li><p>应用</p><ul><li><p>1.常与中位数结合应用，可以描述一组资料在某百分位置上的水平，也可以描述资料的分布特征。</p><ul><li><img src="/img/probability-theory-basic-conception/01/09_percentile.PNG"></li><li>M - P5 &#x3D; P95 - M, 分布近似对称</li><li>M - P5 &lt; P95 - M, 分布呈正偏态</li><li>M - P5 &gt; P95 - M, 分布呈负偏态</li></ul></li><li><p><img src="/img/probability-theory-basic-conception/01/10_percentile.PNG"></p></li><li><p>2.也可用多个百分位数的结合来描述一组观察值的分布特征，如P25和P75合用时，反映中间50%观察值的分布情况；</p></li><li><p>3.百分位数可用于确定非正态分布资料的医学参考值范围。</p></li></ul></li><li><p>计算公式：</p><ul><li><img src="/img/probability-theory-basic-conception/01/11_percentile.PNG"></li><li>Lx,i,fx分别为Px所在组段的下限、组距和频数；∑fL为小于L的各组段的累计频数。</li></ul></li><li><p>注意：应用百分位数，样本含量要足够大，否则不宜取靠近两端的百分位数。</p></li></ul><h3 id="四分位数间距"><a href="#四分位数间距" class="headerlink" title="四分位数间距"></a>四分位数间距</h3><ul><li>定义：四分位数间距(quartile interval, Q)为上四分位数与下四分位数之差(或P75与P25之差)。</li><li>计算公式：<img src="/img/probability-theory-basic-conception/01/12_quartile_interval.PNG"></li><li>应用：用于描述偏态分布以及分布的一端或两端无确切数值资料或分布类型未知资料的离散程度。</li><li><img src="/img/probability-theory-basic-conception/01/13_quartile_interval.PNG"></li><li>四分位数间距包括了一组观察值的一半，故可把四分位数间距看成是中间50%观察值的极差。</li><li>意义：Q越大，变异度越大；反之，Q越小，变异度越小。</li><li>特点：由于四分位数间距不受两端个别极大值或极小值的影响，因而它较极差稳定，但仍未考虑全部观察值的变异度。</li></ul><h3 id="方差"><a href="#方差" class="headerlink" title="方差"></a>方差</h3><ul><li>极差和四分位数间距都只考虑了个别观察值的大小差异，没有全面反映每个观察值的变异程度。</li><li>就总体而言，即应考虑总体中每个观察值X与总体均数μ的差值(X - μ)，即离均差。</li><li>因离均差之和∑(X - μ) &#x3D; 0,不能反映变异度的大小，故用例均差平方和∑(X - μ)^2 (sum of squares of deviations from mean)反映之。离均差平方和的大小除与变异度有关外，还与变量值的个数N有关。为了消除这一影响，取离均差平方和的均数，称方差(variance)或均方(mean of squares)。</li><li>计算公式：<ul><li>总体方差：<img src="/img/probability-theory-basic-conception/01/14_population_variance.PNG"></li><li>样本方差：<img src="/img/probability-theory-basic-conception/01/15_sample_variance.PNG"></li></ul></li><li>n-1为自由度(degree of freedom),一般用ν(niu)表示。</li><li>因方差的度量单位是原度量单位的平方，故计算结果难以解释。</li></ul><h3 id="标准差"><a href="#标准差" class="headerlink" title="标准差"></a>标准差</h3><ul><li>为了使统计量的单位同观察值单位相一致，通常将方差开平方，即得到标准差，标准差也称为均方差。</li><li>计算公式：<ul><li>总体标准差：<img src="/img/probability-theory-basic-conception/01/16_standard_deviation.PNG"></li><li>样本标准差：<img src="/img/probability-theory-basic-conception/01/17_standard_deviation.PNG"></li></ul></li><li>意义：标准差大，表示观察值的变异度大；反之，标准差小，表示观察值的变异度小。</li><li>应用：<ul><li><ol><li>适用于描述对称分布资料尤其是正态分布资料的离散程度；</li></ol></li><li><ol start="2"><li>结合均数，描述正态分布资料的频数分布规律，用于估计医学参考值范围；</li></ol></li><li><ol start="3"><li>结合均数，计算变异系数；</li></ol></li><li><ol start="4"><li>结合样本含量，计算标准误差，估计抽样误差，用于统计推断。</li></ol></li></ul></li></ul><h3 id="变异系数"><a href="#变异系数" class="headerlink" title="变异系数"></a>变异系数</h3><ul><li>变异系数(coefficient of variation, CV)，是标准差与均数的比值，用百分数表示，没有单位。</li><li>计算公式：<img src="/img/probability-theory-basic-conception/01/18_coefficient_variation.PNG"></li><li>应用：常用于比较度量单位不同或均数相差悬殊的两组(或多组)资料的变异度。</li></ul><h2 id="偏度"><a href="#偏度" class="headerlink" title="偏度"></a>偏度</h2><ul><li>定义：偏度是指次数分布非对称的偏态方向程度。为了精确测定次数分布的偏斜状况，统计上采用偏斜度指标。</li></ul><h2 id="峰度"><a href="#峰度" class="headerlink" title="峰度"></a>峰度</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;定量数据的统计特征&quot;&gt;&lt;a href=&quot;#定量数据的统计特征&quot; class=&quot;headerlink&quot; title=&quot;定量数据的统计特征&quot;&gt;&lt;/a&gt;定量数据的统计特征&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;在对一组统计数据的分布变化进行深入研究之前，我们首先研究一组数据的特征。</summary>
      
    
    
    
    <category term="概率论" scheme="http://example.com/categories/%E6%A6%82%E7%8E%87%E8%AE%BA/"/>
    
    
    <category term="概率论基本概念" scheme="http://example.com/tags/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/"/>
    
  </entry>
  
  <entry>
    <title>DMwR-note-01-预测海藻数量(三)</title>
    <link href="http://example.com/2014/10/28/DMwR-note-01-%E9%A2%84%E6%B5%8B%E6%B5%B7%E8%97%BB%E6%95%B0%E9%87%8F(%E4%B8%89)/"/>
    <id>http://example.com/2014/10/28/DMwR-note-01-%E9%A2%84%E6%B5%8B%E6%B5%B7%E8%97%BB%E6%95%B0%E9%87%8F(%E4%B8%89)/</id>
    <published>2014-10-27T23:39:16.000Z</published>
    <updated>2014-11-17T12:35:12.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="写在开头的话"><a href="#写在开头的话" class="headerlink" title="写在开头的话"></a>写在开头的话</h2><hr><p>讨论了缺失值的处理，相当于对数据进行了简单的预处理，今天我们来继续探讨数据集模型的建立。</p><h2 id="数据的模型"><a href="#数据的模型" class="headerlink" title="数据的模型"></a>数据的模型</h2><hr><ul><li>数据的模型简单的说就是一个函数，输入就是我们之前的数据algae，而输出就是我们预期的一些值。</li><li>本案例的主要研究目的是预测140个水样中7种海藻的出现频率。假设海藻频率是数值型数据，因此可以考虑进行回归分析。简单地说，预测任务是建立一个模型来找到一个数值变量和一组解释变量的关系。这个模型既可以根据未来解释变量的值来预测目标变量，也可以帮助更好地理解问题中各个变量之间的相互联系。</li></ul><h3 id="多元化线性回归"><a href="#多元化线性回归" class="headerlink" title="多元化线性回归"></a>多元化线性回归</h3><hr><ul><li><p>多元线性回归模型是最常用的统计数据分析方法，该模型给出了一个有关目标变量与一组解释变量关系的线性函数。</p></li><li><p>数据缺失值的处理：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">library(DMwR)</span><br><span class="line">data(algae)</span><br><span class="line">temp &lt;- algae</span><br><span class="line">temp &lt;- temp[-manyNAs(temp),]</span><br><span class="line">clean.algae &lt;- knnImputation(temp, k = 10)</span><br></pre></td></tr></table></figure></li><li><p>上面的代码首先移除了第62条和第199条水样记录，因为在这两条记录的11个预测变量中有6个是有缺失值的。然后利用数据集个案的相似性来填补缺失值。以上代码运行之后，得到的数据框将不含缺失值。</p></li><li><p>接下来，将建立一个用于预测海藻频率的线性回归模型：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">summary(lm.a1)</span><br></pre></td></tr></table></figure></li><li><p>函数lm()建立一个线性回归模型，其中的第一个参数给出了模型的函数形式。在这个例子中，函数的形式是用数据中其他所有变量来预测变量a1，第一个参数中的点”.”代表数据框中除了a1之外的变量。如果需要用预测变量mxPH和NH4来预测变量a1，就要定义模型为“a1~mxPH + NH4”。还有很多其他定义模型的方式，这都称为R公式，后边用到时进行介绍。参数data是用来设定建模所用的数据集。</p></li><li><p>函数lm()的结果是一个含有线性模型信息的对象。可以通过下列代码获取更多线性模型的信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">lm.a1 &lt;- lm(a1~., data = clean.algae[,1:12])</span><br><span class="line"></span><br><span class="line">Call:</span><br><span class="line">lm(formula = a1 ~ ., data = clean.algae[, 1:12])</span><br><span class="line"></span><br><span class="line">Residuals:</span><br><span class="line">    Min      1Q  Median      3Q     Max </span><br><span class="line">-37.679 -11.893  -2.567   7.410  62.190 </span><br><span class="line"></span><br><span class="line">Coefficients:</span><br><span class="line">              Estimate Std. Error t value Pr(&gt;|t|)   </span><br><span class="line">(Intercept)  42.942055  24.010879   1.788  0.07537 . </span><br><span class="line">seasonspring  3.726978   4.137741   0.901  0.36892   </span><br><span class="line">seasonsummer  0.747597   4.020711   0.186  0.85270   </span><br><span class="line">seasonwinter  3.692955   3.865391   0.955  0.34065   </span><br><span class="line">sizemedium    3.263728   3.802051   0.858  0.39179   </span><br><span class="line">sizesmall     9.682140   4.179971   2.316  0.02166 * </span><br><span class="line">speedlow      3.922084   4.706315   0.833  0.40573   </span><br><span class="line">speedmedium   0.246764   3.241874   0.076  0.93941   </span><br><span class="line">mxPH         -3.589118   2.703528  -1.328  0.18598   </span><br><span class="line">mnO2          1.052636   0.705018   1.493  0.13715   </span><br><span class="line">Cl           -0.040172   0.033661  -1.193  0.23426   </span><br><span class="line">NO3          -1.511235   0.551339  -2.741  0.00674 **</span><br><span class="line">NH4           0.001634   0.001003   1.628  0.10516   </span><br><span class="line">oPO4         -0.005435   0.039884  -0.136  0.89177   </span><br><span class="line">PO4          -0.052241   0.030755  -1.699  0.09109 . </span><br><span class="line">Chla         -0.088022   0.079998  -1.100  0.27265   </span><br><span class="line">---</span><br><span class="line">Signif. codes:  0 ?**?0.001 ?*?0.01 ??0.05 ??0.1 ??1</span><br><span class="line"></span><br><span class="line">Residual standard error: 17.65 on 182 degrees of freedom</span><br><span class="line">Multiple R-squared:  0.3731,Adjusted R-squared:  0.3215 </span><br><span class="line">F-statistic: 7.223 on 15 and 182 DF,  p-value: 2.444e-12</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>在解释函数summary()应用到线性模型对象所得到的信息之前，先介绍R如何处理3个名义变量。当像上面一样进行模型构建时，R会生成一组的辅助变量，即对每一个有k个水平的因子变量，R会生成k-1个辅助变量。这些辅助变量的值为0或者1.当辅助变量的值为1，表明该因子出现，同时表明其他所有辅助变量的值为0。如果所有的k-1个变量的值都是0，则表明因子变量的取值为第k个剩余的值。在以上的汇总结果中，可以看到R为因子变量season生成了3个辅助变量(seasonspring, seasonsummer和seasonwinter)。如果某个水样的season变量的取值为”autumn”，则所有3个赋值变量的值将全部为零。</p></li><li><p>对得到的线性模型对象应用函数summary()，将给出所建立模型的一些诊断信息。首先是有关线性模型中数据拟合的残差(residual)。残差应该是均值为0并且为正态分布。（显然残差最好尽可能的小！）</p></li><li><p>对于每个多元线性回归方程的系数(变量)，R显示它的估计值和标准误差(这些系数变化程度的估计)。为了检验这些系数的重要性，可以进行这些系数为0的假设检验，即<img src="/img/DMwR/02_algae_model/01_formula.PNG">。通常使用t检验来验证这些假设。R计算t值，该值定义为估计系数值与其标准误差的比，即<img src="/img/DMwR/02_algae_model/02_formula.PNG">。R将显示与系数相关联的一列(Pr(&gt; |t|))表示系数为0这一假设被拒绝的概率。因此，该值为0.0001表明有99.99%的置信度认为这个系数并非为0。对于每个测试，R都给出一个标志来表示相应的测试置信度水平。总之，仅对于这些前面有标志的系数，我们至少有90%的置信度来拒绝系数为0的一个假设。</p></li><li><p>另一个由R输出的模型诊断信息是R^2(或者多元R^2或调整R^2)。R^2表明模型与数据的吻合度，即数据所能解释的数据变差的比例。R^2越接近1(几乎100%地解释模型数据的变差)就说模型模拟得很好；R^2越小，说明模型拟合得越差。调整系数则更严格，它考虑回归模型中参数的数量。</p></li><li><p>最后，我们还可以检验任何解释变量和目标变量没有哦依赖这一原假设，即<img src="/img/DMwR/02_algae_model/03_formula.PNG">。可以通过把R给出的F统计值与一个临界值进行比较来进行检验。R提供一个拒绝原假设的置信度水平。因此p值为0.0001表示99.99%的置信度确定原假设是错误的。通常，如果一个模型不能通过这个检验(即得到的p值被认为太大，例如大于0.1)，则单个系数的t检验没有意义。</p></li><li><p>有些诊断信息也可以通过绘制线性模型来进行检验。实际上，可以用一个类似plot(lm.al)的命令得到一系列的线性模型图，它们有助于了解模型的性能。其中的一个图形绘制拟合的目标变量值和模型残差的散点图。误差相对较大时，R通常在该散点图中添加相应的行数，这样就可以方便地检查这些误差较大的记录。R给出的另一个图形是误差的正态Q-Q图，通过它可以检查误差是否符合应有的正态分布。</p></li><li><p>该模型解释的方差比例还不是很理想(大约32%)。还可以拒绝目标变量不依赖于预测变量的假设(F检验的p值很小)。检查某些系数的显著性，可能会质疑有些变量是否应该进入模型中。有多种方法可以用来精简回归模型。本节将介绍<strong>向后消元法</strong>。</p></li><li><p>首先用函数anova()来精简线性模型。当将anova()应用到简单线性模型时，这个函数提供一个模型拟合的方差序贯分析。也就是说，随着公式中项数的增加，模型的残差平方和减少。对前面的模型进行方差分析，结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">anova(lm.a1)</span><br><span class="line"></span><br><span class="line">Analysis of Variance Table</span><br><span class="line"></span><br><span class="line">Response: a1</span><br><span class="line">           Df Sum Sq Mean Sq F value    Pr(&gt;F)    </span><br><span class="line">season      3     85    28.2  0.0905 0.9651944    </span><br><span class="line">size        2  11401  5700.7 18.3088  5.69e-08 ***</span><br><span class="line">speed       2   3934  1967.2  6.3179 0.0022244 ** </span><br><span class="line">mxPH        1   1329  1328.8  4.2677 0.0402613 *  </span><br><span class="line">mnO2        1   2287  2286.8  7.3444 0.0073705 ** </span><br><span class="line">Cl          1   4304  4304.3 13.8239 0.0002671 ***</span><br><span class="line">NO3         1   3418  3418.5 10.9789 0.0011118 ** </span><br><span class="line">NH4         1    404   403.6  1.2963 0.2563847    </span><br><span class="line">oPO4        1   4788  4788.0 15.3774 0.0001246 ***</span><br><span class="line">PO4         1   1406  1405.6  4.5142 0.0349635 *  </span><br><span class="line">Chla        1    377   377.0  1.2107 0.2726544    </span><br><span class="line">Residuals 182  56668   311.4                      </span><br><span class="line">---</span><br><span class="line">Signif. codes:  0 ?**?0.001 ?*?0.01 ??0.05 ??0.1 ??1</span><br></pre></td></tr></table></figure></li><li><p>上面结果表明变量season对减少模型拟合误差的贡献度最小下面将它从模型中剔除：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lm2.a1 = update(lm.a1, .~.-season)</span><br></pre></td></tr></table></figure></li><li><p>函数update()用于对已有的线性模型进行微小的调整。在上面的代码中，应用函数update()从模型lm.a1中移除变量season以得到一个新的模型。新的模型的汇总信息如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">summary(lm2.a1)</span><br><span class="line"></span><br><span class="line">Call:</span><br><span class="line">lm(formula = a1 ~ size + speed + mxPH + mnO2 + Cl + NO3 + NH4 + </span><br><span class="line">    oPO4 + PO4 + Chla, data = clean.algae[, 1:12])</span><br><span class="line"></span><br><span class="line">Residuals:</span><br><span class="line">    Min      1Q  Median      3Q     Max </span><br><span class="line">-36.460 -11.953  -3.044   7.444  63.730 </span><br><span class="line"></span><br><span class="line">Coefficients:</span><br><span class="line">              Estimate Std. Error t value Pr(&gt;|t|)   </span><br><span class="line">(Intercept) 44.9532874 23.2378377   1.934  0.05458 . </span><br><span class="line">sizemedium   3.3092102  3.7825221   0.875  0.38278   </span><br><span class="line">sizesmall   10.2730961  4.1223163   2.492  0.01358 * </span><br><span class="line">speedlow     3.0546270  4.6108069   0.662  0.50848   </span><br><span class="line">speedmedium -0.2976867  3.1818585  -0.094  0.92556   </span><br><span class="line">mxPH        -3.2684281  2.6576592  -1.230  0.22033   </span><br><span class="line">mnO2         0.8011759  0.6589644   1.216  0.22561   </span><br><span class="line">Cl          -0.0381881  0.0333791  -1.144  0.25407   </span><br><span class="line">NO3         -1.5334300  0.5476550  -2.800  0.00565 **</span><br><span class="line">NH4          0.0015777  0.0009951   1.586  0.11456   </span><br><span class="line">oPO4        -0.0062392  0.0395086  -0.158  0.87469   </span><br><span class="line">PO4         -0.0509543  0.0305189  -1.670  0.09669 . </span><br><span class="line">Chla        -0.0841371  0.0794459  -1.059  0.29096   </span><br><span class="line">---</span><br><span class="line">Signif. codes:  0 ?**?0.001 ?*?0.01 ??0.05 ??0.1 ??1</span><br><span class="line"></span><br><span class="line">Residual standard error: 17.57 on 185 degrees of freedom</span><br><span class="line">Multiple R-squared:  0.3682,Adjusted R-squared:  0.3272 </span><br><span class="line">F-statistic: 8.984 on 12 and 185 DF,  p-value: 1.762e-13</span><br></pre></td></tr></table></figure></li><li><p>新模型的拟合指标R^2提高到了32.8%，仍然不是太理想。下面使用anova()函数对两个模型进行正式的比较，但这次使用两个模型作为参数：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">anova(lm.a1, lm2.a1)</span><br><span class="line"></span><br><span class="line">Analysis of Variance Table</span><br><span class="line"></span><br><span class="line">Model 1: a1 ~ season + size + speed + mxPH + mnO2 + Cl + NO3 + NH4 + oPO4 + </span><br><span class="line">    PO4 + Chla</span><br><span class="line">Model 2: a1 ~ size + speed + mxPH + mnO2 + Cl + NO3 + NH4 + oPO4 + PO4 + </span><br><span class="line">    Chla</span><br><span class="line">  Res.Df   RSS Df Sum of Sq      F Pr(&gt;F)</span><br><span class="line">1    182 56668                           </span><br><span class="line">2    185 57116 -3   -447.62 0.4792 0.6971</span><br></pre></td></tr></table></figure></li><li><p>上面的函数通过F检验对两个模型进行方差分析，据此评估两个模型是否有显著不同。这种情况下，尽管误差平方和减少了(-448),但是比较结果说明两者的差距并不显著(显著性值0.6971说明两个模型不同的可能性有30%)。注意，新模型比较简单。为了检查能否移除更多的系数，我们再次讨论对lm2.a1模型使用anova()函数。不断重复这个过程知道没有可剔除的候选系数。为了简化向后消元过程，R有一个函数来执行上面所有过程。</p></li><li><p>下面的代码对初始模型(lm.a1)用向后消元方法得到一个新的线性模型。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line">final.lm = step(lm.a1)</span><br><span class="line"></span><br><span class="line">Start:  AIC=1152.03</span><br><span class="line">a1 ~ season + size + speed + mxPH + mnO2 + Cl + NO3 + NH4 + oPO4 + </span><br><span class="line">    PO4 + Chla</span><br><span class="line"></span><br><span class="line">         Df Sum of Sq   RSS    AIC</span><br><span class="line">- season  3    447.62 57116 1147.6</span><br><span class="line">- speed   2    269.60 56938 1149.0</span><br><span class="line">- oPO4    1      5.78 56674 1150.0</span><br><span class="line">- Chla    1    376.96 57045 1151.3</span><br><span class="line">- Cl      1    443.46 57112 1151.6</span><br><span class="line">- mxPH    1    548.76 57217 1151.9</span><br><span class="line">&lt;none&gt;                56668 1152.0</span><br><span class="line">- mnO2    1    694.11 57363 1152.4</span><br><span class="line">- NH4     1    825.67 57494 1152.9</span><br><span class="line">- PO4     1    898.42 57567 1153.1</span><br><span class="line">- size    2   1857.16 58526 1154.4</span><br><span class="line">- NO3     1   2339.36 59008 1158.0</span><br><span class="line"></span><br><span class="line">Step:  AIC=1147.59</span><br><span class="line">a1 ~ size + speed + mxPH + mnO2 + Cl + NO3 + NH4 + oPO4 + PO4 + </span><br><span class="line">    Chla</span><br><span class="line"></span><br><span class="line">        Df Sum of Sq   RSS    AIC</span><br><span class="line">- speed  2    210.64 57327 1144.3</span><br><span class="line">- oPO4   1      7.70 57124 1145.6</span><br><span class="line">- Chla   1    346.27 57462 1146.8</span><br><span class="line">- Cl     1    404.10 57520 1147.0</span><br><span class="line">- mnO2   1    456.37 57572 1147.2</span><br><span class="line">- mxPH   1    466.95 57583 1147.2</span><br><span class="line">&lt;none&gt;               57116 1147.6</span><br><span class="line">- NH4    1    776.11 57892 1148.3</span><br><span class="line">- PO4    1    860.62 57977 1148.5</span><br><span class="line">- size   2   2175.59 59292 1151.0</span><br><span class="line">- NO3    1   2420.47 59537 1153.8</span><br><span class="line"></span><br><span class="line">Step:  AIC=1144.31</span><br><span class="line">a1 ~ size + mxPH + mnO2 + Cl + NO3 + NH4 + oPO4 + PO4 + Chla</span><br><span class="line"></span><br><span class="line">       Df Sum of Sq   RSS    AIC</span><br><span class="line">- oPO4  1     16.29 57343 1142.4</span><br><span class="line">- Chla  1    223.29 57550 1143.1</span><br><span class="line">- mnO2  1    413.77 57740 1143.7</span><br><span class="line">- Cl    1    472.70 57799 1143.9</span><br><span class="line">- mxPH  1    483.56 57810 1144.0</span><br><span class="line">&lt;none&gt;              57327 1144.3</span><br><span class="line">- NH4   1    720.19 58047 1144.8</span><br><span class="line">- PO4   1    809.30 58136 1145.1</span><br><span class="line">- size  2   2060.95 59388 1147.3</span><br><span class="line">- NO3   1   2379.75 59706 1150.4</span><br><span class="line"></span><br><span class="line">Step:  AIC=1142.37</span><br><span class="line">a1 ~ size + mxPH + mnO2 + Cl + NO3 + NH4 + PO4 + Chla</span><br><span class="line"></span><br><span class="line">       Df Sum of Sq   RSS    AIC</span><br><span class="line">- Chla  1     207.7 57551 1141.1</span><br><span class="line">- mnO2  1     402.6 57746 1141.8</span><br><span class="line">- Cl    1     470.7 57814 1142.0</span><br><span class="line">- mxPH  1     519.7 57863 1142.2</span><br><span class="line">&lt;none&gt;              57343 1142.4</span><br><span class="line">- NH4   1     704.4 58047 1142.8</span><br><span class="line">- size  2    2050.3 59393 1145.3</span><br><span class="line">- NO3   1    2370.4 59713 1148.4</span><br><span class="line">- PO4   1    5818.4 63161 1159.5</span><br><span class="line"></span><br><span class="line">Step:  AIC=1141.09</span><br><span class="line">a1 ~ size + mxPH + mnO2 + Cl + NO3 + NH4 + PO4</span><br><span class="line"></span><br><span class="line">       Df Sum of Sq   RSS    AIC</span><br><span class="line">- mnO2  1     435.3 57986 1140.6</span><br><span class="line">- Cl    1     438.1 57989 1140.6</span><br><span class="line">&lt;none&gt;              57551 1141.1</span><br><span class="line">- NH4   1     746.9 58298 1141.6</span><br><span class="line">- mxPH  1     833.1 58384 1141.9</span><br><span class="line">- size  2    2217.5 59768 1144.6</span><br><span class="line">- NO3   1    2667.1 60218 1148.1</span><br><span class="line">- PO4   1    6309.7 63860 1159.7</span><br><span class="line"></span><br><span class="line">Step:  AIC=1140.58</span><br><span class="line">a1 ~ size + mxPH + Cl + NO3 + NH4 + PO4</span><br><span class="line"></span><br><span class="line">       Df Sum of Sq   RSS    AIC</span><br><span class="line">- NH4   1     531.0 58517 1140.4</span><br><span class="line">- Cl    1     584.9 58571 1140.6</span><br><span class="line">&lt;none&gt;              57986 1140.6</span><br><span class="line">- mxPH  1     819.1 58805 1141.4</span><br><span class="line">- size  2    2478.2 60464 1144.9</span><br><span class="line">- NO3   1    2251.4 60237 1146.1</span><br><span class="line">- PO4   1    9097.9 67084 1167.4</span><br><span class="line"></span><br><span class="line">Step:  AIC=1140.38</span><br><span class="line">a1 ~ size + mxPH + Cl + NO3 + PO4</span><br><span class="line"></span><br><span class="line">       Df Sum of Sq   RSS    AIC</span><br><span class="line">&lt;none&gt;              58517 1140.4</span><br><span class="line">- mxPH  1     784.1 59301 1141.0</span><br><span class="line">- Cl    1     835.6 59353 1141.2</span><br><span class="line">- NO3   1    1987.9 60505 1145.0</span><br><span class="line">- size  2    2664.3 61181 1145.2</span><br><span class="line">- PO4   1    8575.8 67093 1165.5</span><br></pre></td></tr></table></figure></li><li><p>函数step()使用Akaike信息标准进行模型搜索。默认情况下，搜索使用向后消元方法，但通过设置参数direction，可以采用其他的方法(参考该函数的帮助文档以获取更多信息)。</p></li><li><p>可以通过下面的代码来获得最后模型的信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">summary(final.lm)</span><br><span class="line"></span><br><span class="line">Call:</span><br><span class="line">lm(formula = a1 ~ size + mxPH + Cl + NO3 + PO4, data = clean.algae[, </span><br><span class="line">    1:12])</span><br><span class="line"></span><br><span class="line">Residuals:</span><br><span class="line">    Min      1Q  Median      3Q     Max </span><br><span class="line">-28.874 -12.732  -3.741   8.424  62.926 </span><br><span class="line"></span><br><span class="line">Coefficients:</span><br><span class="line">            Estimate Std. Error t value Pr(&gt;|t|)    </span><br><span class="line">(Intercept) 57.28555   20.96132   2.733  0.00687 ** </span><br><span class="line">sizemedium   2.80050    3.40190   0.823  0.41141    </span><br><span class="line">sizesmall   10.40636    3.82243   2.722  0.00708 ** </span><br><span class="line">mxPH        -3.97076    2.48204  -1.600  0.11130    </span><br><span class="line">Cl          -0.05227    0.03165  -1.651  0.10028    </span><br><span class="line">NO3         -0.89529    0.35148  -2.547  0.01165 *  </span><br><span class="line">PO4         -0.05911    0.01117  -5.291 3.32e-07 ***</span><br><span class="line">---</span><br><span class="line">Signif. codes:  0 ?**?0.001 ?*?0.01 ??0.05 ??0.1 ??1</span><br><span class="line"></span><br><span class="line">Residual standard error: 17.5 on 191 degrees of freedom</span><br><span class="line">Multiple R-squared:  0.3527,Adjusted R-squared:  0.3324 </span><br><span class="line">F-statistic: 17.35 on 6 and 191 DF,  p-value: 5.554e-16</span><br></pre></td></tr></table></figure></li><li><p>这个模型所解释的方差比例(R^2)仍然不是很可观，这样的R^2表明对海藻案例应用假定的线性模型是不合适的。</p></li></ul><h3 id="回归树"><a href="#回归树" class="headerlink" title="回归树"></a>回归树</h3><hr><ul><li><p>本节给出R中的另一种回归模型。即本节描述了如何通过建立回归树来预测海藻a1出现的频率。由于这类模型能够处理缺失值，所以这里只需要如前面所述移除62号和199号水样。</p></li><li><p>建立回归树模型如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">library(rpart)</span><br><span class="line">data(algae)</span><br><span class="line">algae = algae[-manyNAs(algae),]</span><br><span class="line">rt.a1 = rpart(a1~., data = algae[,1:12])</span><br></pre></td></tr></table></figure></li><li><p>对象rt.a1的内容如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">rt.a1</span><br><span class="line">n= 198 </span><br><span class="line"></span><br><span class="line">node), <span class="built_in">split</span>, n, deviance, yval</span><br><span class="line">      * denotes terminal node</span><br><span class="line"></span><br><span class="line"> 1) root 198 90401.290 16.996460  </span><br><span class="line">   2) PO4&gt;=43.818 147 31279.120  8.979592  </span><br><span class="line">     4) Cl&gt;=7.8065 140 21622.830  7.492857  </span><br><span class="line">       8) oPO4&gt;=51.118 84  3441.149  3.846429 *</span><br><span class="line">       9) oPO4&lt; 51.118 56 15389.430 12.962500  </span><br><span class="line">        18) mnO2&gt;=10.05 24  1248.673  6.716667 *</span><br><span class="line">        19) mnO2&lt; 10.05 32 12502.320 17.646880  </span><br><span class="line">          38) NO3&gt;=3.1875 9   257.080  7.866667 *</span><br><span class="line">          39) NO3&lt; 3.1875 23 11047.500 21.473910  </span><br><span class="line">            78) mnO2&lt; 8 13  2919.549 13.807690 *</span><br><span class="line">            79) mnO2&gt;=8 10  6370.704 31.440000 *</span><br><span class="line">     5) Cl&lt; 7.8065 7  3157.769 38.714290 *</span><br><span class="line">   3) PO4&lt; 43.818 51 22442.760 40.103920  </span><br><span class="line">     6) mxPH&lt; 7.87 28 11452.770 33.450000  </span><br><span class="line">      12) mxPH&gt;=7.045 18  5146.169 26.394440 *</span><br><span class="line">      13) mxPH&lt; 7.045 10  3797.645 46.150000 *</span><br><span class="line">     7) mxPH&gt;=7.87 23  8241.110 48.204350  </span><br><span class="line">      14) PO4&gt;=15.177 12  3047.517 38.183330 *</span><br><span class="line">      15) PO4&lt; 15.177 11  2673.945 59.136360 *</span><br></pre></td></tr></table></figure></li><li><p>回归树是对某些解释变量分层次的逻辑测试。基于树的模型自动筛选某些相关的变量，这样就会对树进行剪枝，减去某些变量。树从R标为1的根结点开始读，R在这个结点中提供相关的信息。即，可以再该结点中看到一共有198个水样（用于构建树的训练集数据样本量），在这198个水样中，海藻a1出现的平均频率为16.99，相对平均值的偏差为90401.29。树的每个结点有两个分支，这与预测变量的检验结果有关。例如，在根结点中有一个相应于测试“PO4&gt;&#x3D;43.818”为真（含有147个水样）的个案分支（R输出中标为2），同时也有另一个分支包含剩余的51个不满足这个测试的水样（R标记为3）。从结点2有两个分支分布连接到结点4和结点5，具体到哪个结点由对变量CI的检验来确定。不断进行以上的检验，直到达到某一个叶结点，这些叶结点在R中由星号标记出来。那么我们只要从根结点开始根据对该水样的检验结果，追踪某个分支，直到叶结点，我们就可以预测某个水样的频率。叶结点目标变量的平均值就是树的预测值。</p></li><li><p>我们也可以得到回归树的图形表示。可以用函数plot()和函数text()对树对象绘图即可。这两个函数有多个参数来控制树的可视化。为了方便地得到漂亮的树的可视化图形，本书的R添加包中提供了函数prettyTree()。对上面得到的树对象应用该函数，得到图形如图所示：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">prettyTree(rt.a1)</span><br></pre></td></tr></table></figure></li><li><p><img src="/img/DMwR/02_algae_model/04_plot.PNG"></p></li><li><p>函数summary()也可以用于树对象。此函数将给出许多有关于树的测试信息、其他可能考虑的测试以及中间分割等。这里的中间分割是R回归树处理缺失值的一种方法。</p></li><li><p>通常分两步来建立回归树。最初，生成一棵较大的树，然后通过统计估计删除底部的一些结点来对树进行修剪。这个过程的目的是繁殖过度拟合。事实上，一个过度大的树一般会很好地对训练数据集数据进行拟合，但是它会拟合给定数据集中的一写虚假的关系，因此当把该模型用于新数据的预测时，预测性能很差。在许多建模技术中存在过度拟合问题，尤其是当需要逼近的函数的假设条件不是很严格的时候。对于要求不严格的模型，虽然它们的要求不高，有广泛的应用范围，但却存在过度拟合问题，所以它需要一个事后统计估计步骤来避免过度拟合问题。</p></li><li><p>上面使用rpart()函数构建树，在构建树的过程中，当给定条件满足时构建过程就停止。当下列条件满足时，树就构建结束：</p><ul><li><ol><li>偏差的减少小于某一个给定的界限值时；</li></ol></li><li><ol start="2"><li>当结点中的样本数量小于某个给定界限值时；</li></ol></li><li><ol start="3"><li>当树的深度大于一个给定的界限值。</li></ol></li></ul></li><li><p>上面3个界限值分别由rpart()函数的三个参数（cp, minsplit, maxdepth）来确定。它们的默认值分别为0.01、20和30。如果要避免树的过度拟合问题，就要经常检查这些默认值的有效性。这可以通过对得到的树采取事后修剪过程来进行。</p></li><li><p>rpart()添加包实现了一种称为“复杂度损失修剪”的修剪方法（Breiman et al., 1984）。这个方法使用R在每个树结点计算的参数值cp。这种修剪方法试图估计cp值以确保达到预测的准确性和树的大小之间的最佳折中。给出一个由函数rpart()建立的回归树，R可以生成这棵树的一些子树，并估计这些树的性能。这些信息可以通过函数printcp()得到：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">printcp(rt.a1)</span><br><span class="line"></span><br><span class="line">Regression tree:</span><br><span class="line">rpart(formula = a1 ~ ., data = algae[, 1:12])</span><br><span class="line"></span><br><span class="line">Variables actually used <span class="keyword">in</span> tree construction:</span><br><span class="line">[1] Cl   mnO2 mxPH NO3  oPO4 PO4 </span><br><span class="line"></span><br><span class="line">Root node error: 90401/198 = 456.57</span><br><span class="line"></span><br><span class="line">n= 198 </span><br><span class="line"></span><br><span class="line">        CP nsplit rel error  xerror    xstd</span><br><span class="line">1 0.405740      0   1.00000 1.00909 0.13028</span><br><span class="line">2 0.071885      1   0.59426 0.72655 0.11938</span><br><span class="line">3 0.030887      2   0.52237 0.67966 0.11487</span><br><span class="line">4 0.030408      3   0.49149 0.70176 0.11781</span><br><span class="line">5 0.027872      4   0.46108 0.69623 0.11628</span><br><span class="line">6 0.027754      5   0.43321 0.69623 0.11628</span><br><span class="line">7 0.018124      6   0.40545 0.67679 0.11052</span><br><span class="line">8 0.016344      7   0.38733 0.70123 0.11415</span><br><span class="line">9 0.010000      9   0.35464 0.71140 0.11389</span><br></pre></td></tr></table></figure></li><li><p>由rpart()函数建立的回归树是上面列表中的最后一个树（树9）。这个树的cp值为0.01（参数cp的默认值），该树包括九个测试和一个相对误差值（与根结点相比）0.354。然而，R应用10折交叉验证的内部过程，评估该树的平均相对误差为0.70241 ± 0.11523。根据这些更稳健的性能估计信息，可以避免过度拟合问题。可以看到，8号树的预测相对误差（0.67733）最小。另一个选择标准时根据1-SE规则来选择最好的回归树，这包括检查交叉验证的估计误差（“xerror”列），以及标准误差（“xstd”列）。在这个案例中，1-SE规则树是最小的树，误差小于0.67733 + 0.10892 &#x3D; 0.78625，而由1检验的2号树的估计误差为0.73358。如果我们选择这个树而不是R建议的树，我们就可以通过使用不同的cp值来建立这棵树。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">rt2.a1 &lt;- prune(rt.a1, <span class="built_in">cp</span> = 0.08)</span><br><span class="line">rt2.a1</span><br><span class="line"></span><br><span class="line">n= 198 </span><br><span class="line"></span><br><span class="line">node), <span class="built_in">split</span>, n, deviance, yval</span><br><span class="line">      * denotes terminal node</span><br><span class="line"></span><br><span class="line">1) root 198 90401.29 16.996460  </span><br><span class="line">  2) PO4&gt;=43.818 147 31279.12  8.979592 *</span><br><span class="line">  3) PO4&lt; 43.818 51 22442.76 40.103920 *</span><br></pre></td></tr></table></figure></li><li><p>本书添加包中的rpartXse()函数可以自动运行这个过程，它的参数se的默认值为1.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">(rt.a1 &lt;- rpartXse(a1~., data=algae[,1:12]))</span><br><span class="line"></span><br><span class="line">n= 198 </span><br><span class="line"></span><br><span class="line">node), <span class="built_in">split</span>, n, deviance, yval</span><br><span class="line">      * denotes terminal node</span><br><span class="line"></span><br><span class="line">1) root 198 90401.290 16.996460  </span><br><span class="line">  2) PO4&gt;=43.818 147 31279.120  8.979592  </span><br><span class="line">    4) Cl&gt;=7.1665 142 21763.160  7.530282 *</span><br><span class="line">    5) Cl&lt; 7.1665 5   746.792 50.140000 *</span><br><span class="line">  3) PO4&lt; 43.818 51 22442.760 40.103920 *</span><br></pre></td></tr></table></figure></li><li><p>可以应用R的函数snip.rpart()来交互地对树进行修剪。这个函数可以通过两种方式生成一个修剪过的回归树。第一种方法是指出需要修剪那个地方的结点号（可以通过输出树对象来得到树的结点号）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">first.tree &lt;- rpart(a1~., data =algae[,1:12])</span><br><span class="line">snip.rpart(first.tree, c(4,7))</span><br><span class="line"></span><br><span class="line">n= 198 </span><br><span class="line"></span><br><span class="line">node), <span class="built_in">split</span>, n, deviance, yval</span><br><span class="line">      * denotes terminal node</span><br><span class="line"></span><br><span class="line"> 1) root 198 90401.290 16.996460  </span><br><span class="line">   2) PO4&gt;=43.818 147 31279.120  8.979592  </span><br><span class="line">     4) Cl&gt;=7.8065 140 21622.830  7.492857 *</span><br><span class="line">     5) Cl&lt; 7.8065 7  3157.769 38.714290 *</span><br><span class="line">   3) PO4&lt; 43.818 51 22442.760 40.103920  </span><br><span class="line">     6) mxPH&lt; 7.87 28 11452.770 33.450000  </span><br><span class="line">      12) mxPH&gt;=7.045 18  5146.169 26.394440 *</span><br><span class="line">      13) mxPH&lt; 7.045 10  3797.645 46.150000 *</span><br><span class="line">     7) mxPH&gt;=7.87 23  8241.110 48.204350 *</span><br></pre></td></tr></table></figure></li><li><p>这个函数与rpart()函数一样返回一个数对象，所以可以用形如my.tree &lt;- snip.rpart(first.tree, c(4,7))这样的代码来保存这个修剪过的树。</p></li><li><p>另外，也可以再图形窗口下使用snip.rpart()函数。首先，画出回归树，然后调用没有第二个参数的函数。如果点击回归树的某些结点，R会在控制台输出这些结点的信息。如果继续点击这个结点，R就在这个结点对树进行修剪。可以在图形窗口继续修剪回归树，直到右击结束这一交互式的修剪过程。调用该函数的结果仍然是一个数对象：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">prettyTree(first.tree)</span><br><span class="line">snip.rpart(first.tree)</span><br><span class="line"></span><br><span class="line">node number: 2  n= 147 </span><br><span class="line">    response= 8.979592</span><br><span class="line">    Error (dev) =  31279.12 </span><br><span class="line">node number: 6  n= 28 </span><br><span class="line">    response= 33.45</span><br><span class="line">    Error (dev) =  11452.77 </span><br><span class="line">n= 198 </span><br><span class="line"></span><br><span class="line">node), <span class="built_in">split</span>, n, deviance, yval</span><br><span class="line">      * denotes terminal node</span><br><span class="line"></span><br><span class="line"> 1) root 198 90401.290 16.996460  </span><br><span class="line">   2) PO4&gt;=43.818 147 31279.120  8.979592  </span><br><span class="line">     4) Cl&gt;=7.8065 140 21622.830  7.492857  </span><br><span class="line">       8) oPO4&gt;=51.118 84  3441.149  3.846429 *</span><br><span class="line">       9) oPO4&lt; 51.118 56 15389.430 12.962500  </span><br><span class="line">        18) mnO2&gt;=10.05 24  1248.673  6.716667 *</span><br><span class="line">        19) mnO2&lt; 10.05 32 12502.320 17.646880  </span><br><span class="line">          38) NO3&gt;=3.1875 9   257.080  7.866667 *</span><br><span class="line">          39) NO3&lt; 3.1875 23 11047.500 21.473910  </span><br><span class="line">            78) mnO2&lt; 8 13  2919.549 13.807690 *</span><br><span class="line">            79) mnO2&gt;=8 10  6370.704 31.440000 *</span><br><span class="line">     5) Cl&lt; 7.8065 7  3157.769 38.714290 *</span><br><span class="line">   3) PO4&lt; 43.818 51 22442.760 40.103920  </span><br><span class="line">     6) mxPH&lt; 7.87 28 11452.770 33.450000  </span><br><span class="line">      12) mxPH&gt;=7.045 18  5146.169 26.394440 *</span><br><span class="line">      13) mxPH&lt; 7.045 10  3797.645 46.150000 *</span><br><span class="line">     7) mxPH&gt;=7.87 23  8241.110 48.204350  </span><br><span class="line">      14) PO4&gt;=15.177 12  3047.517 38.183330 *</span><br><span class="line">      15) PO4&lt; 15.177 11  2673.945 59.136360 *</span><br></pre></td></tr></table></figure></li><li><p>在上例中，点击并修剪了节点2和结点6.</p></li></ul><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><ul><li>这一节我们建立了模型，用了2种方法，分别是多元回归和回归树。那么下一节就要对我们建立的模型进行评价了。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;写在开头的话&quot;&gt;&lt;a href=&quot;#写在开头的话&quot; class=&quot;headerlink&quot; title=&quot;写在开头的话&quot;&gt;&lt;/a&gt;写在开头的话&lt;/h2&gt;&lt;hr&gt;
&lt;p&gt;讨论了缺失值的处理，相当于对数据进行了简单的预处理，今天我们来继续探讨数据集模型的建立。&lt;/p&gt;
</summary>
      
    
    
    
    <category term="数据挖掘与R语言-案例学习" scheme="http://example.com/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%B8%8ER%E8%AF%AD%E8%A8%80-%E6%A1%88%E4%BE%8B%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="数据挖掘" scheme="http://example.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
  </entry>
  
  <entry>
    <title>DMwR-note-01-预测海藻数量(四)</title>
    <link href="http://example.com/2014/10/28/DMwR-note-01-%E9%A2%84%E6%B5%8B%E6%B5%B7%E8%97%BB%E6%95%B0%E9%87%8F(%E5%9B%9B)/"/>
    <id>http://example.com/2014/10/28/DMwR-note-01-%E9%A2%84%E6%B5%8B%E6%B5%B7%E8%97%BB%E6%95%B0%E9%87%8F(%E5%9B%9B)/</id>
    <published>2014-10-27T23:39:16.000Z</published>
    <updated>2014-11-18T06:53:10.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="写在开头的话"><a href="#写在开头的话" class="headerlink" title="写在开头的话"></a>写在开头的话</h2><hr><ul><li>Ok，上一节我们利用多元回归和回归树两种方法建立了数据模型，那么数据模型可不可靠呢？这一节的任务就是对模型进行评估。</li></ul><h2 id="模型的评价和选择"><a href="#模型的评价和选择" class="headerlink" title="模型的评价和选择"></a>模型的评价和选择</h2><hr><ul><li>上一节给出了本案例的两个预测模型的例子。最明显的问题是，应该使用哪一个模型来获得7种海藻的140个测试样品的预测。为了回答这个问题，需要在可供选择的模型空间中指定一些模型的偏好标准，也就是说，需要详细说明应该如何评价模型的性能。</li><li>有多种评价(和比较)模型的标准。其中最流行的标准是计算模型的预测性能。当然还有其他衡量的标准，例如模型的可解释性，还有对大型数据挖掘特别重要的标准，即模型的计算效率。</li></ul><h3 id="预测函数predict"><a href="#预测函数predict" class="headerlink" title="预测函数predict()"></a>预测函数predict()</h3><ul><li>回归模型的预测性能是通过将目标变量的预测值与实际值进行比较得到的，并从这些比较中计算某些平均误差的度量。一种度量方法是平均绝对误差(MAE)。下面描述如何获得线性回归和回归树的平均绝对误差。第一步，获取需要评价模型预测性能的测试集个案的预测值。在R中，要获得任何模型的预测，就要使用函数predict()进行预测。函数predict()是一个泛型函数，它的一个参数为需要应用的模型，另一个参数为数据的测试集，输出结果为相应的模型预测值：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lm.predictions.a1 &lt;- predict(final.lm, clean.algae)</span><br><span class="line">rt.predictions.a1 &lt;- predict(rt.a1, algae)</span><br></pre></td></tr></table></figure></li><li>上面连个命令得到预测海藻a1的两个模型的预测值。注意，因为原始训练集数据含有缺失值，所以在线性回归模型中使用的是数据框clean.algae。</li></ul><h3 id="平均绝对误差-MAE"><a href="#平均绝对误差-MAE" class="headerlink" title="平均绝对误差(MAE)"></a>平均绝对误差(MAE)</h3><ul><li>得到模型的预测值后，就可以计算出其平均绝对误差：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算平均绝对误差</span></span><br><span class="line">(mae.a1.lm &lt;- mean(abs(lm.predictions.a1 - algae[,<span class="string">&quot;a1&quot;</span>])))</span><br><span class="line">[1] 13.10681</span><br><span class="line"></span><br><span class="line">(mae.a1.rt &lt;- mean(abs(rt.predictions.a1 - algae[,<span class="string">&quot;a1&quot;</span>])))</span><br><span class="line">[1] 10.36242</span><br></pre></td></tr></table></figure></li></ul><h3 id="均方误差-MSE"><a href="#均方误差-MSE" class="headerlink" title="均方误差(MSE)"></a>均方误差(MSE)</h3><ul><li>另一种流行的误差度量是均方误差(MSE)。可以由下列代码计算均方误差：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算均方误差(MSE)</span></span><br><span class="line">(mse.a1.lm &lt;- mean((lm.predictions.a1 - algae[,&quot;a1&quot;])^<span class="number">2</span>))</span><br><span class="line">[1] 295.5407</span><br><span class="line"></span><br><span class="line">(mse.a1.rt &lt;- mean((rt.predictions.a1 - algae[,&quot;a1&quot;])^<span class="number">2</span>))</span><br><span class="line">[1] 227.0339</span><br></pre></td></tr></table></figure></li></ul><h3 id="标准化的平均绝对误差-NMSE"><a href="#标准化的平均绝对误差-NMSE" class="headerlink" title="标准化的平均绝对误差(NMSE)"></a>标准化的平均绝对误差(NMSE)</h3><ul><li>以上后一种误差度量方法的不足之处是：误差值和目标值变量的目标不统一，因此从用户的角度看，这种误差不好解释。即使应用平均绝对误差(MAE)来度量误差，问题是如何判断模型的得分是好还是差。能够解决这一问题的误差度量是标准化后的平均绝对误差(NMSE)。这一统计量是计算模型预测性能和基准模型的预测性能之间的比率。通常采用目标变量的平均值来作为基准模型，代码如下：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算标准化后的平均绝对误差(NMSE)</span></span><br><span class="line">(nmse.a1.lm &lt;- mean((lm.predictions.a1 - algae[,&#x27;a1&#x27;])^<span class="number">2</span> / mean((mean(algae[,&#x27;a1&#x27;])-algae[,&#x27;a1&#x27;])^<span class="number">2</span>)))</span><br><span class="line">[1] 0.6473034</span><br><span class="line"></span><br><span class="line">(nmse.a1.rt &lt;- mean(rt.predictions.a1-algae[,<span class="string">&#x27;a1&#x27;</span>])^2 / mean((mean(algae[,&#x27;a1&#x27;])-algae[,&#x27;a1&#x27;])^<span class="number">2</span>))</span><br><span class="line">[1] 3.121937e-34</span><br></pre></td></tr></table></figure></li><li>NMSE是一个比值，其取值范围通常为0-1。如果模型表现优于这个非常简单基准模型预测，那么NMSE应明显小于1。NMSE的值越小，模型的性能就越好。NMSE的值大于1，意味着模型预测还不如简单地把所有个案的平均值作为预测值。</li><li>在本书提供的R添加包中，函数regr.eval()用来计算线性回归模型的性能度量指标。下面给出应用该函数一个例子。可以查找该函数的帮助文档来获取这个函数的不同用法。<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">regr.eval(algae[,<span class="string">&#x27;a1&#x27;</span>], rt.predictions.a1, train.y = algae[,<span class="string">&#x27;a1&#x27;</span>])</span><br><span class="line">       mae         mse        rmse        mape        nmse        nmae </span><br><span class="line">10.3624227 227.0338940  15.0676439         Inf   0.4972574   0.6202654 </span><br></pre></td></tr></table></figure></li></ul><h3 id="可视化比较模型"><a href="#可视化比较模型" class="headerlink" title="可视化比较模型"></a>可视化比较模型</h3><ul><li>可视化地查看模型的预测值将更加有趣。一种方法是绘制误差的散点图。代码如下：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 可视化查看模型的预测值</span></span><br><span class="line">old.par &lt;- par(mfrow = c(1,2))</span><br><span class="line">plot(lm.predictions.a1, algae[,<span class="string">&#x27;a1&#x27;</span>], main=<span class="string">&quot;Linear Model&quot;</span>, xlab=<span class="string">&quot;Predictions&quot;</span>, ylab=<span class="string">&quot;True Values&quot;</span>)</span><br><span class="line">abline(0,1,lty=2)</span><br><span class="line">plot(rt.predictions.a1, algae[,<span class="string">&#x27;a1&#x27;</span>], main=<span class="string">&quot;Regression Tree&quot;</span>, xlab=<span class="string">&quot;Predictions&quot;</span>, ylab=<span class="string">&quot;True Values&quot;</span>)</span><br><span class="line">abline(0,1,lty=2)</span><br><span class="line">par(old.par)</span><br></pre></td></tr></table></figure></li><li>plot:<br> <img src="/img/DMwR/02_algae_model_judge/01_prediction_true.PNG"></li><li>由上图可以看出，这两个模型在许多个案上的性能比较差。在理想的情况下，模型对所有的个案做出正确的预测时，图中的所有圈应该在虚线上，这条虚线是通过函数abline(0,1,lty&#x3D;2)来绘制的。这条虚线穿过坐标系的原点，代表x坐标和y坐标相等的点集。图中圆圈的x坐标和y坐标分别代表目标变量的预测值和真实值，如果他们相等，那么这些圆圈就会落在这条理想的直线上。但从上图可以看到，情况并非如此！可以用函数identify()来检查哪些预测特别差的样本点，该函数可以让用户通过互动方式点击图形中的点，代码如下：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># identify()</span></span><br><span class="line">plot(lm.predictions.a1, algae[,<span class="string">&#x27;a1&#x27;</span>],main=<span class="string">&quot;Linear Model&quot;</span>, xlab=<span class="string">&quot;Predictions&quot;</span>, ylab=<span class="string">&quot;True Values&quot;</span>)</span><br><span class="line">abline(0,1,lty=2)</span><br><span class="line">algae[identify(lm.predictions.a1, algae[,<span class="string">&#x27;a1&#x27;</span>]),]</span><br></pre></td></tr></table></figure></li><li>运行上面的代码，并在图形上点击，然后右击结束交互过程后，应该看到相应于所点击的圆圈的海藻数据框的行数据–因为这里用函数identify()得到的向量来索引海藻数据框。</li><li>观察上图的左图，他对应的是线性回归模型。注意，有一些个案的海藻频率的预测值为负值。在本案例中，海藻在出现频率为负值时没有意义(至少是0个)。因此，可以用以上知识和海藻频率的最小可能取值来优化上面的线性回归模型。<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sensible.lm.predictions.a1 &lt;- ifelse(lm.predictions.a1 &lt;0,0,lm.predictions.a1)</span><br><span class="line">regr.eval(algae[,<span class="string">&#x27;a1&#x27;</span>], lm.predictions.a1,stats = c(<span class="string">&quot;mae&quot;</span>,<span class="string">&quot;mse&quot;</span>))</span><br><span class="line">     mae       mse </span><br><span class="line">13.10681 295.54069 </span><br><span class="line">regr.eval(algae[,<span class="string">&#x27;a1&#x27;</span>], sensible.lm.predictions.a1, stats = c(<span class="string">&quot;mae&quot;</span>,<span class="string">&quot;mse&quot;</span>))</span><br><span class="line">     mae       mse </span><br><span class="line">12.48276 286.28541</span><br></pre></td></tr></table></figure></li><li>上面代码应用函数ifelse()来改进模型的预测结果。该函数有三个参数，第一个参数是逻辑条件，第二个参数是当逻辑条件为真时函数的取值，第三个参数是当逻辑条件为假时的取值。注意，通过这一小的细节就提高了模型的性能。</li></ul><h3 id="k折交叉验证"><a href="#k折交叉验证" class="headerlink" title="k折交叉验证"></a>k折交叉验证</h3><ul><li><p>根据以上计算出的模型的性能指标，我们倾向于选择回归树模型来预测140个测试样品的频率值，因为该模型有较低的NMSE值。然而，这种推理有一种那个缺陷。我们的分析目标是获得能够对140个测试样品的频率进行预测的最佳模型。由于不知道这些测试样本的目标变量值，所以我们需要估计哪一个模型将在这些测试样本上有较好的性能。这里的关键问题是在不知道数据集真实的目标变量取值时，要获得模型在该数据集上可靠的性能估计。使用已有的训练数据获得模型的性能指标(如前面获得模型的过程)是不可靠的，因为这些计算是有偏的。</p></li><li><p>实际上，有的模型可以很容易地获得训练数据的零误差预测。然而，模型的这一优秀性能很难推广到目标变量值未知的心样本上。正如之前所述，这种现象通常称为过拟合训练数据。因为，为了选择一个合适的模型，我们需要获得模型在未知数据上预测性能的更加可靠的估计。k折交叉验证是获得模型性能可靠估计的一种常用方法，它适用于像本案例这样的小数据集。这种方法可以简要介绍如下。</p><ul><li>首先获取k个同样大小的随机训练数据子集。</li><li>对于这k个子集的每一个子集，用除去它之外的其余k-1个子集建立模型，然后用第k个子集来评估这个模型，最后存储模型的性能指标</li><li>对其余的每个子集重复以上过程，最后有K个性能指标的测量值，这些性能指标是通过在没有用于建模的数据上计算得到，这也是关键之处。</li></ul></li><li><p>k折交叉验证估计是这k个性能指标的平均。常见的k&#x3D;10.有时我们会重复进行多次k折交叉验证以获得更加可靠的估计。</p><ul><li>总之，党对一项预测任务时，需要作出以下决策：<ul><li>为预测任务选择模型(同一算法的不同参数设定也可以认为是不同的模型)。</li><li>选择比较模型性能的评估指标</li><li>选择获取评估指标的可靠估计的实验方法。</li></ul></li></ul></li><li><p>在本书提供的R包中，提供了函数experimentalComparison()，它用来进行模型的选择和比较任务。它可以和不同的估计方法一起使用，如交叉验证法。这个函数有三个参数：1.用于比较的数据集，2.需要比较的可选模型，3.实验过程中的系数。我们以海藻数据集为例，用它来比较线性回归模型和几个不同回归树模型。</p></li><li><p>函数experimentalComparison()使用于任何模型和任何数据，在这个意义上，它是一个泛型函数。使用者提供一组实现待比较的模型的函数。其中每一个函数应该对训练集和测试集实现一个完整的“训练+测试+评估”周期。在评估过程的每一次迭代中，调用这些函数。这些函数应该返回一个向量，其元素为交叉验证中用户需要的性能评估指标值。下面给出两个目标模型的函数：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">cv.rpart &lt;- <span class="keyword">function</span>(form,train,<span class="built_in">test</span>,...)&#123;</span><br><span class="line">  m &lt;- rpartXse(from,train,...)</span><br><span class="line">  p &lt;- predict(m,<span class="built_in">test</span>)</span><br><span class="line">  mse &lt;- mean((p-resp(form,test))^2)</span><br><span class="line">  c(nmse = mse/mean((mean(resp(form,train))-resp(form,<span class="built_in">test</span>))^2))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">cv.lm &lt;- <span class="keyword">function</span>(form, train, <span class="built_in">test</span>,...)&#123;</span><br><span class="line">  m &lt;- lm(form,train,...)</span><br><span class="line">  p &lt;- predict(m,<span class="built_in">test</span>)</span><br><span class="line">  p &lt;- ifelse(p&lt;0,0,p)</span><br><span class="line">  mse &lt;- mean((p-resp(form,test))^2)</span><br><span class="line">  c(nmse=mse/mean((mean(resp(form,train))-resp(form,<span class="built_in">test</span>))^2))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>在这个示例中，假设用NMSE作为线性回归模型和回归树模型的性能评估指标。所有这些用户定义的函数的前三个参数应该是公式、训练数据和测试数据。实验过程调用函数时可以应用的其他参数包括要评估模型所需要的参数。虽然所评估的两个模型应用了完全不同的学习算法，但是两个模型函数都有同样的“训练+测试+评估”周期。函数的定义还包括一个特殊参数“…”。这个特殊参数可以用在任意的R函数中，它允许一个特定函数具有可变的参数。这个结构用于给实际模型传递所需要的额外参数(例如在函数rpartXse()中和函数lm()中)。这些函数的另一个特殊之处是应用本书添加包提供的函数resp()，它用于根据公式获得数据集的目标变量值。</p></li><li><p>在定义好用于模型学习和测试的函数后，就可以按下列代码进行模型的交叉验证比较：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">res &lt;- experimentalComparison(</span><br><span class="line">  c(dataset(a1~.,clean.algae[,1:12],<span class="string">&quot;a1&quot;</span>)),</span><br><span class="line">  c(variants(<span class="string">&#x27;cv.lm&#x27;</span>),</span><br><span class="line">    variants(<span class="string">&#x27;cv.rpart&#x27;</span>,se=c(0,0.5,1))),</span><br><span class="line">    cvSettings(3,10,1234)</span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#####  CROSS VALIDATION  EXPERIMENTAL COMPARISON #####</span></span><br><span class="line"></span><br><span class="line">** DATASET :: a1</span><br><span class="line"></span><br><span class="line">++ LEARNER :: cv.lm  variant -&gt;  cv.lm.v1 </span><br><span class="line"></span><br><span class="line"> 3 x 10 - Fold Cross Validation run with seed =  1234 </span><br><span class="line">Repetition  1 </span><br><span class="line">Fold:  1  2  3  4  5  6  7  8  9  10</span><br><span class="line">Repetition  2 </span><br><span class="line">Fold:  1  2  3  4  5  6  7  8  9  10</span><br><span class="line">Repetition  3 </span><br><span class="line">Fold:  1  2  3  4  5  6  7  8  9  10</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">++ LEARNER :: cv.rpart  variant -&gt;  cv.rpart.v1 </span><br><span class="line"></span><br><span class="line"> 3 x 10 - Fold Cross Validation run with seed =  1234 </span><br><span class="line">Repetition  1 </span><br><span class="line">Fold:  1  2  3  4  5  6  7  8  9  10</span><br><span class="line">Repetition  2 </span><br><span class="line">Fold:  1  2  3  4  5  6  7  8  9  10</span><br><span class="line">Repetition  3 </span><br><span class="line">Fold:  1  2  3  4  5  6  7  8  9  10</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">++ LEARNER :: cv.rpart  variant -&gt;  cv.rpart.v2 </span><br><span class="line"></span><br><span class="line"> 3 x 10 - Fold Cross Validation run with seed =  1234 </span><br><span class="line">Repetition  1 </span><br><span class="line">Fold:  1  2  3  4  5  6  7  8  9  10</span><br><span class="line">Repetition  2 </span><br><span class="line">Fold:  1  2  3  4  5  6  7  8  9  10</span><br><span class="line">Repetition  3 </span><br><span class="line">Fold:  1  2  3  4  5  6  7  8  9  10</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">++ LEARNER :: cv.rpart  variant -&gt;  cv.rpart.v3 </span><br><span class="line"></span><br><span class="line"> 3 x 10 - Fold Cross Validation run with seed =  1234 </span><br><span class="line">Repetition  1 </span><br><span class="line">Fold:  1  2  3  4  5  6  7  8  9  10</span><br><span class="line">Repetition  2 </span><br><span class="line">Fold:  1  2  3  4  5  6  7  8  9  10</span><br><span class="line">Repetition  3 </span><br><span class="line">Fold:  1  2  3  4  5  6  7  8  9  10</span><br></pre></td></tr></table></figure></li><li><p>像先前提到的那样，第一个参数是含有在实验比较中所应用数据集的一个向量。每个数据集的声明形式为dataset(<formular>,<data frame>,<label>)。函数experimentalComparison()的第二个参数包含要研究的可选的模型方法。每个模型方法通过函数variant()来指定，该函数的第一个参数是用户定义的用于“学习+测试+评估”周期的函数名称。其余的可选参数用来给出估计方法的其他参数的可选值。函数variantes()根据所有参数值的组合生成一组可选模型。在上面的例子代码中，模型“cv.lm”采用了默认参数值，而模型“cv.rpart”的参数se则给出了不同的取值。这意味着实验将包含回归树的三个版本，这点可以在上面的函数输出中得到确认。函数experimentalComparison()的第三个参数是设定交叉验证实验的参数，即k折交叉验证实验过程重复的次数(这里设为3)、k的取值(10)、随机数生成器的种子。最后的参数(随机数种子)设定可以保证在必要的情况之下可以重视我们的实验(例如更换了训练模型系统)。</p></li><li><p>这个代码调用的结果是一个复杂的对象，它包含实验比较的所有信息。在本书的R添加包中提供了多种获取这些信息的函数。例如，下面代码提供了比较结果的概要：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">summary(res)</span><br><span class="line"></span><br><span class="line">== Summary of a  Cross Validation  Experiment ==</span><br><span class="line"></span><br><span class="line"> 3 x 10 - Fold Cross Validation run with seed =  1234 </span><br><span class="line"></span><br><span class="line">* Data sets ::  a1</span><br><span class="line">* Learners  ::  cv.lm.v1, cv.rpart.v1, cv.rpart.v2, cv.rpart.v3</span><br><span class="line"></span><br><span class="line">* Summary of Experiment Results:</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">-&gt; Datataset:  a1 </span><br><span class="line"></span><br><span class="line">*Learner: cv.lm.v1 </span><br><span class="line">             nmse</span><br><span class="line">avg     0.7196105</span><br><span class="line">std     0.1833064</span><br><span class="line">min     0.4678248</span><br><span class="line">max     1.2218455</span><br><span class="line">invalid 0.0000000</span><br><span class="line"></span><br><span class="line">*Learner: cv.rpart.v1 </span><br><span class="line">             nmse</span><br><span class="line">avg     0.6440843</span><br><span class="line">std     0.2521952</span><br><span class="line">min     0.2146359</span><br><span class="line">max     1.1712674</span><br><span class="line">invalid 0.0000000</span><br><span class="line"></span><br><span class="line">*Learner: cv.rpart.v2 </span><br><span class="line">             nmse</span><br><span class="line">avg     0.6873747</span><br><span class="line">std     0.2669942</span><br><span class="line">min     0.2146359</span><br><span class="line">max     1.3356744</span><br><span class="line">invalid 0.0000000</span><br><span class="line"></span><br><span class="line">*Learner: cv.rpart.v3 </span><br><span class="line">             nmse</span><br><span class="line">avg     0.7167122</span><br><span class="line">std     0.2579089</span><br><span class="line">min     0.3476446</span><br><span class="line">max     1.3356744</span><br><span class="line">invalid 0.0000000</span><br></pre></td></tr></table></figure></li><li><p>从结果中可知，其中的一个回归树有最优的NMSE值。这个NMSE值是否明显优于其他模型，目前还不明显，本节的后面将回到这个问题。可以得到这些结果的可视化图形:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot(res)</span><br></pre></td></tr></table></figure></li><li><p>plot:<br><img src="/img/DMwR/02_algae_model_judge/02_nmse.PNG"></p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;写在开头的话&quot;&gt;&lt;a href=&quot;#写在开头的话&quot; class=&quot;headerlink&quot; title=&quot;写在开头的话&quot;&gt;&lt;/a&gt;写在开头的话&lt;/h2&gt;&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;Ok，上一节我们利用多元回归和回归树两种方法建立了数据模型，那么数据模型可不可靠呢？这</summary>
      
    
    
    
    <category term="数据挖掘与R语言-案例学习" scheme="http://example.com/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%B8%8ER%E8%AF%AD%E8%A8%80-%E6%A1%88%E4%BE%8B%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="数据挖掘" scheme="http://example.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
  </entry>
  
  <entry>
    <title>DMwR-note-01-预测海藻数量(二)</title>
    <link href="http://example.com/2014/10/26/DMwR-note-01-%E9%A2%84%E6%B5%8B%E6%B5%B7%E8%97%BB%E6%95%B0%E9%87%8F(%E4%BA%8C)/"/>
    <id>http://example.com/2014/10/26/DMwR-note-01-%E9%A2%84%E6%B5%8B%E6%B5%B7%E8%97%BB%E6%95%B0%E9%87%8F(%E4%BA%8C)/</id>
    <published>2014-10-26T12:12:23.000Z</published>
    <updated>2015-01-05T07:36:16.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="写在开头的话"><a href="#写在开头的话" class="headerlink" title="写在开头的话"></a>写在开头的话</h2><hr><p>上次的笔记讲了数据的读取，窥探和可视化，这次我们来分析一下数据当中的缺失值。对于缺失值的正确处理也是数据分析当中很重要的一步。</p><h2 id="数据缺失"><a href="#数据缺失" class="headerlink" title="数据缺失"></a>数据缺失</h2><hr><ul><li><p>数据缺失是一种非常普遍的情形，但是有些数据分析的方法无法对缺失值进行处理，这样就会带来问题。</p></li><li><p>当我们处理含有缺失值的数据时，可以运用一下几种最常见的策略：</p><ul><li>将含有缺失值的案例剔除</li><li>根据变量之间的相关关系填补缺失值</li><li>根据案例之间的相似性填补缺失值</li><li>使用能够处理缺失值数据的工具</li></ul></li><li><p>在开始之前，我们先在Rstudio中载入包和数据</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">library(DMwR)</span><br><span class="line">data(algae)</span><br></pre></td></tr></table></figure></li></ul><h3 id="将缺失部分剔除"><a href="#将缺失部分剔除" class="headerlink" title="将缺失部分剔除"></a>将缺失部分剔除</h3><hr><ul><li><p>剔除缺失值的操作非常容易实现，特别当缺失值在数据当中所占的比例比较小的时候，这个选择比较合理。</p></li><li><p>在剔除缺失值之前，我们勿急，最好先检查观测值，或者至少得到这些观测值的个数，</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">algae[!complete.cases(algae),]</span><br><span class="line">    season   size  speed mxPH mnO2    Cl   NO3 NH4    oPO4     PO4  Chla   a1</span><br><span class="line">28  autumn  small   high 6.80 11.1 9.000 0.630  20   4.000      NA  2.70 30.3</span><br><span class="line">38  spring  small   high 8.00   NA 1.450 0.810  10   2.500   3.000  0.30 75.8</span><br><span class="line">48  winter  small    low   NA 12.6 9.000 0.230  10   5.000   6.000  1.10 35.5</span><br><span class="line">55  winter  small   high 6.60 10.8    NA 3.245  10   1.000   6.500    NA 24.3</span><br><span class="line">56  spring  small medium 5.60 11.8    NA 2.220   5   1.000   1.000    NA 82.7</span><br><span class="line">57  autumn  small medium 5.70 10.8    NA 2.550  10   1.000   4.000    NA 16.8</span><br><span class="line">58  spring  small   high 6.60  9.5    NA 1.320  20   1.000   6.000    NA 46.8</span><br><span class="line">59  summer  small   high 6.60 10.8    NA 2.640  10   2.000  11.000    NA 46.9</span><br><span class="line">60  autumn  small medium 6.60 11.3    NA 4.170  10   1.000   6.000    NA 47.1</span><br><span class="line">61  spring  small medium 6.50 10.4    NA 5.970  10   2.000  14.000    NA 66.9</span><br><span class="line">62  summer  small medium 6.40   NA    NA    NA  NA      NA  14.000    NA 19.4</span><br><span class="line">63  autumn  small   high 7.83 11.7 4.083 1.328  18   3.333   6.667    NA 14.4</span><br><span class="line">116 winter medium   high 9.70 10.8 0.222 0.406  10  22.444  10.111    NA 41.0</span><br><span class="line">161 spring  large    low 9.00  5.8    NA 0.900 142 102.000 186.000 68.05  1.7</span><br><span class="line">184 winter  large   high 8.00 10.9 9.055 0.825  40  21.083  56.091    NA 16.8</span><br><span class="line">199 winter  large medium 8.00  7.6    NA    NA  NA      NA      NA    NA  0.0</span><br><span class="line">      a2  a3   a4  a5  a6  a7</span><br><span class="line">28   1.9 0.0  0.0 2.1 1.4 2.1</span><br><span class="line">38   0.0 0.0  0.0 0.0 0.0 0.0</span><br><span class="line">48   0.0 0.0  0.0 0.0 0.0 0.0</span><br><span class="line">55   0.0 0.0  0.0 0.0 0.0 0.0</span><br><span class="line">56   0.0 0.0  0.0 0.0 0.0 0.0</span><br><span class="line">57   4.6 3.9 11.5 0.0 0.0 0.0</span><br><span class="line">58   0.0 0.0 28.8 0.0 0.0 0.0</span><br><span class="line">59   0.0 0.0 13.4 0.0 0.0 0.0</span><br><span class="line">60   0.0 0.0  0.0 0.0 1.2 0.0</span><br><span class="line">61   0.0 0.0  0.0 0.0 0.0 0.0</span><br><span class="line">62   0.0 0.0  2.0 0.0 3.9 1.7</span><br><span class="line">63   0.0 0.0  0.0 0.0 0.0 0.0</span><br><span class="line">116  1.5 0.0  0.0 0.0 0.0 0.0</span><br><span class="line">161 20.6 1.5  2.2 0.0 0.0 0.0</span><br><span class="line">184 19.6 4.0  0.0 0.0 0.0 0.0</span><br><span class="line">199 12.5 3.7  1.0 0.0 0.0 4.9</span><br><span class="line"></span><br><span class="line">nrow(algae[!complete.cases(algae),])</span><br><span class="line">[1] 16</span><br></pre></td></tr></table></figure></li><li><p>函数complete.cases()产生一个布尔值向量，该向量的元素个数与algae数据框中的行数相同，如果数据框的相应行中不含NA值(即为一个完整的观测值)，函数返回值就是TRUE。“！”逻辑非，因此上述指令显示了含有缺失值的水样记录。</p></li><li><p>为了从数据框中剔除这16个样本，我们可以这样简单的输入：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">algae1 &lt;- na.omit(algae)</span><br></pre></td></tr></table></figure></li><li><p>这样我们就剔除了源数据中的所有含有缺失值的记录。但同时问题也浮出来了：数据分析的前提是有效数据越多越好。若果数据中含有缺失值的记录比例不低，那么这种做法会导致剩余数据的分析结果出现很大的偏差；或者另外一种情况，虽然缺失值的记录比例低，但是缺失值记录当中有很多是只是含有一个缺失值的，这样的剔除有点浪费数据，所以，下面我们利用函数找到缺失值记录当中含有缺失值最多的来进行剔除。</p></li><li><p>例如，观察样本中的数据，我们可以看到第62条和第199条记录中的11个解释变量中有6个是缺失值。我们就来剔除它们。</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">algae2 &lt;- algae[-c(62,199),]</span><br></pre></td></tr></table></figure><ul><li>更进一步的，如果数据量大，单凭肉眼观察是不合理的，所以我们需要找出缺失值较多的记录的下标。下面的代码可以找出海藻数据集中每行数据的缺失值个数：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">algae3 &lt;- apply(algae, 1, <span class="keyword">function</span>(x) <span class="built_in">sum</span>(is.na(x)))</span><br><span class="line">algae3</span><br><span class="line">  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0</span><br><span class="line"> [37] 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 2 2 2 2 2 2 2 6 1 0 0 0 0 0 0 0 0 0</span><br><span class="line"> [73] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</span><br><span class="line">[109] 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</span><br><span class="line">[145] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</span><br><span class="line">[181] 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 6 0</span><br></pre></td></tr></table></figure><ul><li><p>函数apply()属于R中功能非常强大的一类函数。这类函数又称为元函数，它们可以在某些条件下对对象应用其他函数。对函数apply()而言，它可以把任何其他函数应用到一个多维对象的各个维度上。使用函数apply()时，它把一个函数应用到数据框的每一行。这个被应用的函数在apply()函数的第三个参数给出，对数据框的每一个行都分别调用该函数。</p></li><li><p>在这个案例中我们使用一个临时函数。它只在调用apply()函数时才存在。另外，函数apply()的第三个也可以是一个“正常”函数的函数名。临时函数的功能室计算对象x中NA的数量。在R中逻辑值TRUE等于数值1，逻辑值FALSE等于0，这意味着当加一个布尔值向量时，得到向量中取值为TRUE的元素的个数。</p></li><li><p>根据以上代码，可以编写一个程序找出algae中含有给定数目缺失值的行。在本书提供的添加包中有这个函数。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">manyNAs(algae, 0.2)</span><br><span class="line">[1]  62 199</span><br></pre></td></tr></table></figure></li><li><p>函数manyNAs()的功能是找出缺失值个数大于20%的行。在第二个参数中可以设置一个精确的列数作为界限。因此，用下面的代码就无须知道含有缺失值较多的行的具体数量：</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">algae4 &lt;- algae[-manyNAs(algae),]</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>manyNAs()函数的第二个参数的默认值是0.2。</li></ul><h3 id="用最高频率值来填补缺失值"><a href="#用最高频率值来填补缺失值" class="headerlink" title="用最高频率值来填补缺失值"></a>用最高频率值来填补缺失值</h3><hr><ul><li><p>填补含有缺失值的记录的另一个方法就是尝试找到这些缺失值最可能的值。同样的，这里有多种策略可供选择，不同策略对逼近程度和算法复杂度的权衡不同。</p></li><li><p>填补缺失数据最简单和快捷的方法是使用一些代表中心趋势的值。代表中心趋势的值反映了变量分布的最常见值，因此中心趋势值是最自然的选择。有多个代表数据中心趋势的指标，例如，平均值、中位数、众数等。最合适的选择由变量的分布决定。对于接近正态分布来说，所有的观测值都较好地集中在平均值周围，平均值就是最佳的选择。然而，对于偏态分布，或者有离群值的变量来说，选择平均值不好。偏态分布的大部分值都聚集在变量分布的一侧，因此平均值不能作为最常见值的代表。另一方面，离群值(极值)的存在会扭曲平均值，这就导致了平均值不具有代表性的问题。因此，在对变量分布进行检查之前选择平均值作为中心趋势的代表是不明智的例如，某些R的绘图工具。对偏态分布或者有离群值的分布而言，中位数是更好的代表数据中心趋势的指标。</p></li><li><p>比如，样本algae[48,]中的变量mxPH有缺失值。由于该变量分布近似正态分布，见<a class="link"   href="http://chenyuqing.github.io/2014/10/23/DMwR-note-01-%E9%A2%84%E6%B5%8B%E6%B5%B7%E8%97%BB%E6%95%B0%E9%87%8F/" >DMwR-note-01-预测海藻数量(一)<i class="fas fa-external-link-alt"></i></a>，我们可以选用平均值来填补这个“洞”，计算方法如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">temp &lt;- algae</span><br><span class="line">temp[48,<span class="string">&quot;mxPH&quot;</span>] &lt;- mean(algae<span class="variable">$mxPH</span>, na.rm=T)</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>这里，函数mean()计算数值向量的平均值，参数na.rm&#x3D;T使计算时忽略缺失数据。</p></li><li><p>大多数时候采用一次填补一列中的所有缺失值而不是像上面那样一行一行地逐个填补。以变量Chla为例，这个变量在第12行上有缺失值。另外，这也是平均值不能代表大多数变量值的一种情况。事实上，Chla的分布偏向较低的数值，并且它有几个极端值，这些都使得平均值不能代表大多数的变量值。因此，我们使用中位数来填补这一类的缺失值：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">temp &lt;- algae</span><br><span class="line">temp[is.na(algae<span class="variable">$Chla</span>), <span class="string">&quot;Chla&quot;</span>] &lt;- median(algae<span class="variable">$Chla</span>, na.rm=T)</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>本书插件包中提供的函数centralInputation()可以用数据的中心趋势值来填补数据集的所有缺失值。岁数值型变量，该函数用中位数；对名义变量，它采用众数。该函数的应用如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">temp &lt;- algae</span><br><span class="line">temp &lt;- temp[-manyNAs(algae),]</span><br><span class="line">temp &lt;- centralInputation(temp)</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>使用无偏方法来寻找最佳数据填补值复杂，对于大型数据挖掘问题可能并不适用。</p></li></ul><h3 id="通过变量的相关关系来填补缺失值"><a href="#通过变量的相关关系来填补缺失值" class="headerlink" title="通过变量的相关关系来填补缺失值"></a>通过变量的相关关系来填补缺失值</h3><hr><ul><li><p>另一种获取缺失值较少偏差估计值的方法是探寻变量之间的相关关系。比如，听过变量值之间的相关关系，能够发现某变量与mxPH高度相关。这可以使我们得到含有缺失值的第48条样本更可能的填补值。这比之前使用平均值的方法将更胜一筹。</p></li><li><p>应用如下命令来得到变量间的相关值：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">temp &lt;- algae</span><br><span class="line">cor(temp[, 4:18], use = <span class="string">&quot;complete.obs&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>函数cor()的功能室产生变量之间的相关值矩阵(因为前3个变量时名义变量，所以计算相关值时不考虑它们)。设定参数use &#x3D; “complete.obs”时，R在计算相关值时忽略含有NA的记录。相关值在1（或-1）周围表示相应的两个变量之间的强正（或负）线性相关关系。然后其他R函数可以得到变量间相关的近似函数形式，它可以让我们通过一个变量的值计算出另一个变量的值</p></li><li><p>函数cor()的输出结果并不是很清晰，但可以通过symnum()来改善结果的输出形式，例如：</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">temp &lt;- algae</span><br><span class="line">symnum(cor(temp[, 4:18], use = <span class="string">&quot;complete.obs&quot;</span>))</span><br><span class="line">     mP mO Cl NO NH o P Ch a1 a2 a3 a4 a5 a6 a7</span><br><span class="line">mxPH 1                                         </span><br><span class="line">mnO2    1                                      </span><br><span class="line">Cl         1                                   </span><br><span class="line">NO3           1                                </span><br><span class="line">NH4           ,  1                             </span><br><span class="line">oPO4    .  .        1                          </span><br><span class="line">PO4     .  .        * 1                        </span><br><span class="line">Chla .                  1                      </span><br><span class="line">a1         .        . .    1                   </span><br><span class="line">a2   .                  .     1                </span><br><span class="line">a3                               1             </span><br><span class="line">a4      .           . .             1          </span><br><span class="line">a5                                     1       </span><br><span class="line">a6            .  .                     .  1    </span><br><span class="line">a7                                           1 </span><br><span class="line">attr(,<span class="string">&quot;legend&quot;</span>)</span><br><span class="line">[1] 0 <span class="string">&#x27; &#x27;</span> 0.3 <span class="string">&#x27;.&#x27;</span> 0.6 <span class="string">&#x27;,&#x27;</span> 0.8 <span class="string">&#x27;+&#x27;</span> 0.9 <span class="string">&#x27;*&#x27;</span> 0.95 <span class="string">&#x27;B&#x27;</span> 1</span><br></pre></td></tr></table></figure><ul><li>这种用符号表示相关值的方法更为清晰，特别是对于大的相关矩阵。</li><li>在本案例中，大多数变量之间是不相关的。然而，有2个例外：变量NH4和NO3之间，变量PO4和oPO4之间。后两者之间的相关值很高（大于0.9）。变量NH4和NO3之间的相关性不是特别明显（为0.72），因此根据他们来确定缺失数据是很危险的。此外，因为样本62和样本199有太多的变量含有缺失值，所以如果剔除它们，样本中的变量NH4和NO3就没有缺失值了。至于变量PO4和oPO4，它们之间相关性可以帮助填补这两个变量的缺失值。为了达到这个目标，我们需要找到这两个变量之间的线性关系，方法如下：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">temp &lt;- algae</span><br><span class="line">temp &lt;- temp[-manyNAs(temp),]</span><br><span class="line">lm(PO4 ~ oPO4, data = temp)</span><br><span class="line"></span><br><span class="line">Call:</span><br><span class="line">lm(formula = PO4 ~ oPO4, data = temp)</span><br><span class="line"></span><br><span class="line">Coefficients:</span><br><span class="line">(Intercept)         oPO4  </span><br><span class="line">     42.897        1.293 </span><br></pre></td></tr></table></figure><ul><li><p>函数lm()可以用来获取形如Y&#x3D;β0+β1χ1+…+βnχn的线性模型。上述结果得到的线性模型是：PO4 &#x3D; 42.897 + 1.293 * oPO4。如果这两个变量不是同是有缺失值，那么通过这个模型计算这些变量的缺失值。</p></li><li><p>在剔除样本62和样本199后，还剩下一个样本（样本28）在变量PO4上有缺失值，可以简单地使用上面的线性关系计算缺失值的填补值：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">temp &lt;- algae</span><br><span class="line">temp[28, <span class="string">&quot;PO4&quot;</span>] &lt;- 42.897 + 1.293 * temp[28, <span class="string">&quot;oPO4&quot;</span>]</span><br></pre></td></tr></table></figure></li><li><p>然而，为了说明这个方法，我们假设变量PO4有很多个缺失值。如何使用上述的线性关系计算所有的缺失值呢？最好的方法就是构造一个函数，它可以根据给定的oPO4的值就是PO4的值，然后对所有缺失值应用这个函数。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">temp &lt;- algae</span><br><span class="line">temp &lt;- temp[-manyNAs(temp),]</span><br><span class="line">fillPO4 &lt;- <span class="keyword">function</span>(oP) &#123;</span><br><span class="line"><span class="keyword">if</span>(is.na(oP))</span><br><span class="line"><span class="built_in">return</span>(NA)</span><br><span class="line"><span class="keyword">else</span> <span class="built_in">return</span>(42.897+1.293*oP)</span><br><span class="line">&#125;</span><br><span class="line">temp[is.na(temp<span class="variable">$PO4</span>), <span class="string">&quot;PO4&quot;</span>] &lt;- sapply(temp[is.na(temp<span class="variable">$PO4</span>),<span class="string">&quot;PO4&quot;</span>], fillPO4)</span><br></pre></td></tr></table></figure></li><li><p>上面代码中创建了一个叫做fillPO4()的函数，该函数有一个参数来接受变量oPO4的值，通过这个值，根据模型计算对应的PO4的值。然后，将这个函数应用到变量PO4有缺失值的所有样本中。这个过程可以通过另外一个元函数sapply()来实现。函数sapply()的第一个参数是一个向量，第二个参数为一个函数，返回的结果是另一个向量，该向量和第一个参数有相同的长度，向量中的元素为sapply()中第一个向量中的每一个元素作为参数传递到第二个函数后返回的结果。这意味着sapply()的结果将是填补变量PO4缺失值的向量。</p></li><li><p>对线性关系的研究使我们能够填充一些新的缺失值。然而，还有几个观测值含有缺失值。可以试探着探索案例数据中含有缺失值的变量和名义变量之间的关系。这可以通过应用R添加包lattice中的函数来绘制条件直方图来进行。代码如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">temp &lt;- algae</span><br><span class="line">histogram(~mxPH|season, data = temp)</span><br></pre></td></tr></table></figure><p>Pot:<br><img src="/img/DMwR/02_algae_NA/01_mxPH_season.PNG"></p></li><li><p>上面代码绘制在不同季节变量mxPH的直方图。每个直方图对应于某个季节的观测值数据。注意，上图的季节顺序不是按照自然的时间顺序，可以转换数据框中因子季节标签的顺序，这样可以使图形中的季节值为自然顺序。代码如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">temp &lt;- algae</span><br><span class="line">temp<span class="variable">$season</span> &lt;- <span class="built_in">factor</span>(temp<span class="variable">$season</span>, levels = c(<span class="string">&quot;spring&quot;</span>, <span class="string">&quot;summer&quot;</span>, <span class="string">&quot;autumn&quot;</span>, <span class="string">&quot;winter&quot;</span>))</span><br><span class="line">histogram(~mxPH|season, data = temp)</span><br></pre></td></tr></table></figure><p>Pot:<br><img src="/img/DMwR/02_algae_NA/02_mxPH_season.PNG"></p></li><li><p>由图看出，季节对mxPH的值没有显著的影响。</p></li></ul><h3 id="通过探索案例之间的相似性来填补缺失值"><a href="#通过探索案例之间的相似性来填补缺失值" class="headerlink" title="通过探索案例之间的相似性来填补缺失值"></a>通过探索案例之间的相似性来填补缺失值</h3><ul><li><p>不同于探索数据集列（变量）之间的相关性，本节尝试使用行（观测值）之间的相似性来填补缺失值。我们可以使用这种方法来填补除去那两个含有太多NA值的样本外的其他缺失数据。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">temp &lt;- algae</span><br><span class="line">temp &lt;- temp[-manyNAs(temp),]</span><br></pre></td></tr></table></figure></li><li><p>本节所描述的方法假设如果两个水样是相似的，其中一个水样在某些变量上有缺失值，那么该缺失值很可能与另外一个水样的值是相似的。为了使用这种直观的方法，首先定义相似性的概念。相似性经常由描述观察值的多元度量空间的变量所定义。在文献中有许多度量相似性的指标，常用的就是欧氏距离。这个距离可以非正式地定义为任何两个案例的观测值之差的平方和。计算公式如下：<br><img src="/img/DMwR/02_algae_NA/03_formular.PNG"></p></li><li><p>下面描述的方法将使用这种度量来寻找与任何含有缺失值的案例最相似的10个水样，并用它们来填补缺失值。我们考虑两种应用这些值的方法。第一种方法简单地计算着10个最相近的案例的中位数并用这个中位数来填补缺失值。如果缺失值是名义变量（本案例的algae数据不存在这种情况），我们采用这10个最相似数据中出现次数最多的值（众数）。第二种方法采用这些相似数据的加权均值。权重的大小随着距待填补缺失值的个案的距离增大而减小。这里用高斯核函数从距离获得权重。如果相邻个案距待填补缺失值的个案的距离为d，则它的值在加权平均重的权重为：<br><img src="/img/DMwR/02_algae_NA/04_formular.PNG"></p></li><li><p>上面的方法可以通过本书添加包中的函数knnImputation()来实现。这个函数用一个欧氏距离的变种来找到距任何个案最近的k个邻居。这个变种的欧氏距离可以应用于同时含有名义变量和数值变量的数据集中。计算公式如下：<br><img src="/img/DMwR/02_algae_NA/05_formular.PNG"></p></li><li><p>其中δi是变量i的两个值之间的距离，即<br><img src="/img/DMwR/02_algae_NA/06_formular.PNG"></p></li><li><p>在计算距离时，一般要对数值变量进行标准化，即<br><img src="/img/DMwR/02_algae_NA/07_formular.PNG"></p></li><li><p>下面说明如何使用knnImputation()函数。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">temp &lt;- algae</span><br><span class="line">temp &lt;- knnImputation(temp, k -10)</span><br></pre></td></tr></table></figure></li><li><p>吐过用中位数来填补缺失值，可以使用如下代码</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">temp &lt;- algae</span><br><span class="line">temp &lt;- knnImputation(temp, k = 10, meth = <span class="string">&quot;median&quot;</span>)</span><br></pre></td></tr></table></figure></li><li><p>总之，通过这些简单的操作，数据集中不在含有NA值（缺失值），为使用R的其他函数进行分析做好充分的准备工作。</p></li></ul><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><hr><ul><li>本节主要讨论了数据缺失值的处理，缺失值少的时候可以直接删除，但是当缺失值比较多的时候，然后会影响到整个数据集的正确性时，就要考虑用相关性或相似性来处理了。</li><li>本次博文是根据《数据挖掘与R语言(Luis Torgo著)》这本书的内容而写的笔记，本博文中所涉及的内容版权均归原作者所有。</li><li>下节讨论的主题是数据的建模。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;写在开头的话&quot;&gt;&lt;a href=&quot;#写在开头的话&quot; class=&quot;headerlink&quot; title=&quot;写在开头的话&quot;&gt;&lt;/a&gt;写在开头的话&lt;/h2&gt;&lt;hr&gt;
&lt;p&gt;上次的笔记讲了数据的读取，窥探和可视化，这次我们来分析一下数据当中的缺失值。对于缺失值的正确处理也</summary>
      
    
    
    
    <category term="数据挖掘与R语言-案例学习" scheme="http://example.com/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%B8%8ER%E8%AF%AD%E8%A8%80-%E6%A1%88%E4%BE%8B%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="数据挖掘" scheme="http://example.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
  </entry>
  
</feed>
