<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="Tim Chen(motion$)">
    
    <title>
        
            40 道ML/Data Science的初创公司(可能)的面试题 |
        
        In Web3.0 We Trust
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="shortcut icon" href="/img/favicon.ico">
    
<link rel="stylesheet" href="/font/css/fontawesome.min.css">

    
<link rel="stylesheet" href="/font/css/regular.min.css">

    
<link rel="stylesheet" href="/font/css/solid.min.css">

    
<link rel="stylesheet" href="/font/css/brands.min.css">

    <script id="hexo-configurations">
    let KEEP = window.KEEP || {}
    KEEP.hexo_config = {"hostname":"example.com","root":"/","language":"zh-CN","path":"search.xml"}
    KEEP.theme_config = {"toc":{"enable":true,"number":true,"expand_all":true,"init_open":true},"style":{"primary_color":"#7bed9f","logo":"/img/favicon.ico","favicon":"/img/favicon.ico","avatar":"/img/favicon.ico","font_size":"16px","font_family":"STKaiti, STHeiti","hover":{"shadow":true,"scale":true},"first_screen":{"enable":true,"header_transparent":false,"background_img":"/img/bg.svg","description":null,"font_color":"#7bed9f","hitokoto":true},"scroll":{"progress_bar":true,"percent":false}},"local_search":{"enable":true,"preload":true},"code_copy":{},"code_block":{"tools":{"enable":true,"style":"mac"},"highlight_theme":"default"},"side_tools":{},"pjax":{"enable":true},"lazyload":{"enable":false},"comment":{"enable":true,"use":"gitalk","valine":{"appid":null,"appkey":null,"server_urls":null,"placeholder":null},"gitalk":{"github_id":"chenyuqing","github_admins":["chenyuqing"],"repository":"gittalk-comment","client_id":"9e91691916561f410b89","client_secret":"b1f7e5e85cbcc4197d669d0731ef300bc7630dc7","proxy":null},"twikoo":{"env_id":null,"region":null,"version":"1.6.8"},"waline":{"server_url":null,"reaction":false,"version":2}},"post":{"author_label":{"enable":true,"auto":true,"custom_label_list":["Trainee","Engineer","Architect"]},"word_count":{"enable":true,"wordcount":true,"min2read":true},"img_align":"left","copyright_info":true},"version":"3.6.1"}
    KEEP.language_ago = {"second":"%s 秒前","minute":"%s 分钟前","hour":"%s 小时前","day":"%s 天前","week":"%s 周前","month":"%s 个月前","year":"%s 年前"}
    KEEP.language_code_block = {"copy":"复制代码","copied":"已复制","fold":"折叠代码块","folded":"已折叠"}
    KEEP.language_copy_copyright = {"copy":"复制版权信息","copied":"已复制","title":"原文标题","author":"原文作者","link":"原文链接"}
  </script>
<meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
</head>


<body>
<div class="progress-bar-container">
    
        <span class="scroll-progress-bar"></span>
    

    
        <span class="pjax-progress-bar"></span>
        <i class="pjax-progress-icon fas fa-circle-notch fa-spin"></i>
    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            
<header class="header-wrapper">

    <div class="header-content">
        <div class="left">
            
                <a class="logo-image" href="/">
                    <img src="/img/favicon.ico">
                </a>
            
            <a class="logo-title" href="/">
               In Web3.0 We Trust
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            <a class=""
                               href="/"
                            >
                                首页
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/archives"
                            >
                                归档
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/categories"
                            >
                                分类
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/tags"
                            >
                                标签
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/books"
                            >
                                读书
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/jokes"
                            >
                                段子
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/about"
                            >
                                关于我
                            </a>
                        </li>
                    
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="fas fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/">首页</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/archives">归档</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/categories">分类</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/tags">标签</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/books">读书</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/jokes">段子</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/about">关于我</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="post-page-container">
        <div class="article-content-container">

            <div class="article-title">
                <span class="title-hover-animation">40 道ML/Data Science的初创公司(可能)的面试题</span>
            </div>

            
                <div class="article-header">
                    <div class="avatar">
                        <img src="/img/favicon.ico">
                    </div>
                    <div class="info">
                        <div class="author">
                            <span class="name">Tim Chen(motion$)</span>
                            
                                <span class="author-label">Lv5</span>
                            
                        </div>
                        <div class="meta-info">
                            
<div class="article-meta-info">
    <span class="article-date article-meta-item">
        
            <i class="fa-regular fa-calendar-plus"></i>&nbsp;
        
        <span class="pc">2016-10-03 16:19:38</span>
        <span class="mobile">2016-10-03 16:19</span>
    </span>
    
        <span class="article-update-date article-meta-item">
        <i class="fas fa-file-pen"></i>&nbsp;
        <span class="pc">2023-07-16 09:44:24</span>
    </span>
    
    
        <span class="article-categories article-meta-item">
            <i class="fas fa-folder"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/categories/%E6%8A%80%E8%83%BD-%E4%BF%AE%E8%A1%8C-%E8%BF%9B%E6%AD%A5/">技能-修行-进步</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    
    
        <span class="article-tags article-meta-item">
            <i class="fas fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/tags/%E9%9D%A2%E8%AF%95/">面试</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
        <span class="article-wordcount article-meta-item">
            <i class="fas fa-file-word"></i>&nbsp;<span>8.2k 字</span>
        </span>
    
    
        <span class="article-min2read article-meta-item">
            <i class="fas fa-clock"></i>&nbsp;<span>28 分钟</span>
        </span>
    
    
        <span class="article-pv article-meta-item">
            <i class="fas fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                        </div>
                    </div>
                </div>
            

            <div class="article-content keep-markdown-body">
                

                <ul>
<li>By Manish Saraswat, <a class="link"   target="_blank" rel="noopener" href="https://www.analyticsvidhya.com/blog/2016/09/40-interview-questions-asked-at-startups-in-machine-learning-data-science/" >Original Link<i class="fas fa-external-link-alt"></i></a></li>
<li>09&#x2F;16&#x2F;2016</li>
</ul>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><blockquote>
<p><b><font color="red">留心，这些问题你要三思！</font></b></p>
</blockquote>
<ul>
<li>在今天，机器学习和数据科学家被认为是下一代工业改革的驱动力。这也意味着有很多新进的初创公司在寻找数据科学家。那么，该如何给你振奋人心的职业生涯一个更好的开始呢？</li>
<li>当然，想进入这个行业并不容易。显然你必须要对公司的理念，团队和远景感兴趣。你可能在你的职业之路上遇到一写很棘手的技术问题。本题集和初创公司做的东西有紧密联系。他们会不会提供咨询？他们会不会创建ML产品？你在面试之前就该提前考虑这个问题？</li>
<li>为了帮助你准备下一场面试，我整理了40个看似可信但是其中暗藏端倪的问题，它们都有可能出现在你的面试当中。如果你能够轻松应对并且深刻理解问题，那么请放心，你可以在面试中打一场硬仗。</li>
<li>备注：轻松应对这些问题的核心是你对ML有实际操作经验和了解相关的统计概念。</li>
</ul>
<h2 id="机器学习的面试问题"><a href="#机器学习的面试问题" class="headerlink" title="机器学习的面试问题"></a>机器学习的面试问题</h2><ul>
<li><p><b><font color="blue"> Q1，给你一个1000列，100万行的数据集。这个数据集是一个分类问题。你经理要求你减少这个数据集的维度以减少模型计算所花的时间。你的机器有内存限制。你会怎么做？(你可以做出实际的假设)</font></b></p>
</li>
<li><p><b>答：</b>在一台内存有限的机器上处理高纬度的数据是一个很费力的任务，你的面试官肯定意识到这一点。以下是你可以拿来应对的方法：</p>
<ol>
<li>由于我们的内存有限，我们首先应该关闭所有不需要的程序，包括浏览器，这样我们才能把内存的利用最大化。</li>
<li>我们可以随机对数据集进行抽样。这就意味着我们可以创建一个更小的数据集，假如，1000个变量，30万行的数据集，然后做计算。</li>
<li>要减少维度，我们可以把数值型和分类型的变量分开，然后去掉相关的变量。对于数值型数据，我们利用相关性分析，对于分类型数据，我们利用卡方检验。</li>
<li>另外，我们可以做PCA，然后挑出数据集中能够解释最大方差的变量。</li>
<li>利用在线学习算法，像Vowpal Wabbit (Python提供)，也是一个选择。</li>
<li>利用随机梯度下降来创建一个线性模型也是有帮助的。</li>
<li>我们也可以把数据集的商业理解考虑进去，然后估计哪些predictors能够影响respone variable。但是这是一个凭直觉的方法，如果分析错误就会造成信息的损失。</li>
</ol>
</li>
<li><p><b>备注：</b>对于第4，5点，请务必了解在线算法和随机梯度下降算法。另外还有更高级的算法。</p>
</li>
<li><p><b><font color="blue"> Q2， PCA中的旋转是必须的吗？如果是，那么你没有旋转的话，会发生什么？</font></b></p>
</li>
<li><p><b>答：</b>是的，旋转(正交直线)是必须的，因为它能最大化捕捉到的变量之间的差异。这会使变量更容易解释。不要忘记，这确切是PCA的动机所在，我们的目标是选择更少的components，这些变量能够解释数据集的最大方差。通过旋转，components的相关位置不会改变，她仅仅改变这些点的实际坐标。</p>
</li>
<li><p>如果我们没有进行旋转，PCA的作用就会减少，而我们需要选择更多的components来解释数据集的方差。</p>
</li>
<li><p>了解更多：<a class="link"   target="_blank" rel="noopener" href="https://www.analyticsvidhya.com/blog/2016/03/practical-guide-principal-component-analysis-python/" >PCA<i class="fas fa-external-link-alt"></i></a></p>
</li>
<li><p><b><font color="blue"> Q3，给你一个数据集，这个数据集包含这样的缺失值，它的分布是沿着中位数，标准差是1。那么，有百分之几的数据不受影响？为什么呢？</font></b></p>
</li>
<li><p><b>答：</b>这道题有足够的提示让你思考。由于数据是沿着中位数分布的，我们假设它是一个正态分布。我们知道在一个正态分布中，68%的数据包含在均值(或者众数，中位数)为中心1为标准差的范围内，那么就有32%的数据是不受影响的。所以，32%的数据将会不受缺失值的影响。</p>
</li>
<li><p><b><font color="blue"> Q4，给你一个癌症检测的数据，你建了一个分类模型并且模型的准确率达到了96%。为什么你不能对你模型的表现感到满意？你会怎么做？</font></b></p>
</li>
<li><p><b>答：</b>如果你处理了足够多的数据集，你可以推断癌症检测造成了不平衡的数据。在一个不平衡的数据集中，准确率不应该被当作表现的衡量标准，因为96%仅仅是预测对了大多数的类别，但是我们感兴趣的类别是小部分的4%，它恰恰是被用来用作癌症的诊断。所以，为了评估模型的表现，我们应该利用Sensitivity(True Positive Rate)，Specificity(True Negative Rate)，F measure用来诊断分类器的性能。如果小部分的分类性能是很无力的，我们可以采取一下的措施：</p>
<ol>
<li>我们可以利用欠采样，过采样或者SMOTE(一种采样技术)使得数据平衡。</li>
<li>我们可以通过概率校正来改变预测阈值，然后利用AUC-ROC曲线找到一个最优的阈值。</li>
<li>我们可以给类别赋予权重，让小部分的类别得到更大的权重。</li>
<li>我们可以做异常检测。</li>
</ol>
</li>
<li><p><b>了解更多：</b><a class="link"   target="_blank" rel="noopener" href="https://www.analyticsvidhya.com/blog/2016/03/practical-guide-deal-imbalanced-classification-problems/" >Imbalanced Classification<i class="fas fa-external-link-alt"></i></a></p>
</li>
<li><p><b><font color="blue"> Q5，为什么朴素贝叶斯那么“朴素”？</font></b></p>
</li>
<li><p><b>答：</b>朴素贝叶斯“朴素”是因为它假设了数据集中的特征都是平等重要且相互独立的。我们知道，这些假设在现实生活中存在的几率是很小的。</p>
</li>
<li><p><b><font color="blue"> Q6，解释朴素贝叶斯中的概念：先验概率，似然和边缘似然。</font></b></p>
</li>
<li><p><b>答：</b>先验概率就是数据集中独立(二分类)变量的比重，就是一个最简单的分类。譬如，一个数据集中，独立变量是二分类的(0或者1)。1(垃圾邮件)的比重是70%，0(正常邮件)的比重是30%。所以，我们可以估计新邮件有70%的几率被分作垃圾邮件。</p>
</li>
<li><p>似然就是给定的观测量在其他变量的条件下被分作1的概率。譬如，在之前的垃圾邮件中“FREE”这个词的概率就是似然。边缘似然就是，“FREE”这个词被用在任何信息当中的概率。</p>
</li>
<li><p><b><font color="blue"> Q7，你正在处理一个时间序列的数据集。你经理要求你创建一个高准确率的模型。你一开始就用决策树算法，因为你知道它对任意类型的数据都处理得不错。然后，你试了一个时间序列的回归模型并且得到了更高的准确率。这会发生吗？为什么呢？</font></b></p>
</li>
<li><p><b>答：</b>时间序列数据是受线性限制的。另一方面，我们知道决策树算法是适用于检测非线性的交互。决策树不能很好地提供robust的预测是因为它没有像线性模型那样能很好地map到数据的线性关系。所以，我们知道，线性回归模型可以对给定的线性数据提供更robust的预测。</p>
</li>
<li><p><b><font color="blue"> Q8，你被分配了一个新的project，这个project是帮助某公司的食物派送减低成本的。问题是：公司的派送团队没能及时地派送食物，结果，顾客就不开心。然后为了让驳回顾客的芳心，公司最后决定免派送费。你认为哪一个机器学习方法能够拯救他们呢？</font></b></p>
</li>
<li><p><b>答：</b>你可能很快的在脑海中扫描了一遍机器学习算法。但是，请放松一下，这个问题考的是你的机器学习的基础。</p>
</li>
<li><p>这不是一个机器学习的问题。这是一个路径优化的问题。一个机器学习的算法包括三个基本要素：</p>
<ol>
<li>问题中存在一个模式</li>
<li>你不能通过数学计算来解决它(即使是写指数方程)</li>
<li>你要有数据</li>
</ol>
</li>
<li><p>我们通常找出这三个要素来决定是否能把机器学习当成一个解决实际问题的工具。</p>
</li>
<li><p><b><font color="blue"> Q9，你发现你的模型出现了低偏差高方差的问题，你应该怎么解决？为什么呢？</font></b></p>
</li>
<li><p><b>答：</b>低偏差说明模型的预测值非常接近真实值。换句话说，这个模型能够很灵活地模仿到训练数据分布。看似这是很成功，但是不要忘记，一个灵活的模型往往没有泛化能力。这意味着，当模型对新数据进行预测时，它可能会给出很差的结果。</p>
</li>
<li><p>这样的话，我们可以利用bagging算法(譬如随机森林)来解决高方差的问题。Bagging算法通过重复的随机采样把数据集分成很多个子集。然后，用这些样本来做不同的算法得到一个模型的集合。之后，最终的预测是对模型集中的模型进行不同的组合，分类的话就用投票的方式，回归的话就用求均值的方式。</p>
</li>
<li><p>另外，为了防止高方差，我们可以：</p>
<ol>
<li>利用正则化技术，对模型的高系数进行惩罚，从而降低模型的复杂度</li>
<li>对特征的重要性进行排序然后利用前n个。因为，如果全部的特征都用上，算法可能没办法很好地找到有意义的信号。</li>
</ol>
</li>
<li><p><b><font color="blue"> Q10，给你一个数据集，它包含了很多变量，但是你已经知道其中的一些有很高的关联性变量了。你的经理要求你利用PCA进行处理。你会先把有关联性的变量删掉吗？为什么呢？</font></b></p>
</li>
<li><p><b>答：</b>可能你会说NO，但是这是不对的。抛开有关联性的数据对PCA有实质的影响不说，如果没有删掉有关联性的变量，那么一个特定的成分的方差就会膨胀。</p>
</li>
<li><p>譬如，你有3个变量的数据集，其中2个是有关联性的。如果你对数据进行PCA处理，那么第一个主要的成分就会展示2倍的方差，比没有关联性变量存在的时候。另外，添加有关联性的变量会使得PCA把更多的重要性给以它们，这恰恰是误导的。</p>
</li>
<li><p><b><font color="blue"> Q11，运行了几个小时之后，你很焦急想要创建一个准确率高的模型。结果，你建了一个5GB的模型集合，考虑到一个boosting算法会产生奇迹。但是，很不幸的，没有一个模型的表现能比基准分(benchmark score)更好。最后，你决定组合这些模型。我们都知道ensemble模型都会得到很高的准确率，但是你的却没有。请问到底是哪里出了问题呢？</font></b></p>
</li>
<li><p><b>答：</b>总所周知，ensemble learners的核心思想是通过组合简单的弱模型来得到一个强模型。但是当模型之间是独立的时候，组合出来的模型才会表现得很好。所以，我们建立了5GB的模型集合，但是准确率却没有提升，这就暗示着模型之间是有关联性的。有关联性的模型的问题是它们都提供了相同的信息。</p>
</li>
<li><p>譬如，如果模型1，2，3都是关联的，那么当模型1把User122分类为1时，模型2和模型3也会得到同样的分类结果，即使它的真实值是0。所以，ensemble learners是建立在没有关联性的弱模型集合的基础上，这样的组合才能得到更好的predictions。</p>
</li>
<li><p><b><font color="blue"> Q12，kNN和kmeans聚类有什么不同？</font></b></p>
</li>
<li><p><b>答：</b>不要给名字中的k误导了。你应该知道这两个算法之间最基本的不同是：kmeans是一个无监督学习方法而kNN是一个有监督的学习方法。kNN是一个分类(或者回归)的方法。</p>
</li>
<li><p>kmeans算法是对一个数据集进行划分以至于组成有同质性族群，其中的点与点之间的距离是相近的。这个算法尽量保持这些族群之间的可划分性。而无监督的学习方法中的族群是没有标签的。</p>
</li>
<li><p>kNN算法试着对没有标签的数据按临近的距离进行k(k可以是任何小于sample的数)分类。它又被称作懒惰学习方法因为它涉及到模型的最小训练集。所以，它不会用训练数据对新的数据进行泛化。</p>
</li>
<li><p><b><font color="blue"> Q13，True Positive Rate和Recall是什么关系？写出公式。</font></b></p>
</li>
<li><p><b>答：</b>True Positive Rate &#x3D; Recall。是的，它们有相同的公式(TP&#x2F;(TP+FN))。</p>
</li>
<li><p><b>了解更多：</b><a class="link"   target="_blank" rel="noopener" href="https://www.analyticsvidhya.com/blog/2016/02/7-important-model-evaluation-error-metrics/" >Evaluation Metrics<i class="fas fa-external-link-alt"></i></a></p>
</li>
<li><p><b><font color="blue"> Q14，你建立了一个多重回归模型。模型的R方并没有你预期的那么好。为了改进，你去掉了截距，模型的R方由原来的0.3升到了0.8。请问这是可能的吗？是如何做到的？</font></b></p>
</li>
<li><p><b>答：</b>是的，是有可能的。我们需要理解截距在回归模型中的重要性。截距说明模型的预测是没有任何的独立变量的，如预测的均值。公式：R² &#x3D; 1 – ∑(y – y´)²&#x2F;∑(y – ymean)²，其中y´ 是预测值。</p>
</li>
<li><p>当截距存在的时候，R方值把模型的wrt评估到均值模型当中。当截距不存在的时候，模型就不会这样做。巨大的分母∑(y - y´)²&#x2F;∑(y)²就把等式的值变得比实际的要小，然后造成了高的R方。</p>
</li>
<li><p><b><font color="blue"> Q15，分析了模型之后，你的经理得知你的模型有多重共线性。你会怎么验证模型？没有信息的流失，你可以建立一个更好的模型吗？</font></b></p>
</li>
<li><p><b>答：</b>要检查多重共线性，我们可以创建一个相关系数矩阵来辨识或者删除相关系数达到75%的变量(这个阈值的设置是主观的)。另外，我们可以计算方差膨胀因子(Variance Inflation Factor)来检查多重共线性。 VIF的值&lt;&#x3D;4意味着没有多重共线性，VIF的值&gt;&#x3D;10预示着有严重的多重共线性。最后，我们还可以利用公差来判断多重共线性的出现与否。</p>
</li>
<li><p>但是删除相关变量可能导致信息流失。为了保持变量，我们可以用惩罚性回归模型，像lasso回归或者ridge回归。还有，我们可以加入一些随机噪声变量到相关变量当中，这样变量间就会变得不同。但是，加入噪声可能影响预测准确率。所以，这个方法也要小心使用。</p>
</li>
<li><p><b>了解更多：</b><a class="link"   target="_blank" rel="noopener" href="https://www.analyticsvidhya.com/blog/2016/07/deeper-regression-analysis-assumptions-plots-solutions/" >Regression<i class="fas fa-external-link-alt"></i></a></p>
</li>
<li><p><b><font color="blue"> Q16，什么时候Ridge回归比Lasso回归更好用？</font></b></p>
</li>
<li><p><b>答：</b>你可以引用ISLR这本书的作者Hastie Tibshirani的话，他说：In presence of few variables with medium&#x2F; large sized effect, use lasso regression. In presence of many variables with small&#x2F; medium size effect, use ridge regression.</p>
</li>
<li><p>理论上说，lasso回归(L1)既做了变量选择也做了参数的收缩，而Ridge回归(L2)只是做了参数的收缩，最后把所有的系数都会算进了模型中。当存在相关变量时，ridge回归回事更好的选择。而且，ridge回归在最小二乘因子有比较高的方差时表现最好。所以，她取决于模型的客观性。</p>
</li>
<li><p><b>了解更多：</b><a class="link"   target="_blank" rel="noopener" href="https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-ridge-lasso-regression-python/" >Ridge and Lasso Regression<i class="fas fa-external-link-alt"></i></a></p>
</li>
<li><p><b><font color="blue"> Q17，全球平均气温的提升导致了海盗数量的减少。那么我们可以说海盗数量的减少造成了全球气温的变化吗？</font></b></p>
</li>
<li><p><b>答：</b>读完题目后，你应该这就是典型的“因果与相关”的问题。不，我们不能得出海盗数量的减少造成了气温的改变，因为可能是其他因素(潜伏或者混淆的变量)影响着气候。</p>
</li>
<li><p>所以，或许全球平均气温和海盗数量有一定的关系，但是基于这样的信息我们不能说海盗减少是因为全球平均气温的升高。</p>
</li>
<li><p><b>了解更多：</b><a class="link"   target="_blank" rel="noopener" href="https://www.analyticsvidhya.com/blog/2015/06/establish-causality-events/" >Causation and Correlation<i class="fas fa-external-link-alt"></i></a></p>
</li>
<li><p><b><font color="blue"> Q18，在处理数据的时候，如何选择重要的变量？请解释你的方法。</font></b></p>
</li>
<li><p><b>答：</b>以下是一些常用的变量选择方法：</p>
<ol>
<li>在选择重要变量之前，先把有相关性的变量删掉</li>
<li>利用线性回归基于P值选择变量</li>
<li>利用前向选择，后向选择和逐步选择法</li>
<li>利用随机森林，Xgboost或者对变量的重要性列表</li>
<li>利用Lasso回归</li>
<li>对所有变量做信息增益，然后选择前n个特征</li>
</ol>
</li>
<li><p><b><font color="blue"> Q19，相关性系数和方差有什么不同？</font></b></p>
</li>
<li><p><b>答：</b>相关性系数是协方差的标准形式。</p>
</li>
<li><p>协方差不容易进行比较。譬如，如果我们计算了工资和年龄的协方差，我们不能把他们进行比较，因为他们之间的scales不一样。为了解决这个情况，我们计算相关性系数，得到一个在-1和1之间的数值，就不用考虑它们之间不同的scales了。</p>
</li>
<li><p><b><font color="blue"> Q20，有没有可能求连续变量和分类变量之间的相关性系数吗？如果可以，怎么做？</font></b></p>
</li>
<li><p><b>答：</b>是的，我们可以利用ANCOVA(协方差分析)技术来获得连续性和分类变量之间的相关性系数。</p>
</li>
<li><p><b><font color="blue"> Q21，同样是基于树的算法，随机森林和梯度提升算法(GBM)之间有什么不同？</font></b></p>
</li>
<li><p><b>答：</b>最基本的不同是，随机森林利用bagging技术来做预测，GBM是用boosting技术来做预测。</p>
</li>
<li><p>在bagging技术当中，一个额数据集被随机抽样法分成了n个样本。之后利用单个学习方法对所有的样本进行建模。之后，最终的预测结果是通过对多个模型的预测值进行投票或者求均值的方法得到的。bagging是并行化的。在boosting当中，在第一轮的模型进行预测之后，这个算法就会把误分类模型的权值加大，这样就可以在随后的建模过程中对模型进行修正。这种顺序性的过程直到最后的预测值满足停止标准值为止。</p>
</li>
<li><p>随机森林通过减低方差改善了模型的准确率。树的生长和最大化方差的降幅没有关系。另外，GBM同时减低了bias和方差来改善模型的准确率。</p>
</li>
<li><p><b>了解更多：</b><a class="link"   target="_blank" rel="noopener" href="https://www.analyticsvidhya.com/blog/2016/04/complete-tutorial-tree-based-modeling-scratch-in-python/" >Tree based modeling<i class="fas fa-external-link-alt"></i></a></p>
</li>
<li><p><b><font color="blue"> Q22，运行一个二分类树算法并不难。那你知道树是如何分割的吗？譬如，树是如何决定哪一个结点作为根节点，哪一个结点作为后继节点的吗？</font></b></p>
</li>
<li><p><b>答：</b>一个分类树的生成是基于基尼系数和结点的熵。简单的说，树算法会找到最适合把数据集划分成子节点的变量。</p>
</li>
<li><p>基尼系数是说，如果我们随机选择了两个群体，那么它们必须是属于同一类的，然后概率和为1。我们可以这样来计算基尼系数：</p>
<ol>
<li>计算子节点的基尼系数，用概率的成功和失败的平方和公式： (p^2+q^2)。</li>
<li>利用每个分割节点的权重基尼得分计算它们的基尼系数</li>
</ol>
</li>
<li><p>熵是衡量混乱程度的标准，即是否更适合分割：</p>
</li>
<li><p>这里的p和q分别代表节点成功和失败的概率。熵是0当一个节点是同质的时候。它最大的时候是当一个节点的两个分类各占50%。我们要求小的熵。</p>
</li>
<li><p><b><font color="blue"> Q23，你利用1000棵树建立了一个随机森林。你非常高兴因为你得到了训练错误率是0。但是，验证错误率是34.23。发生了什么事了？你训练的模型完美吗？</font></b></p>
</li>
<li><p><b>答：</b>这个模型是过拟合了。训练错误率是0意味着分类器在某程度上很好的拟合了你的训练数据，但是它对未知数据的预测性很差。所以，当我们用这个分类器来预测新数据时，它找不到新数据的模式并且返回了很高的错误率。在随机森林中，当我们用了超过了我们所需要的树时就会发生这种情况。所以，为了避免这种问题，我们就要用交叉验证来调节树的数量。</p>
</li>
<li><p><b><font color="blue"> Q24，你得到了一个数据集，他的变量数p&gt;样本数n。为什么OLS是一个不好的方法？你应该用什么技术来解决，为什么呢？</font></b></p>
</li>
<li><p><b>答：</b>在如此高纬度的数据集中，我们不可以利用经典的回归技术，因为假设都会失败。当p&gt;n时，我们不能计算一个最小二乘系数了，变量是非常大的时候，OSL就不可行了。</p>
</li>
<li><p>为了解决这种情况，我们可以利用惩罚性回归方法，像lasso，LARS，ridge这些能够收缩系数的方法来减少变量。更准确的说，ridge回归表现最好，当最小二乘因子有高方差的时候。</p>
</li>
<li><p>其它的方法还有取子集回归，前向逐步回归。</p>
</li>
<li><p><b><font color="blue"> Q25，什么是凸多边形(convex hull)？(思考一下SVM)</font></b></p>
</li>
<li><p><b>答：</b>在可分割的数据中，convex hull就是两组数据点的边界部分。一旦convex hull创建了，我们就可以得到最大边界超平面(MMH)，它是两个convex hulls之间的垂直平分线。MMH是一条能最大化的分割两组数据的直线。</p>
</li>
<li><p><b><font color="blue"> Q26，我们知道一位热编码会增加数据集的维度。但是，标签编码却不会，为什么呢？</font></b></p>
</li>
<li><p><b>答：</b>不要给这个问题给搞混了。它只是问你两个编码之间的差别。</p>
</li>
<li><p>利用一位热编码，数据集的维度(变量)就会增加因为它为分类变量的每一个level表现创建了一个新的变量。譬如，一个变量叫“颜色”。这个变量有3个level，红，蓝和绿。一位热编码就会产生3个新的变量<b>Color.Red, Color.Blue, Color.Green</b>，然后它们的值包含0和1。</p>
</li>
<li><p>在类标签编码中，分类变量被编成0和1，所以没有产生新的变量。类标签编码通常用在二分类变量当中。</p>
</li>
<li><p><b><font color="blue"> Q27，在时间序列的数据集中，你会用哪一种交叉验证方法，k折叠还是留一验证？</font></b></p>
</li>
<li><p><b>答：</b>都不是。</p>
</li>
<li><p>在时间序列问题中，k折叠会产生问题，因为可能有些模式在第4年和第5年中，但是没有在第3年中。重采样会分离这些，然后我们可以用去年来做验证，这是不对的。但是我们可以用5-fold的正向推理策略：</p>
<ul>
<li>fold 1: training [1], test[2]</li>
<li>fold 2: training[1,2], test[3]</li>
<li>fold 3: training[1,2,3], test[4]</li>
<li>fold 4: training[1,2,3,4], test[5]</li>
<li>fold 5: training[1,2,3,4,5], test[6]</li>
</ul>
</li>
<li><p>1,2,3,4,5,6代表年。</p>
</li>
<li><p><b><font color="blue"> Q28，给你一个数据集，但是它包含了缺失值的变量，且缺失值占了超过30%，譬如，50个变量，有8个变量的缺失值超过了30%。你会怎么处理？</font></b></p>
</li>
<li><p><b>答：</b>我们可以做以下处理：</p>
<ol>
<li>给缺失值赋一个唯一分类值，谁知道缺失值会不会破译一些趋势呢</li>
<li>我们可以直接删掉它们</li>
<li>或者，我们可以根据目标变量检查它们的分布，如果我们能找到模式，那么我们就赋于缺失值一个新的分类，否则就删掉它们。</li>
</ol>
</li>
<li><p><b><font color="blue"> Q29，亚马逊上的“浏览此商品的顾客也同时浏览。。。”这个推荐系统是什么算法的结果？</font></b></p>
</li>
<li><p><b>答：</b>推荐系统的核心思想是协同过滤。</p>
</li>
<li><p>协同过滤算法是通过用户行为来推荐物品。它是通过物品的交易记录，评价，选择以及购买信息来挖掘其他用户的行为。其他用户对物品的行为和爱好被用来当作给新用户推荐的依据。这个例子中，物品的特征是不知道的。</p>
</li>
<li><p><b>了解更多：</b><a class="link"   target="_blank" rel="noopener" href="https://www.analyticsvidhya.com/blog/2015/10/recommendation-engines/" >Recommender System<i class="fas fa-external-link-alt"></i></a></p>
</li>
<li><p><b><font color="blue"> Q30，你怎么理解Type one and Type two error ?</font></b></p>
</li>
<li><p><b>答：</b>Type I error 是指统计学中的一类错误，意思是本来是错误的结论却被接受了。TypeII error 是指统计学中的二类错误，也就是本来是正确的错误却被拒绝了。简而言之，就是存伪和弃真。</p>
</li>
<li><p>在混淆矩阵当中，我们可以说Type I error就是当我们把实际的0预测分类为1，Type II error就是当我们把实际的1预测分类为0.</p>
</li>
<li><p><b><font color="blue"> Q31，你正在做一个分类的问题。为了达到验证的目标，你随机的从训练集抽样分为训练集和验证集。你对你的模型的泛化能力很有信心因为它的验证错误率非常高。但是，结果却是十分失望，你的测试准确率很低。到底是怎么了？</font></b></p>
</li>
<li><p><b>答：</b>在分类问题当中，我们应该常常用分层抽样而不是随机抽样。因为随机抽样并没有考虑到目标类别的比例。相反，分层抽样就会保证目标变量的分布也会保证样本的分布。</p>
</li>
<li><p><b><font color="blue"> Q32，你被要求利用R², adjusted R² 和tolerance来对回归模型进行评价。你会用哪一个作为标准？</font></b></p>
</li>
<li><p><b>答：</b>Tolerance(1 &#x2F; VIF)是用作多重共线性的预示。它是衡量一个预测中的变量的百分比不能给另一个预测占据的程度。Tolerance越大越好。</p>
</li>
<li><p>我们认为adjusted R² 和R² 来评估模型是截然不同的，因为当我们增加变量的时候，无论预测准确率有没有改进，R²都会增加 。但是adjusted R²仅仅是在增加变量而提高了模型的准确率的时候才会增加。很难去确定adjusted R²的通常值，因为它会随着数据的不同而不同。譬如，基因变异数据集中，低的adjusted R²值的模型依然会有比较不错的预测能力，但是对比于股票数据，低的adjusted R²值就会得到不好的模型。</p>
</li>
<li><p><b><font color="blue"> Q33，在k-means或者kNN中，我们计算相近点之间的距离是用欧几里得距离，为什么我们不用曼哈顿距离呢？</font></b></p>
</li>
<li><p><b>答：</b>我们不用曼哈顿距离是因为它真能垂直计算或者平行计算距离，它有维度限制。另外，欧几里得距离是用在任意空间当中计算的。因为，数据是可以表示在任何的维度空间当中的，所以欧几里得距离是更好的选择。</p>
</li>
<li><p>譬如，在一个棋盘上，象和车的移动就是通过曼哈顿距离来计算的，因为他们只能垂直做或者平行的移动。</p>
</li>
<li><p><b><font color="blue"> Q34，像一个5岁的孩子来介绍一下机器学习。</font></b></p>
</li>
<li><p><b>答：</b>非常简单。就像宝宝学走路一样。每一次的跌倒，他们都会无意识地学习并且意识到他们下一次就应该挺直的走而不是弯下来走。当下一次他们跌倒，他们会感到疼，他们会哭，但是，他们就不会再那样走了。为了避免疼痛，他们会更努力尝试。为了成功，他们会借助门后或者墙的力量或者任何接近他们的东西，这样他们就会站的更稳。</p>
</li>
<li><p>这是机器如何从它的周围环境学习和发展直觉的过程。</p>
</li>
<li><p>注：这道面试题就是考你能不能很好把复杂的文件简单化解释一下。</p>
</li>
<li><p><b><font color="blue"> Q35，我知道一个线性回归通常是用adjusted R²或者F值来评估的。那你如何评估一个罗吉斯特回归模型呢？</font></b></p>
</li>
<li><p><b>答：</b>我们可以用以下方法：</p>
<ol>
<li>因为逻辑斯特回归是用来预测概率的，我们可以用混淆矩阵的AUC-ROC曲线来评估它的性能。</li>
<li>另外，逻辑斯特回归当中类似adjusted R²的评估标准是AIC。AIC是通过模型系数的数量来惩罚模型的拟合标准。所以，我们要的是有最小AIC值的模型。</li>
<li>空异常(Null Deviance)说明模型仅仅通过截距来预测。数值越小，模型越好。残差(Residual deviance)说明模型添加了独立变量来进行预测的。数值越小，模型越好。</li>
</ol>
</li>
<li><p><b>了解更多：</b><a class="link"   target="_blank" rel="noopener" href="https://www.analyticsvidhya.com/blog/2015/11/beginners-guide-on-logistic-regression-in-r/" >Logistic Regression<i class="fas fa-external-link-alt"></i></a></p>
</li>
<li><p><b><font color="blue"> Q36，有那么多的机器学习方法，给你一个数据集，你会决定用什么方法呢？</font></b></p>
</li>
<li><p><b>答：</b>你应该说，选择用哪一种机器学习方法取决于数据的类型。如果给你的数据集是一个线性的，那么线性回归算法最适合。如果你处理的是图像，语音数据，那么神经网络可以建一个更稳固的模型。</p>
</li>
<li><p>如果数据包含一些非线性的关系，那么boosting或者bagging算法就是一个选择。如果商业需求是建一个能够发布的模型，那么我们会用回归或者决策树模型(容易解释)而不是一些黑箱的方法，像SVM，GBM等等。</p>
</li>
<li><p>简单来说，没有绝对的方法，我们应该要认真的理解我们要用的算法。</p>
</li>
<li><p><b><font color="blue"> Q37，你认为把分类变量当成连续的变量来处理，会使得预测模型更好吗？</font></b></p>
</li>
<li><p><b>答：</b>为了得到更准确的预测，分类变量只有在它是有序的时候才被当成连续的变量，这样才合理。</p>
</li>
<li><p><b><font color="blue"> Q38，在机器学习当中，什么时候用到规则化技术(regularization)？</font></b></p>
</li>
<li><p><b>答：</b>当模型变得过拟合或者欠拟合时，规则化(Regularization)变得越来越重要了。这个技术在很多特征的模型中加入了一个惩罚项。所以，它试着把很多的变量的系数变成0以至于减少成本。这样可以帮助降低模型的复杂度从而可以提高模型的泛化能力。</p>
</li>
<li><p><b><font color="blue"> Q39，你怎么理解bias variance权衡？</font></b></p>
</li>
<li><p><b>答：</b>当模型能在数学上表示成3个成分的时候，这个错误就会出现。以下就是这些成分：</p>
</li>
<li><p>偏差错误是将预测的均值和真实值的差异程度量化了。一个高的偏差错误意味着我们得到的是一个欠拟合模型，它总是偏离了真实的趋势。而方差则是模型预测值和真实值的分散程度。高方差说明模型在训练数据上过拟合了，然后在新数据上预测很差。</p>
</li>
<li><p><b><font color="blue"> Q40，OLS(最小二乘法)对应线性回归，最大似然对应逻辑斯特回归。请解释这句话。</font></b></p>
</li>
<li><p><b>答：</b>简单来说，最小二乘法和最大似然都是对回归方法进行未知参数的预估的方法。</p>
</li>
<li><p>最小二乘法(Ordinary least square)用在线性回归中估计参数，目的是要真实值和预测值之间的距离最小。最大似然是帮助选择一个参数值，使得模型能够最大化产生观测数据。</p>
</li>
</ul>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><ul>
<li>你可能很轻松地回答了所有问题，但是我们的目标是要理解它们并且可以举一反三，理解透相关的问题。如果你没能很好应对这些问题，也不用担心，从现在开始学习，从现在开始关注学习的问题。</li>
<li>这些问题是为大家提供了初创公司的面试问题的概况。我相信这些问题引起了你深入学习机器学习的欲望，现在开始计划吧。</li>
</ul>

            </div>

            
                <div class="post-copyright-info">
                    
<div class="article-copyright-info-container">
    <ul class="copyright-info-content">
        <li class="post-title">
            <span class="type">本文标题</span>：<span class="content">40 道ML/Data Science的初创公司(可能)的面试题</span>
        </li>
        <li class="post-author">
            <span class="type">本文作者</span>：<span class="content">Tim Chen(motion$)</span>
        </li>
        <li class="post-time">
            <span class="type">创建时间</span>：<span class="content">2016-10-03 16:19:38</span>
        </li>
        <li class="post-link">
            <span class="type">本文链接</span>：<span class="content">2016/10/03/ML/40/</span>
        </li>
        <li class="post-license">
            <span class="type">版权声明</span>：<span class="content">本博客所有文章除特别声明外，均采用 <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">BY-NC-SA</a> 许可协议。转载请注明出处！</span>
        </li>
    </ul>
    <div class="copy-copyright-info flex-center tooltip" data-content="复制版权信息" data-offset-y="-2px">
        <i class="fa-solid fa-copy"></i>
    </div>
</div>

                </div>
            

            
                <ul class="post-tags-box">
                    
                        <li class="tag-item">
                            <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">#机器学习</a>&nbsp;
                        </li>
                    
                        <li class="tag-item">
                            <a href="/tags/%E9%9D%A2%E8%AF%95/">#面试</a>&nbsp;
                        </li>
                    
                </ul>
            

            
                <div class="article-nav">
                    
                        <div class="article-prev">
                            <a class="prev"
                               rel="prev"
                               href="/2017/02/15/%E6%8A%80%E8%83%BD-%E4%BF%AE%E8%A1%8C-%E8%BF%9B%E6%AD%A5-R%E8%AF%AD%E8%A8%80/KNN-example01-breast-cancer-predict/"
                            >
                            <span class="left arrow-icon flex-center">
                              <i class="fas fa-chevron-left"></i>
                            </span>
                                <span class="title flex-center">
                                <span class="post-nav-title-item">KNN Example 01 To predict the cancer of breast cancer</span>
                                <span class="post-nav-item">上一篇</span>
                            </span>
                            </a>
                        </div>
                    
                    
                        <div class="article-next">
                            <a class="next"
                               rel="next"
                               href="/2015/12/30/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%E7%B3%BB%E5%88%97/%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB-%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%E5%8D%9A%E5%AE%A2%E7%B3%BB%E5%88%97-%E8%BF%9E%E8%BD%BD/"
                            >
                            <span class="title flex-center">
                                <span class="post-nav-title-item">基于SVM技术的手写数字识别-毕业设计博客系列-连载</span>
                                <span class="post-nav-item">下一篇</span>
                            </span>
                                <span class="right arrow-icon flex-center">
                              <i class="fas fa-chevron-right"></i>
                            </span>
                            </a>
                        </div>
                    
                </div>
            

            
                <div class="comment-container">
                    
<div class="comments-container">
    <div id="comments-anchor"></div>
    <div class="comment-area-title">
        <i class="fas fa-comments"></i>&nbsp;评论
    </div>
    
        
            

    <div class="gitalk-comment-container">
        <div id="gitalk-container"></div>
        <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk/dist/gitalk.css">
        <script data-pjax src="//cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.js"></script>
        <script data-pjax>
          function loadGitalk() {
            let __gitalk__pathname = decodeURI(location.pathname);
            const __gitalk__pathnameLength = __gitalk__pathname.length;
            const __gitalk__pathnameMaxLength = 50;
            if (__gitalk__pathnameLength > __gitalk__pathnameMaxLength) {
              __gitalk__pathname = __gitalk__pathname.substring(0, __gitalk__pathnameMaxLength - 3) + '...';
            }

            try {
              Gitalk && new Gitalk({
                clientID: '9e91691916561f410b89',
                clientSecret: 'b1f7e5e85cbcc4197d669d0731ef300bc7630dc7',
                repo: 'gittalk-comment',
                owner: 'chenyuqing',
                admin: 'chenyuqing',
                id: __gitalk__pathname,
                proxy: '',
                language: 'zh-CN'
              }).render('gitalk-container');
            } catch (e) {
              window.Gitalk = null;
            }
          }

          if ('true' === 'true') {
            const loadGitalkTimeout = setTimeout(() => {
              loadGitalk();
              clearTimeout(loadGitalkTimeout);
            }, 1000);
          } else {
            window.addEventListener('DOMContentLoaded', loadGitalk);
          }
        </script>
    </div>



        
    
</div>

                </div>
            
        </div>

        
            <div class="toc-content-container">
                <div class="post-toc-wrap">
    <div class="post-toc">
        <ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction"><span class="nav-number">1.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98"><span class="nav-number">2.</span> <span class="nav-text">机器学习的面试问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%90%8E%E8%AE%B0"><span class="nav-number">3.</span> <span class="nav-text">后记</span></a></li></ol>
    </div>
</div>

            </div>
        
    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom">
            
<footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
                <span>2012</span> -
            
            2024
            
                &nbsp;<i class="fas fa-heart icon-animate"></i>
                &nbsp;<a href="/">Tim Chen(motion$)</a>
            
        </div>
        
            <script async data-pjax
                    src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    访问人数&nbsp;<span id="busuanzi_value_site_uv"></span>&ensp;
                
                
                    总访问量&nbsp;<span id="busuanzi_value_site_pv"></span>
                
            </div>
        
        <div class="theme-info info-item">
            由 <a target="_blank" href="https://hexo.io">Hexo</a> 驱动&nbsp;|&nbsp;主题&nbsp;<a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.6.1</a>
        </div>
        
        
            <div class="deploy-info info-item">
                
                    <a target="_blank" rel="nofollow" href="https://github.com/chenyuqing/chenyuqing.github.io">
                
                    本站由 <span class="tooltip" data-content="GitHub Pages"><img src="/images/deploy-provider/github.png"></span> 提供部署服务
                
                    </a>
                
            </div>
        
    </div>
</footer>

        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="tools-list">
        <!-- TOC aside toggle -->
        
            <li class="tools-item flex-center toggle-show-toc">
                <i class="fas fa-list"></i>
            </li>
        

        <!-- go comment -->
        
            <li class="tools-item flex-center go-to-comments">
                <i class="fas fa-comment"></i>
                <span class="post-comments-count"></span>
            </li>
        
    </ul>
</div>

        </div>
    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        

        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="fas fa-arrow-up"></i>
            </li>
        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
    </ul>
</div>

    </div>

    <div class="zoom-in-image-mask">
    <img class="zoom-in-image">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="搜索..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="close-popup-btn">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>




<script src="/js/utils.js"></script>

<script src="/js/main.js"></script>

<script src="/js/header-shrink.js"></script>

<script src="/js/back2top.js"></script>

<script src="/js/dark-light-toggle.js"></script>





    
<script src="/js/local-search.js"></script>




    
<script src="/js/code-block.js"></script>





<div class="post-scripts pjax">
    
        
<script src="/js/post-helper.js"></script>

        
            
<script src="/js/libs/anime.min.js"></script>

        
        
            
<script src="/js/toc.js"></script>

        
    
</div>


    
<script src="/js/libs/pjax.min.js"></script>

<script>
    window.addEventListener('DOMContentLoaded', () => {
        window.pjax = new Pjax({
            selectors: [
                'head title',
                '.page-container',
                '.pjax'
            ],
            history: true,
            debug: false,
            cacheBust: false,
            timeout: 0,
            analytics: false,
            currentUrlFullReload: false,
            scrollRestoration: false,
            // scrollTo: true,
        });

        document.addEventListener('pjax:send', () => {
            KEEP.utils.pjaxProgressBarStart();
        });

        document.addEventListener('pjax:complete', () => {
            KEEP.utils.pjaxProgressBarEnd();
            window.pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
            KEEP.refresh();
        });
    });
</script>



</body>
</html>
