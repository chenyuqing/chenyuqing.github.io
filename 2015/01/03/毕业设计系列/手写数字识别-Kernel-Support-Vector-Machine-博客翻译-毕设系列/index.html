<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="Tim Chen(motion$)">
    
    <title>
        
            手写数字识别-Kernel Support Vector Machine-论文翻译-毕设系列 |
        
        In Web3 | Truth &gt; Trust
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="shortcut icon" href="/img/favicon.ico">
    
<link rel="stylesheet" href="/font/css/fontawesome.min.css">

    
<link rel="stylesheet" href="/font/css/regular.min.css">

    
<link rel="stylesheet" href="/font/css/solid.min.css">

    
<link rel="stylesheet" href="/font/css/brands.min.css">

    <script id="hexo-configurations">
    let KEEP = window.KEEP || {}
    KEEP.hexo_config = {"hostname":"example.com","root":"/","language":"zh-CN","path":"search.xml"}
    KEEP.theme_config = {"toc":{"enable":true,"number":true,"expand_all":true,"init_open":true},"style":{"primary_color":"#7bed9f","logo":"/img/favicon.ico","favicon":"/img/favicon.ico","avatar":"/img/favicon.ico","font_size":"16px","font_family":"STKaiti, STHeiti","hover":{"shadow":true,"scale":true},"first_screen":{"enable":true,"header_transparent":false,"background_img":"/img/bg.svg","description":null,"font_color":"#7bed9f","hitokoto":true},"scroll":{"progress_bar":true,"percent":false}},"local_search":{"enable":true,"preload":true},"code_copy":{},"code_block":{"tools":{"enable":true,"style":"mac"},"highlight_theme":"default"},"side_tools":{},"pjax":{"enable":true},"lazyload":{"enable":false},"comment":{"enable":true,"use":"gitalk","valine":{"appid":null,"appkey":null,"server_urls":null,"placeholder":null},"gitalk":{"github_id":"chenyuqing","github_admins":["chenyuqing"],"repository":"gittalk-comment","client_id":"9e91691916561f410b89","client_secret":"b1f7e5e85cbcc4197d669d0731ef300bc7630dc7","proxy":null},"twikoo":{"env_id":null,"region":null,"version":"1.6.8"},"waline":{"server_url":null,"reaction":false,"version":2}},"post":{"author_label":{"enable":true,"auto":true,"custom_label_list":["Trainee","Engineer","Architect"]},"word_count":{"enable":true,"wordcount":true,"min2read":true},"img_align":"left","copyright_info":true},"version":"3.6.1"}
    KEEP.language_ago = {"second":"%s 秒前","minute":"%s 分钟前","hour":"%s 小时前","day":"%s 天前","week":"%s 周前","month":"%s 个月前","year":"%s 年前"}
    KEEP.language_code_block = {"copy":"复制代码","copied":"已复制","fold":"折叠代码块","folded":"已折叠"}
    KEEP.language_copy_copyright = {"copy":"复制版权信息","copied":"已复制","title":"原文标题","author":"原文作者","link":"原文链接"}
  </script>
<meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
</head>


<body>
<div class="progress-bar-container">
    
        <span class="scroll-progress-bar"></span>
    

    
        <span class="pjax-progress-bar"></span>
        <i class="pjax-progress-icon fas fa-circle-notch fa-spin"></i>
    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            
<header class="header-wrapper">

    <div class="header-content">
        <div class="left">
            
                <a class="logo-image" href="/">
                    <img src="/img/favicon.ico">
                </a>
            
            <a class="logo-title" href="/">
               In Web3 | Truth &gt; Trust
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            <a class=""
                               href="/"
                            >
                                首页
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/archives"
                            >
                                归档
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/categories"
                            >
                                分类
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/tags"
                            >
                                标签
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/books"
                            >
                                读书
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/jokes"
                            >
                                段子
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/about"
                            >
                                关于我
                            </a>
                        </li>
                    
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="fas fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/">首页</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/archives">归档</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/categories">分类</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/tags">标签</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/books">读书</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/jokes">段子</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/about">关于我</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="post-page-container">
        <div class="article-content-container">

            <div class="article-title">
                <span class="title-hover-animation">手写数字识别-Kernel Support Vector Machine-论文翻译-毕设系列</span>
            </div>

            
                <div class="article-header">
                    <div class="avatar">
                        <img src="/img/favicon.ico">
                    </div>
                    <div class="info">
                        <div class="author">
                            <span class="name">Tim Chen(motion$)</span>
                            
                                <span class="author-label">Lv5</span>
                            
                        </div>
                        <div class="meta-info">
                            
<div class="article-meta-info">
    <span class="article-date article-meta-item">
        
            <i class="fa-regular fa-calendar-plus"></i>&nbsp;
        
        <span class="pc">2015-01-03 14:29:02</span>
        <span class="mobile">2015-01-03 14:29</span>
    </span>
    
        <span class="article-update-date article-meta-item">
        <i class="fas fa-file-pen"></i>&nbsp;
        <span class="pc">2023-07-16 09:38:41</span>
    </span>
    
    
        <span class="article-categories article-meta-item">
            <i class="fas fa-folder"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/categories/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%E7%B3%BB%E5%88%97/">毕业设计系列</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    
    
        <span class="article-tags article-meta-item">
            <i class="fas fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/tags/%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/">手写数字识别</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/tags/Kernel-Support-Vector-Machine/">Kernel Support Vector Machine</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
        <span class="article-wordcount article-meta-item">
            <i class="fas fa-file-word"></i>&nbsp;<span>4k 字</span>
        </span>
    
    
        <span class="article-min2read article-meta-item">
            <i class="fas fa-clock"></i>&nbsp;<span>15 分钟</span>
        </span>
    
    
        <span class="article-pv article-meta-item">
            <i class="fas fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                        </div>
                    </div>
                </div>
            

            <div class="article-content keep-markdown-body">
                

                <h1 id="写在前面的话"><a href="#写在前面的话" class="headerlink" title="写在前面的话"></a>写在前面的话</h1><ul>
<li>本篇博文是翻译自Code Project上的<a class="link"   target="_blank" rel="noopener" href="http://www.codeproject.com/script/Membership/View.aspx?mid=1841592" >César de Souza<i class="fas fa-external-link-alt"></i></a>教授的关于用Kernel Support Vector Machine手写数字识别的博客。认真学习借鉴一下。</li>
<li>出处：<a class="link"   target="_blank" rel="noopener" href="http://www.codeproject.com/Articles/106583/Handwriting-Recognition-Revisited-Kernel-Support-V" >Handwriting Recognition Revisited: Kernel Support Vector Machines<i class="fas fa-external-link-alt"></i></a></li>
</ul>
<h1 id="博文正文"><a href="#博文正文" class="headerlink" title="博文正文"></a>博文正文</h1><ul>
<li>在上一篇文章中，我们讨论了怎么利用基于核函数的辨别分析(Kernel Discriminant Analysis)的方法来解决手写数字识别的问题。在这里，我们将要讨论如何利用基于核函数的支持向量机(Kernel Support Vector Machine)的一些技巧来解决手写数字的识别问题。</li>
<li><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/download.png"><a class="link"   target="_blank" rel="noopener" href="http://www.codeproject.com/KB/recipes/handwriting-svm/accord-handwritting-svm-src.zip" >Download source code - 584 KB <i class="fas fa-external-link-alt"></i></a></li>
<li><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/download.png"><a class="link"   target="_blank" rel="noopener" href="http://www.codeproject.com/KB/recipes/handwriting-svm/accord-handwritting-svm-bin.zip" >Download sample application - 522 KB<i class="fas fa-external-link-alt"></i></a></li>
<li><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/download.png">Download the <a class="link"   target="_blank" rel="noopener" href="http://accord-framework.net/" >Accord.NET Machine Learning Framework.<i class="fas fa-external-link-alt"></i></a></li>
<li>由于在最新的代码库中，它通常包含了最新的功能增强和修正，所以请下载  最新的<a class="link"   target="_blank" rel="noopener" href="http://accord-framework.net/" >Accord.NET Framework<i class="fas fa-external-link-alt"></i></a>.</li>
<li><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/font.png"></li>
</ul>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><ul>
<li>在上一篇文章中，我想向大家展示怎么用<a class="link"   target="_blank" rel="noopener" href="http://crsouza.blogspot.com/2010/01/kernel-discriminant-analysis-in-c.html" >核判别分析法<i class="fas fa-external-link-alt"></i></a>来解决手写数字识别的问题。但是，我发现自己并没有更多的关注手写数字识别的问题，因为我把焦点都放在了KDA方法上了，而不是识别问题本身。在本篇文章中，我会给大家展示一个更好的方法来解决数字识别的问题。</li>
<li>核判别分析方法有自己的问题集。尽管它在处理高维度的数据是没有任何问题，但当样本的数量达到O(n³)，它就显得有些无能为力了。另外一个更严重的问题是在模型评估过程中核判别分析方法需要载入全部数据集，这样令它很难推广(例如嵌入式系统)。</li>
<li>在上一篇文章的最后，我提到了SVM其实是一种解决数字识别的更好的方法。SVM的一个优点是它们的解决问题的方法比较单一，不像KDA,它们在数据评估的过程中不需要载入全部数据集，而只是需要非常小部分的数据。这部分数据就是我们所通常称的”支持向量”。</li>
</ul>
<h3 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h3><ul>
<li><a class="link"   target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/Support_vector_machine" >支持向量机<i class="fas fa-external-link-alt"></i></a>是属于<a class="link"   target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/Supervised_learning" >监督学习<i class="fas fa-external-link-alt"></i></a>方法中的一种，它既可以用作<a class="link"   target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/Statistical_classification" >分类<i class="fas fa-external-link-alt"></i></a>，也可以用做<a class="link"   target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/Regression_analysis" >回归<i class="fas fa-external-link-alt"></i></a>。简单的说，给定一个训练数据样本，其中的每条记录都有一个标记变量，它标记着本条记录是属于哪一个分类的(现在讨论的是二类分类器)，然后数据集通过SVM分类器进行训练得到一个<a class="link"   target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/Classifier_(mathematics)" >决策模型<i class="fas fa-external-link-alt"></i></a>，这个模型可以预测新进来的一条记录是属于两个分类中的哪一种。如果样本中的每条记录是落在空间上的某个点，那么一个SVM的线性分类器可以看做是空间中的一个分界，把空间分成两类，这样我们希望把样本分成两类的清晰的间隔，它越宽越好。新的样本点看它落在间隔的那一边上就可以预测它属于那一类的了。<br><br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/SVM-1.png"></li>
<li>一个线性SVM是由给定的支持向量<strong>z</strong>集合和权重<strong>w</strong>集合组成。由N个支持向量z1,z2…zN和w1,w2…wN构成的支持向量机输出的计算公式是：<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/SVM-fornular-1.png"></li>
<li>一个决策函数通常把这个作为输入变量，然后转化为一个二类分类器。通常地，我们用sign(.)函数，就是符号函数，输入变量大于0的作为一类，输入变量小于0的作为另外一类。</li>
</ul>
<h3 id="基于核函数的支持向量机"><a href="#基于核函数的支持向量机" class="headerlink" title="基于核函数的支持向量机"></a>基于核函数的支持向量机</h3><ul>
<li>如上所述，原始的SVM的最优化平面是一个<a class="link"   target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/Linear_classifier" >线性分类器<i class="fas fa-external-link-alt"></i></a>。然而，从它在1963年提出的30年后，一些研究者(包括原提出者自己)建议把<a class="link"   target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/Kernel_trick" >核技巧<i class="fas fa-external-link-alt"></i></a>应用到那些最大边界超平面来创建一个非线性分类器。结果引起了研究<a class="link"   target="_blank" rel="noopener" href="http://www.kernel-machines.org/" >“核方法”<i class="fas fa-external-link-alt"></i></a>的一片浪潮，而核方法开始成为一个最有力的而且最受欢迎的分类方法。</li>
<li>不容置疑的是，核技巧是一种非常有力的工具，它提供了一种仅仅依赖于求两个向量的点积的算法来打通了线性和非线性的之间的桥梁。事实上，我们首先把输入数据映射到一个高维空间，然后一个线性的算法就可以在这个空间上操作在原始空间中的非线性的输入数据。</li>
<li>这个“技巧”的厉害之处在于它根本就不用计算映射后的点积；我们所需要做的是找到一个适合的核函数来代替所有的点积(这样便可以简化了计算)。核函数标记特征空间中的一个内积，它通常记为：<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/kernel-function-form.png"><br>(其中Ψ()代表映射函数)。</li>
<li>利用核函数，算法能被带入到高维空间而不需要明确的把输入点映射到这个空间上。这是非常取巧的，特别是当高维的特征空间是无穷多维的，它是不可以计算的时候。正是由于原始的SVM的公式中包含点积运算，它是可以直接应用核技巧的。即使结果分类器在高维特征空间中是个超平面，但在原始空间中它还是非线性的。核技巧的应用同样为不同的视野去进行比较的分类器提供了非常有力的理论支持，例如，生物。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/kernel-transform.png"></li>
<li>可以很明显的看出，通过核函数(of the form K(z,x) &#x3D; &lt;z,x&gt; &#x3D; zTx)，我们又得到了原始线性SVM的相似公式。想了解更详细的关于核技巧的资料和核函数应用的例子，可以参考<a class="link"   target="_blank" rel="noopener" href="http://www.codeproject.com/KB/recipes/handwriting-kda.aspx" >previous article about Kernel Discriminant Analysis<i class="fas fa-external-link-alt"></i></a>，或者<a class="link"   target="_blank" rel="noopener" href="http://crsouza.blogspot.com/2010/03/kernel-functions-for-machine-learning.html" >Kernel Functions for Machine Learning Applications<i class="fas fa-external-link-alt"></i></a>。</li>
</ul>
<h3 id="多分类的支持向量机"><a href="#多分类的支持向量机" class="headerlink" title="多分类的支持向量机"></a>多分类的支持向量机</h3><ul>
<li>很不幸的，不像<a class="link"   target="_blank" rel="noopener" href="http://www.codeproject.com/KB/recipes/handwriting-kda.aspx" >KDA<i class="fas fa-external-link-alt"></i></a>，支持向量机并没有很自然的推广到多分类的问题。原始的SVM是一个<a class="link"   target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/Binary_classification" >二类分类器<i class="fas fa-external-link-alt"></i></a>，它一次只可以在两个分类中进行预测。然而，<a class="link"   target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/Support_vector_machines#Multiclass_SVM" >现实问题需要更多的是可以用SVM解决多分类问题<i class="fas fa-external-link-alt"></i></a>，下面我们就来举一个例子。</li>
<li>假设我们有三个分类A,B,C。现在，假设我们只有二类分类器，那么我们怎么把二类分类器去解决一个多分类器的问题呢？其中一个可行的方法就是把我们的多分类问问题拆成多个二类分类器的集合。下面左边的矩阵是泳衣解决三个分类的分类器的二类分类器的所有组合：<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/binary-conbination.png"></li>
<li>然而，注意到上面左边的矩阵中有一些多余的情况。譬如，计算AxA是没有意义的。还有，计算AxB之后再计算BxA是很低效率的，我们计算了AxB后，可以通过取反就得到了BxA。丢弃了多余的选项后，我们只剩下右边的(半透明的，除了AxA,BxB,CxC)矩阵。观察可知，一个n类的分类问题可以拆分成n(n-1)&#x2F;2个二类分类器的组合组成的小的子集合。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/n-binary.png"></li>
<li>现在我们得到了3个二类分类的问题，所以，我们需要创建3个SVM来解决每一个子问题。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/3-SVM.png"></li>
<li>要确定一个分类，我们就看3个SVM当中谁的投票最多。譬如，A在第一个SVM中胜出，而C在其他的两个SVM中都胜出。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/3-SVM-2.png"></li>
<li>如果我们把胜出次数最多的作为赢家，那么我们应该把它归为C类。这种方法通常称作多分类器中的”一对一”策略。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/table-one-against-one.png"></li>
<li>另外一种方法是利用“一对多”的策略，把输入放到所有的SVM中，然后选择最高的输出的那个SVM。很不幸的，我们不能保证有最高的输出就是最好的SVM。这个不作本文讨论的范畴。</li>
</ul>
<h2 id="源代码"><a href="#源代码" class="headerlink" title="源代码"></a>源代码</h2><ul>
<li>基于核方法的支持向量机的代码也是属于<a class="link"   target="_blank" rel="noopener" href="http://accord-framework.net/" >Accord.NET<i class="fas fa-external-link-alt"></i></a>的一部分，这个框架我做了数年。它是在<a class="link"   target="_blank" rel="noopener" href="http://code.google.com/p/aforge/" >AForge.NET<i class="fas fa-external-link-alt"></i></a>的顶层建立的,<a class="link"   target="_blank" rel="noopener" href="http://code.google.com/p/aforge/" >AForge.NET<i class="fas fa-external-link-alt"></i></a>是计算机视觉，机器学习中非常受欢迎的框架，它集合了我过去的研究中的多个主题。目前，它有了<a class="link"   target="_blank" rel="noopener" href="http://crsouza.blogspot.com/2009/09/principal-component-analysis-in-c.html" >PCA<i class="fas fa-external-link-alt"></i></a>, <a class="link"   target="_blank" rel="noopener" href="http://crsouza.blogspot.com/2010/01/kernel-principal-component-analysis-in.html" >KPCA<i class="fas fa-external-link-alt"></i></a>, <a class="link"   target="_blank" rel="noopener" href="http://crsouza.blogspot.com/2010/01/linear-discriminant-analysis-in-c.html" >LDA<i class="fas fa-external-link-alt"></i></a>, <a class="link"   target="_blank" rel="noopener" href="http://crsouza.blogspot.com/2010/01/kernel-discriminant-analysis-in-c.html" >KDA<i class="fas fa-external-link-alt"></i></a>, <a class="link"   target="_blank" rel="noopener" href="http://crsouza.blogspot.com/2010/02/logistic-regression-in-c.html" >LR<i class="fas fa-external-link-alt"></i></a>, <a class="link"   target="_blank" rel="noopener" href="http://crsouza.blogspot.com/2010/04/partial-least-squares-analysis-and.html" >PLS<i class="fas fa-external-link-alt"></i></a>, <a class="link"   target="_blank" rel="noopener" href="http://crsouza.blogspot.com/2010/04/kernel-support-vector-machines-for.html" >SVMs<i class="fas fa-external-link-alt"></i></a>, <a class="link"   target="_blank" rel="noopener" href="http://www.codeproject.com/Articles/69647/Hidden-Markov-Models-in-Csharp.aspx" >HMMs<i class="fas fa-external-link-alt"></i></a>, <a class="link"   target="_blank" rel="noopener" href="http://www.codeproject.com/Articles/55691/Neural-Network-Learning-by-the-Levenberg-Marquardt.aspx" >LM-ANN<i class="fas fa-external-link-alt"></i></a>和其他的缩写。这个项目在Github上举办，地址是：<a class="link"   target="_blank" rel="noopener" href="https://github.com/accord-net/framework/" >https://github.com/accord-net/framework/<i class="fas fa-external-link-alt"></i></a>。最小的版本中包含了最小的bug修正，完善和功能加强，新特征等，我强烈推荐大家直接从Github上下载最新的版本库。</li>
</ul>
<h3 id="支持向量机-1"><a href="#支持向量机-1" class="headerlink" title="支持向量机"></a>支持向量机</h3><ul>
<li>支持向量机类结构如下：(C#和VB实现)<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/svm-class-structure.png"></li>
<li><a class="link"   target="_blank" rel="noopener" href="http://accord-framework.net/docs/html/T_Accord_MachineLearning_VectorMachines_KernelSupportVectorMachine.htm" >KernelSupportVectorMachine<i class="fas fa-external-link-alt"></i></a>类继承SupportVectorMachine类，加了kernel方法。MulticlassSupportVectorMachine类集合了一堆实现了“一对一”策略的KernelSupportVectorMachines类来实现多分类器。框架的API在此：<a class="link"   target="_blank" rel="noopener" href="http://accord-framework.net/docs/html/N_Accord_Statistics_Kernels.htm" >extensive list of machine learning kernel functions to chose from<i class="fas fa-external-link-alt"></i></a>.</li>
</ul>
<h3 id="训练算法"><a href="#训练算法" class="headerlink" title="训练算法"></a>训练算法</h3><ul>
<li>训练算法既可以实现分类也可以实现回归。它们是<a class="link"   target="_blank" rel="noopener" href="http://research.microsoft.com/apps/pubs/default.aspx?id=69644" >Platt的序列最优化(SMO)算法<i class="fas fa-external-link-alt"></i></a>的直接实现。MulticlassSupportVectorLearning类提供了一个回调函数，名字是Configure，它可以被任何的算法选择并进行配置。这个方法并没有强加需要利用哪一种算法，而且还允许用户利用自定义的算法来进行训练。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/svm-class-structure-2.png"></li>
<li>因为MulticlassSupportVectorLearning算法一次可以训练一堆独立的机器，所以它容易实现并行运算。事实上，这些实现方法在单台机器中可以充分利用剩下的核。<figure class="highlight c#"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"><span class="doctag">///</span> <span class="doctag">&lt;summary&gt;</span></span></span><br><span class="line"><span class="comment"><span class="doctag">///</span>   Runs the one-against-one learning algorithm.</span></span><br><span class="line"><span class="comment"><span class="doctag">///</span> <span class="doctag">&lt;/summary&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="built_in">double</span> <span class="title">Run</span>(<span class="params"><span class="built_in">bool</span> computeError</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">// For each class i</span></span><br><span class="line">    AForge.Parallel.For(<span class="number">0</span>, msvm.Classes, <span class="built_in">delegate</span>(<span class="built_in">int</span> i)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// For each class j</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="built_in">int</span> j = <span class="number">0</span>; j &lt; i; j++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// Retrieve the associated machine</span></span><br><span class="line">            <span class="keyword">var</span> machine = msvm[i,j];</span><br><span class="line"></span><br><span class="line">            <span class="comment">// Retrieve the associated classes</span></span><br><span class="line">            <span class="built_in">int</span>[] idx = outputs.Find(x =&gt; x == i || x == j);</span><br><span class="line">            <span class="built_in">double</span>[][] subInputs = inputs.Submatrix(idx);</span><br><span class="line">            <span class="built_in">int</span>[] subOutputs = outputs.Submatrix(idx);</span><br><span class="line">   </span><br><span class="line">            <span class="comment">// Transform in a two-class problem</span></span><br><span class="line">            subOutputs.ApplyInPlace(x =&gt; x = (x == i) ? <span class="number">-1</span> : <span class="number">1</span>);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// Train the machine on the two-class problem.</span></span><br><span class="line">            configure(machine, subInputs, subOutputs).Run(<span class="literal">false</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>上面的代码利用了<a class="link"   target="_blank" rel="noopener" href="http://www.codeproject.com/KB/cs/aforge_parallel.aspx" >AForge.NET Parallel<i class="fas fa-external-link-alt"></i></a>的构造器和<a class="link"   target="_blank" rel="noopener" href="http://crsouza.blogspot.com/2010/08/matrix-manipulation-using-accordnet.html" >Accord.NET matrix extensions<i class="fas fa-external-link-alt"></i></a>。我决定不用最新加的 .NET 4.0 Parallel Extensions,所以这个框架还是兼容.NET 3.5 applications的应用的。</li>
</ul>
<h2 id="数字识别"><a href="#数字识别" class="headerlink" title="数字识别"></a>数字识别</h2><h3 id="UCI的光学数字数据集"><a href="#UCI的光学数字数据集" class="headerlink" title="UCI的光学数字数据集"></a>UCI的光学数字数据集</h3><ul>
<li>如果你读了上一篇文章<a class="link"   target="_blank" rel="noopener" href="http://crsouza.blogspot.com/2010/01/kernel-discriminant-analysis-in-c.html" >Kernel Discriminant Analysis for Handwritten Digit Recognition<i class="fas fa-external-link-alt"></i></a>，那么请跳过本小节。本小节只是对UCI机器学习的光学数字数据库的介绍。</li>
<li><a class="link"   target="_blank" rel="noopener" href="http://archive.ics.uci.edu/ml/" >UCI机器学习库<i class="fas fa-external-link-alt"></i></a>是一个被机器学习社区用于做机器学习算法实践分析的数据库，域理论，数据生成器的集合。其中一个就是<a class="link"   target="_blank" rel="noopener" href="http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits" >光学识别的手写数字数据集<i class="fas fa-external-link-alt"></i></a>，又叫Optdigits Dataset.</li>
<li>原始的光学数字数据是一个个32x32的矩阵。它们提供经过预处理的数字形式，数字被分成非重叠的4x4块，每一块上像素都合计了。这就生成了8x8输入矩阵，每一个元素都是0到16的整数。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/digit.png"></li>
</ul>
<h3 id="基于多分类的SVM的数字分类器"><a href="#基于多分类的SVM的数字分类器" class="headerlink" title="基于多分类的SVM的数字分类器"></a>基于多分类的SVM的数字分类器</h3><ul>
<li>核方法引起了很大的兴趣，因为它可以应用到那些需要进行预处理的(例如，数据降维)数据的问题上和被模型化的数据结构的扩展知识上。即使我们对数据知之甚少，核方法的直接应用往往得到令人感兴趣的结果。利用核方法实现最佳化是一个非常难的任务，因为我们用无穷多的核函数可供选择，而每个核函数也有无穷多的参数可供调整。</li>
<li>下面的代码向我们展示了基于核函数的支持向量机是怎么实现的。输入的是一个1024的全向量。这个对神经网络来说是不切实际的，例如，通常的核方法处理高维数的问题是没问题的，因为它不会遭受维数灾难。<figure class="highlight c#"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Extract inputs and outputs</span></span><br><span class="line"><span class="built_in">int</span> samples = <span class="number">500</span>;</span><br><span class="line"><span class="built_in">double</span>[][] input = <span class="keyword">new</span> <span class="built_in">double</span>[samples][];</span><br><span class="line"><span class="built_in">int</span>[] output = <span class="keyword">new</span> <span class="built_in">int</span>[samples];</span><br><span class="line"><span class="keyword">for</span> (<span class="built_in">int</span> i = <span class="number">0</span>; i &lt; samples; i++)</span><br><span class="line">&#123;</span><br><span class="line">   ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Create the chosen Kernel with given parameters</span></span><br><span class="line">IKernel kernel = <span class="keyword">new</span> Polynomial((<span class="built_in">int</span>)numDegree.Value, (<span class="built_in">double</span>)numConstant.Value);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Create the Multi-class Support Vector Machine using the selected Kernel</span></span><br><span class="line">ksvm = <span class="keyword">new</span> MulticlassSupportVectorMachine(<span class="number">1024</span>, kernel, <span class="number">10</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Create the learning algorithm using the machine and the training data</span></span><br><span class="line"><span class="keyword">var</span> ml = <span class="keyword">new</span> MulticlassSupportVectorLearning(ksvm, input, output);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Extract training parameters from the interface</span></span><br><span class="line"><span class="built_in">double</span> complexity = (<span class="built_in">double</span>)numComplexity.Value;</span><br><span class="line"><span class="built_in">double</span> epsilon = (<span class="built_in">double</span>)numEpsilon.Value;</span><br><span class="line"><span class="built_in">double</span> tolerance = (<span class="built_in">double</span>)numTolerance.Value;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Configure the learning algorithm</span></span><br><span class="line">ml.Configure = <span class="built_in">delegate</span>(KernelSupportVectorMachine svm, </span><br><span class="line">                        <span class="built_in">double</span>[][] cinput, <span class="built_in">int</span>[] coutput)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">var</span> smo = <span class="keyword">new</span> SequentialMinimalOptimization(svm, cinput, coutput);</span><br><span class="line">    smo.Complexity = complexity;</span><br><span class="line">    smo.Epsilon    = epsilon;</span><br><span class="line">    smo.Tolerance  = tolerance;</span><br><span class="line">    <span class="keyword">return</span> smo;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Train the machines. It should take a while.</span></span><br><span class="line"><span class="built_in">double</span> error = ml.Run();</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="应用例子"><a href="#应用例子" class="headerlink" title="应用例子"></a>应用例子</h2><h3 id="学习"><a href="#学习" class="headerlink" title="学习"></a>学习</h3><ul>
<li>样例应用附带源代码，它实现了基于核函数的多分类支持向量机的手写数字识别。下载了应用后，打开并点击菜单，然后选择”Open”。它就会载入数据。</li>
<li>要开始训练数据，点击“Start training”。利用默认设置，应该不会太长时间。因为代码是用了并行运算，核数越多，训练越快。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/app-1.png"></li>
<li>训练完成后，点击“Classify”开始分类测试数据集。利用默认值，它应该可以得到95%的正确率，大概是500个数据中有475个分类正确。识别率的大小会随着每次训练的不同而有小小的波动。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/app-2.png"></li>
<li>相同的集合和相同的训练和测试样本已经在上一篇中的基于核方法的判别分析方法中使用。而SVM却得到更高的运行效率和更少的内存，更多的样本数可能得到更高的正确率。</li>
<li>训练后，创建的SVM可以在“Machine”这个tab中看到。每次的SVM的支持向量和临界值可以在第一个数据格视图中通过选择一个数据入口而看到。向量越暗，在决策过程中它的权值就越大。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/app-3.png"></li>
</ul>
<h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><ul>
<li>即使识别率刚刚超过3%，但是识别的正确率已经比KDA大大的提升了。点击“Classification”tab，我们可以手动地为用户手写的数字测试多分类支持向量机。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/app-4.png"></li>
<li>我们看到SVM方法产生了更强壮的结果，即使手写很差的数字也能识别正确：<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/app-5.png"></li>
<li>最后，有一个视频演示：</li>
</ul>
<iframe height=498 width=610 src="http://player.youku.com/embed/XODYzNjk3NzMy" frameborder=0 allowfullscreen></iframe>

<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li>在本文中，我们详细叙述和探索了基于核方法的SVM来解决手写数字识别的问题，并且可以得到更好的结果。</li>
<li>SVM适合小样本的数据训练。</li>
</ul>
<h2 id="继续阅读"><a href="#继续阅读" class="headerlink" title="继续阅读"></a>继续阅读</h2><ul>
<li><a class="link"   target="_blank" rel="noopener" href="http://www.codeproject.com/KB/recipes/handwriting-kda.aspx" >Handwriting Recognition using Kernel Discriminant Analysis<i class="fas fa-external-link-alt"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="http://crsouza.blogspot.com/2010/04/kernel-support-vector-machines-for.html" >Kernel Functions for Machine Learning Applications<i class="fas fa-external-link-alt"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="http://crsouza.blogspot.com/2010/04/kernel-support-vector-machines-for.html" >Kernel Support Vector Machines (SVM)<i class="fas fa-external-link-alt"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="http://crsouza.blogspot.com/2009/09/principal-component-analysis-in-c.html" >Principal Component Analysis (PCA)<i class="fas fa-external-link-alt"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="http://crsouza.blogspot.com/2010/01/kernel-principal-component-analysis-in.html" >Kernel Principal Component Analysis (KPCA)<i class="fas fa-external-link-alt"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="http://crsouza.blogspot.com/2010/01/linear-discriminant-analysis-in-c.html" >Linear Discriminant Analysis (LDA)<i class="fas fa-external-link-alt"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="http://crsouza.blogspot.com/2010/01/kernel-discriminant-analysis-in-c.html" >Non-Linear Discriminant Analysis with Kernels (KDA)<i class="fas fa-external-link-alt"></i></a></li>
<li><a class="link"   target="_blank" rel="noopener" href="http://crsouza.blogspot.com/2010/02/logistic-regression-in-c.html" >Logistic Regression Analysis<i class="fas fa-external-link-alt"></i></a></li>
</ul>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul>
<li>Wikipedia contributors,<a class="link"   target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/Sequential_Minimal_Optimization" >“Sequential Minimal Optimization”<i class="fas fa-external-link-alt"></i></a>, Wikipedia, The Free Encyclopedia,<a class="link"   target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/Sequential_Minimal_Optimization" >http://en.wikipedia.org/wiki/Sequential_Minimal_Optimization<i class="fas fa-external-link-alt"></i></a> (accessed April 24, 2010).</li>
<li>Wikipedia contributors, <a class="link"   target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/Support_vector_machine" >“Support Vector Machine”<i class="fas fa-external-link-alt"></i></a>, Wikipedia, The Free Encyclopedia,<a class="link"   target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/Support_vector_machine" >http://en.wikipedia.org/wiki/Support_vector_machine<i class="fas fa-external-link-alt"></i></a>,(accessed April 24, 2010).</li>
<li>John C. Platt,<a class="link"   target="_blank" rel="noopener" href="http://research.microsoft.com/en-us/um/people/jplatt/smoTR.pdf" >Sequential Minimal Optimization: A Fast Algorithm for Training Support Vector Machines<i class="fas fa-external-link-alt"></i></a> , Microsoft Research, 1998.</li>
<li>J. P. Lewis,<a class="link"   target="_blank" rel="noopener" href="http://www.idiom.com/~zilla/Work/Notes/svmtutorial.pdf" >A Short SVM (Support Vector Machine) Tutorial.<i class="fas fa-external-link-alt"></i></a>,CGIT Lab &#x2F; IMSC, University of Southern California.</li>
<li>A. J. Smola and B. Scholkopf,<a class="link"   target="_blank" rel="noopener" href="http://www.kernel-machines.org/publications/SmoSch98c" >A Tutorial on Support Vector Regression.<i class="fas fa-external-link-alt"></i></a>,NeuroCOLT2 Technical Report Series, 1998.</li>
<li>S. K. Shevade et al.<a class="link"   target="_blank" rel="noopener" href="http://drona.csa.iisc.ernet.in/~chiru/papers/ieee_smo_reg.ps.gz" >Improvements to SMO Algorithm for SVM Regression<i class="fas fa-external-link-alt"></i></a>,1999.</li>
<li>G. W. Flake, S. Lawrence<a class="link"   target="_blank" rel="noopener" href="http://www.keerthis.com/smoreg_ieee_shevade_00.pdf" >Efficient SVM Regression Training with SMO<i class="fas fa-external-link-alt"></i></a></li>
<li>A. Asuncion &amp; D.J. Newman,<a class="link"   target="_blank" rel="noopener" href="http://archive.ics.uci.edu/ml/index.html" >UCI Machine Learning Repository.<i class="fas fa-external-link-alt"></i></a>Irvine, CA: University of California, School of Information and Computer Science (2007).</li>
<li>Andrew Kirillov,<a class="link"   target="_blank" rel="noopener" href="http://aforgenet.com/framework" >The AForge.NET Framework<i class="fas fa-external-link-alt"></i></a>.The AForge.NET Computer Vision, Artificial Intelligence and Robotics Website, 2010.</li>
<li>C. R. Souza, <a class="link"   target="_blank" rel="noopener" href="http://crsouza.blogspot.com/2010/03/kernel-functions-for-machine-learning.html" >Kernel Functions for Machine Learning Applications.<i class="fas fa-external-link-alt"></i></a> 17 Mar. 2010. Web.</li>
</ul>
<h1 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h1><ul>
<li>翻译这篇文章后，除了对翻译的难度有了更深一层的认知之后，本次只要是对SVM进行多分类问题的解决有了更深的认识。SVM本来是一个二类分类器，那么要解决多分类问题，应该要什么思路呢？就是用二类分类器进行组合，然后通过“一对一”策略来解决多分类分类器。</li>
</ul>

            </div>

            
                <div class="post-copyright-info">
                    
<div class="article-copyright-info-container">
    <ul class="copyright-info-content">
        <li class="post-title">
            <span class="type">本文标题</span>：<span class="content">手写数字识别-Kernel Support Vector Machine-论文翻译-毕设系列</span>
        </li>
        <li class="post-author">
            <span class="type">本文作者</span>：<span class="content">Tim Chen(motion$)</span>
        </li>
        <li class="post-time">
            <span class="type">创建时间</span>：<span class="content">2015-01-03 14:29:02</span>
        </li>
        <li class="post-link">
            <span class="type">本文链接</span>：<span class="content">2015/01/03/毕业设计系列/手写数字识别-Kernel-Support-Vector-Machine-博客翻译-毕设系列/</span>
        </li>
        <li class="post-license">
            <span class="type">版权声明</span>：<span class="content">本博客所有文章除特别声明外，均采用 <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">BY-NC-SA</a> 许可协议。转载请注明出处！</span>
        </li>
    </ul>
    <div class="copy-copyright-info flex-center tooltip" data-content="复制版权信息" data-offset-y="-2px">
        <i class="fa-solid fa-copy"></i>
    </div>
</div>

                </div>
            

            
                <ul class="post-tags-box">
                    
                        <li class="tag-item">
                            <a href="/tags/%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/">#手写数字识别</a>&nbsp;
                        </li>
                    
                        <li class="tag-item">
                            <a href="/tags/Kernel-Support-Vector-Machine/">#Kernel Support Vector Machine</a>&nbsp;
                        </li>
                    
                </ul>
            

            
                <div class="article-nav">
                    
                        <div class="article-prev">
                            <a class="prev"
                               rel="prev"
                               href="/2015/01/04/ML/%E3%80%90%E5%9F%BA%E7%A1%80%E3%80%91%E5%B8%B8%E7%94%A8%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%9F%A5%E8%AF%86%E7%82%B9/"
                            >
                            <span class="left arrow-icon flex-center">
                              <i class="fas fa-chevron-left"></i>
                            </span>
                                <span class="title flex-center">
                                <span class="post-nav-title-item">【基础】常用的机器学习&amp;数据挖掘知识点</span>
                                <span class="post-nav-item">上一篇</span>
                            </span>
                            </a>
                        </div>
                    
                    
                        <div class="article-next">
                            <a class="next"
                               rel="next"
                               href="/2015/01/01/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%E7%B3%BB%E5%88%97/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91-%E6%AF%95%E8%AE%BE%E7%B3%BB%E5%88%97/"
                            >
                            <span class="title flex-center">
                                <span class="post-nav-title-item">最小二乘法论文翻译-毕设系列</span>
                                <span class="post-nav-item">下一篇</span>
                            </span>
                                <span class="right arrow-icon flex-center">
                              <i class="fas fa-chevron-right"></i>
                            </span>
                            </a>
                        </div>
                    
                </div>
            

            
                <div class="comment-container">
                    
<div class="comments-container">
    <div id="comments-anchor"></div>
    <div class="comment-area-title">
        <i class="fas fa-comments"></i>&nbsp;评论
    </div>
    
        
            

    <div class="gitalk-comment-container">
        <div id="gitalk-container"></div>
        <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk/dist/gitalk.css">
        <script data-pjax src="//cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.js"></script>
        <script data-pjax>
          function loadGitalk() {
            let __gitalk__pathname = decodeURI(location.pathname);
            const __gitalk__pathnameLength = __gitalk__pathname.length;
            const __gitalk__pathnameMaxLength = 50;
            if (__gitalk__pathnameLength > __gitalk__pathnameMaxLength) {
              __gitalk__pathname = __gitalk__pathname.substring(0, __gitalk__pathnameMaxLength - 3) + '...';
            }

            try {
              Gitalk && new Gitalk({
                clientID: '9e91691916561f410b89',
                clientSecret: 'b1f7e5e85cbcc4197d669d0731ef300bc7630dc7',
                repo: 'gittalk-comment',
                owner: 'chenyuqing',
                admin: 'chenyuqing',
                id: __gitalk__pathname,
                proxy: '',
                language: 'zh-CN'
              }).render('gitalk-container');
            } catch (e) {
              window.Gitalk = null;
            }
          }

          if ('true' === 'true') {
            const loadGitalkTimeout = setTimeout(() => {
              loadGitalk();
              clearTimeout(loadGitalkTimeout);
            }, 1000);
          } else {
            window.addEventListener('DOMContentLoaded', loadGitalk);
          }
        </script>
    </div>



        
    
</div>

                </div>
            
        </div>

        
            <div class="toc-content-container">
                <div class="post-toc-wrap">
    <div class="post-toc">
        <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2%E7%9A%84%E8%AF%9D"><span class="nav-number">1.</span> <span class="nav-text">写在前面的话</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8D%9A%E6%96%87%E6%AD%A3%E6%96%87"><span class="nav-number">2.</span> <span class="nav-text">博文正文</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AE%80%E4%BB%8B"><span class="nav-number">2.1.</span> <span class="nav-text">简介</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA"><span class="nav-number">2.1.1.</span> <span class="nav-text">支持向量机</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E6%A0%B8%E5%87%BD%E6%95%B0%E7%9A%84%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA"><span class="nav-number">2.1.2.</span> <span class="nav-text">基于核函数的支持向量机</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E5%88%86%E7%B1%BB%E7%9A%84%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA"><span class="nav-number">2.1.3.</span> <span class="nav-text">多分类的支持向量机</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%BA%90%E4%BB%A3%E7%A0%81"><span class="nav-number">2.2.</span> <span class="nav-text">源代码</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA-1"><span class="nav-number">2.2.1.</span> <span class="nav-text">支持向量机</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E7%AE%97%E6%B3%95"><span class="nav-number">2.2.2.</span> <span class="nav-text">训练算法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB"><span class="nav-number">2.3.</span> <span class="nav-text">数字识别</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#UCI%E7%9A%84%E5%85%89%E5%AD%A6%E6%95%B0%E5%AD%97%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">2.3.1.</span> <span class="nav-text">UCI的光学数字数据集</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E5%A4%9A%E5%88%86%E7%B1%BB%E7%9A%84SVM%E7%9A%84%E6%95%B0%E5%AD%97%E5%88%86%E7%B1%BB%E5%99%A8"><span class="nav-number">2.3.2.</span> <span class="nav-text">基于多分类的SVM的数字分类器</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BA%94%E7%94%A8%E4%BE%8B%E5%AD%90"><span class="nav-number">2.4.</span> <span class="nav-text">应用例子</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AD%A6%E4%B9%A0"><span class="nav-number">2.4.1.</span> <span class="nav-text">学习</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BB%93%E6%9E%9C"><span class="nav-number">2.4.2.</span> <span class="nav-text">结果</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">2.5.</span> <span class="nav-text">总结</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BB%A7%E7%BB%AD%E9%98%85%E8%AF%BB"><span class="nav-number">2.6.</span> <span class="nav-text">继续阅读</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E8%80%83"><span class="nav-number">2.7.</span> <span class="nav-text">参考</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%90%8E%E8%AE%B0"><span class="nav-number">3.</span> <span class="nav-text">后记</span></a></li></ol>
    </div>
</div>

            </div>
        
    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom">
            
<footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
                <span>2012</span> -
            
            2025
            
                &nbsp;<i class="fas fa-heart icon-animate"></i>
                &nbsp;<a href="/">Tim Chen(motion$)</a>
            
        </div>
        
            <script async data-pjax
                    src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    访问人数&nbsp;<span id="busuanzi_value_site_uv"></span>&ensp;
                
                
                    总访问量&nbsp;<span id="busuanzi_value_site_pv"></span>
                
            </div>
        
        <div class="theme-info info-item">
            由 <a target="_blank" href="https://hexo.io">Hexo</a> 驱动&nbsp;|&nbsp;主题&nbsp;<a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.6.1</a>
        </div>
        
        
            <div class="deploy-info info-item">
                
                    <a target="_blank" rel="nofollow" href="https://github.com/chenyuqing/chenyuqing.github.io">
                
                    本站由 <span class="tooltip" data-content="GitHub Pages"><img src="/images/deploy-provider/github.png"></span> 提供部署服务
                
                    </a>
                
            </div>
        
    </div>
</footer>

        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="tools-list">
        <!-- TOC aside toggle -->
        
            <li class="tools-item flex-center toggle-show-toc">
                <i class="fas fa-list"></i>
            </li>
        

        <!-- go comment -->
        
            <li class="tools-item flex-center go-to-comments">
                <i class="fas fa-comment"></i>
                <span class="post-comments-count"></span>
            </li>
        
    </ul>
</div>

        </div>
    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        

        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="fas fa-arrow-up"></i>
            </li>
        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
    </ul>
</div>

    </div>

    <div class="zoom-in-image-mask">
    <img class="zoom-in-image">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="搜索..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="close-popup-btn">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>




<script src="/js/utils.js"></script>

<script src="/js/main.js"></script>

<script src="/js/header-shrink.js"></script>

<script src="/js/back2top.js"></script>

<script src="/js/dark-light-toggle.js"></script>





    
<script src="/js/local-search.js"></script>




    
<script src="/js/code-block.js"></script>





<div class="post-scripts pjax">
    
        
<script src="/js/post-helper.js"></script>

        
            
<script src="/js/libs/anime.min.js"></script>

        
        
            
<script src="/js/toc.js"></script>

        
    
</div>


    
<script src="/js/libs/pjax.min.js"></script>

<script>
    window.addEventListener('DOMContentLoaded', () => {
        window.pjax = new Pjax({
            selectors: [
                'head title',
                '.page-container',
                '.pjax'
            ],
            history: true,
            debug: false,
            cacheBust: false,
            timeout: 0,
            analytics: false,
            currentUrlFullReload: false,
            scrollRestoration: false,
            // scrollTo: true,
        });

        document.addEventListener('pjax:send', () => {
            KEEP.utils.pjaxProgressBarStart();
        });

        document.addEventListener('pjax:complete', () => {
            KEEP.utils.pjaxProgressBarEnd();
            window.pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
            KEEP.refresh();
        });
    });
</script>



</body>
</html>
