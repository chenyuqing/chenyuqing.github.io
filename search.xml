<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>什么是神经网络？</title>
    <url>/2017/02/21/ML/03-what-is-neural-network/</url>
    <content><![CDATA[<h2 id="为什么需要神经网络？"><a href="#为什么需要神经网络？" class="headerlink" title="为什么需要神经网络？"></a>为什么需要神经网络？</h2><ul>
<li><img src="/img/tf_tutorial/03_neural_network/neural.jpg" title="https://pic2.zhimg.com/df53fac99fc53ba5a90666abcca25e6d_b.jpg"></li>
<li>神经网络原本是生物学当中的知识。如上图所示，就是一个神经网络的放大图，在图中我们可以看到好几个大的节点，生物术语叫做神经元，而神经元之间可以看到连接着小的神经线。这就如同一个图的结构一样，包含了节点和连接节点的边。那么不同的神经元是有不同的功能的，而神经线(非专业术语)可以给不同的神经元传递信息。这样的一个神经网络可以完成很多不同的功能，如我们的大脑一样，我们的大脑遍布着神经网络，而我们的大脑是我们身体的控制中心，实现了非常多的功能。</li>
<li>所以在机器学习当中为什么需要机器学习呢？因为机器学习当中现时的模型简单，有时候解决不了复杂的问题。所以为了对付复杂的模式，就用到了神经网络。</li>
</ul>
<h2 id="神经网络的架构"><a href="#神经网络的架构" class="headerlink" title="神经网络的架构"></a>神经网络的架构</h2><ul>
<li>一般的神经网络架构是包含输入层(input layer)，隐藏层(hidden layer)和输出层(output layer)。</li>
<li><img src="/img/tf_tutorial/03_neural_network/nn_architecture.jpg" title="http://futurehumanevolution.com/wp-content/uploads/Artificial-Intelligence-Neural-Network-Nodes.jpg"></li>
</ul>
<h2 id="神经网络的计算"><a href="#神经网络的计算" class="headerlink" title="神经网络的计算"></a>神经网络的计算</h2><ul>
<li>那么神经网络是如何计算的呢？在神经网络中，神经元都是有功能的，我们称之为激活函数，当input输入网络时，会经过神经元，神经元会通过激活函数判断当前的输入是否应该激活，如果激活了就会进入下一层，如果没有激活，那么这个input就不会进入到下一层了。同样的input输入到不同的节点时得到的结果不一样，是因为节点上的激活函数不同，激活函数不同也就是weighs和bias不同。</li>
<li>当input到达输出层时会得到一个预测值，神经网络通过比较预测值和实际值的误差，并不断地调整节点的weights和bias，从而使得预测值和实际值之间的误差越来越小，预测效果会越来越好，这个过程就叫做training。</li>
</ul>
<h2 id="最简单的神经网络-感知器-Perceptron"><a href="#最简单的神经网络-感知器-Perceptron" class="headerlink" title="最简单的神经网络-感知器(Perceptron)"></a>最简单的神经网络-感知器(Perceptron)</h2><ul>
<li>感知器是一个简单的二类分类模型，也是最简单的神经网络结构。它是由心理学家Frank Rosenblatt于1957年提出的。它的结构模型如下：</li>
<li><img src="/img/tf_tutorial/03_neural_network/perceptron.png" title="http://1.bp.blogspot.com/-P5zuvA_ZrYk/TobOno7uRFI/AAAAAAAAAIM/tnIVcdNoWaU/s1600/perceptron.png"></li>
<li>它就是一个简单的输入层和输出层。输入的每个样本会有两个feature，x1和x2。x1和x2对应的权重是w1和w2。中间的f函数是一个点乘函数，就是f(X) &#x3D; x1 * w1 + x2 * w2。然后接着的是一个阈值函数，也可以叫做分段函数。只要函数值大于预定的阈值，那么就会输出1，相反，就会输出-1。这就实现了一个二类分类器。</li>
<li>感知器是一个简单的二分类的分类器，但是它只能解决线性问题。什么是线性问题呢？就是用一个条直线就能划分的问题。那么，像我们学过的“逻辑与”与“逻辑或”这样的线性问题是怎么用感知器来实现的呢？</li>
</ul>
<h3 id="感知器实现“逻辑与”-AND-和“逻辑或”-OR"><a href="#感知器实现“逻辑与”-AND-和“逻辑或”-OR" class="headerlink" title="感知器实现“逻辑与”(AND)和“逻辑或”(OR)"></a>感知器实现“逻辑与”(AND)和“逻辑或”(OR)</h3><ul>
<li>我们先来看一下“逻辑与”的真值表和它的函数图吧：</li>
<li><img src="/img/tf_tutorial/03_neural_network/and.png" title="http://hahack.com/images/ann2/tZUEt.png"></li>
<li>然后“逻辑或”的真值表和它的函数图：</li>
<li><img src="/img/tf_tutorial/03_neural_network/or.png" title="http://hahack.com/images/ann2/eqMxJ.png"></li>
<li>那么感知器是如何解决线性问题的呢？上面我们提到的一个阈值函数，假设我们的阈值为T，那么函数的定义可以写成：</li>
<li><img src="/img/tf_tutorial/03_neural_network/equation1.jpg"></li>
<li>所以划分分类的直线就是：</li>
<li><img src="/img/tf_tutorial/03_neural_network/equation2.jpg"></li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步-ML</category>
      </categories>
      <tags>
        <tag>Tensorflow tutorial</tag>
        <tag>ML</tag>
        <tag>DL</tag>
      </tags>
  </entry>
  <entry>
    <title>老石谈芯-人工智能的底层逻辑</title>
    <url>/2022/05/21/ML/AI%E5%BA%95%E5%B1%82%E9%80%BB%E8%BE%91/</url>
    <content><![CDATA[<h1 id="AI创新的天花板"><a href="#AI创新的天花板" class="headerlink" title="AI创新的天花板"></a>AI创新的天花板</h1><ul>
<li>暴力美学，大数据+大算力 探索模型的边界</li>
<li>从感知智能→ 认知智能</li>
<li>根据应用设计算法</li>
</ul>
<h1 id="AI算法的全局观"><a href="#AI算法的全局观" class="headerlink" title="AI算法的全局观"></a>AI算法的全局观</h1><ul>
<li>AI的“圣杯”问题<ul>
<li>怎么样做逻辑 ？</li>
<li>怎么样让AI拥有常识？</li>
<li>怎么样建模记忆？</li>
<li>感知 → 认知 ？<ul>
<li>继续深挖神经网络</li>
<li>神经主义+符号主义</li>
<li>传统逻辑推理的新提升</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="数字石油"><a href="#数字石油" class="headerlink" title="数字石油"></a>数字石油</h1><ul>
<li>数字是现代社会的石油</li>
<li>传统模式，以模型为中心 → 新模式，以数据为中心</li>
<li>数据隐私带来的新问题<ul>
<li>联合建模，联邦学习：一种分布式机器学习技术，保护数据隐私，实现共同建模，打破数据孤岛</li>
<li><ul>
<li>设计范式的转变（Paradigm Shift）</li>
</ul>
</li>
<li>从关注算法 → 到关注数据</li>
</ul>
</li>
<li>数据墙<ul>
<li>cpu → RAM → NPU → GPU</li>
<li>对数据设计温度<ul>
<li>冷数据：访问频率低，性能要求低，适合存硬盘</li>
<li>温数据：访问频率较高，数据较为零散，适合放SSD</li>
<li>热数据：访问频率高，性能要求高，适合放内存</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="芯片和硬件为AI量身定制？"><a href="#芯片和硬件为AI量身定制？" class="headerlink" title="芯片和硬件为AI量身定制？"></a>芯片和硬件为AI量身定制？</h1><ul>
<li><p>云原生，AI原生，把硬件算力环境放到云端</p>
</li>
<li><p>AI硬件 &#x3D; GPU 吗？</p>
</li>
<li><p>异构系统如何编程和控制？</p>
<ul>
<li>Intel 的OneAPI</li>
</ul>
</li>
<li><p>AI系统，还有那些创新方向？</p>
<ul>
<li>End-to-end解决方案</li>
<li>以数据为中心的软件开发，通过大数据编程，数据驱动来发现规则，制造机器人的机器人</li>
</ul>
</li>
<li><p>AI如何落地应用？</p>
<ul>
<li>观点1，从需求出发，同时考虑非技术因素</li>
<li>观点2，小样本学习，未来的机会</li>
<li>观点3，统一的平台，推进高校协作</li>
<li>观点，AI LAB必然会消失</li>
<li>观点，单靠技术创业是不够的</li>
</ul>
</li>
<li><p>AI的未来发展，路在何方？</p>
<ul>
<li>需要摩尔定律的加持</li>
<li>互联网技术或者虚拟经济→ 传统行业或者实体经济渗透</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步-ML</category>
      </categories>
      <tags>
        <tag>人工智能的底层逻辑</tag>
      </tags>
  </entry>
  <entry>
    <title>40 道ML/Data Science的初创公司(可能)的面试题</title>
    <url>/2016/10/03/ML/40/</url>
    <content><![CDATA[<ul>
<li>By Manish Saraswat, <a class="link"   href="https://www.analyticsvidhya.com/blog/2016/09/40-interview-questions-asked-at-startups-in-machine-learning-data-science/" >Original Link<i class="fas fa-external-link-alt"></i></a></li>
<li>09&#x2F;16&#x2F;2016</li>
</ul>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><blockquote>
<p><b><font color="red">留心，这些问题你要三思！</font></b></p>
</blockquote>
<ul>
<li>在今天，机器学习和数据科学家被认为是下一代工业改革的驱动力。这也意味着有很多新进的初创公司在寻找数据科学家。那么，该如何给你振奋人心的职业生涯一个更好的开始呢？</li>
<li>当然，想进入这个行业并不容易。显然你必须要对公司的理念，团队和远景感兴趣。你可能在你的职业之路上遇到一写很棘手的技术问题。本题集和初创公司做的东西有紧密联系。他们会不会提供咨询？他们会不会创建ML产品？你在面试之前就该提前考虑这个问题？</li>
<li>为了帮助你准备下一场面试，我整理了40个看似可信但是其中暗藏端倪的问题，它们都有可能出现在你的面试当中。如果你能够轻松应对并且深刻理解问题，那么请放心，你可以在面试中打一场硬仗。</li>
<li>备注：轻松应对这些问题的核心是你对ML有实际操作经验和了解相关的统计概念。</li>
</ul>
<h2 id="机器学习的面试问题"><a href="#机器学习的面试问题" class="headerlink" title="机器学习的面试问题"></a>机器学习的面试问题</h2><ul>
<li><p><b><font color="blue"> Q1，给你一个1000列，100万行的数据集。这个数据集是一个分类问题。你经理要求你减少这个数据集的维度以减少模型计算所花的时间。你的机器有内存限制。你会怎么做？(你可以做出实际的假设)</font></b></p>
</li>
<li><p><b>答：</b>在一台内存有限的机器上处理高纬度的数据是一个很费力的任务，你的面试官肯定意识到这一点。以下是你可以拿来应对的方法：</p>
<ol>
<li>由于我们的内存有限，我们首先应该关闭所有不需要的程序，包括浏览器，这样我们才能把内存的利用最大化。</li>
<li>我们可以随机对数据集进行抽样。这就意味着我们可以创建一个更小的数据集，假如，1000个变量，30万行的数据集，然后做计算。</li>
<li>要减少维度，我们可以把数值型和分类型的变量分开，然后去掉相关的变量。对于数值型数据，我们利用相关性分析，对于分类型数据，我们利用卡方检验。</li>
<li>另外，我们可以做PCA，然后挑出数据集中能够解释最大方差的变量。</li>
<li>利用在线学习算法，像Vowpal Wabbit (Python提供)，也是一个选择。</li>
<li>利用随机梯度下降来创建一个线性模型也是有帮助的。</li>
<li>我们也可以把数据集的商业理解考虑进去，然后估计哪些predictors能够影响respone variable。但是这是一个凭直觉的方法，如果分析错误就会造成信息的损失。</li>
</ol>
</li>
<li><p><b>备注：</b>对于第4，5点，请务必了解在线算法和随机梯度下降算法。另外还有更高级的算法。</p>
</li>
<li><p><b><font color="blue"> Q2， PCA中的旋转是必须的吗？如果是，那么你没有旋转的话，会发生什么？</font></b></p>
</li>
<li><p><b>答：</b>是的，旋转(正交直线)是必须的，因为它能最大化捕捉到的变量之间的差异。这会使变量更容易解释。不要忘记，这确切是PCA的动机所在，我们的目标是选择更少的components，这些变量能够解释数据集的最大方差。通过旋转，components的相关位置不会改变，她仅仅改变这些点的实际坐标。</p>
</li>
<li><p>如果我们没有进行旋转，PCA的作用就会减少，而我们需要选择更多的components来解释数据集的方差。</p>
</li>
<li><p>了解更多：<a class="link"   href="https://www.analyticsvidhya.com/blog/2016/03/practical-guide-principal-component-analysis-python/" >PCA<i class="fas fa-external-link-alt"></i></a></p>
</li>
<li><p><b><font color="blue"> Q3，给你一个数据集，这个数据集包含这样的缺失值，它的分布是沿着中位数，标准差是1。那么，有百分之几的数据不受影响？为什么呢？</font></b></p>
</li>
<li><p><b>答：</b>这道题有足够的提示让你思考。由于数据是沿着中位数分布的，我们假设它是一个正态分布。我们知道在一个正态分布中，68%的数据包含在均值(或者众数，中位数)为中心1为标准差的范围内，那么就有32%的数据是不受影响的。所以，32%的数据将会不受缺失值的影响。</p>
</li>
<li><p><b><font color="blue"> Q4，给你一个癌症检测的数据，你建了一个分类模型并且模型的准确率达到了96%。为什么你不能对你模型的表现感到满意？你会怎么做？</font></b></p>
</li>
<li><p><b>答：</b>如果你处理了足够多的数据集，你可以推断癌症检测造成了不平衡的数据。在一个不平衡的数据集中，准确率不应该被当作表现的衡量标准，因为96%仅仅是预测对了大多数的类别，但是我们感兴趣的类别是小部分的4%，它恰恰是被用来用作癌症的诊断。所以，为了评估模型的表现，我们应该利用Sensitivity(True Positive Rate)，Specificity(True Negative Rate)，F measure用来诊断分类器的性能。如果小部分的分类性能是很无力的，我们可以采取一下的措施：</p>
<ol>
<li>我们可以利用欠采样，过采样或者SMOTE(一种采样技术)使得数据平衡。</li>
<li>我们可以通过概率校正来改变预测阈值，然后利用AUC-ROC曲线找到一个最优的阈值。</li>
<li>我们可以给类别赋予权重，让小部分的类别得到更大的权重。</li>
<li>我们可以做异常检测。</li>
</ol>
</li>
<li><p><b>了解更多：</b><a class="link"   href="https://www.analyticsvidhya.com/blog/2016/03/practical-guide-deal-imbalanced-classification-problems/" >Imbalanced Classification<i class="fas fa-external-link-alt"></i></a></p>
</li>
<li><p><b><font color="blue"> Q5，为什么朴素贝叶斯那么“朴素”？</font></b></p>
</li>
<li><p><b>答：</b>朴素贝叶斯“朴素”是因为它假设了数据集中的特征都是平等重要且相互独立的。我们知道，这些假设在现实生活中存在的几率是很小的。</p>
</li>
<li><p><b><font color="blue"> Q6，解释朴素贝叶斯中的概念：先验概率，似然和边缘似然。</font></b></p>
</li>
<li><p><b>答：</b>先验概率就是数据集中独立(二分类)变量的比重，就是一个最简单的分类。譬如，一个数据集中，独立变量是二分类的(0或者1)。1(垃圾邮件)的比重是70%，0(正常邮件)的比重是30%。所以，我们可以估计新邮件有70%的几率被分作垃圾邮件。</p>
</li>
<li><p>似然就是给定的观测量在其他变量的条件下被分作1的概率。譬如，在之前的垃圾邮件中“FREE”这个词的概率就是似然。边缘似然就是，“FREE”这个词被用在任何信息当中的概率。</p>
</li>
<li><p><b><font color="blue"> Q7，你正在处理一个时间序列的数据集。你经理要求你创建一个高准确率的模型。你一开始就用决策树算法，因为你知道它对任意类型的数据都处理得不错。然后，你试了一个时间序列的回归模型并且得到了更高的准确率。这会发生吗？为什么呢？</font></b></p>
</li>
<li><p><b>答：</b>时间序列数据是受线性限制的。另一方面，我们知道决策树算法是适用于检测非线性的交互。决策树不能很好地提供robust的预测是因为它没有像线性模型那样能很好地map到数据的线性关系。所以，我们知道，线性回归模型可以对给定的线性数据提供更robust的预测。</p>
</li>
<li><p><b><font color="blue"> Q8，你被分配了一个新的project，这个project是帮助某公司的食物派送减低成本的。问题是：公司的派送团队没能及时地派送食物，结果，顾客就不开心。然后为了让驳回顾客的芳心，公司最后决定免派送费。你认为哪一个机器学习方法能够拯救他们呢？</font></b></p>
</li>
<li><p><b>答：</b>你可能很快的在脑海中扫描了一遍机器学习算法。但是，请放松一下，这个问题考的是你的机器学习的基础。</p>
</li>
<li><p>这不是一个机器学习的问题。这是一个路径优化的问题。一个机器学习的算法包括三个基本要素：</p>
<ol>
<li>问题中存在一个模式</li>
<li>你不能通过数学计算来解决它(即使是写指数方程)</li>
<li>你要有数据</li>
</ol>
</li>
<li><p>我们通常找出这三个要素来决定是否能把机器学习当成一个解决实际问题的工具。</p>
</li>
<li><p><b><font color="blue"> Q9，你发现你的模型出现了低偏差高方差的问题，你应该怎么解决？为什么呢？</font></b></p>
</li>
<li><p><b>答：</b>低偏差说明模型的预测值非常接近真实值。换句话说，这个模型能够很灵活地模仿到训练数据分布。看似这是很成功，但是不要忘记，一个灵活的模型往往没有泛化能力。这意味着，当模型对新数据进行预测时，它可能会给出很差的结果。</p>
</li>
<li><p>这样的话，我们可以利用bagging算法(譬如随机森林)来解决高方差的问题。Bagging算法通过重复的随机采样把数据集分成很多个子集。然后，用这些样本来做不同的算法得到一个模型的集合。之后，最终的预测是对模型集中的模型进行不同的组合，分类的话就用投票的方式，回归的话就用求均值的方式。</p>
</li>
<li><p>另外，为了防止高方差，我们可以：</p>
<ol>
<li>利用正则化技术，对模型的高系数进行惩罚，从而降低模型的复杂度</li>
<li>对特征的重要性进行排序然后利用前n个。因为，如果全部的特征都用上，算法可能没办法很好地找到有意义的信号。</li>
</ol>
</li>
<li><p><b><font color="blue"> Q10，给你一个数据集，它包含了很多变量，但是你已经知道其中的一些有很高的关联性变量了。你的经理要求你利用PCA进行处理。你会先把有关联性的变量删掉吗？为什么呢？</font></b></p>
</li>
<li><p><b>答：</b>可能你会说NO，但是这是不对的。抛开有关联性的数据对PCA有实质的影响不说，如果没有删掉有关联性的变量，那么一个特定的成分的方差就会膨胀。</p>
</li>
<li><p>譬如，你有3个变量的数据集，其中2个是有关联性的。如果你对数据进行PCA处理，那么第一个主要的成分就会展示2倍的方差，比没有关联性变量存在的时候。另外，添加有关联性的变量会使得PCA把更多的重要性给以它们，这恰恰是误导的。</p>
</li>
<li><p><b><font color="blue"> Q11，运行了几个小时之后，你很焦急想要创建一个准确率高的模型。结果，你建了一个5GB的模型集合，考虑到一个boosting算法会产生奇迹。但是，很不幸的，没有一个模型的表现能比基准分(benchmark score)更好。最后，你决定组合这些模型。我们都知道ensemble模型都会得到很高的准确率，但是你的却没有。请问到底是哪里出了问题呢？</font></b></p>
</li>
<li><p><b>答：</b>总所周知，ensemble learners的核心思想是通过组合简单的弱模型来得到一个强模型。但是当模型之间是独立的时候，组合出来的模型才会表现得很好。所以，我们建立了5GB的模型集合，但是准确率却没有提升，这就暗示着模型之间是有关联性的。有关联性的模型的问题是它们都提供了相同的信息。</p>
</li>
<li><p>譬如，如果模型1，2，3都是关联的，那么当模型1把User122分类为1时，模型2和模型3也会得到同样的分类结果，即使它的真实值是0。所以，ensemble learners是建立在没有关联性的弱模型集合的基础上，这样的组合才能得到更好的predictions。</p>
</li>
<li><p><b><font color="blue"> Q12，kNN和kmeans聚类有什么不同？</font></b></p>
</li>
<li><p><b>答：</b>不要给名字中的k误导了。你应该知道这两个算法之间最基本的不同是：kmeans是一个无监督学习方法而kNN是一个有监督的学习方法。kNN是一个分类(或者回归)的方法。</p>
</li>
<li><p>kmeans算法是对一个数据集进行划分以至于组成有同质性族群，其中的点与点之间的距离是相近的。这个算法尽量保持这些族群之间的可划分性。而无监督的学习方法中的族群是没有标签的。</p>
</li>
<li><p>kNN算法试着对没有标签的数据按临近的距离进行k(k可以是任何小于sample的数)分类。它又被称作懒惰学习方法因为它涉及到模型的最小训练集。所以，它不会用训练数据对新的数据进行泛化。</p>
</li>
<li><p><b><font color="blue"> Q13，True Positive Rate和Recall是什么关系？写出公式。</font></b></p>
</li>
<li><p><b>答：</b>True Positive Rate &#x3D; Recall。是的，它们有相同的公式(TP&#x2F;(TP+FN))。</p>
</li>
<li><p><b>了解更多：</b><a class="link"   href="https://www.analyticsvidhya.com/blog/2016/02/7-important-model-evaluation-error-metrics/" >Evaluation Metrics<i class="fas fa-external-link-alt"></i></a></p>
</li>
<li><p><b><font color="blue"> Q14，你建立了一个多重回归模型。模型的R方并没有你预期的那么好。为了改进，你去掉了截距，模型的R方由原来的0.3升到了0.8。请问这是可能的吗？是如何做到的？</font></b></p>
</li>
<li><p><b>答：</b>是的，是有可能的。我们需要理解截距在回归模型中的重要性。截距说明模型的预测是没有任何的独立变量的，如预测的均值。公式：R² &#x3D; 1 – ∑(y – y´)²&#x2F;∑(y – ymean)²，其中y´ 是预测值。</p>
</li>
<li><p>当截距存在的时候，R方值把模型的wrt评估到均值模型当中。当截距不存在的时候，模型就不会这样做。巨大的分母∑(y - y´)²&#x2F;∑(y)²就把等式的值变得比实际的要小，然后造成了高的R方。</p>
</li>
<li><p><b><font color="blue"> Q15，分析了模型之后，你的经理得知你的模型有多重共线性。你会怎么验证模型？没有信息的流失，你可以建立一个更好的模型吗？</font></b></p>
</li>
<li><p><b>答：</b>要检查多重共线性，我们可以创建一个相关系数矩阵来辨识或者删除相关系数达到75%的变量(这个阈值的设置是主观的)。另外，我们可以计算方差膨胀因子(Variance Inflation Factor)来检查多重共线性。 VIF的值&lt;&#x3D;4意味着没有多重共线性，VIF的值&gt;&#x3D;10预示着有严重的多重共线性。最后，我们还可以利用公差来判断多重共线性的出现与否。</p>
</li>
<li><p>但是删除相关变量可能导致信息流失。为了保持变量，我们可以用惩罚性回归模型，像lasso回归或者ridge回归。还有，我们可以加入一些随机噪声变量到相关变量当中，这样变量间就会变得不同。但是，加入噪声可能影响预测准确率。所以，这个方法也要小心使用。</p>
</li>
<li><p><b>了解更多：</b><a class="link"   href="https://www.analyticsvidhya.com/blog/2016/07/deeper-regression-analysis-assumptions-plots-solutions/" >Regression<i class="fas fa-external-link-alt"></i></a></p>
</li>
<li><p><b><font color="blue"> Q16，什么时候Ridge回归比Lasso回归更好用？</font></b></p>
</li>
<li><p><b>答：</b>你可以引用ISLR这本书的作者Hastie Tibshirani的话，他说：In presence of few variables with medium&#x2F; large sized effect, use lasso regression. In presence of many variables with small&#x2F; medium size effect, use ridge regression.</p>
</li>
<li><p>理论上说，lasso回归(L1)既做了变量选择也做了参数的收缩，而Ridge回归(L2)只是做了参数的收缩，最后把所有的系数都会算进了模型中。当存在相关变量时，ridge回归回事更好的选择。而且，ridge回归在最小二乘因子有比较高的方差时表现最好。所以，她取决于模型的客观性。</p>
</li>
<li><p><b>了解更多：</b><a class="link"   href="https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-ridge-lasso-regression-python/" >Ridge and Lasso Regression<i class="fas fa-external-link-alt"></i></a></p>
</li>
<li><p><b><font color="blue"> Q17，全球平均气温的提升导致了海盗数量的减少。那么我们可以说海盗数量的减少造成了全球气温的变化吗？</font></b></p>
</li>
<li><p><b>答：</b>读完题目后，你应该这就是典型的“因果与相关”的问题。不，我们不能得出海盗数量的减少造成了气温的改变，因为可能是其他因素(潜伏或者混淆的变量)影响着气候。</p>
</li>
<li><p>所以，或许全球平均气温和海盗数量有一定的关系，但是基于这样的信息我们不能说海盗减少是因为全球平均气温的升高。</p>
</li>
<li><p><b>了解更多：</b><a class="link"   href="https://www.analyticsvidhya.com/blog/2015/06/establish-causality-events/" >Causation and Correlation<i class="fas fa-external-link-alt"></i></a></p>
</li>
<li><p><b><font color="blue"> Q18，在处理数据的时候，如何选择重要的变量？请解释你的方法。</font></b></p>
</li>
<li><p><b>答：</b>以下是一些常用的变量选择方法：</p>
<ol>
<li>在选择重要变量之前，先把有相关性的变量删掉</li>
<li>利用线性回归基于P值选择变量</li>
<li>利用前向选择，后向选择和逐步选择法</li>
<li>利用随机森林，Xgboost或者对变量的重要性列表</li>
<li>利用Lasso回归</li>
<li>对所有变量做信息增益，然后选择前n个特征</li>
</ol>
</li>
<li><p><b><font color="blue"> Q19，相关性系数和方差有什么不同？</font></b></p>
</li>
<li><p><b>答：</b>相关性系数是协方差的标准形式。</p>
</li>
<li><p>协方差不容易进行比较。譬如，如果我们计算了工资和年龄的协方差，我们不能把他们进行比较，因为他们之间的scales不一样。为了解决这个情况，我们计算相关性系数，得到一个在-1和1之间的数值，就不用考虑它们之间不同的scales了。</p>
</li>
<li><p><b><font color="blue"> Q20，有没有可能求连续变量和分类变量之间的相关性系数吗？如果可以，怎么做？</font></b></p>
</li>
<li><p><b>答：</b>是的，我们可以利用ANCOVA(协方差分析)技术来获得连续性和分类变量之间的相关性系数。</p>
</li>
<li><p><b><font color="blue"> Q21，同样是基于树的算法，随机森林和梯度提升算法(GBM)之间有什么不同？</font></b></p>
</li>
<li><p><b>答：</b>最基本的不同是，随机森林利用bagging技术来做预测，GBM是用boosting技术来做预测。</p>
</li>
<li><p>在bagging技术当中，一个额数据集被随机抽样法分成了n个样本。之后利用单个学习方法对所有的样本进行建模。之后，最终的预测结果是通过对多个模型的预测值进行投票或者求均值的方法得到的。bagging是并行化的。在boosting当中，在第一轮的模型进行预测之后，这个算法就会把误分类模型的权值加大，这样就可以在随后的建模过程中对模型进行修正。这种顺序性的过程直到最后的预测值满足停止标准值为止。</p>
</li>
<li><p>随机森林通过减低方差改善了模型的准确率。树的生长和最大化方差的降幅没有关系。另外，GBM同时减低了bias和方差来改善模型的准确率。</p>
</li>
<li><p><b>了解更多：</b><a class="link"   href="https://www.analyticsvidhya.com/blog/2016/04/complete-tutorial-tree-based-modeling-scratch-in-python/" >Tree based modeling<i class="fas fa-external-link-alt"></i></a></p>
</li>
<li><p><b><font color="blue"> Q22，运行一个二分类树算法并不难。那你知道树是如何分割的吗？譬如，树是如何决定哪一个结点作为根节点，哪一个结点作为后继节点的吗？</font></b></p>
</li>
<li><p><b>答：</b>一个分类树的生成是基于基尼系数和结点的熵。简单的说，树算法会找到最适合把数据集划分成子节点的变量。</p>
</li>
<li><p>基尼系数是说，如果我们随机选择了两个群体，那么它们必须是属于同一类的，然后概率和为1。我们可以这样来计算基尼系数：</p>
<ol>
<li>计算子节点的基尼系数，用概率的成功和失败的平方和公式： (p^2+q^2)。</li>
<li>利用每个分割节点的权重基尼得分计算它们的基尼系数</li>
</ol>
</li>
<li><p>熵是衡量混乱程度的标准，即是否更适合分割：</p>
</li>
<li><p>这里的p和q分别代表节点成功和失败的概率。熵是0当一个节点是同质的时候。它最大的时候是当一个节点的两个分类各占50%。我们要求小的熵。</p>
</li>
<li><p><b><font color="blue"> Q23，你利用1000棵树建立了一个随机森林。你非常高兴因为你得到了训练错误率是0。但是，验证错误率是34.23。发生了什么事了？你训练的模型完美吗？</font></b></p>
</li>
<li><p><b>答：</b>这个模型是过拟合了。训练错误率是0意味着分类器在某程度上很好的拟合了你的训练数据，但是它对未知数据的预测性很差。所以，当我们用这个分类器来预测新数据时，它找不到新数据的模式并且返回了很高的错误率。在随机森林中，当我们用了超过了我们所需要的树时就会发生这种情况。所以，为了避免这种问题，我们就要用交叉验证来调节树的数量。</p>
</li>
<li><p><b><font color="blue"> Q24，你得到了一个数据集，他的变量数p&gt;样本数n。为什么OLS是一个不好的方法？你应该用什么技术来解决，为什么呢？</font></b></p>
</li>
<li><p><b>答：</b>在如此高纬度的数据集中，我们不可以利用经典的回归技术，因为假设都会失败。当p&gt;n时，我们不能计算一个最小二乘系数了，变量是非常大的时候，OSL就不可行了。</p>
</li>
<li><p>为了解决这种情况，我们可以利用惩罚性回归方法，像lasso，LARS，ridge这些能够收缩系数的方法来减少变量。更准确的说，ridge回归表现最好，当最小二乘因子有高方差的时候。</p>
</li>
<li><p>其它的方法还有取子集回归，前向逐步回归。</p>
</li>
<li><p><b><font color="blue"> Q25，什么是凸多边形(convex hull)？(思考一下SVM)</font></b></p>
</li>
<li><p><b>答：</b>在可分割的数据中，convex hull就是两组数据点的边界部分。一旦convex hull创建了，我们就可以得到最大边界超平面(MMH)，它是两个convex hulls之间的垂直平分线。MMH是一条能最大化的分割两组数据的直线。</p>
</li>
<li><p><b><font color="blue"> Q26，我们知道一位热编码会增加数据集的维度。但是，标签编码却不会，为什么呢？</font></b></p>
</li>
<li><p><b>答：</b>不要给这个问题给搞混了。它只是问你两个编码之间的差别。</p>
</li>
<li><p>利用一位热编码，数据集的维度(变量)就会增加因为它为分类变量的每一个level表现创建了一个新的变量。譬如，一个变量叫“颜色”。这个变量有3个level，红，蓝和绿。一位热编码就会产生3个新的变量<b>Color.Red, Color.Blue, Color.Green</b>，然后它们的值包含0和1。</p>
</li>
<li><p>在类标签编码中，分类变量被编成0和1，所以没有产生新的变量。类标签编码通常用在二分类变量当中。</p>
</li>
<li><p><b><font color="blue"> Q27，在时间序列的数据集中，你会用哪一种交叉验证方法，k折叠还是留一验证？</font></b></p>
</li>
<li><p><b>答：</b>都不是。</p>
</li>
<li><p>在时间序列问题中，k折叠会产生问题，因为可能有些模式在第4年和第5年中，但是没有在第3年中。重采样会分离这些，然后我们可以用去年来做验证，这是不对的。但是我们可以用5-fold的正向推理策略：</p>
<ul>
<li>fold 1: training [1], test[2]</li>
<li>fold 2: training[1,2], test[3]</li>
<li>fold 3: training[1,2,3], test[4]</li>
<li>fold 4: training[1,2,3,4], test[5]</li>
<li>fold 5: training[1,2,3,4,5], test[6]</li>
</ul>
</li>
<li><p>1,2,3,4,5,6代表年。</p>
</li>
<li><p><b><font color="blue"> Q28，给你一个数据集，但是它包含了缺失值的变量，且缺失值占了超过30%，譬如，50个变量，有8个变量的缺失值超过了30%。你会怎么处理？</font></b></p>
</li>
<li><p><b>答：</b>我们可以做以下处理：</p>
<ol>
<li>给缺失值赋一个唯一分类值，谁知道缺失值会不会破译一些趋势呢</li>
<li>我们可以直接删掉它们</li>
<li>或者，我们可以根据目标变量检查它们的分布，如果我们能找到模式，那么我们就赋于缺失值一个新的分类，否则就删掉它们。</li>
</ol>
</li>
<li><p><b><font color="blue"> Q29，亚马逊上的“浏览此商品的顾客也同时浏览。。。”这个推荐系统是什么算法的结果？</font></b></p>
</li>
<li><p><b>答：</b>推荐系统的核心思想是协同过滤。</p>
</li>
<li><p>协同过滤算法是通过用户行为来推荐物品。它是通过物品的交易记录，评价，选择以及购买信息来挖掘其他用户的行为。其他用户对物品的行为和爱好被用来当作给新用户推荐的依据。这个例子中，物品的特征是不知道的。</p>
</li>
<li><p><b>了解更多：</b><a class="link"   href="https://www.analyticsvidhya.com/blog/2015/10/recommendation-engines/" >Recommender System<i class="fas fa-external-link-alt"></i></a></p>
</li>
<li><p><b><font color="blue"> Q30，你怎么理解Type one and Type two error ?</font></b></p>
</li>
<li><p><b>答：</b>Type I error 是指统计学中的一类错误，意思是本来是错误的结论却被接受了。TypeII error 是指统计学中的二类错误，也就是本来是正确的错误却被拒绝了。简而言之，就是存伪和弃真。</p>
</li>
<li><p>在混淆矩阵当中，我们可以说Type I error就是当我们把实际的0预测分类为1，Type II error就是当我们把实际的1预测分类为0.</p>
</li>
<li><p><b><font color="blue"> Q31，你正在做一个分类的问题。为了达到验证的目标，你随机的从训练集抽样分为训练集和验证集。你对你的模型的泛化能力很有信心因为它的验证错误率非常高。但是，结果却是十分失望，你的测试准确率很低。到底是怎么了？</font></b></p>
</li>
<li><p><b>答：</b>在分类问题当中，我们应该常常用分层抽样而不是随机抽样。因为随机抽样并没有考虑到目标类别的比例。相反，分层抽样就会保证目标变量的分布也会保证样本的分布。</p>
</li>
<li><p><b><font color="blue"> Q32，你被要求利用R², adjusted R² 和tolerance来对回归模型进行评价。你会用哪一个作为标准？</font></b></p>
</li>
<li><p><b>答：</b>Tolerance(1 &#x2F; VIF)是用作多重共线性的预示。它是衡量一个预测中的变量的百分比不能给另一个预测占据的程度。Tolerance越大越好。</p>
</li>
<li><p>我们认为adjusted R² 和R² 来评估模型是截然不同的，因为当我们增加变量的时候，无论预测准确率有没有改进，R²都会增加 。但是adjusted R²仅仅是在增加变量而提高了模型的准确率的时候才会增加。很难去确定adjusted R²的通常值，因为它会随着数据的不同而不同。譬如，基因变异数据集中，低的adjusted R²值的模型依然会有比较不错的预测能力，但是对比于股票数据，低的adjusted R²值就会得到不好的模型。</p>
</li>
<li><p><b><font color="blue"> Q33，在k-means或者kNN中，我们计算相近点之间的距离是用欧几里得距离，为什么我们不用曼哈顿距离呢？</font></b></p>
</li>
<li><p><b>答：</b>我们不用曼哈顿距离是因为它真能垂直计算或者平行计算距离，它有维度限制。另外，欧几里得距离是用在任意空间当中计算的。因为，数据是可以表示在任何的维度空间当中的，所以欧几里得距离是更好的选择。</p>
</li>
<li><p>譬如，在一个棋盘上，象和车的移动就是通过曼哈顿距离来计算的，因为他们只能垂直做或者平行的移动。</p>
</li>
<li><p><b><font color="blue"> Q34，像一个5岁的孩子来介绍一下机器学习。</font></b></p>
</li>
<li><p><b>答：</b>非常简单。就像宝宝学走路一样。每一次的跌倒，他们都会无意识地学习并且意识到他们下一次就应该挺直的走而不是弯下来走。当下一次他们跌倒，他们会感到疼，他们会哭，但是，他们就不会再那样走了。为了避免疼痛，他们会更努力尝试。为了成功，他们会借助门后或者墙的力量或者任何接近他们的东西，这样他们就会站的更稳。</p>
</li>
<li><p>这是机器如何从它的周围环境学习和发展直觉的过程。</p>
</li>
<li><p>注：这道面试题就是考你能不能很好把复杂的文件简单化解释一下。</p>
</li>
<li><p><b><font color="blue"> Q35，我知道一个线性回归通常是用adjusted R²或者F值来评估的。那你如何评估一个罗吉斯特回归模型呢？</font></b></p>
</li>
<li><p><b>答：</b>我们可以用以下方法：</p>
<ol>
<li>因为逻辑斯特回归是用来预测概率的，我们可以用混淆矩阵的AUC-ROC曲线来评估它的性能。</li>
<li>另外，逻辑斯特回归当中类似adjusted R²的评估标准是AIC。AIC是通过模型系数的数量来惩罚模型的拟合标准。所以，我们要的是有最小AIC值的模型。</li>
<li>空异常(Null Deviance)说明模型仅仅通过截距来预测。数值越小，模型越好。残差(Residual deviance)说明模型添加了独立变量来进行预测的。数值越小，模型越好。</li>
</ol>
</li>
<li><p><b>了解更多：</b><a class="link"   href="https://www.analyticsvidhya.com/blog/2015/11/beginners-guide-on-logistic-regression-in-r/" >Logistic Regression<i class="fas fa-external-link-alt"></i></a></p>
</li>
<li><p><b><font color="blue"> Q36，有那么多的机器学习方法，给你一个数据集，你会决定用什么方法呢？</font></b></p>
</li>
<li><p><b>答：</b>你应该说，选择用哪一种机器学习方法取决于数据的类型。如果给你的数据集是一个线性的，那么线性回归算法最适合。如果你处理的是图像，语音数据，那么神经网络可以建一个更稳固的模型。</p>
</li>
<li><p>如果数据包含一些非线性的关系，那么boosting或者bagging算法就是一个选择。如果商业需求是建一个能够发布的模型，那么我们会用回归或者决策树模型(容易解释)而不是一些黑箱的方法，像SVM，GBM等等。</p>
</li>
<li><p>简单来说，没有绝对的方法，我们应该要认真的理解我们要用的算法。</p>
</li>
<li><p><b><font color="blue"> Q37，你认为把分类变量当成连续的变量来处理，会使得预测模型更好吗？</font></b></p>
</li>
<li><p><b>答：</b>为了得到更准确的预测，分类变量只有在它是有序的时候才被当成连续的变量，这样才合理。</p>
</li>
<li><p><b><font color="blue"> Q38，在机器学习当中，什么时候用到规则化技术(regularization)？</font></b></p>
</li>
<li><p><b>答：</b>当模型变得过拟合或者欠拟合时，规则化(Regularization)变得越来越重要了。这个技术在很多特征的模型中加入了一个惩罚项。所以，它试着把很多的变量的系数变成0以至于减少成本。这样可以帮助降低模型的复杂度从而可以提高模型的泛化能力。</p>
</li>
<li><p><b><font color="blue"> Q39，你怎么理解bias variance权衡？</font></b></p>
</li>
<li><p><b>答：</b>当模型能在数学上表示成3个成分的时候，这个错误就会出现。以下就是这些成分：</p>
</li>
<li><p>偏差错误是将预测的均值和真实值的差异程度量化了。一个高的偏差错误意味着我们得到的是一个欠拟合模型，它总是偏离了真实的趋势。而方差则是模型预测值和真实值的分散程度。高方差说明模型在训练数据上过拟合了，然后在新数据上预测很差。</p>
</li>
<li><p><b><font color="blue"> Q40，OLS(最小二乘法)对应线性回归，最大似然对应逻辑斯特回归。请解释这句话。</font></b></p>
</li>
<li><p><b>答：</b>简单来说，最小二乘法和最大似然都是对回归方法进行未知参数的预估的方法。</p>
</li>
<li><p>最小二乘法(Ordinary least square)用在线性回归中估计参数，目的是要真实值和预测值之间的距离最小。最大似然是帮助选择一个参数值，使得模型能够最大化产生观测数据。</p>
</li>
</ul>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><ul>
<li>你可能很轻松地回答了所有问题，但是我们的目标是要理解它们并且可以举一反三，理解透相关的问题。如果你没能很好应对这些问题，也不用担心，从现在开始学习，从现在开始关注学习的问题。</li>
<li>这些问题是为大家提供了初创公司的面试问题的概况。我相信这些问题引起了你深入学习机器学习的欲望，现在开始计划吧。</li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title>Object Detection Solution</title>
    <url>/2022/03/18/ML/Object-Detection-Solution/</url>
    <content><![CDATA[<ul>
<li><p><a class="link"   href="https://support.huaweicloud.com/intl/en-us/engineers-modelarts/modelarts_eval_0000.html" >Reference - HuaWei Clound - ModeArts,网站被删除<i class="fas fa-external-link-alt"></i></a></p>
</li>
<li><p>To analyze the performance of object detection model, there are two main parts to do: (1) 误检分析，False positive analysis; (2) 漏检分析，False negative analysis.</p>
</li>
</ul>
<p>同样的， 对于误检分析和漏检分析，我们可以把数据划分4个部分，（1）TP(标注漏标，但实际能够检测成功的目标)；（2）Positio false positive（预测结果类别正确，但是和GT的iou不满足；（3）Class false positive（预测结果和GT的iou满足，但是类别不正确）；（4）Background false postive（背景误检）</p>
<p>把TP加回原来的TP，然后就可以画一个饼图出来。</p>
<ol>
<li>如果类别误检占的比重高，建议训练的时候使用multi-scale，多尺度训练。<br><img src="/img/wuweiwu/obj_det_hw/01.png"></li>
<li>如果位置误检占的比重高，建议训练的时候关注IOU-loss，建议使用DIOU-loss。<br><img src="/img/wuweiwu/obj_det_hw/02.png"></li>
<li>如果背景误检占的比重高，建议训练的时候关注bounding box loss，通常用的是smooth-L1 loss，可以使用balanced loss。<br><img src="/img/wuweiwu/obj_det_hw/03.png"></li>
<li>如果数据中的类别框高比差异较大，比如人是竖立的矩形，车是横向的矩形，需要考虑到模型对框高比的敏感度，建议模型backbone采用FPN结构。<br><img src="/img/wuweiwu/obj_det_hw/04.png"></li>
<li>模型对检测目标的亮度敏感（如下图），建议使用DropBlock<br><img src="/img/wuweiwu/obj_det_hw/05.png"><br><img src="/img/wuweiwu/obj_det_hw/06.png"></li>
<li>模型对检测目标的清晰度敏感个（如下图），建议使用DropBlock</li>
<li>模型对检测目标的面积大小敏感，例如，检测头盔类别，而头盔在图片中的框大多数都是小的，另外一个类别是挖掘机，挖掘机在图片中的框大多数都是大的，建议使用balanced loss。<br><img src="/img/wuweiwu/obj_det_hw/07.png"><br><img src="/img/wuweiwu/obj_det_hw/08.png"></li>
</ol>
]]></content>
      <categories>
        <category>技能-修行-进步-ML</category>
      </categories>
      <tags>
        <tag>物体检测</tag>
      </tags>
  </entry>
  <entry>
    <title>FLOPs</title>
    <url>/2023/05/31/ML/FLOPs/</url>
    <content><![CDATA[<h1 id="NPU的性能参数分解"><a href="#NPU的性能参数分解" class="headerlink" title="NPU的性能参数分解"></a>NPU的性能参数分解</h1><p>注意相同 FLOPs 的两个模型其运行速度是会相差很多的，因为影响模型运行速度的两个重要因素只通过 FLOPs 是考虑不到的，比如 MAC（Memory Access Cost）和网络并行度；二是具有相同 FLOPs 的模型在不同的平台上可能运行速度不一样。</p>
<p>&#x3D;&#x3D;模型参数量的分析是为了了解内存占用情况，内存带宽其实比 FLOPs 更重要。目前的计算机结构下，单次内存访问比单次运算慢得多的多。&#x3D;&#x3D;对每一层网络，端侧设备需要：</p>
<p>从主内存中读取输入向量 &#x2F; feature map；<br>从主内存中读取权重并计算点积；<br>将输出向量或 feature map 写回主内存。</p>
<h2 id="双精度、单精度和半精度"><a href="#双精度、单精度和半精度" class="headerlink" title="双精度、单精度和半精度"></a>双精度、单精度和半精度</h2><p>CPU&#x2F;GPU 的浮点计算能力得区分不同精度的浮点数，分为双精度 FP64、单精度 FP32 和半精度 FP16。因为采用不同位数的浮点数的表达精度不一样，所以造成的计算误差也不一样，对于需要处理的数字范围大而且需要精确计算的科学计算来说，就要求采用双精度浮点数，而对于常见的多媒体和图形处理计算，32 位的单精度浮点计算已经足够了，对于要求精度更低的机器学习等一些应用来说，半精度 16 位浮点数就可以甚至 8 位浮点数就已经够用了。 对于浮点计算来说， CPU 可以同时支持不同精度的浮点运算，但在 GPU 里针对单精度和双精度就需要各自独立的计算单元。</p>
<h2 id="浮点计算能力"><a href="#浮点计算能力" class="headerlink" title="浮点计算能力"></a>浮点计算能力</h2><p>FLOPS：每秒浮点运算次数，每秒所执行的浮点运算次数，浮点运算包括了所有涉及小数的运算，比整数运算更费时间。下面几个是表示浮点运算能力的单位。我们一般常用 TFLOPS(Tops) 作为衡量 NPU&#x2F;GPU 性能&#x2F;算力的指标，比如海思 3519AV100 芯片的算力为 1.7Tops 神经网络运算性能。</p>
<p>MFLOPS（megaFLOPS）：等于每秒一佰万（&#x3D;10^6）次的浮点运算。<br>GFLOPS（gigaFLOPS）：等于每秒拾亿（&#x3D;10^9）次的浮点运算。<br>TFLOPS（teraFLOPS）：等于每秒万亿（&#x3D;10^12）次的浮点运算。<br>PFLOPS（petaFLOPS）：等于每秒千万亿（&#x3D;10^15）次的浮点运算。<br>EFLOPS（exaFLOPS）：等于每秒百亿亿（&#x3D;10^18）次的浮点运算。</p>
<h2 id="硬件利用率-Utilization"><a href="#硬件利用率-Utilization" class="headerlink" title="硬件利用率(Utilization)"></a>硬件利用率(Utilization)</h2><p>在这种情况下，利用率（Utilization）是可以有效地用于实际工作负载的芯片的原始计算能力的百分比。深度学习和神经网络使用相对数量较少的计算原语（computational primitives），而这些数量很少的计算原语却占用了大部分计算时间。矩阵乘法（MM）和转置是基本操作。MM 由乘法累加（MAC）操作组成。OPs&#x2F;s（每秒完成操作的数量）指标通过每秒可以完成多少个 MAC（每次乘法和累加各被认为是 1 个 operation，因此 MAC 实际上是 2 个 OP）得到。所以我们可以将利用率定义为实际使用的运算能力和原始运算能力的比值：<br>————————————————<br>版权声明：本文为CSDN博主「那个苏轼回不来了丶」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。<br>原文链接：<a class="link"   href="https://blog.csdn.net/qq_45763093/article/details/118519790" >https://blog.csdn.net/qq_45763093/article/details/118519790<i class="fas fa-external-link-alt"></i></a></p>
]]></content>
      <categories>
        <category>技能-修行-进步</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>FLOPs</tag>
      </tags>
  </entry>
  <entry>
    <title>物体识别算法-RCN, Fast-RCNN, Faster-RCNN和YOLO</title>
    <url>/2019/08/27/ML/Object-Detection-algo-RCNN-Fast-RCNN-Faster-RCNN-Yolo/</url>
    <content><![CDATA[<ul>
<li><p>Origin link, <a class="link"   href="https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e" > R-CNN, Fast R-CNN, Faster R-CNN, YOLO — Object Detection Algorithms
<i class="fas fa-external-link-alt"></i></a> </p>
</li>
<li><p><img src="/img/media-od-rcnn-yolo/view.jpg" alt="view" title="view"></p>
</li>
</ul>
<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><ul>
<li>计算机视觉是一个交叉学科，(自从CNN发展以来)它已经取得了极大的进步并且无人驾驶汽车已经占据了舞台中心。另一个计算机视觉的组成部分是物体检测。物体识别在姿态预估，车辆识别和无人监控等地方都提升了应用。物体检测算法和分类算法的不同是，我们尝试在图片中利用bounding box来定位出我们感兴趣的物体。另外，你可能在一张图片上不止画出一个bouding box， 你可能会画出多个bouding box来表示我们预先不知道的我们所感兴趣的不同物体。<br><img src="/img/media-od-rcnn-yolo/cat.png" alt="cat" title="cat"><br><img src="/img/media-od-rcnn-yolo/duck.png" alt="duck" title="duck"></li>
<li>解决物体检测问题，为什么不能直接建立一个标准的CNN+FC的网络结构呢？主要的原因是输出层的长度是可变的，而不是固定的，因为我们感兴趣的物体出现的次数也是可变的。一个最naive的方法来解决这个问题就是我们从图片上划出大小不同的区域，然后利用CNN来进行分类。而这个方法的难点是物体出现的区域是大小不同的，有着不同的长宽比。所以，你需要选择巨量的区域框，而这是一个指数增长的计算量。所以，像RCNN和YOLO这些算法就被提出用来找到这些区域框，并且是要快速的找到。</li>
</ul>
<h3 id="RCNN"><a href="#RCNN" class="headerlink" title="RCNN"></a>RCNN</h3><ul>
<li>为了绕过要选择巨量的区域框的问题，<a class="link"   href="https://arxiv.org/pdf/1311.2524.pdf" >Ross Girshick et al<i class="fas fa-external-link-alt"></i></a> ，提出了一个方法，我们利用<strong>selective serach</strong>这个算法从一张图片上提取出2k个区域框，我们称之为区域候选框。然后，我们就直接对这2k个区域候选框进行分类，而不是像之前的巨量的区域框了。<strong>selective serach</strong>算法步骤如下：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Selective search:</span><br><span class="line">1. Generate initial sub-segmentation, we generate many candidate regions</span><br><span class="line">2. Use greedy algorithm to recursively combine similar regions into larger ones </span><br><span class="line">3. Use the generated regions to produce the final candidate region proposals</span><br></pre></td></tr></table></figure>
<img src="/img/media-od-rcnn-yolo/rcnn.png" alt="rcnn" title="rcnn"></li>
<li>想了解更多的<strong>selective serach</strong>算法，请参考以下<a class="link"   href="https://ivi.fnwi.uva.nl/isis/publications/2013/UijlingsIJCV2013/UijlingsIJCV2013.pdf" >链接<i class="fas fa-external-link-alt"></i></a> 。得到的2k个区域候选框会被压缩成一个正方形，然后喂给了CNN网络，它的输出是一个4096维的特征向量。CNN就是一个特征提取器，输出层包含了图片的特征，然后这个特征层就会喂给了<strong>SVM</strong>用以分类。另外，为了预测候选框上是否存在物体，算法同样预测了4个groud truth的偏移量，一增加bouding box的精度。譬如，给定一个区域候选框，算法可能预测了人的存在，但是那个人的头一半是在候选框之外，所以这个偏移量是用来调整bouding box的。<br><img src="/img/media-od-rcnn-yolo/rcnn-2.png" alt="rcnn-2" title="rcnn-2"></li>
</ul>
<h4 id="RCNN的问题"><a href="#RCNN的问题" class="headerlink" title="RCNN的问题"></a>RCNN的问题</h4><ul>
<li>每张图片要训练2k次网络是一个非常耗时的操作</li>
<li>测试的时候每张图片需要花费47秒</li>
<li><strong>selective serach</strong>算法是一个固定的算法，所以，这个算法是没有学习的过程的。这样就容易产生一些差的区域候选框</li>
</ul>
<h3 id="Fast-RCNN"><a href="#Fast-RCNN" class="headerlink" title="Fast RCNN"></a>Fast RCNN</h3><p><img src="/img/media-od-rcnn-yolo/fast-rcnn.png" alt="fast rcnn" title="fast rcnn"></p>
<ul>
<li>RCNN相同的作者提出了解决RCNN本身存在的问题的算法， 我们称之为<strong>Faster RCNN</strong>。这个算法和RCNN有比较多的相同之处，不同的是Faster RCNN不是喂区域候选框给CNN网络，而是直接喂原图片，然后生成一个卷积feature map。从这个卷积feature map中，我们生产候选框，然后压缩成正方形，再利用ROI pooling 处理成固定大小的feature map，然后喂给了全连接层。输出的ROI特征向量，我们利用softmax层来预测候选框中的物体类别和bounding box的偏移量。</li>
<li>Fast RCNN比RCNN快的原因是你不需要每次都喂2k个候选框给CNN网络，进行2k次CNN的操作。而是一张图只进行一次CNN网络的操作，然后得到feature map。<br><img src="/img/media-od-rcnn-yolo/fast-rcnn-cmp.png" alt="fast rcnn cmp" title="fast rcnn cmp"></li>
<li>由以上对比图，我们可知fast-rcnn在训练和测试阶段都比rcnn提升了非常多的时间。当你看到fast rcnn的测试时间， 区域候选框的提取成为了fast rcnn的bottlenecks。这就是我们在faster rcnn中需要解决的问题。</li>
</ul>
<h3 id="Faster-RCNN"><a href="#Faster-RCNN" class="headerlink" title="Faster RCNN"></a>Faster RCNN</h3><p><img src="/img/media-od-rcnn-yolo/faster-rcnn.png" alt="faster rcnn" title="faster rcnn"></p>
<ul>
<li><strong>RCNN</strong>和<strong>Fast RCNN</strong>都使用了<strong>selective search</strong>算法来找出候选框。而<strong>selective search</strong>是一个非常耗时的过程，这严重影响了算法的性能。所以， <a class="link"   href="https://arxiv.org/pdf/1506.01497.pdf" >Shaoqing Ren et al<i class="fas fa-external-link-alt"></i></a> ，提出了一个物体检测算法，它剔除了<strong>selective search</strong>算法，而是让网络自己学习找多区域候选框。</li>
<li>和<strong>Fast RCNN</strong>相似，图片直接喂给CNN网络进行特征提取，得到feature map。然后我们不用<strong>selective search</strong>来提前候选框，而是利用另一个CNN网络来预测区域候选框。预测的区域候选框之后再通过ROI pooling层，得到输出的特征层，最后在这个特征层上做区域候选框的预测和bounding box的偏移量预测。<br><img src="/img/media-od-rcnn-yolo/rcnn-test-time.png" alt="RCNN Test Time" title="RCNN Test Time"></li>
<li>由以上图可见到，Faster RCNN比RCNN和Fast RCNN在测试速度方面都提升了非常多。所以，它甚至是可以用到实时的物体检测了。</li>
</ul>
<h3 id="YOLO-你只需看一次"><a href="#YOLO-你只需看一次" class="headerlink" title="YOLO-你只需看一次"></a>YOLO-你只需看一次</h3><iframe src="https://giphy.com/embed/10VZfgNU9YBPpK" width="480" height="360" frameBorder="0" class="giphy-embed" allowFullScreen></iframe><p><a class="link"   href="https://giphy.com/gifs/explosion-throwing-yolo-10VZfgNU9YBPpK" >via GIPHY<i class="fas fa-external-link-alt"></i></a></p>
- **RCNN系列**的检测算法都是利用区域来定位图片中的物体。CNN网络并没有看到完整的图片。但是，图片的某些部分是非常有可能存在物体的。YOLO和**RCNN系列**算法有很大的不同。在YOLO当中，单个CNN网络预测了bouding boxes和这些boxes中的物体的类别。
![yolo](/img/media-od-rcnn-yolo/yolo.png  "yolo")
- **YOLO**算法直接把一张图片分成**SxS**的网格，在每个网格中我们取m个bounding boxes。对每个bounding box，网络输出了类别概率和bounding box的偏移量。bounding boxes满足类别概率大于设定阈值的被用来定位图片中的物体。
- YOLO是比其他检测方法快一个数量级的（达到45/fps）。YOLO的限制是对小物体的识别比较难。譬如，它很男检测到一群鸟。这是由于算法的空间限制。
### 总结
- 计算机视觉会议每年都收到大量新的新颖的想法，我觉得我们会一步步的利用AI迈向了更好的检测表现。会越来越好。我希望这些你们能够清晰的读懂了这些概念。谢谢！
<iframe src="https://giphy.com/embed/DCHmHrxi4PG92" width="480" height="329" frameBorder="0" class="giphy-embed" allowFullScreen></iframe><p><a class="link"   href="https://giphy.com/gifs/batman-dislike-DCHmHrxi4PG92" >via GIPHY<i class="fas fa-external-link-alt"></i></a></p>]]></content>
      <categories>
        <category>技能-修行-进步-ML</category>
      </categories>
      <tags>
        <tag>translation</tag>
        <tag>物体识别</tag>
        <tag>Faster-RCNN</tag>
        <tag>RCNN</tag>
        <tag>YOLO</tag>
      </tags>
  </entry>
  <entry>
    <title>循环神经网络 Part 1-简介</title>
    <url>/2017/03/29/ML/RNN-tutorial-Part-1-Introduction/</url>
    <content><![CDATA[<ul>
<li><p>本文翻自<a class="link"   href="http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/" >WILDML<i class="fas fa-external-link-alt"></i></a></p>
</li>
<li><p>循环神经网络(RNNs)是一个目前在许多的自然语言处理(NLP)任务当中表现了出色的性能的模型。但是，除了它最近的火热之外，我能找到的关于RNNs模型的工作原理和实现的资源非常的有限。所以我才着手写了这个tutorial。我分了几个部分来写RNN的tutorial：</p>
<ol>
<li>RNNs简介(本tutorial)</li>
<li>用Python和Theano实现RNN</li>
<li>理解定时后向传播算法和梯度消失的问题</li>
<li>实现一个GRU&#x2F;LSTM RNN</li>
</ol>
</li>
<li><p>在本tutorial中我们实现了一个基于语言模型的RNN。这个语言模型应用包括两个部分：第一，它允许我们对一个可能出现在现实当中的抽象句子做一个评分，这个分数可以用来评判句子的语法和语义的准确性。这样的模型是典型的机器翻译系统当中的一个部分。第二，一个语言模型允许我们生成一个新的文本(我认为这是一个非常cool的应用)。在Shakespeare(莎士比亚)文章上训练一个语言模型，它可以生成一个新的类莎士比亚的文本。<a class="link"   href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" >Andrej Karpathy写的贴子<i class="fas fa-external-link-alt"></i></a>很好地阐明了基于RNN的字符level的语言模型能够干什么。</p>
</li>
<li><p>我假设你们对于基本的神经网络都熟悉了。如果你们并不熟悉的话，你可以先去看一下这个贴子,<a class="link"   href="http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/" >从零开始实现一个神经网络<i class="fas fa-external-link-alt"></i></a>，它会指导你非RNN背后神经网络的思想和实现。</p>
</li>
</ul>
<h2 id="什么是RNNs"><a href="#什么是RNNs" class="headerlink" title="什么是RNNs?"></a>什么是RNNs?</h2><ul>
<li><p>RNN的核心思想是利用序列信息。在传统的神经网络中，我们假设所有的inputs和outputs都是彼此独立的。但是在很多的任务当中，这是一个非常不合理的想法。如果你想预测一个句子当中的下一个单词，你最好能知道它前面跟着的是什么单词。RNNs当中的”recurrent”，递归，是因为它对于序列当中的每一个元素都执行了同样的任务，当前的output和之前的计算有依赖关系。RNNs的另一种理解就是它有一个“记忆体”记住了到目前为止所计算的信息。理论上RNNs能够利用任意长序列上的信息，但是实际上它们只是局限于能回看前面几步上的信息(以后会更多)。这就是一个典型的RNN模型图：</p>
</li>
<li><p><img src="/img/tf_tutorial/05_RNN/rnn.jpg" title="http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/09/rnn.jpg"></p>
</li>
<li><p>上面这张图就是RNN展开成全连接的网络图。展开的意思就是我们把所有的序列写出来。譬如，如果我们关注的序列是包含5个单词的，那么展开的网络图就是5层的网络，每一层对应一个单词。图中的公式参数意义如下：</p>
<ul>
<li>$x_t$是在时间$t$时的输入。譬如，$x_1$可以是序列中对应到第二个单词的one_hot向量。($X_0$是第一个)</li>
<li>$s_t$是在时间$t$时的隐层状态。它是网络的“记忆体”。$s_t$是基于前一个隐层状态和当前的输入计算出来的:</li>
<li><img src="/img/tf_tutorial/05_RNN/eq1.jpg"> 这个函数f通常是一个非线性函数，如tanh或者ReLU。$s_{-1}$是用来计算第一个隐层的，通常初始化为全0。</li>
<li>$o_t$是在步骤$t$时的输出。譬如，如果我们想去预测句子当中的下一个单词，结果会是一个概率向量，它对应着我们字典中的每一个单词。$o_t&#x3D;softmax(V*s_t)$</li>
</ul>
</li>
<li><p>以下是一些我们需要注意的地方：</p>
<ul>
<li>你可以把$s_t$看作是网络的记忆体。$s_t$捕获了前一步所发生的信息。输出$o_t$是单独基于时间$t$时的记忆算出来的。像以上简单提到的，实际上它有点复杂，因为$s_t$一般不能够捕获太多次之前的信息。</li>
<li>不想传统的深度学习网络，每一层都用了不同的参数，RNN当中的每一层是共享一组参数的($U,V,W$)。这也说明了我们每一层都是做了相同的操作的，只是每次的inputs不同了。这就大大减少了我们要学习的参数的数量。</li>
<li>上面的图当中每一层都有一个输出，但是有些任务当中这些输出并不是必须的。譬如，在做句子的情感分析当中，我们可能就是需要最后一个输出而已，而不是每一层的outputs。简单来说，我们不是每一层都需要输入。RNN的主要特点是它的的隐层状态，它捕获了序列当中的一些信息。</li>
</ul>
</li>
</ul>
<h2 id="RNN能够干什么？"><a href="#RNN能够干什么？" class="headerlink" title="RNN能够干什么？"></a>RNN能够干什么？</h2><ul>
<li>RNN在许多的自然语言处理(NLP)任务中当中获得非常好的结果。这里我不得不提到的一个常用到的RNN模型就是<a class="link"   href="https://en.wikipedia.org/wiki/Long_short_term_memory" >LSTMs<i class="fas fa-external-link-alt"></i></a>。相比普通的RNN模型，它能更好的捕获到长期的依赖信息。但是不要担心，LSTMs也是我们这个tutorial中的RNN差不多，只是它的隐层状态的计算会有所不同。我们会在下一个贴子当中详解LSTMs。这里我们只是列举一些RNN在NLP当中应用的例子。</li>
</ul>
<h2 id="语言建模和生成文本"><a href="#语言建模和生成文本" class="headerlink" title="语言建模和生成文本"></a>语言建模和生成文本</h2><ul>
<li>给定一个序列的单词，我们要预测当给定前一个单词时，下一个单词会出现的概率。语言模型会让我们评判一个什么序列的单词如何才可能是一个句子。这也是机器翻译当中的一个重要的输入(通常概率高的句子都是正确的)。预测下一个单词的另一个作用是我们会得到一个生成模型，这个模型可以通过从输出概率当中进行采样来生成新的文本。利用我们的训练数据，我们可以生成各种各样的单词序列。在语言模型当中，我们的输入通常是一个单词的序列(譬如加密成一个one-hot向量)，然后我们的输出就是预测的单词的序列。当我们训练网络时，我们把$o_t&#x3D;x_{t+1}$，因为我们希望时间$t$时的输出是真实的下一个单词。</li>
<li>语言模型和生成文本的相关论文：<ul>
<li><a class="link"   href="http://www.fit.vutbr.cz/research/groups/speech/publi/2010/mikolov_interspeech2010_IS100722.pdf" >Recurrent neural network based language model<i class="fas fa-external-link-alt"></i></a></li>
<li><a class="link"   href="http://www.fit.vutbr.cz/research/groups/speech/publi/2011/mikolov_icassp2011_5528.pdf" >Extensions of Recurrent neural network based language model<i class="fas fa-external-link-alt"></i></a></li>
<li><a class="link"   href="http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Sutskever_524.pdf" >Generating Text with Recurrent Neural Networks<i class="fas fa-external-link-alt"></i></a></li>
</ul>
</li>
</ul>
<h2 id="机器翻译"><a href="#机器翻译" class="headerlink" title="机器翻译"></a>机器翻译</h2><ul>
<li>机器模型和语言模型非常的相似，它的输入也是一种语种的单词序列(譬如德语)。我们想要输出的是目标语种的单词序列(譬如英语)。一个主要的不同就是我们的输出是当所有的输入都计算过了才开始的，因为我们翻译的句子中的第一个单词是需要所有的输入序列的信息才能确定的。</li>
<li><img src="/img/tf_tutorial/05_RNN/RNN_for_machine_translation.png" title="RNN for Machine Translation. Image Source: http://cs224d.stanford.edu/lectures/CS224d-Lecture8.pdf"></li>
<li>机器翻译的相关论文：<ul>
<li><a class="link"   href="http://www.aclweb.org/anthology/P14-1140.pdf" >A Recursive Recurrent Neural Network for Statistical Machine Translation<i class="fas fa-external-link-alt"></i></a></li>
<li><a class="link"   href="http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf" >Sequence to Sequence Learning with Neural Networks<i class="fas fa-external-link-alt"></i></a></li>
<li><a class="link"   href="http://research.microsoft.com/en-us/um/people/gzweig/Pubs/EMNLP2013RNNMT.pdf" >Joint Language and Translation Modeling with Recurrent Neural Networks<i class="fas fa-external-link-alt"></i></a></li>
</ul>
</li>
</ul>
<h2 id="语音识别"><a href="#语音识别" class="headerlink" title="语音识别"></a>语音识别</h2><ul>
<li>给定一个从声波中得到的声学信号的输入序列，我们能够利用它们的概率来预测一个序列的语音片段。</li>
<li>语音识别的相关论文：<ul>
<li><a class="link"   href="http://www.jmlr.org/proceedings/papers/v32/graves14.pdf" >Towards End-to-End Speech Recognition with Recurrent Neural Networks<i class="fas fa-external-link-alt"></i></a></li>
</ul>
</li>
</ul>
<h2 id="生成图片描述"><a href="#生成图片描述" class="headerlink" title="生成图片描述"></a>生成图片描述</h2><ul>
<li>结合卷积神经网络(CNN)和RNN的模型能够对没标签的图片生成描述。这是一个非常惊人的工作。这个组合模型还能把图片当中找到的特征和生成的单词一一对应。</li>
<li><img src="/img/tf_tutorial/05_RNN/cnn-rnn.png" title="Deep Visual-Semantic Alignments for Generating Image Descriptions. Source: http://cs.stanford.edu/people/karpathy/deepimagesent/"></li>
</ul>
<h2 id="训练RNNs"><a href="#训练RNNs" class="headerlink" title="训练RNNs"></a>训练RNNs</h2><ul>
<li>训练RNN和训练传统的神经网络很相似。我们也用到后向传播(backpropagtion)算法，但是有小小不同。因为参数在整个网络中的每一层是共享的，而每一层输出的梯度不仅仅依赖于当前这一步的计算，还依赖前一步的计算。譬如，为了计算$t&#x3D;4$时的梯度，我们需要往后传播3层，并且把它们的梯度加起来。这就是定时后向传播(BPTT)。如果这还是没有那么清晰的话，不要担心，我们之后还会有更多的详情。现在，我们要注意到用BPTT来训练普通的RNNs，因为梯度消失的问题，所以很难学习到长期的依赖信息(譬如，每一层之间的信息相差甚远)。但还是有一些模型来解决这个问题的，像特定的RNNs模型(LSTMs)就是特别设计用来解决这些问题的。</li>
</ul>
<h2 id="RNNs扩展"><a href="#RNNs扩展" class="headerlink" title="RNNs扩展"></a>RNNs扩展</h2><ul>
<li>经过研究者们那么多年的研究，他们已经发展了更为复杂的RNNs模型来解决普通的RNN模型的一些不足。我们接下来的贴子会讲到更多的细节，但是我想在本部分中做一个简单的总结，这样我们才能对RNNs模型的分类更为熟悉。</li>
<li>**双向RNNs(Bidirectional RNNs)**就是基于这样的思想：时间$t$的输出可能不仅仅依赖鱼序列当中的前面的元素，还包括了未来的元素。譬如，预测一个序列当中的缺失的单词，你可能要看到前面和后边的内容。双向RNNs非常容易。他们就是把两个RNNs堆叠在一起。输出是基于两个RNNs模型的隐层计算得到的。</li>
<li><img src="/img/tf_tutorial/05_RNN/bidirectional-rnn.png"></li>
<li><strong>深度(Bidirectional)RNNs</strong>和双向RNNs很相似，就是我们现在每一个时间点有多层。实际上这给了我们一个更高的学习容量(但是我们也需要大量的训练数据)。</li>
<li><img src="/img/tf_tutorial/05_RNN/deep-bi-rnn.png"></li>
<li><strong>LSTM网络</strong>现在非常流行。LSTMs和RNNs在架构上没什么大的不同，但是它们利用了不同的函数来计算隐层状态。LSTMs中的记忆体叫做<strong>cells</strong>，你可以把它们当成一个黑盒子，它吃进了前一个状态$h_{t-1}$和当前的输入$x_t$。这些cells内部决定哪些应该保持，哪些应该删除。然后它们就会合并前一个状态，当前状态和当前的输入。结果证明了这类型的units非常有效地捕获了长期的依赖信息。LSTMs一开始可能很疑惑，但是如果你感兴趣的话，可以读一下<a class="link"   href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" >这篇详细的解释<i class="fas fa-external-link-alt"></i></a>。</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li>目前还是理解的不错的。我希望你现在对RNNs已有了一个基本的理解。在下一个贴子中我们会利用Python和Theano实现我们RNN语言模型的第一个版本，请在留言区留下你的问题。</li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>循环神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>正则表达式课堂笔记</title>
    <url>/2014/10/18/ML/RegularExpression/</url>
    <content><![CDATA[<h2 id="写在开头的话"><a href="#写在开头的话" class="headerlink" title="写在开头的话"></a>写在开头的话</h2><p>题：最近我在<a class="link"   href="http://www.dataguru.cn/" >炼数成金社区<i class="fas fa-external-link-alt"></i></a>上《R七种武器之网络爬虫RCurl》这一门课，然后三周的短课程在最后一周就提到了正则表达式。刚好我在大二的时候有听过传智播客的老师讲过，还有点印象，听起课来还蛮舒服的，倒也觉得这个东西还是挺重要的，它就像是一个模式，用以解决一类事情，如过滤邮箱地址等，故我现在做个笔记，以博客的形式。</p>
<h2 id="对一个新事物学习的模式"><a href="#对一个新事物学习的模式" class="headerlink" title="对一个新事物学习的模式"></a>对一个新事物学习的模式</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(What is it)是什么?</span><br><span class="line">(How to <span class="keyword">do</span> it)怎么做?</span><br><span class="line">(Why we need it)为什么?</span><br></pre></td></tr></table></figure>
<h2 id="正则表达式是什么？"><a href="#正则表达式是什么？" class="headerlink" title="正则表达式是什么？"></a>正则表达式是什么？</h2><h3 id="字符串的操作-R语言"><a href="#字符串的操作-R语言" class="headerlink" title="字符串的操作(R语言)"></a>字符串的操作(R语言)</h3><ul>
<li>由于正则表达式是字符串的一些规则，所以我们首先温习一下字符串的基本操作<ul>
<li>赋值   </li>
<li>长度：nchar、字符串个数：length</li>
<li>替换：chartr(原始字符、替换字符、字符串)</li>
<li>连接：paste 参数sep，collapse</li>
<li>切割：strsplit</li>
<li>比较：&gt;、&lt;、&#x3D;&#x3D;、！&#x3D;</li>
<li>并集、交集、补集：union,intersect,setdiff</li>
<li>截取：sustr，substring</li>
<li>匹配：match，pmatch，charmatch  <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 赋值</span></span><br><span class="line">hello &lt;- <span class="string">&quot;Hello World!&quot;</span></span><br><span class="line">hello</span><br><span class="line">[1] <span class="string">&quot;Hello World!&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 长度:nchar</span></span><br><span class="line">nchar(hello)</span><br><span class="line">[1] 12</span><br><span class="line"><span class="comment"># 字符串个数:length</span></span><br><span class="line">hello2 &lt;- c(<span class="string">&quot;Hello&quot;</span>,<span class="string">&quot;World!&quot;</span>)</span><br><span class="line">length(hello2)</span><br><span class="line">[1] 2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 替换：chartr(原始字符、替换字符、字符串)</span></span><br><span class="line"><span class="comment"># 原始字符和替换字符的长度一一对应，如例：e对1，l对2，o对3</span></span><br><span class="line">chartr(<span class="string">&quot;elo&quot;</span>,<span class="string">&quot;123&quot;</span>,hello)</span><br><span class="line">[1] <span class="string">&quot;H1223 W3r2d!&quot;</span></span><br><span class="line">hello</span><br><span class="line">[1] <span class="string">&quot;Hello World!&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 连接：paste 参数sep，collapse</span></span><br><span class="line"><span class="comment"># sep=&quot;&quot;表示字符串间无缝结合</span></span><br><span class="line"><span class="built_in">paste</span>(<span class="string">&quot;Hello&quot;</span>,<span class="string">&quot;World!&quot;</span>,sep=<span class="string">&quot;&quot;</span>)</span><br><span class="line">[1] <span class="string">&quot;HelloWorld!&quot;</span></span><br><span class="line"><span class="comment"># 不设sep参数，默认字符串间是空格</span></span><br><span class="line"><span class="built_in">paste</span>(<span class="string">&quot;Hello&quot;</span>,<span class="string">&quot;World!&quot;</span>)</span><br><span class="line">[1] <span class="string">&quot;Hello World!&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 字符串切割strsplit</span></span><br><span class="line"><span class="comment"># 第一个参数为要切割的字符串，第二个参数为字符串的切割值</span></span><br><span class="line">str=<span class="string">&quot;My/name/is/Tim/Chan!&quot;</span></span><br><span class="line">strsplit(str,<span class="string">&quot;/&quot;</span>)</span><br><span class="line">[[1]]</span><br><span class="line">[1] <span class="string">&quot;My&quot;</span>    <span class="string">&quot;name&quot;</span>  <span class="string">&quot;is&quot;</span>    <span class="string">&quot;Tim&quot;</span>   <span class="string">&quot;Chan!&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 字符串的比较</span></span><br><span class="line"><span class="comment"># 字符串的比较准则：从左到右逐个字符按照字母表顺序一一对比</span></span><br><span class="line">a = <span class="string">&quot;a&quot;</span></span><br><span class="line">b = <span class="string">&quot;b&quot;</span></span><br><span class="line">a &gt; b</span><br><span class="line">[1] FALSE</span><br><span class="line">b &gt; a</span><br><span class="line">[1] TRUE</span><br><span class="line">c = <span class="string">&quot;ab&quot;</span></span><br><span class="line">d = <span class="string">&quot;aaaaaaa&quot;</span></span><br><span class="line">c &gt;d</span><br><span class="line">[1] TRUE</span><br><span class="line">a == b</span><br><span class="line">[1] FALSE</span><br><span class="line"></span><br><span class="line"><span class="comment"># 并集、交集、补集：union,intersect,setdiff</span></span><br><span class="line"><span class="comment"># 高中集合知识温习，假设有a,b两个集合</span></span><br><span class="line"><span class="comment"># 并集：所有ａ集合和所有ｂ集合的元素组成的新的集合，重复元素只出现一次</span></span><br><span class="line"><span class="comment"># 交集：取既在a集合也在b集合的元素组成的集合</span></span><br><span class="line"><span class="comment"># 补集：setdiff(a,b)，取在a中的元素但不在b中的元素组成的集合</span></span><br><span class="line">a = c(<span class="string">&quot;a&quot;</span>,<span class="string">&quot;b&quot;</span>,<span class="string">&quot;c&quot;</span>,<span class="string">&quot;d&quot;</span>,<span class="string">&quot;e&quot;</span>)</span><br><span class="line">b = c(<span class="string">&quot;c&quot;</span>,<span class="string">&quot;d&quot;</span>,<span class="string">&quot;e&quot;</span>,<span class="string">&quot;f&quot;</span>,<span class="string">&quot;g&quot;</span>)</span><br><span class="line"><span class="comment"># 取并集</span></span><br><span class="line">union(a,b)</span><br><span class="line">[1] <span class="string">&quot;a&quot;</span> <span class="string">&quot;b&quot;</span> <span class="string">&quot;c&quot;</span> <span class="string">&quot;d&quot;</span> <span class="string">&quot;e&quot;</span> <span class="string">&quot;f&quot;</span> <span class="string">&quot;g&quot;</span></span><br><span class="line"><span class="comment"># 取交集</span></span><br><span class="line">intersect(a,b)</span><br><span class="line">[1] <span class="string">&quot;c&quot;</span> <span class="string">&quot;d&quot;</span> <span class="string">&quot;e&quot;</span></span><br><span class="line"><span class="comment"># 取补集</span></span><br><span class="line">setdiff(a,b)</span><br><span class="line">[1] <span class="string">&quot;a&quot;</span> <span class="string">&quot;b&quot;</span></span><br><span class="line">setdiff(b,a)</span><br><span class="line">[1] <span class="string">&quot;f&quot;</span> <span class="string">&quot;g&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 截取：substr,substring</span></span><br><span class="line"><span class="comment"># substr(x, start, stop)</span></span><br><span class="line"><span class="comment"># substring(text, first, last = 1000000L)</span></span><br><span class="line"><span class="comment"># 准备字符串</span></span><br><span class="line">strs</span><br><span class="line">[1] <span class="string">&quot;abcdefghijklmnopqrstuvwxyz&quot;</span></span><br><span class="line"><span class="comment"># 第一种比较，没有不同</span></span><br><span class="line">substr(strs,2,5)</span><br><span class="line">[1] <span class="string">&quot;bcde&quot;</span></span><br><span class="line">substring(strs,2,5)</span><br><span class="line">[1] <span class="string">&quot;bcde&quot;</span></span><br><span class="line"><span class="comment"># 第二种比较</span></span><br><span class="line"><span class="comment"># substring截取的字符串分布对应位置：2-5,3-6,4-7,5-8</span></span><br><span class="line"><span class="comment"># 而substr只处理第一个位置2-5</span></span><br><span class="line">substring(strs,2:5,5:8)</span><br><span class="line">[1] <span class="string">&quot;bcde&quot;</span> <span class="string">&quot;cdef&quot;</span> <span class="string">&quot;defg&quot;</span> <span class="string">&quot;efgh&quot;</span></span><br><span class="line">substr(strs,2:5,5:8)</span><br><span class="line">[1] <span class="string">&quot;bcde&quot;</span></span><br><span class="line"><span class="comment"># 第三种比较，没有指定stop参数</span></span><br><span class="line"><span class="comment"># substring默认为渠道字符串末尾</span></span><br><span class="line"><span class="comment"># substr则报错</span></span><br><span class="line">substring(strs,2)</span><br><span class="line">[1] <span class="string">&quot;bcdefghijklmnopqrstuvwxyz&quot;</span></span><br><span class="line">substr(strs,2)</span><br><span class="line">Error <span class="keyword">in</span> substr(strs, 2) : argument <span class="string">&quot;stop&quot;</span> is missing, with no default</span><br><span class="line"></span><br><span class="line"><span class="comment"># 匹配 match,pmatch,charmatch</span></span><br><span class="line"><span class="comment"># matcht：完整匹配</span></span><br><span class="line"><span class="comment"># pmatch，charmatch部分匹配</span></span><br><span class="line">	</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<p>More info:<a class="link"   href="http://baike.baidu.com/view/94238.htm?fr=aladdin" >百度百科<i class="fas fa-external-link-alt"></i></a></p>
<h3 id="正则表达式的简单定义"><a href="#正则表达式的简单定义" class="headerlink" title="正则表达式的简单定义"></a>正则表达式的简单定义</h3><ul>
<li>正则表达式主要是对字符串操作的一系列规则。</li>
</ul>
<h3 id="正则表达式入门"><a href="#正则表达式入门" class="headerlink" title="正则表达式入门"></a>正则表达式入门</h3><ul>
<li>:转义字符</li>
<li>.:除了换行以外的任意字符</li>
<li>^:一行字符串的起始</li>
<li>$:一行字符串的结束</li>
<li>*:零个或多个字符</li>
<li>+:一个或多个字符</li>
<li>?:零个或者一个字符</li>
<li>保留字符都需要在前面加上转义字符来表示</li>
</ul>
<h2 id="正则表达式怎么实现？"><a href="#正则表达式怎么实现？" class="headerlink" title="正则表达式怎么实现？"></a>正则表达式怎么实现？</h2><h2 id="为什么我们需要正则表达式？"><a href="#为什么我们需要正则表达式？" class="headerlink" title="为什么我们需要正则表达式？"></a>为什么我们需要正则表达式？</h2><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2>]]></content>
      <categories>
        <category>技能-修行-进步</category>
      </categories>
      <tags>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title>Training your own datasets with Darknet</title>
    <url>/2021/11/07/ML/Training-your-own-datasets-with-Darknet/</url>
    <content><![CDATA[<ul>
<li>date, 2018-11-07 14:48:57</li>
</ul>
<h3 id="Data-collection-amp-labeling"><a href="#Data-collection-amp-labeling" class="headerlink" title="Data collection &amp; labeling"></a>Data collection &amp; labeling</h3><ol>
<li>Use your own way to collect your data, usually the size of image doesn’t matter. It’ll better to be fit in (48, 48) ~ (1280, 720)</li>
<li>When you finished your own dataset, you should label your images.<ul>
<li>tools : <a class="link"   href="https://github.com/tzutalin/labelImg" >labelImage<i class="fas fa-external-link-alt"></i></a> </li>
<li>Usage : refer to the github</li>
</ul>
</li>
</ol>
<hr>
<h3 id="Install-Darknet"><a href="#Install-Darknet" class="headerlink" title="Install Darknet"></a>Install Darknet</h3><ol>
<li><a class="link"   href="https://pjreddie.com/darknet/install/" >Darknet Installation<i class="fas fa-external-link-alt"></i></a> , compile with GPU and Opencv if it’s necessary</li>
</ol>
<hr>
<h3 id="Create-VOC-format-dataset"><a href="#Create-VOC-format-dataset" class="headerlink" title="Create VOC format dataset"></a>Create VOC format dataset</h3><ul>
<li><p>(1)  In the root of darknet, create a folder names ‘VOCdevkit’, and create a folder names what you want to name your dataset. like ‘VOC2019_oppo’, which has to start with ‘VOC’.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd /path/darknet</span><br><span class="line">mkdir VOCdevkit</span><br><span class="line">cd VOCdevkit</span><br><span class="line">mkdir VOC2019_oppo</span><br></pre></td></tr></table></figure>
</li>
<li><p>(2) Directory like this :</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">└── VOCdevkit</span><br><span class="line">    └── VOC2019_oppo</span><br><span class="line">        ├── Annotations</span><br><span class="line">        ├── ImageSets</span><br><span class="line">        │   └── Main</span><br><span class="line">        └── JPEGImages</span><br></pre></td></tr></table></figure></li>
<li><p>(3) Move the images into <strong>JPEGImages</strong> and xml files into <strong>Annotations</strong>.</p>
</li>
<li><p>(4) Split the train, val and test, create a py script like belows</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">## split_train_val.py</span></span><br><span class="line"><span class="keyword">import</span> os,random</span><br><span class="line"></span><br><span class="line"><span class="comment"># read the filenames from a file</span></span><br><span class="line">dirname = <span class="string">&#x27;./Annotations&#x27;</span></span><br><span class="line">files = [f[:-<span class="number">4</span>] <span class="keyword">for</span> f <span class="keyword">in</span> os.listdir(dirname) <span class="keyword">if</span> f[-<span class="number">4</span>:].lower() == <span class="string">&#x27;.xml&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># random divide  </span></span><br><span class="line">trainval = random.sample(files, <span class="built_in">len</span>(files)//<span class="number">2</span>)</span><br><span class="line">test = [f <span class="keyword">for</span> f <span class="keyword">in</span> files <span class="keyword">if</span> f <span class="keyword">not</span> <span class="keyword">in</span> trainval]</span><br><span class="line"></span><br><span class="line"><span class="comment"># random divide </span></span><br><span class="line">train = random.sample(trainval, <span class="built_in">len</span>(trainval)//<span class="number">2</span>)</span><br><span class="line">val = [f <span class="keyword">for</span> f <span class="keyword">in</span> trainval <span class="keyword">if</span> f <span class="keyword">not</span> <span class="keyword">in</span> train]</span><br><span class="line"></span><br><span class="line"><span class="comment"># save to txt file</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">list2txt</span>(<span class="params">arr, fname</span>):</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(fname+<span class="string">&#x27;.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> a <span class="keyword">in</span> arr:</span><br><span class="line">            f.write(a+<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line">list2txt(trainval, <span class="string">&#x27;trainval&#x27;</span>)</span><br><span class="line">list2txt(test, <span class="string">&#x27;test&#x27;</span>)</span><br><span class="line">list2txt(train, <span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">list2txt(val, <span class="string">&#x27;val&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>then run the script, you will get four files, then move them into the <strong>ImageSets&#x2F;Main&#x2F;</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python split_train_val.py</span><br><span class="line"></span><br><span class="line">mv test.txt ImageSets/Main/</span><br><span class="line">mv train.txt ImageSets/Main/</span><br><span class="line">mv trainval.txt ImageSets/Main/</span><br><span class="line">mv val.txt ImageSets/Main/</span><br></pre></td></tr></table></figure></li>
<li><p>(5) Now you have the directory like this</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">└── VOCdevkit</span><br><span class="line">    └── VOC2019_oppo</span><br><span class="line">        ├── Annotations</span><br><span class="line">        ├── ImageSets</span><br><span class="line">        │   └── Main</span><br><span class="line">        │       ├── test.txt</span><br><span class="line">        │       ├── train.txt</span><br><span class="line">        │       ├── trainval.txt</span><br><span class="line">        │       └── val.txt</span><br><span class="line">        ├── JPEGImages</span><br><span class="line">        └── split_train_val.py</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
<hr>
<h3 id="Use-the-voc-labe-to-generate-Image-path-list"><a href="#Use-the-voc-labe-to-generate-Image-path-list" class="headerlink" title="Use the voc_labe to generate Image path list"></a>Use the voc_labe to generate Image path list</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd /path/darknet</span><br><span class="line">touch voc_label.py</span><br><span class="line">vim voc_label.py</span><br></pre></td></tr></table></figure>
<ul>
<li>(1) create a python script<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">## name voc_label.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> xml.etree.ElementTree <span class="keyword">as</span> ET</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> os <span class="keyword">import</span> listdir, getcwd</span><br><span class="line"><span class="keyword">from</span> os.path <span class="keyword">import</span> join</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. change to your labels</span></span><br><span class="line"><span class="comment"># oppo for example</span></span><br><span class="line"><span class="comment"># 4 classes, A5s, A7, reno, reno10x</span></span><br><span class="line">sets = [(<span class="string">&#x27;2019_oppo&#x27;</span>, <span class="string">&#x27;train&#x27;</span>), (<span class="string">&#x27;2019_oppo&#x27;</span>, <span class="string">&#x27;val&#x27;</span>), (<span class="string">&#x27;2019_oppo&#x27;</span>, <span class="string">&#x27;test&#x27;</span>)]</span><br><span class="line">classes = [<span class="string">&#x27;A5s&#x27;</span>, <span class="string">&#x27;A7&#x27;</span>, <span class="string">&#x27;reno&#x27;</span>, <span class="string">&#x27;reno10x&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convert</span>(<span class="params">size, box</span>):</span><br><span class="line">    dw = <span class="number">1.</span>/(size[<span class="number">0</span>])</span><br><span class="line">    dh = <span class="number">1.</span>/(size[<span class="number">1</span>])</span><br><span class="line">    x = (box[<span class="number">0</span>] + box[<span class="number">1</span>])/<span class="number">2.0</span> - <span class="number">1</span></span><br><span class="line">    y = (box[<span class="number">2</span>] + box[<span class="number">3</span>])/<span class="number">2.0</span> - <span class="number">1</span></span><br><span class="line">    w = box[<span class="number">1</span>] - box[<span class="number">0</span>]</span><br><span class="line">    h = box[<span class="number">3</span>] - box[<span class="number">2</span>]</span><br><span class="line">    x = x*dw</span><br><span class="line">    w = w*dw</span><br><span class="line">    y = y*dh</span><br><span class="line">    h = h*dh</span><br><span class="line">    <span class="keyword">return</span> (x,y,w,h)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convert_annotation</span>(<span class="params">year, image_id</span>):</span><br><span class="line">    <span class="comment"># 2. change to your path </span></span><br><span class="line">    in_file = <span class="built_in">open</span>(<span class="string">&#x27;/home/ares2/darknet/VOCdevkit/VOC%s/Annotations/%s.xml&#x27;</span>%(year, image_id))</span><br><span class="line">    out_file = <span class="built_in">open</span>(<span class="string">&#x27;/home/ares2/darknet/VOCdevkit/VOC%s/labels/%s.txt&#x27;</span>%(year, image_id), <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line">    tree=ET.parse(in_file)</span><br><span class="line">    root = tree.getroot()</span><br><span class="line">    size = root.find(<span class="string">&#x27;size&#x27;</span>)</span><br><span class="line">    w = <span class="built_in">int</span>(size.find(<span class="string">&#x27;width&#x27;</span>).text)</span><br><span class="line">    h = <span class="built_in">int</span>(size.find(<span class="string">&#x27;height&#x27;</span>).text)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> obj <span class="keyword">in</span> root.<span class="built_in">iter</span>(<span class="string">&#x27;object&#x27;</span>):</span><br><span class="line">        difficult = obj.find(<span class="string">&#x27;difficult&#x27;</span>).text</span><br><span class="line">        cls = obj.find(<span class="string">&#x27;name&#x27;</span>).text</span><br><span class="line">        <span class="keyword">if</span> cls <span class="keyword">not</span> <span class="keyword">in</span> classes <span class="keyword">or</span> <span class="built_in">int</span>(difficult)==<span class="number">1</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        cls_id = classes.index(cls)</span><br><span class="line">        xmlbox = obj.find(<span class="string">&#x27;bndbox&#x27;</span>)</span><br><span class="line">        b = (<span class="built_in">float</span>(xmlbox.find(<span class="string">&#x27;xmin&#x27;</span>).text), <span class="built_in">float</span>(xmlbox.find(<span class="string">&#x27;xmax&#x27;</span>).text), <span class="built_in">float</span>(xmlbox.find(<span class="string">&#x27;ymin&#x27;</span>).text), <span class="built_in">float</span>(xmlbox.find(<span class="string">&#x27;ymax&#x27;</span>).text))</span><br><span class="line">        bb = convert((w,h), b)</span><br><span class="line">        out_file.write(<span class="built_in">str</span>(cls_id) + <span class="string">&quot; &quot;</span> + <span class="string">&quot; &quot;</span>.join([<span class="built_in">str</span>(a) <span class="keyword">for</span> a <span class="keyword">in</span> bb]) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line">wd = getcwd()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> year, image_set <span class="keyword">in</span> sets:</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&#x27;VOCdevkit/VOC%s/labels/&#x27;</span>%(year)):</span><br><span class="line">        os.makedirs(<span class="string">&#x27;VOCdevkit/VOC%s/labels/&#x27;</span>%(year))</span><br><span class="line">    <span class="comment"># 3. change to your path</span></span><br><span class="line">    image_ids = <span class="built_in">open</span>(<span class="string">&#x27;/home/ares2/darknet/VOCdevkit/VOC%s/ImageSets/Main/%s.txt&#x27;</span>%(year, image_set)).read().strip().split()</span><br><span class="line">    list_file = <span class="built_in">open</span>(<span class="string">&#x27;%s_%s.txt&#x27;</span>%(year, image_set), <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> image_id <span class="keyword">in</span> image_ids:</span><br><span class="line">        list_file.write(<span class="string">&#x27;%s/VOCdevkit/VOC%s/JPEGImages/%s.jpg\n&#x27;</span>%(wd, year, image_id))</span><br><span class="line">        convert_annotation(year, image_id)</span><br><span class="line">    list_file.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li>remember that there are 3 places you need to change</li>
<li>this will generate 3 files: <ul>
<li><strong>2019_oppo_train.txt</strong></li>
<li><strong>2019_oppo_val.txt</strong></li>
<li><strong>2019_oppo_test.txt</strong></li>
</ul>
</li>
<li>Usually I merge <strong>2019_oppo_train.txt</strong> and <strong>2019_oppo_test.txt</strong> as <strong>2019_oppo_train.txt</strong> <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd /path/darknet</span><br><span class="line">mkdir oppo_od_bak</span><br><span class="line">cd oppo_od_bak</span><br><span class="line">mkdir cfg</span><br></pre></td></tr></table></figure></li>
<li>from the <strong>darknet&#x2F;cfg&#x2F;</strong> you can find the <strong>yolo-voc.cfg</strong> and the <strong>yolo-tiny.cfg</strong> and from the <a class="link"   href="https://pjreddie.com/darknet/yolo/" >official website<i class="fas fa-external-link-alt"></i></a> you can download the <strong>pretrained models</strong>, like for the <strong>yolo-voc</strong> is <a class="link"   href="https://pjreddie.com/media/files/darknet53.conv.74" >darknet53.conv.74<i class="fas fa-external-link-alt"></i></a>.</li>
</ul>
<hr>
<h3 id="Prepare-your-cfg-file"><a href="#Prepare-your-cfg-file" class="headerlink" title="Prepare your cfg file"></a>Prepare your cfg file</h3><ul>
<li>the 3 files you use to train the yolo is <ul>
<li><strong>yourdata.names</strong></li>
<li><strong>yourdata.data</strong></li>
<li><strong>yourcfg.cfg</strong></li>
</ul>
</li>
<li>(1) <strong>yourdata.names</strong> contains the labels of your dataset, each label for a line</li>
<li>(2) <strong>yourdata.data</strong> example<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">classes= #classes #类别数目</span><br><span class="line">train  = /path/yourfilename_train.txt # 训练数据</span><br><span class="line">valid  = /path/yourfilenane_val.txt # 验证数据</span><br><span class="line">names = data/yourname.names # class labels</span><br><span class="line">backup = /backup/ # 权重保存所在文件</span><br></pre></td></tr></table></figure></li>
<li>remember to delete the comments</li>
<li>(3) <strong>yourcfg.cfg</strong><ul>
<li>you can use the <strong>yolo-voc.cfg</strong> or the <strong>yolo-tiny.cfg</strong></li>
<li>remember to change these places</li>
</ul>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vim yolo-voc.cfg</span><br><span class="line"></span><br><span class="line">## Remember to comment the testing and uncomment the training</span><br><span class="line">[net]</span><br><span class="line"># Testing</span><br><span class="line"># batch=1</span><br><span class="line"># subdivisions=1</span><br><span class="line"># Training</span><br><span class="line">batch=64</span><br><span class="line">subdivisions=16</span><br></pre></td></tr></table></figure>
<ul>
<li>YOU should change every [yolo] layer.<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[convolutional]</span><br><span class="line">size=1</span><br><span class="line">stride=1</span><br><span class="line">pad=1</span><br><span class="line">filters=27 ## YOU SHOULD CHANGE THE # OF FILTERS</span><br><span class="line">## filters = (classes + 5) * 3</span><br><span class="line">activation=linear</span><br><span class="line"></span><br><span class="line">[yolo]</span><br><span class="line">mask = 6,7,8</span><br><span class="line">anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326</span><br><span class="line">classes=4  ## CHANGE TO THE NUMBER OF YOUR LABELS</span><br><span class="line">num=9</span><br><span class="line">jitter=.3</span><br><span class="line">ignore_thresh = .5</span><br><span class="line">truth_thresh = 1</span><br><span class="line">random=1</span><br></pre></td></tr></table></figure></li>
</ul>
<hr>
<h3 id="Start-Training"><a href="#Start-Training" class="headerlink" title="Start Training"></a>Start Training</h3><ul>
<li>First time you train, use the pretrained classification model<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd path/darknet/</span><br><span class="line"># yolo-tiny</span><br><span class="line">./darknet detector train cfg/yourdata.data cfg/yourcfg.cfg backup/bo_can_tiny_176.weights</span><br><span class="line"># yolo-voc</span><br><span class="line">./darknet detector train cfg/yourdata.data cfg/yourcfg.cfg backup/darknet53.conv.74</span><br></pre></td></tr></table></figure></li>
</ul>
<hr>
<h3 id="Know-your-log"><a href="#Know-your-log" class="headerlink" title="Know your log"></a>Know your log</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Region <span class="number">82</span> Avg IOU: <span class="number">0.801934</span>, Class: <span class="number">0.737764</span>, Obj: <span class="number">0.782024</span>, No Obj: <span class="number">0.006216</span>, <span class="number">.5</span>R: <span class="number">1.000000</span>, <span class="number">.75</span>R: <span class="number">1.000000</span>, count: <span class="number">5</span> </span><br><span class="line">Region <span class="number">94</span> Avg IOU: <span class="number">0.706899</span>, Class: <span class="number">0.073915</span>, Obj: <span class="number">0.544467</span>, No Obj: <span class="number">0.000506</span>, <span class="number">.5</span>R: <span class="number">1.000000</span>, <span class="number">.75</span>R: <span class="number">0.000000</span>, count: <span class="number">1</span> </span><br><span class="line">Region <span class="number">106</span> Avg IOU: <span class="number">0.831056</span>, Class: <span class="number">0.037965</span>, Obj: <span class="number">0.026004</span>, No Obj: <span class="number">0.000057</span>, <span class="number">.5</span>R: <span class="number">1.000000</span>, <span class="number">.75</span>R: <span class="number">1.000000</span>, count: <span class="number">1</span> </span><br><span class="line">Region <span class="number">82</span> Avg IOU: <span class="number">0.731572</span>, Class: <span class="number">0.800899</span>, Obj: <span class="number">0.793200</span>, No Obj: <span class="number">0.005694</span>, <span class="number">.5</span>R: <span class="number">1.000000</span>, <span class="number">.75</span>R: <span class="number">0.333333</span>, count: <span class="number">3</span> </span><br><span class="line">Region <span class="number">94</span> Avg IOU: <span class="number">0.607969</span>, Class: <span class="number">0.199724</span>, Obj: <span class="number">0.884315</span>, No Obj: <span class="number">0.000286</span>, <span class="number">.5</span>R: <span class="number">1.000000</span>, <span class="number">.75</span>R: <span class="number">0.000000</span>, count: <span class="number">1</span> </span><br><span class="line">Region <span class="number">106</span> Avg IOU: -nan, Class: -nan, Obj: -nan, No Obj: <span class="number">0.000015</span>, <span class="number">.5</span>R: -nan, <span class="number">.75</span>R: -nan, count:</span><br></pre></td></tr></table></figure>
<ul>
<li>（1）以上输出显示了所有训练图片的一个批次（batch），批次大小的划分根据我们在 .cfg 文件中设置的subdivisions参数。在我使用的 .cfg 文件中 batch &#x3D; 64 ，subdivision &#x3D; 16，所以在训练输出中，训练迭代包含了16组，每组又包含了4张图片，跟设定的batch和subdivision的值一致。<br>但是此处有16*3条信息，每组包含三条信息，分别是：<br>Region 82 Avg IOU:<br>Region 94 Avg IOU:<br>Region 106 Avg IOU:<br>三个尺度上预测不同大小的框 82卷积层 为最大的预测尺度，使用较大的mask，但是可以预测出较小的物体 94卷积层 为中间的预测尺度，使用中等的mask， 106卷积层为最小的预测尺度，使用较小的mask，可以预测出较大的物体</li>
<li>（2）每个batch都会有这样一个输出：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">2706: 1.350835, 1.386559 avg, 0.001000 rate, 3.323842 seconds, 173184 images</span><br></pre></td></tr></table></figure></li>
</ul>
<p>2706：batch是第几组。<br>1.350835：总损失<br>1.386559 avg ： 平均损失<br>0.001000 rate：当前的学习率<br>3.323842 seconds： 当前batch训练所花的时间<br>173184 images ： 目前为止参与训练的图片总数 &#x3D; 2706 * 64 </p>
<ul>
<li>（3）<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Region 82 Avg IOU: 0.798032, Class: 0.559781, Obj: 0.515851, No Obj: 0.006533, .5R: 1.000000, .75R: 1.000000,  count: 2</span><br></pre></td></tr></table></figure></li>
</ul>
<p>Region Avg IOU: 表示在当前subdivision内的图片的平均IOU，代表预测的矩形框和真实目标的交集与并集之比.<br>Class: 标注物体分类的正确率，期望该值趋近于1。<br>Obj: 越接近1越好。<br>No Obj: 期望该值越来越小，但不为零。<br>count: count后的值是所有的当前subdivision图片（本例中一共4张）中包含正样本的图片的数量。</p>
<ul>
<li>参考：<a class="link"   href="https://blog.csdn.net/qq_33444963/article/details/80842179" >https://blog.csdn.net/qq_33444963&#x2F;article&#x2F;details&#x2F;80842179<i class="fas fa-external-link-alt"></i></a></li>
</ul>
<hr>
<h3 id="Training-experience"><a href="#Training-experience" class="headerlink" title="Training experience"></a>Training experience</h3><ul>
<li><p><strong>YOLO-TINY</strong></p>
<ul>
<li>It’s a simple network for feature extraction, fit to the simple circumstances.</li>
<li>Each class should have more than 500 images</li>
<li>Training more than 1000 epoches</li>
<li>Fast but low accurate.</li>
</ul>
</li>
<li><p><strong>YOLO-VOC</strong></p>
<ul>
<li>It’s a complicated network training on the Imagenet</li>
<li>Each class should have more than 300 images</li>
<li>Traing more than 10000 epoches.</li>
<li>Slow but accurate</li>
</ul>
</li>
<li><p>Overall, more images, the model will be better. You can try to add images slowly.</p>
</li>
</ul>
<h3 id="How-to-run-your-own-yolov3-model-with-Opencv"><a href="#How-to-run-your-own-yolov3-model-with-Opencv" class="headerlink" title="How to run your own yolov3 model with Opencv"></a>How to run your own yolov3 model with Opencv</h3><ul>
<li>first you need to install the opencv</li>
<li>then, you just copy three files from what you have trained<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yourname.name</span><br><span class="line">yourcfg.cfg</span><br><span class="line">yourweights.weights</span><br></pre></td></tr></table></figure></li>
<li>then set them in the config file<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class FLAGS:</span><br><span class="line">    # Initialize the parameters</span><br><span class="line">    confThreshold = 0.65  # Confidence threshold</span><br><span class="line">    nmsThreshold = 0.3  # Non-maximum suppression threshold</span><br><span class="line">    inpWidth = 416  # Width of network&#x27;s input image</span><br><span class="line">    inpHeight = 416  # Height of network&#x27;s input image</span><br><span class="line"></span><br><span class="line">    camera_id = 0</span><br><span class="line"></span><br><span class="line">    # Load names of classes</span><br><span class="line">    classesFile = &quot;./shelves_od_300/shelves_od.names&quot;</span><br><span class="line">    classes = None</span><br><span class="line">    with open(classesFile, &#x27;rt&#x27;) as f:</span><br><span class="line">        classes = f.read().rstrip(&#x27;\n&#x27;).split(&#x27;\n&#x27;)</span><br><span class="line"></span><br><span class="line">    # Give the configuration and weight files for the model and load the network using them</span><br><span class="line">    modelConfiguration = &quot;./shelves_od_300/yolov3-voc.cfg&quot;</span><br><span class="line">    modelWeights = &quot;./shelves_od_300/yolov3-voc_latest.weights&quot;</span><br></pre></td></tr></table></figure></li>
<li>Finally, run the script below<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># This code is written at BigVision LLC. It is based on the OpenCV project. It is subject to the license terms in the LICENSE file found in this distribution and at http://opencv.org/license.html</span><br><span class="line"></span><br><span class="line"># Usage example:  python3 object_detection_yolo.py --video=run.mp4</span><br><span class="line">#                 python3 object_detection_yolo.py --image=bird.jpg</span><br><span class="line"></span><br><span class="line">import cv2 as cv</span><br><span class="line">import argparse</span><br><span class="line">import sys</span><br><span class="line">import numpy as np</span><br><span class="line">import os.path</span><br><span class="line">import uuid</span><br><span class="line"></span><br><span class="line">from config import FLAGS</span><br><span class="line"></span><br><span class="line"># Initialize the parameters</span><br><span class="line">confThreshold = FLAGS.confThreshold  #Confidence threshold</span><br><span class="line">nmsThreshold = FLAGS.nmsThreshold   #Non-maximum suppression threshold</span><br><span class="line">inpWidth = FLAGS.inpWidth       #Width of network&#x27;s input image</span><br><span class="line">inpHeight = FLAGS.inpHeight      #Height of network&#x27;s input image</span><br><span class="line"></span><br><span class="line">classes = FLAGS.classes</span><br><span class="line">global _i</span><br><span class="line">_i = 1000</span><br><span class="line"># Get the =-.l2 of the output layers</span><br><span class="line">def getOutputsNames(net):</span><br><span class="line">    # Get the names of all the layers in the network</span><br><span class="line">    layersNames = net.getLayerNames()</span><br><span class="line">    # Get the names of the output layers, i.e. the layers with unconnected outputs</span><br><span class="line">    return [layersNames[i[0] - 1] for i in net.getUnconnectedOutLayers()]</span><br><span class="line"></span><br><span class="line"># Draw the predicted bounding box</span><br><span class="line">def drawPred(frame, classId, conf, left, top, right, bottom):</span><br><span class="line">    # Draw a bounding box.</span><br><span class="line">    cv.rectangle(frame, (left, top), (right, bottom), (255, 178, 50), 3)</span><br><span class="line">    </span><br><span class="line">    label = &#x27;%.2f&#x27; % conf</span><br><span class="line">        </span><br><span class="line">    # Get the label for the class name and its confidence</span><br><span class="line">    if classes:</span><br><span class="line">        assert(classId &lt; len(classes))</span><br><span class="line">        label = &#x27;%s:%s&#x27; % (classes[classId], label)</span><br><span class="line"></span><br><span class="line">    #Display the label at the top of the bounding box</span><br><span class="line">    labelSize, baseLine = cv.getTextSize(label, cv.FONT_HERSHEY_SIMPLEX, 0.5, 1)</span><br><span class="line">    top = max(top, labelSize[1])</span><br><span class="line">    cv.rectangle(frame, (left, top - round(1.5*labelSize[1])), (left + round(1.5*labelSize[0]), top + baseLine), (255, 255, 255), cv.FILLED)</span><br><span class="line">    cv.putText(frame, label, (left, top), cv.FONT_HERSHEY_SIMPLEX, 0.75, (0,0,0), 1)</span><br><span class="line"></span><br><span class="line"># Remove the bounding boxes with low confidence using non-maxima suppression</span><br><span class="line">def postprocess(frame, outs):</span><br><span class="line">    frameHeight = frame.shape[0]</span><br><span class="line">    frameWidth = frame.shape[1]</span><br><span class="line"></span><br><span class="line">    # Scan through all the bounding boxes output from the network and keep only the</span><br><span class="line">    # ones with high confidence scores. Assign the box&#x27;s class label as the class with the highest score.</span><br><span class="line">    classIds = []</span><br><span class="line">    confidences = []</span><br><span class="line">    boxes = []</span><br><span class="line">    for out in outs:</span><br><span class="line">        for detection in out:</span><br><span class="line">            scores = detection[5:]</span><br><span class="line">            classId = np.argmax(scores)</span><br><span class="line">            confidence = scores[classId]</span><br><span class="line">            if confidence &gt; confThreshold:</span><br><span class="line">                center_x = int(detection[0] * frameWidth)</span><br><span class="line">                center_y = int(detection[1] * frameHeight)</span><br><span class="line">                width = int(detection[2] * frameWidth)</span><br><span class="line">                height = int(detection[3] * frameHeight)</span><br><span class="line">                left = int(center_x - width / 2)</span><br><span class="line">                top = int(center_y - height / 2)</span><br><span class="line">                classIds.append(classId)</span><br><span class="line">                confidences.append(float(confidence))</span><br><span class="line">                boxes.append([left, top, width, height])</span><br><span class="line">    global _i</span><br><span class="line">    # Perform non maximum suppression to eliminate redundant overlapping boxes with</span><br><span class="line">    # lower confidences.</span><br><span class="line">    indices = cv.dnn.NMSBoxes(boxes, confidences, confThreshold, nmsThreshold)</span><br><span class="line">    for i in indices:</span><br><span class="line">        i = i[0]</span><br><span class="line">        box = boxes[i]</span><br><span class="line">        left = box[0]</span><br><span class="line">        top = box[1]</span><br><span class="line">        width = box[2]</span><br><span class="line">        height = box[3]</span><br><span class="line"></span><br><span class="line">        ## save crop image</span><br><span class="line">        crop_img = frame[top:top+height, left:left+width, ]</span><br><span class="line">        #resized_img = cv.resize(crop_img, (100, 100))</span><br><span class="line">        #if _i % 5 == 0:</span><br><span class="line">        #cv.imwrite(&#x27;save_imgs/&#x27;+str(uuid.uuid1())+&#x27;.jpg&#x27;, crop_img)</span><br><span class="line">        _i = _i + 1</span><br><span class="line">        drawPred(frame, classIds[i], confidences[i], left, top, left + width, top + height)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def processing_yolov3(args):</span><br><span class="line"></span><br><span class="line">    net = cv.dnn.readNetFromDarknet(FLAGS.modelConfiguration, FLAGS.modelWeights)</span><br><span class="line">    net.setPreferableBackend(cv.dnn.DNN_BACKEND_OPENCV)</span><br><span class="line">    net.setPreferableTarget(cv.dnn.DNN_TARGET_CPU)</span><br><span class="line"></span><br><span class="line">    # Process inputs</span><br><span class="line">    winName = &#x27;Deep learning object detection in OpenCV&#x27;</span><br><span class="line">    cv.namedWindow(winName, cv.WINDOW_NORMAL)</span><br><span class="line"></span><br><span class="line">    outputFile = &quot;yolo_out_py.avi&quot;</span><br><span class="line">    if (args.image):</span><br><span class="line">        # Open the image file</span><br><span class="line">        if not os.path.isfile(args.image):</span><br><span class="line">            print(&quot;Input image file &quot;, args.image, &quot; doesn&#x27;t exist&quot;)</span><br><span class="line">            sys.exit(1)</span><br><span class="line">        cap = cv.VideoCapture(args.image)</span><br><span class="line">        outputFile = args.image[:-4]+&#x27;_yolo_out_py.jpg&#x27;</span><br><span class="line">    elif (args.video):</span><br><span class="line">        # Open the video file</span><br><span class="line">        if not os.path.isfile(args.video):</span><br><span class="line">            print(&quot;Input video file &quot;, args.video, &quot; doesn&#x27;t exist&quot;)</span><br><span class="line">            sys.exit(1)</span><br><span class="line">        cap = cv.VideoCapture(args.video)</span><br><span class="line">        outputFile = args.video[:-4]+&#x27;_yolo_out_py.avi&#x27;</span><br><span class="line">    else:</span><br><span class="line">        # Webcam input</span><br><span class="line">        cap = cv.VideoCapture(FLAGS.camera_id)</span><br><span class="line"></span><br><span class="line">        cap.set(3, 720)</span><br><span class="line">        cap.set(4, 1280)</span><br><span class="line"></span><br><span class="line">    # Get the video writer initialized to save the output video</span><br><span class="line">    if (not args.image):</span><br><span class="line">        vid_writer = cv.VideoWriter(outputFile, cv.VideoWriter_fourcc(&#x27;M&#x27;,&#x27;J&#x27;,&#x27;P&#x27;,&#x27;G&#x27;), 30, (round(cap.get(cv.CAP_PROP_FRAME_WIDTH)),round(cap.get(cv.CAP_PROP_FRAME_HEIGHT))))</span><br><span class="line"></span><br><span class="line">    while cv.waitKey(1) &lt; 0:</span><br><span class="line"></span><br><span class="line">        # get frame from the video</span><br><span class="line">        hasFrame, frame = cap.read()</span><br><span class="line"></span><br><span class="line">        # Stop the program if reached end of video</span><br><span class="line">        if not hasFrame:</span><br><span class="line">            print(&quot;Done processing !!!&quot;)</span><br><span class="line">            print(&quot;Output file is stored as &quot;, outputFile)</span><br><span class="line">            cv.waitKey(3000)</span><br><span class="line">            # Release device</span><br><span class="line">            cap.release()</span><br><span class="line">            break</span><br><span class="line"></span><br><span class="line">        # Create a 4D blob from a frame.</span><br><span class="line">        blob = cv.dnn.blobFromImage(frame, 1/255, (inpWidth, inpHeight), [0,0,0], 1, crop=False)</span><br><span class="line"></span><br><span class="line">        # Sets the input to the network</span><br><span class="line">        net.setInput(blob)</span><br><span class="line"></span><br><span class="line">        # Runs the forward pass to get output of the output layers</span><br><span class="line">        outs = net.forward(getOutputsNames(net))</span><br><span class="line"></span><br><span class="line">        # Remove the bounding boxes with low confidence</span><br><span class="line">        postprocess(frame, outs)</span><br><span class="line"></span><br><span class="line">        # Put efficiency information. The function getPerfProfile returns the overall time for inference(t) and the timings for each of the layers(in layersTimes)</span><br><span class="line">        t, _ = net.getPerfProfile()</span><br><span class="line">        label = &#x27;Inference time: %.2f ms&#x27; % (t * 1000.0 / cv.getTickFrequency())</span><br><span class="line">        cv.putText(frame, label, (0, 15), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255))</span><br><span class="line"></span><br><span class="line">        # Write the frame with the detection boxes</span><br><span class="line">        if (args.image):</span><br><span class="line">            cv.imwrite(outputFile, frame.astype(np.uint8))</span><br><span class="line">        else:</span><br><span class="line">            vid_writer.write(frame.astype(np.uint8))</span><br><span class="line"></span><br><span class="line">        cv.imshow(winName, frame)</span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    parser = argparse.ArgumentParser(description=&#x27;Object Detection using YOLO in OPENCV&#x27;)</span><br><span class="line">    parser.add_argument(&#x27;--image&#x27;, help=&#x27;Path to image file.&#x27;)</span><br><span class="line">    parser.add_argument(&#x27;--video&#x27;, help=&#x27;Path to video file.&#x27;)</span><br><span class="line">    args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    processing_yolov3(args)</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步-ML</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>yolov3</tag>
        <tag>darknet</tag>
      </tags>
  </entry>
  <entry>
    <title>comparison of MTCNN on RK3399</title>
    <url>/2021/03/08/ML/comparison-of-MTCNN-on-RK3399/</url>
    <content><![CDATA[<ul>
<li>date, 2019-03-08 12:04:23</li>
</ul>
<h2 id="在RK板上运行mtcnn的方案"><a href="#在RK板上运行mtcnn的方案" class="headerlink" title="在RK板上运行mtcnn的方案"></a>在RK板上运行mtcnn的方案</h2><h3 id="1-运行caffe版本的mtcnn"><a href="#1-运行caffe版本的mtcnn" class="headerlink" title="1. 运行caffe版本的mtcnn"></a>1. 运行caffe版本的mtcnn</h3><ul>
<li>在RK上安装OPENCL的Caffe(环境配置)<ul>
<li>先装OPENBLAS，后装Caffe</li>
<li>中间遇到ViennaCL库没找到，但是安装出错</li>
</ul>
</li>
<li>在RK板上运行python版的mtcnn-caffe</li>
<li>在RK板上运行C++版的mtcnn-caffe</li>
</ul>
<h3 id="2-运行tensorflow-lite版本的mtcnn"><a href="#2-运行tensorflow-lite版本的mtcnn" class="headerlink" title="2. 运行tensorflow-lite版本的mtcnn"></a>2. 运行tensorflow-lite版本的mtcnn</h3><ul>
<li>在RK板上安装tensorflow-lite(环境配置)<ul>
<li>这一部分的教程较少，安装出错</li>
</ul>
</li>
<li>把mtcnn的模型转换成lite模型</li>
<li>运行mtcnn</li>
</ul>
<h3 id="3-测试mtcnn-tensorflow-在不同机器上的fps"><a href="#3-测试mtcnn-tensorflow-在不同机器上的fps" class="headerlink" title="3. 测试mtcnn(tensorflow)在不同机器上的fps"></a>3. 测试mtcnn(tensorflow)在不同机器上的fps</h3><p>星期五, 08. 三月 2019 11:32上午 </p>
<ul>
<li><p>test_video : outpy4.avi</p>
</li>
<li><p>image size : 480 x 640</p>
</li>
</ul>
<hr>
<table>
<thead>
<tr>
<th>fps</th>
<th>CPU</th>
<th>GPU</th>
</tr>
</thead>
<tbody><tr>
<td>HP_Zhan(MX150)2G</td>
<td>5.05</td>
<td>12.04</td>
</tr>
<tr>
<td>JTx2 (Pascal GPU) 8G</td>
<td>4.00</td>
<td>6.23</td>
</tr>
<tr>
<td>RK3399   (No GPU)</td>
<td>1.52</td>
<td>None</td>
</tr>
</tbody></table>
<hr>
<ul>
<li>image size : 216 x 512</li>
</ul>
<hr>
<table>
<thead>
<tr>
<th>fps</th>
<th>CPU</th>
<th>GPU</th>
</tr>
</thead>
<tbody><tr>
<td>HP_Zhan(MX150)&#x2F;2G</td>
<td>10.45</td>
<td>22.96</td>
</tr>
<tr>
<td>JTx2 (Pascal GPU) &#x2F;8G</td>
<td>8.64</td>
<td>11.89</td>
</tr>
<tr>
<td>RK3399  (No GPU)</td>
<td>2.81</td>
<td>None</td>
</tr>
</tbody></table>
<h3 id="4-优化mtcnn的思路"><a href="#4-优化mtcnn的思路" class="headerlink" title="4. 优化mtcnn的思路"></a>4. 优化mtcnn的思路</h3><p>reference : <a class="link"   href="https://blog.csdn.net/Relocy/article/details/84075570" >MTCNN优化和另类用法<i class="fas fa-external-link-alt"></i></a></p>
<ul>
<li>MTCNN速度的瓶颈<ul>
<li>图片越大Pnet耗时也就越大。</li>
<li>人脸越多Onet和Rnet耗时越大。</li>
<li>噪点比较多的夜晚图像会导致Pnet误检测增多。</li>
</ul>
</li>
</ul>
<ul>
<li><p>从input_size入手，缩小input_size可以加快速度，如：480x640 -&gt; 216 x 512，可以提高40%左右的速率</p>
</li>
<li><p>换caffe框架，想办法把RK板上的GPU利用起来实现加速</p>
</li>
</ul>
<h3 id="5-caffe2-VS-tensorflow-MTCNN"><a href="#5-caffe2-VS-tensorflow-MTCNN" class="headerlink" title="5. caffe2 VS tensorflow (MTCNN)"></a>5. caffe2 VS tensorflow (MTCNN)</h3><ul>
<li>在HP-Zhan-Tim上跑GPU，每个流程跑3次</li>
</ul>
<table>
<thead>
<tr>
<th>Framwork</th>
<th>tensorflow</th>
<th>caffe2</th>
</tr>
</thead>
<tbody><tr>
<td>FPS</td>
<td>GPU-1&#x2F;GPU-2&#x2F;GPU-3</td>
<td>GPU-1&#x2F;GPU-2&#x2F;GPU-3</td>
</tr>
<tr>
<td>480x640</td>
<td><strong>13.41</strong>&#x2F;13.08&#x2F;12.75</td>
<td>13.69&#x2F;<strong>13.73</strong>&#x2F;13.58</td>
</tr>
<tr>
<td>216X512</td>
<td>22.43&#x2F;22.62&#x2F;<strong>23.09</strong></td>
<td><strong>30.01</strong>&#x2F;29.25&#x2F;29.82</td>
</tr>
</tbody></table>
]]></content>
      <tags>
        <tag>mtcnn</tag>
        <tag>RK3399</tag>
      </tags>
  </entry>
  <entry>
    <title>how_to_install_openpose_in_ubuntu1604</title>
    <url>/2019/07/02/ML/how-to-install-openpose-in-ubuntu1604/</url>
    <content><![CDATA[<ul>
<li><a class="link"   href="https://blog.csdn.net/linhai1028/article/details/79452977" >reference1<i class="fas fa-external-link-alt"></i></a> </li>
<li><a class="link"   href="https://www.aiuai.cn/aifarm708.html" >reference2<i class="fas fa-external-link-alt"></i></a> </li>
<li><a class="link"   href="https://github.com/CMU-Perceptual-Computing-Lab/openpose/issues/1027" >reference3<i class="fas fa-external-link-alt"></i></a></li>
</ul>
<h3 id="Download-source-from-the-github"><a href="#Download-source-from-the-github" class="headerlink" title="Download source from the github"></a>Download source from the github</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone --recursive git@github.com:CMU-Perceptual-Computing-Lab/openpose.git</span><br></pre></td></tr></table></figure>
<ul>
<li>Remember to use the <strong>–recursive</strong> to download other source</li>
</ul>
<h3 id="Install-the-cmake-gui"><a href="#Install-the-cmake-gui" class="headerlink" title="Install the cmake-gui"></a>Install the cmake-gui</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install cmake-gui</span><br></pre></td></tr></table></figure>
<ul>
<li><img src="/img/install_openpose/cmake-gui.png" alt="cmake-gui"></li>
</ul>
<h3 id="Download-the-models"><a href="#Download-the-models" class="headerlink" title="Download the models"></a>Download the models</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd openpose/models/</span><br><span class="line">./getModels.sh</span><br></pre></td></tr></table></figure>
<ul>
<li>if it doesn’t work for you, you can try to download them directly<ul>
<li><a class="link"   href="http://posefs1.perception.cs.cmu.edu/OpenPose/models/pose/body_25/pose_iter_584000.caffemodel" >BODY_25 - pose_iter_584000.caffemodel<i class="fas fa-external-link-alt"></i></a> </li>
<li><a class="link"   href="http://posefs1.perception.cs.cmu.edu/OpenPose/models/pose/coco/pose_iter_440000.caffemodel" >COCO - pose_iter_440000.caffemodel<i class="fas fa-external-link-alt"></i></a> </li>
<li><a class="link"   href="http://posefs1.perception.cs.cmu.edu/OpenPose/models/pose/mpi/pose_iter_160000.caffemodel" >MPI - pose_iter_160000.caffemodel<i class="fas fa-external-link-alt"></i></a> </li>
<li><a class="link"   href="http://posefs1.perception.cs.cmu.edu/OpenPose/models/face/pose_iter_116000.caffemodel" >Face - pose_iter_116000.caffemodel<i class="fas fa-external-link-alt"></i></a> </li>
<li><a class="link"   href="http://posefs1.perception.cs.cmu.edu/OpenPose/models/hand/pose_iter_102000.caffemodel" >Hand - pose_iter_102000.caffemodel<i class="fas fa-external-link-alt"></i></a></li>
</ul>
</li>
</ul>
<h3 id="Complie"><a href="#Complie" class="headerlink" title="Complie"></a>Complie</h3><ul>
<li><p><strong>First you should have caffe&amp; OpenCV installed in your PC</strong></p>
</li>
<li><p>Open the cmake-gui and fill the source code and build path</p>
</li>
<li><p><img src="/img/install_openpose/fill_path.png" alt="fill_path"> </p>
</li>
<li><p>Click the configure and choose the default button</p>
</li>
<li><p><img src="/img/install_openpose/cmake-setup.png" alt="cmake-setup"> </p>
</li>
<li><p>Then set up your path of <strong>Caffe</strong> and click the <strong>Configure</strong> button, after that, click the <strong>Generate</strong> button</p>
</li>
<li><p><img src="/img/install_openpose/complie_complete.jpg" alt="complete"> </p>
</li>
<li><p>When you see the <strong>Generating Done</strong>, you should do this </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd build</span><br><span class="line">make -j `nproc`</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="caffe-issue"><a href="#caffe-issue" class="headerlink" title="caffe issue"></a>caffe issue</h3><ul>
<li><p>If you install the latest caffe, you may occur the problem like that </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">can&#x27;t read the caffemodel or parase the model files</span><br></pre></td></tr></table></figure></li>
<li><p>It may be two reasons </p>
<ul>
<li>caffe issue.</li>
<li>the model file is broken, you can try to download it again.</li>
</ul>
</li>
<li><p>So if it’s the caffe issue, you can download the caffe from openpose github and complie it alone.</p>
</li>
</ul>
<h3 id="Some-issues"><a href="#Some-issues" class="headerlink" title="Some issues"></a>Some issues</h3><ul>
<li>You may occur some issues like these</li>
<li><img src="/img/install_openpose/caffe_issues.jpg" alt="caffe_issue"> <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SOLVED BY MUUPAN!</span><br><span class="line"></span><br><span class="line">You need to generate caffe.pb.h manually using protoc as follows.</span><br><span class="line"></span><br><span class="line">In the directory you installed Caffe to</span><br><span class="line"></span><br><span class="line">protoc src/caffe/proto/caffe.proto --cpp_out=.</span><br><span class="line">mkdir include/caffe/proto</span><br><span class="line">mv src/caffe/proto/caffe.pb.h include/caffe/proto</span><br></pre></td></tr></table></figure></li>
<li>After that you complie again, you may incur the other issue about the version of protoc<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/home/visionml/caffe-master/include/caffe/proto/caffe.pb.h:12:2: error: #error This file was generated by a newer version of protoc which is</span><br></pre></td></tr></table></figure></li>
<li><img src="/img/install_openpose/protoc_version.jpg" alt="protoc_version"> </li>
<li>You could try the older version of protoc</li>
</ul>
<h3 id="Python-API-complie"><a href="#Python-API-complie" class="headerlink" title="Python API complie"></a>Python API complie</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd build/python/</span><br><span class="line">sudo make install -j `nproc`</span><br></pre></td></tr></table></figure>
<h3 id="Add-path-to-bash"><a href="#Add-path-to-bash" class="headerlink" title="Add path to bash"></a>Add path to bash</h3><ul>
<li>Fisrt way (Recommand)<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vim ~/.bashrc</span><br><span class="line"># (Add this line to the end of the file)</span><br><span class="line">export PYTHONPATH=/path/to/openpose/build/python:</span><br></pre></td></tr></table></figure></li>
<li>Second way<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a. After a successful build, go look for the file - build/python/openpose/pyopenpose.cpython-35m-x86_64-linux-gnu.so and copy to /usr/local/lib/python3.5/dist-packages</span><br><span class="line"></span><br><span class="line">b. in /usr/local/lib/python3.6/dist-packages I create a symbolic link -</span><br><span class="line">-  sudo ln -s pyopenpose.cpython-35m-x86_64-linux-gnu.so pyopenpose</span><br><span class="line"></span><br><span class="line">c. Verify that your LD_LIBRARY_PATH from env has the entry /usr/local/lib/python3.5/dist-packages</span><br><span class="line"></span><br><span class="line">d. Now, go to build/examples/tutorial_api_python and do some modification to 1_body_from_image.py</span><br><span class="line"></span><br><span class="line">i) look for the line from openpose import pyopenpose as op and change to import pyopenpose as op</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="Try-a-test-of-python"><a href="#Try-a-test-of-python" class="headerlink" title="Try a test of python"></a>Try a test of python</h3><ul>
<li>Fisrt way (Recommand)<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python</span><br><span class="line">&gt;&gt;&gt; import openpose</span><br><span class="line">&gt;&gt;&gt; from openpose import pyopenpose as op </span><br></pre></td></tr></table></figure></li>
<li>Second way<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python</span><br><span class="line">&gt;&gt;&gt; import pyopenpose as op</span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步-ML</category>
      </categories>
      <tags>
        <tag>openpose</tag>
      </tags>
  </entry>
  <entry>
    <title>Review on 轻量级卷积神经网络的设计</title>
    <url>/2019/11/17/ML/light-framework-for-CNN/</url>
    <content><![CDATA[<h2 id="为什么需要轻量网络？"><a href="#为什么需要轻量网络？" class="headerlink" title="为什么需要轻量网络？"></a>为什么需要轻量网络？</h2><h3 id="经典backbone网络存在的问题"><a href="#经典backbone网络存在的问题" class="headerlink" title="经典backbone网络存在的问题"></a>经典backbone网络存在的问题</h3><ul>
<li>尽管随着近年来backbone网络的快速发展，由AlexNet到VGG，由VGG到GoogleNet，由GoogleNet到ResNet等等。模型的精度越来越高，</li>
<li>但是通常模型占用内存很大，模型参数很多，这样的话在边缘设备上运行就会很慢。</li>
<li>所以我们需要设计一些参数量更少的网络结构，这样的模型占用内存小，在边缘设备上跑的更快。</li>
</ul>
<h3 id="怎么解决这个问题"><a href="#怎么解决这个问题" class="headerlink" title="怎么解决这个问题"></a>怎么解决这个问题</h3><pre><code>1. 网络压缩
2. 轻量网络的设计
</code></pre>
<h2 id="本Review只是讨论轻量网络的设计"><a href="#本Review只是讨论轻量网络的设计" class="headerlink" title="本Review只是讨论轻量网络的设计"></a>本Review只是讨论轻量网络的设计</h2><ul>
<li>轻量网络设计的发展历程，我们按照提出的时间可以分为3个版本<br>  （1）Version 1， 【2016-2017】，SqueezeNet–&gt; MobileNet –&gt; ShuffleNet –&gt; Xception<br>  （2）Version 2， 【2017-2018】，SqueezeNext–&gt; MobileNetV2 –&gt; ShuffleNetV2<br>  （3）Version 3， 【2018-2019】，AutoShuffleNet–&gt; MobileNetV3</li>
<li>这里我们总结一下5个轻量网络，<strong>SqueezeNet，MobileNet，ShuffleNet，MobileNetV2，ShuffleNetV2</strong></li>
</ul>
<h2 id="SqueezeNet"><a href="#SqueezeNet" class="headerlink" title="SqueezeNet"></a>SqueezeNet</h2><ol>
<li>核心思想<br>a. 用更多的1*1卷积核替代3*3卷积核的使用，因为1*1卷积核可以在保output&#x3D;input的同时减少了通道数<br>b. 在3*3卷积核中用更少的通道数，这样直接减少了模型的参数<br>c. 延迟下采样</li>
<li>模块化卷积fire module<br><img src="/img/light-cnn/squeezeNet.png" alt="fire module" title="fire module"></li>
</ol>
<ul>
<li>fire module包含2个部分：Squeeze Layer和Expend Layer。</li>
<li>Squeeze Layer直接用1*1降低了通道数并保持output&#x3D;input</li>
<li>Expend Layer是1*1卷积和3*3卷积的混合使用</li>
</ul>
<ol start="3">
<li>实验结果</li>
</ol>
<ul>
<li>SqueezeNet的参数比AlexNet少50x，但是模型性能(accuracy)与AlexNet结晶。</li>
</ul>
<h2 id="MobileNet"><a href="#MobileNet" class="headerlink" title="MobileNet"></a>MobileNet</h2><ol>
<li>核心思想，深度可分离卷积结构 depthwise separable convolution</li>
</ol>
<ul>
<li>深度可分离卷积是把一个传统卷积层分解成了2个卷积层，depthwise -wise和point-wise convolutiion.<ul>
<li>depthwise -wise卷积是单独在通道上做的卷积，是分组卷积中groups&#x3D;channels的极端情况。</li>
<li>point-wise卷积是用1*1卷积核连接通道之间的特征信息。<br><img src="/img/light-cnn/mobilenetv1.png" alt="mobilenet" title="mobilenet"></li>
</ul>
</li>
<li>可以计算参数如下<br><img src="/img/light-cnn/orig-conv.png" alt="traditional-convolution" title="traditional convolution"><br><img src="/img/light-cnn/depth-wise-sep-con.png" alt="depthwise-separable-convolution" title="depthwise-separable-convolution"></li>
<li>结构图如下<br><img src="/img/light-cnn/depth-wise-conv.png" alt="depth-wise-convlution" title="depth-wise-convlution"></li>
</ul>
<ol start="2">
<li>实验结果</li>
</ol>
<ul>
<li>深度可分离卷积实现了和传统卷积相同的输入和输出操作，在保证准确率的条件下，但是计算参数量减少约为原来的1&#x2F;7，计算时间减少约为原来的1&#x2F;9。</li>
</ul>
<h2 id="MobileNetV2"><a href="#MobileNetV2" class="headerlink" title="MobileNetV2"></a>MobileNetV2</h2><ol>
<li>核心思想，Inverted Residuals &amp; Linear Bottlenecks</li>
</ol>
<ul>
<li><p>首先说一下ResNet中的Residual block的思想，就是在进行3*3卷积之前，插入1*1卷积进行通道数的“压缩”，在3*3卷积之后又插入1*1卷积进行通道数的“扩张”（input~&#x3D;output）。<br><img src="/img/light-cnn/bottleneck.png" alt="bottleneck" title="bottleneck"></p>
</li>
<li><p>而Inverted Residuals则是反了过来，先用1*1卷积进行通道数的“扩张”，然后经过3*3的depthwise separable convolution，最后插入1*1卷积进行通道数的“压缩”(input~&#x3D;output).<br><img src="/img/light-cnn/inverted-residual.png" alt="inverted-residuals" title="inverted-residuals"></p>
</li>
<li><p>Linear Bottlenecks，original bottlenecks是在卷积层之后做elwise + Relu，而linear bottlenecks则是elwise + withou relu。原因是本来参数量不多的情况下，如果用relu让负半轴为0，那么模型的学习能力就更有限了，所以直接删除relu。</p>
</li>
<li><p>利用stride&#x3D;2的卷积层做下采样。结构图如下<br><img src="/img/light-cnn/mobilenet-v2.png" alt="mobilenet-v2" title="mobilenet-v2"></p>
</li>
</ul>
<h2 id="ShuffleNet"><a href="#ShuffleNet" class="headerlink" title="ShuffleNet"></a>ShuffleNet</h2><ol>
<li>核心思想，用1*1Group Conv做channel shuffle。<br><img src="/img/light-cnn/channel-shuffle.png" alt="channel-shuffle" title="channel-shuffle"></li>
</ol>
<ul>
<li>shuffle unit<br><img src="/img/light-cnn/shuffleNet-unit.png" alt="shuffle-unit" title="shuffle-unit"></li>
</ul>
<h2 id="ShuffleNetV2"><a href="#ShuffleNetV2" class="headerlink" title="ShuffleNetV2"></a>ShuffleNetV2</h2><ol>
<li>核心思想，Time &#x3D; T(FLOPS) + T(I&#x2F;O)。</li>
</ol>
<ul>
<li>提出了4个指导原则，<br>  a, 当input channel&#x3D;output channel，卷积计算所需的MAC(memory access cost)最为节省。<br>  <img src="/img/light-cnn/shfln-v2-g1.png" alt="Guidie-1" title="Guidie-1"><br>  b, 过多的group convolution操作会加大MAC开销。<br>  <img src="/img/light-cnn/shfln-v2-g2.png" alt="Guidie-2" title="Guidie-2"><br>  c, 网络结构整体的碎片化会减少其可并行优化的程序。<br>  <img src="/img/light-cnn/shfln-v2-g3.png" alt="Guidie-3" title="Guidie-3"><br>  d, Else-wise操作小号的时间较多。<br>  <img src="/img/light-cnn/shfln-v2-g4.png" alt="Guidie-4" title="Guidie-4"></li>
</ul>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><ul>
<li>实践中，首选是ShuffleNet-V2&#x2F;MobileNet-V2，第二选择是MoblileNet</li>
</ul>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>SqueezeNet <a class="link"   href="https://arxiv.org/abs/1602.07360" >https://arxiv.org/abs/1602.07360<i class="fas fa-external-link-alt"></i></a><br>MobileNet <a class="link"   href="https://arxiv.org/abs/1704.04861" >https://arxiv.org/abs/1704.04861<i class="fas fa-external-link-alt"></i></a><br>ShuffleNet <a class="link"   href="https://arxiv.org/abs/1707.01083" >https://arxiv.org/abs/1707.01083<i class="fas fa-external-link-alt"></i></a><br>MobileNetV2 <a class="link"   href="https://arxiv.org/abs/1801.04381" >https://arxiv.org/abs/1801.04381<i class="fas fa-external-link-alt"></i></a><br>ShuffleNetV2 <a class="link"   href="https://arxiv.org/abs/1807.11164" >https://arxiv.org/abs/1807.11164<i class="fas fa-external-link-alt"></i></a><br>Resnet <a class="link"   href="https://arxiv.org/abs/1512.03385" >https://arxiv.org/abs/1512.03385<i class="fas fa-external-link-alt"></i></a></p>
<p>SqueezeNet<br><a class="link"   href="https://zhuanlan.zhihu.com/p/31558773" >https://zhuanlan.zhihu.com/p/31558773<i class="fas fa-external-link-alt"></i></a><br><a class="link"   href="https://blog.csdn.net/csdnldp/article/details/78648543" >https://blog.csdn.net/csdnldp/article/details/78648543<i class="fas fa-external-link-alt"></i></a></p>
<p>MobileNet<br><a class="link"   href="https://www.cnblogs.com/adong7639/p/7918527.html" >https://www.cnblogs.com/adong7639/p/7918527.html<i class="fas fa-external-link-alt"></i></a></p>
<p>MobileNetV2<br><a class="link"   href="https://blog.csdn.net/u011995719/article/details/79135818" >https://blog.csdn.net/u011995719/article/details/79135818<i class="fas fa-external-link-alt"></i></a></p>
<p>ShuffleNetV2<br><a class="link"   href="https://www.jianshu.com/p/71e32918ea0a" >https://www.jianshu.com/p/71e32918ea0a<i class="fas fa-external-link-alt"></i></a></p>
<p><a class="link"   href="https://zhuanlan.zhihu.com/p/35405071" >https://zhuanlan.zhihu.com/p/35405071<i class="fas fa-external-link-alt"></i></a></p>
]]></content>
      <categories>
        <category>技能-修行-进步-ML</category>
      </categories>
      <tags>
        <tag>deep learning</tag>
        <tag>light framwork</tag>
        <tag>convolution</tag>
      </tags>
  </entry>
  <entry>
    <title>Training your own data with TF object detection API</title>
    <url>/2021/02/03/ML/Training-your-own-data-with-TF-object-detection-API/</url>
    <content><![CDATA[<h2 id="System-Info"><a href="#System-Info" class="headerlink" title="System Info"></a>System Info</h2><ul>
<li>Ubuntu 16.04</li>
<li>Git</li>
<li>TF 2.0</li>
<li>pillow</li>
<li>lxml</li>
<li>protobuf ( &gt; 3.3 , my version, 3.11.2)</li>
<li><a class="link"   href="https://www.cnblogs.com/gezhuangzhuang/p/10613468.html" >ref1-tensorflow+ssd_mobilenet实现目标检测的训练<i class="fas fa-external-link-alt"></i></a></li>
<li><a class="link"   href="https://blog.csdn.net/dy_guox/article/details/79111949" >ref2-（更新视频教程）Tensorflow object detection API 搭建属于自己的物体识别模型（2）——训练并使用自己的模型<i class="fas fa-external-link-alt"></i></a></li>
<li><a class="link"   href="https://blog.csdn.net/linolzhang/article/details/87121875" >ref3-Tensorflow object detection API训练自己的数据<i class="fas fa-external-link-alt"></i></a></li>
</ul>
<h2 id="To-dos"><a href="#To-dos" class="headerlink" title="To-dos"></a>To-dos</h2><ul>
<li><a class="link"   href="https://github.com/tensorflow/models/tree/master/research/object_detection" >TF object detection API<i class="fas fa-external-link-alt"></i></a></li>
</ul>
<h3 id="Env-prepare"><a href="#Env-prepare" class="headerlink" title="Env prepare"></a>Env prepare</h3><ul>
<li>Clone the <a class="link"   href="https://github.com/tensorflow/models" >model repository<i class="fas fa-external-link-alt"></i></a> into local</li>
<li><a class="link"   href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md" >Guid for installation<i class="fas fa-external-link-alt"></i></a></li>
</ul>
<h3 id="Make-your-own-dataset"><a href="#Make-your-own-dataset" class="headerlink" title="Make your own dataset"></a>Make your own dataset</h3><ul>
<li>For us, we have the yolo format annotaion files(txt files), but TFRecord format data is fit to the tensorlow.</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yolo-2-voc.py</span><br><span class="line">voc-2-csv.py</span><br><span class="line">csv-2-tfrecord.py</span><br></pre></td></tr></table></figure>
<h4 id="yolo-to-voc"><a href="#yolo-to-voc" class="headerlink" title="yolo to voc"></a>yolo to voc</h4><ul>
<li>Prepare two folders, one for <strong>annotation files</strong> and the other for the <strong>image files</strong>. VOC format(xml files) will save into the <strong>converted_lanbels</strong> folder.</li>
<li><strong>manual change your own data label-mappings</strong></li>
<li>Notice that the value of <strong>(x, y, width, height) are integers</strong> .<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Script to convert yolo annotations to voc format</span><br><span class="line"></span><br><span class="line"># Sample format</span><br><span class="line"># &lt;annotation&gt;</span><br><span class="line">#     &lt;folder&gt;_image_fashion&lt;/folder&gt;</span><br><span class="line">#     &lt;filename&gt;brooke-cagle-39574.jpg&lt;/filename&gt;</span><br><span class="line">#     &lt;size&gt;</span><br><span class="line">#         &lt;width&gt;1200&lt;/width&gt;</span><br><span class="line">#         &lt;height&gt;800&lt;/height&gt;</span><br><span class="line">#         &lt;depth&gt;3&lt;/depth&gt;</span><br><span class="line">#     &lt;/size&gt;</span><br><span class="line">#     &lt;segmented&gt;0&lt;/segmented&gt;</span><br><span class="line">#     &lt;object&gt;</span><br><span class="line">#         &lt;name&gt;head&lt;/name&gt;</span><br><span class="line">#         &lt;pose&gt;Unspecified&lt;/pose&gt;</span><br><span class="line">#         &lt;truncated&gt;0&lt;/truncated&gt;</span><br><span class="line">#         &lt;difficult&gt;0&lt;/difficult&gt;</span><br><span class="line">#         &lt;bndbox&gt;</span><br><span class="line">#             &lt;xmin&gt;549&lt;/xmin&gt;</span><br><span class="line">#             &lt;ymin&gt;251&lt;/ymin&gt;</span><br><span class="line">#             &lt;xmax&gt;625&lt;/xmax&gt;</span><br><span class="line">#             &lt;ymax&gt;335&lt;/ymax&gt;</span><br><span class="line">#         &lt;/bndbox&gt;</span><br><span class="line">#     &lt;/object&gt;</span><br><span class="line"># &lt;annotation&gt;</span><br><span class="line">import os</span><br><span class="line">import xml.etree.cElementTree as ET</span><br><span class="line">from PIL import Image</span><br><span class="line"></span><br><span class="line">ANNOTATIONS_DIR_PREFIX = &quot;annotations&quot;</span><br><span class="line"></span><br><span class="line">DESTINATION_DIR = &quot;converted_labels&quot;</span><br><span class="line"></span><br><span class="line">CLASS_MAPPING = &#123;</span><br><span class="line">    &#x27;0&#x27;: &#x27;cream_hazelnut&#x27;,</span><br><span class="line">    &#x27;1&#x27;: &#x27;cream_berry&#x27;,</span><br><span class="line">    &#x27;2&#x27;: &#x27;cream_cherry&#x27;,</span><br><span class="line">    &#x27;3&#x27;: &#x27;yida_cool_lemon&#x27;,</span><br><span class="line">    &#x27;4&#x27;: &#x27;box_yogurt_mango&#x27;,</span><br><span class="line">    &#x27;5&#x27;: &#x27;white_strawberry&#x27;,</span><br><span class="line">    &#x27;6&#x27;: &#x27;cookies_lemon&#x27;,</span><br><span class="line">    &#x27;7&#x27;: &#x27;yogurt_cranberry&#x27;,</span><br><span class="line">    &#x27;8&#x27;: &#x27;box_cookies_matcha&#x27;,</span><br><span class="line">    &#x27;9&#x27;: &#x27;cookies_matcha&#x27;,</span><br><span class="line">    &#x27;10&#x27;: &#x27;yogurt_mango&#x27;,</span><br><span class="line">    &#x27;11&#x27;: &#x27;white_passionfruit&#x27;,</span><br><span class="line">    &#x27;12&#x27;: &#x27;yida_cool_litchi&#x27;,</span><br><span class="line">    &#x27;13&#x27;: &#x27;box_white_strawberry&#x27;</span><br><span class="line">    # Add your remaining classes here.</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def create_root(file_prefix, width, height):</span><br><span class="line">    root = ET.Element(&quot;annotations&quot;)</span><br><span class="line">    ET.SubElement(root, &quot;filename&quot;).text = &quot;&#123;&#125;.jpg&quot;.format(file_prefix)</span><br><span class="line">    ET.SubElement(root, &quot;folder&quot;).text = &quot;images&quot;</span><br><span class="line">    size = ET.SubElement(root, &quot;size&quot;)</span><br><span class="line">    ET.SubElement(size, &quot;width&quot;).text = str(width)</span><br><span class="line">    ET.SubElement(size, &quot;height&quot;).text = str(height)</span><br><span class="line">    ET.SubElement(size, &quot;depth&quot;).text = &quot;3&quot;</span><br><span class="line">    return root</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def create_object_annotation(root, voc_labels):</span><br><span class="line">    for voc_label in voc_labels:</span><br><span class="line">        obj = ET.SubElement(root, &quot;object&quot;)</span><br><span class="line">        ET.SubElement(obj, &quot;name&quot;).text = voc_label[0]</span><br><span class="line">        ET.SubElement(obj, &quot;pose&quot;).text = &quot;Unspecified&quot;</span><br><span class="line">        ET.SubElement(obj, &quot;truncated&quot;).text = str(0)</span><br><span class="line">        ET.SubElement(obj, &quot;difficult&quot;).text = str(0)</span><br><span class="line">        bbox = ET.SubElement(obj, &quot;bndbox&quot;)</span><br><span class="line">        ET.SubElement(bbox, &quot;xmin&quot;).text = str(voc_label[1])</span><br><span class="line">        ET.SubElement(bbox, &quot;ymin&quot;).text = str(voc_label[2])</span><br><span class="line">        ET.SubElement(bbox, &quot;xmax&quot;).text = str(voc_label[3])</span><br><span class="line">        ET.SubElement(bbox, &quot;ymax&quot;).text = str(voc_label[4])</span><br><span class="line">    return root</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def create_file(file_prefix, width, height, voc_labels):</span><br><span class="line">    root = create_root(file_prefix, width, height)</span><br><span class="line">    root = create_object_annotation(root, voc_labels)</span><br><span class="line">    tree = ET.ElementTree(root)</span><br><span class="line">    tree.write(&quot;&#123;&#125;/&#123;&#125;.xml&quot;.format(DESTINATION_DIR, file_prefix))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def read_file(file_path):</span><br><span class="line">    file_prefix = file_path.split(&quot;.txt&quot;)[0]</span><br><span class="line">    image_file_name = &quot;&#123;&#125;.jpg&quot;.format(file_prefix)</span><br><span class="line">    img = Image.open(&quot;&#123;&#125;/&#123;&#125;&quot;.format(&quot;images&quot;, image_file_name))</span><br><span class="line">    w, h = img.size</span><br><span class="line">    </span><br><span class="line">    with open(&quot;&#123;&#125;/&#123;&#125;&quot;.format(ANNOTATIONS_DIR_PREFIX, file_path), &#x27;r&#x27;) as file:</span><br><span class="line">        lines = file.readlines()</span><br><span class="line">        voc_labels = []</span><br><span class="line">        for line in lines:</span><br><span class="line">            voc = []</span><br><span class="line">            line = line.strip()</span><br><span class="line">            data = line.split()</span><br><span class="line">            voc.append(CLASS_MAPPING.get(data[0]))</span><br><span class="line">            bbox_width = float(data[3]) * w</span><br><span class="line">            bbox_height = float(data[4]) * h</span><br><span class="line">            center_x = float(data[1]) * w</span><br><span class="line">            center_y = float(data[2]) * h</span><br><span class="line">            voc.append(int(center_x - (bbox_width / 2)))</span><br><span class="line">            voc.append(int(center_y - (bbox_height / 2)))</span><br><span class="line">            voc.append(int(center_x + (bbox_width / 2)))</span><br><span class="line">            voc.append(int(center_y + (bbox_height / 2)))</span><br><span class="line">            voc_labels.append(voc)</span><br><span class="line">        create_file(file_prefix, w, h, voc_labels)</span><br><span class="line">    print(&quot;Processing complete for file: &#123;&#125;/&#123;&#125;&quot;.format(ANNOTATIONS_DIR_PREFIX, file_path))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def start():</span><br><span class="line">    if not os.path.exists(DESTINATION_DIR):</span><br><span class="line">        os.makedirs(DESTINATION_DIR)</span><br><span class="line">    for filename in os.listdir(ANNOTATIONS_DIR_PREFIX):</span><br><span class="line">        if filename.endswith(&#x27;txt&#x27;):</span><br><span class="line">            read_file(filename)</span><br><span class="line">        else:</span><br><span class="line">            print(&quot;Skipping file: &#123;&#125;&quot;.format(filename))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    start()</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="train-test-split-on-xml-files"><a href="#train-test-split-on-xml-files" class="headerlink" title="train test split on xml files"></a>train test split on xml files</h4><ul>
<li>You can change the percentage to split the dataset manually.<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import os</span><br><span class="line">import random</span><br><span class="line">import time</span><br><span class="line">import shutil</span><br><span class="line"></span><br><span class="line">xmlfilepath = r&#x27;./Annotations&#x27;</span><br><span class="line">saveBasePath = r&quot;./&quot;</span><br><span class="line"></span><br><span class="line">trainval_percent = 0.8</span><br><span class="line">train_percent = 0.8</span><br><span class="line">total_xml = os.listdir(xmlfilepath)</span><br><span class="line">num = len(total_xml)</span><br><span class="line">list = range(num)</span><br><span class="line">tv = int(num * trainval_percent)</span><br><span class="line">tr = int(tv * train_percent)</span><br><span class="line">trainval = random.sample(list, tv)</span><br><span class="line">train = random.sample(trainval, tr)</span><br><span class="line">print(&quot;train and val size&quot;, tv)</span><br><span class="line">print(&quot;train size&quot;, tr)</span><br><span class="line"></span><br><span class="line">start = time.time()</span><br><span class="line"></span><br><span class="line">test_num = 0</span><br><span class="line">val_num = 0</span><br><span class="line">train_num = 0</span><br><span class="line">print(&#x27;total xml : &#123;&#125;&#x27;.format(total_xml))</span><br><span class="line"></span><br><span class="line">for i in list:</span><br><span class="line">    name = total_xml[i]</span><br><span class="line">    # print(&#x27;name : &#123;&#125;&#x27;.format(name))</span><br><span class="line">    if i in trainval:  # train and val set</span><br><span class="line">        if i in train:</span><br><span class="line">            directory = &quot;train&quot;</span><br><span class="line">            train_num += 1</span><br><span class="line">            xml_path = os.path.join(os.getcwd(), &#x27;&#123;&#125;&#x27;.format(directory))</span><br><span class="line">            if (not os.path.exists(xml_path)):</span><br><span class="line">                os.mkdir(xml_path)</span><br><span class="line">            filePath = os.path.join(xmlfilepath, name)</span><br><span class="line">            newfile = os.path.join(saveBasePath, os.path.join(directory, name))</span><br><span class="line">            # print(&#x27;newfile : &#123;&#125;&#x27;.format(newfile))</span><br><span class="line">            shutil.copyfile(filePath, newfile)</span><br><span class="line">        else:</span><br><span class="line">            directory = &quot;validation&quot;</span><br><span class="line">            xml_path = os.path.join(os.getcwd(), &#x27;&#123;&#125;&#x27;.format(directory))</span><br><span class="line">            if (not os.path.exists(xml_path)):</span><br><span class="line">                os.mkdir(xml_path)</span><br><span class="line">            val_num += 1</span><br><span class="line">            filePath = os.path.join(xmlfilepath, name)</span><br><span class="line">            newfile = os.path.join(saveBasePath, os.path.join(directory, name))</span><br><span class="line">            # print(&#x27;newfile : &#123;&#125;&#x27;.format(newfile))</span><br><span class="line">            shutil.copyfile(filePath, newfile)</span><br><span class="line">    else:</span><br><span class="line">        directory = &quot;test&quot;</span><br><span class="line">        xml_path = os.path.join(os.getcwd(), &#x27;&#123;&#125;&#x27;.format(directory))</span><br><span class="line">        if (not os.path.exists(xml_path)):</span><br><span class="line">            os.mkdir(xml_path)</span><br><span class="line">        test_num += 1</span><br><span class="line">        filePath = os.path.join(xmlfilepath, name)</span><br><span class="line">        newfile = os.path.join(saveBasePath, os.path.join(directory, name))</span><br><span class="line">        # print(&#x27;name : &#123;&#125;&#x27;.format(name))</span><br><span class="line">        shutil.copyfile(filePath, newfile)</span><br><span class="line"></span><br><span class="line">end = time.time()</span><br><span class="line">seconds = end - start</span><br><span class="line">print(&quot;train total : &quot; + str(train_num))</span><br><span class="line">print(&quot;validation total : &quot; + str(val_num))</span><br><span class="line">print(&quot;test total : &quot; + str(test_num))</span><br><span class="line">total_num = train_num + val_num + test_num</span><br><span class="line">print(&quot;total number : &quot; + str(total_num))</span><br><span class="line">print(&quot;Time taken : &#123;0&#125; seconds&quot;.format(seconds))</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="voc-to-csv"><a href="#voc-to-csv" class="headerlink" title="voc to csv"></a>voc to csv</h4><ul>
<li>Transfer the xml files to csv for trian, test and validation folder individually.</li>
<li>You should change the save path for your own csv files.<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import os</span><br><span class="line">import glob</span><br><span class="line">import pandas as pd</span><br><span class="line">import xml.etree.ElementTree as ET</span><br><span class="line"></span><br><span class="line">def xml_to_csv(path):</span><br><span class="line">    xml_list = []</span><br><span class="line">    for xml_file in glob.glob(path + &#x27;/*.xml&#x27;):</span><br><span class="line">        tree = ET.parse(xml_file)</span><br><span class="line">        root = tree.getroot()</span><br><span class="line"></span><br><span class="line">        print(root.find(&#x27;filename&#x27;).text)</span><br><span class="line">        for member in root.findall(&#x27;object&#x27;):</span><br><span class="line">            value = (root.find(&#x27;filename&#x27;).text,</span><br><span class="line">                int(root.find(&#x27;size&#x27;)[0].text),   #width</span><br><span class="line">                int(root.find(&#x27;size&#x27;)[1].text),   #height</span><br><span class="line">                member[0].text,</span><br><span class="line">                int(member[4][0].text),</span><br><span class="line">                int(float(member[4][1].text)),</span><br><span class="line">                int(member[4][2].text),</span><br><span class="line">                int(member[4][3].text)</span><br><span class="line">                )</span><br><span class="line">            xml_list.append(value)</span><br><span class="line">    column_name = [&#x27;filename&#x27;, &#x27;width&#x27;, &#x27;height&#x27;, &#x27;class&#x27;, &#x27;xmin&#x27;, &#x27;ymin&#x27;, &#x27;xmax&#x27;, &#x27;ymax&#x27;]</span><br><span class="line">    xml_df = pd.DataFrame(xml_list, columns=column_name)</span><br><span class="line">    return xml_df</span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    for directory in [&#x27;train&#x27;,&#x27;test&#x27;,&#x27;validation&#x27;]:</span><br><span class="line">        xml_path = os.path.join(os.getcwd(), &#x27;./&#123;&#125;&#x27;.format(directory))</span><br><span class="line"></span><br><span class="line">        xml_df = xml_to_csv(xml_path)</span><br><span class="line">        # xml_df.to_csv(&#x27;whsyxt.csv&#x27;, index=None)</span><br><span class="line">        xml_df.to_csv(&#x27;/home/tim/workspace/models/research/object_detection/data/dove_cholo_&#123;&#125;_labels.csv&#x27;.format(directory), index=None)</span><br><span class="line">        print(&#x27;Successfully converted xml to csv.&#x27;)</span><br><span class="line"></span><br><span class="line">main()</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="csv-to-tfrecord"><a href="#csv-to-tfrecord" class="headerlink" title="csv to tfrecord"></a>csv to tfrecord</h4><ul>
<li>You should set your JPEGImage path.<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/usr/bin/env python3</span><br><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">Created on Tue Mar  5 15:28:55 2019</span><br><span class="line"></span><br><span class="line">@author: z</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">Usage:</span><br><span class="line">  # From tensorflow/models/</span><br><span class="line">  # Create train data:</span><br><span class="line">  python generate_tfrecord.py --csv_input=data/tv_vehicle_labels.csv  --output_path=train.record</span><br><span class="line">  # Create test data:</span><br><span class="line">  python generate_tfrecord.py --csv_input=data/test_labels.csv  --output_path=test.record</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">import os</span><br><span class="line">import io</span><br><span class="line">import pandas as pd</span><br><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">from PIL import Image</span><br><span class="line">from object_detection.utils import dataset_util</span><br><span class="line">from collections import namedtuple, OrderedDict</span><br><span class="line"></span><br><span class="line">os.chdir(&#x27;/home/tim/workspace/models/research/&#x27;)</span><br><span class="line"></span><br><span class="line">flags = tf.app.flags</span><br><span class="line">flags.DEFINE_string(&#x27;csv_input&#x27;, &#x27;&#x27;, &#x27;Path to the CSV input&#x27;)</span><br><span class="line">flags.DEFINE_string(&#x27;output_path&#x27;, &#x27;&#x27;, &#x27;Path to output TFRecord&#x27;)</span><br><span class="line">FLAGS = flags.FLAGS</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># TO-DO replace this with label map</span><br><span class="line">def class_text_to_int(row_label):</span><br><span class="line">    # 你的所有类别, 必须从1开始，0被征用作为了背景。</span><br><span class="line">    if row_label == &#x27;cream_berry&#x27;:</span><br><span class="line">        return 1</span><br><span class="line">    elif row_label == &#x27;cream_cherry&#x27;:</span><br><span class="line">        return 2</span><br><span class="line">    elif row_label == &#x27;yida_cool_lemon&#x27;:</span><br><span class="line">        return 3</span><br><span class="line">    elif row_label == &#x27;box_yogurt_mango&#x27;:</span><br><span class="line">        return 4</span><br><span class="line">    elif row_label == &#x27;white_strawberry&#x27;:</span><br><span class="line">        return 5</span><br><span class="line">    elif row_label == &#x27;cookies_lemon&#x27;:</span><br><span class="line">        return 6</span><br><span class="line">    elif row_label == &#x27;yogurt_cranberry&#x27;:</span><br><span class="line">        return 7</span><br><span class="line">    elif row_label == &#x27;box_cookies_matcha&#x27;:</span><br><span class="line">        return 8</span><br><span class="line">    elif row_label == &#x27;cookies_matcha&#x27;:</span><br><span class="line">        return 9</span><br><span class="line">    elif row_label == &#x27;yogurt_mango&#x27;:</span><br><span class="line">        return 10</span><br><span class="line">    elif row_label == &#x27;white_passionfruit&#x27;:</span><br><span class="line">        return 11</span><br><span class="line">    elif row_label == &#x27;yida_cool_litchi&#x27;:</span><br><span class="line">        return 12</span><br><span class="line">    elif row_label == &#x27;box_white_strawberry&#x27;:</span><br><span class="line">        return 13</span><br><span class="line">    elif row_label == &#x27;cream_hazelnut&#x27;:</span><br><span class="line">        return 14</span><br><span class="line">    else:</span><br><span class="line">        return None</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def split(df, group):</span><br><span class="line">    data = namedtuple(&#x27;data&#x27;, [&#x27;filename&#x27;, &#x27;object&#x27;])</span><br><span class="line">    gb = df.groupby(group)</span><br><span class="line">    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def create_tf_example(group, path):</span><br><span class="line">    with tf.gfile.GFile(os.path.join(path, &#x27;&#123;&#125;&#x27;.format(group.filename)), &#x27;rb&#x27;) as fid:</span><br><span class="line">        encoded_jpg = fid.read()</span><br><span class="line">    encoded_jpg_io = io.BytesIO(encoded_jpg)</span><br><span class="line">    image = Image.open(encoded_jpg_io)</span><br><span class="line">    width, height = image.size</span><br><span class="line"></span><br><span class="line">    filename = group.filename.encode(&#x27;utf8&#x27;)</span><br><span class="line">    image_format = b&#x27;jpg&#x27;</span><br><span class="line">    xmins = []</span><br><span class="line">    xmaxs = []</span><br><span class="line">    ymins = []</span><br><span class="line">    ymaxs = []</span><br><span class="line">    classes_text = []</span><br><span class="line">    classes = []</span><br><span class="line"></span><br><span class="line">    for index, row in group.object.iterrows():</span><br><span class="line">        xmins.append(row[&#x27;xmin&#x27;] / width)</span><br><span class="line">        xmaxs.append(row[&#x27;xmax&#x27;] / width)</span><br><span class="line">        ymins.append(row[&#x27;ymin&#x27;] / height)</span><br><span class="line">        ymaxs.append(row[&#x27;ymax&#x27;] / height)</span><br><span class="line">        classes_text.append(row[&#x27;class&#x27;].encode(&#x27;utf8&#x27;))</span><br><span class="line">        classes.append(class_text_to_int(row[&#x27;class&#x27;]))</span><br><span class="line"></span><br><span class="line">    tf_example = tf.train.Example(features=tf.train.Features(feature=&#123;</span><br><span class="line">        &#x27;image/height&#x27;: dataset_util.int64_feature(height),</span><br><span class="line">        &#x27;image/width&#x27;: dataset_util.int64_feature(width),</span><br><span class="line">        &#x27;image/filename&#x27;: dataset_util.bytes_feature(filename),</span><br><span class="line">        &#x27;image/source_id&#x27;: dataset_util.bytes_feature(filename),</span><br><span class="line">        &#x27;image/encoded&#x27;: dataset_util.bytes_feature(encoded_jpg),</span><br><span class="line">        &#x27;image/format&#x27;: dataset_util.bytes_feature(image_format),</span><br><span class="line">        &#x27;image/object/bbox/xmin&#x27;: dataset_util.float_list_feature(xmins),</span><br><span class="line">        &#x27;image/object/bbox/xmax&#x27;: dataset_util.float_list_feature(xmaxs),</span><br><span class="line">        &#x27;image/object/bbox/ymin&#x27;: dataset_util.float_list_feature(ymins),</span><br><span class="line">        &#x27;image/object/bbox/ymax&#x27;: dataset_util.float_list_feature(ymaxs),</span><br><span class="line">        &#x27;image/object/class/text&#x27;: dataset_util.bytes_list_feature(classes_text),</span><br><span class="line">        &#x27;image/object/class/label&#x27;: dataset_util.int64_list_feature(classes),</span><br><span class="line">    &#125;))</span><br><span class="line">    return tf_example</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main(_):</span><br><span class="line">    writer = tf.python_io.TFRecordWriter(FLAGS.output_path)</span><br><span class="line">    path = os.path.join(os.getcwd(), &#x27;object_detection/VOCdevkit/VOC2020_dove_cholo/JPEGImages/&#x27;)</span><br><span class="line">    examples = pd.read_csv(FLAGS.csv_input)</span><br><span class="line">    grouped = split(examples, &#x27;filename&#x27;)</span><br><span class="line">    num = 0</span><br><span class="line">    for group in grouped:</span><br><span class="line">        num += 1</span><br><span class="line">        tf_example = create_tf_example(group, path)</span><br><span class="line">        writer.write(tf_example.SerializeToString())</span><br><span class="line">        if (num % 100 == 0):  # 每完成100个转换，打印一次</span><br><span class="line">            print(num)</span><br><span class="line"></span><br><span class="line">    writer.close()</span><br><span class="line">    output_path = os.path.join(os.getcwd(), FLAGS.output_path)</span><br><span class="line">    print(&#x27;Successfully created the TFRecords: &#123;&#125;&#x27;.format(output_path))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    tf.app.run()</span><br></pre></td></tr></table></figure></li>
<li>command to generate tfrecord files<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd models/research/</span><br><span class="line"></span><br><span class="line">python generate_tfrecord.py --csv_input=object_detection/data/dove_cholo_test_labels.csv --output_path=dove_test.tfrecord</span><br><span class="line"></span><br><span class="line">python generate_tfrecord.py --csv_input=object_detection/data/dove_cholo_validation_labels.csv --output_path=dove_validation.tfrecord</span><br><span class="line"></span><br><span class="line">python generate_tfrecord.py --csv_input=object_detection/data/dove_cholo_train_labels.csv --output_path=dove_train.tfrecord</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="Training-model"><a href="#Training-model" class="headerlink" title="Training model"></a>Training model</h3><ul>
<li>Things to prepare<ul>
<li>create your own label-map.pbtxt<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd models/research/object_detection/data</span><br><span class="line">create label-map.pbtxt</span><br><span class="line">contents are belows</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	item &#123;</span><br><span class="line">	  id: 1    # id 从1开始编号</span><br><span class="line">	  name: &#x27;red pedestrian&#x27;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	item &#123;</span><br><span class="line">	  id: 2</span><br><span class="line">	  name: &#x27;green pedestrian&#x27;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure></li>
<li>model config file list<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd object_detection/samples/config/</span><br><span class="line"></span><br><span class="line">(base) tim@tim-System-Product-Name:~/workspace/models/research/object_detection/samples/configs$ tree</span><br><span class="line">.</span><br><span class="line">├── embedded_ssd_mobilenet_v1_coco.config</span><br><span class="line">├── facessd_mobilenet_v2_quantized_320x320_open_image_v4.config</span><br><span class="line">├── faster_rcnn_inception_resnet_v2_atrous_coco.config</span><br><span class="line">├── faster_rcnn_inception_resnet_v2_atrous_cosine_lr_coco.config</span><br><span class="line">├── faster_rcnn_inception_resnet_v2_atrous_oid.config</span><br><span class="line">├── faster_rcnn_inception_resnet_v2_atrous_oid_v4.config</span><br><span class="line">├── faster_rcnn_inception_resnet_v2_atrous_pets.config</span><br><span class="line">├── faster_rcnn_inception_v2_coco.config</span><br><span class="line">├── faster_rcnn_inception_v2_pets.config</span><br><span class="line">├── faster_rcnn_nas_coco.config</span><br><span class="line">├── faster_rcnn_resnet101_atrous_coco.config</span><br><span class="line">├── faster_rcnn_resnet101_ava_v2.1.config</span><br><span class="line">├── faster_rcnn_resnet101_coco.config</span><br><span class="line">├── faster_rcnn_resnet101_fgvc.config</span><br><span class="line">├── faster_rcnn_resnet101_kitti.config</span><br><span class="line">├── faster_rcnn_resnet101_pets.config</span><br><span class="line">├── faster_rcnn_resnet101_voc07.config</span><br><span class="line">├── faster_rcnn_resnet152_coco.config</span><br><span class="line">├── faster_rcnn_resnet152_pets.config</span><br><span class="line">├── faster_rcnn_resnet50_coco.config</span><br><span class="line">├── faster_rcnn_resnet50_fgvc.config</span><br><span class="line">├── faster_rcnn_resnet50_pets.config</span><br><span class="line">├── mask_rcnn_inception_resnet_v2_atrous_coco.config</span><br><span class="line">├── mask_rcnn_inception_v2_coco.config</span><br><span class="line">├── mask_rcnn_resnet101_atrous_coco.config</span><br><span class="line">├── mask_rcnn_resnet101_pets.config</span><br><span class="line">├── mask_rcnn_resnet50_atrous_coco.config</span><br><span class="line">├── rfcn_resnet101_coco.config</span><br><span class="line">├── rfcn_resnet101_pets.config</span><br><span class="line">├── ssd_inception_v2_coco.config</span><br><span class="line">├── ssd_inception_v2_pets.config</span><br><span class="line">├── ssd_inception_v3_pets.config</span><br><span class="line">├── ssdlite_mobilenet_edgetpu_320x320_coco.config</span><br><span class="line">├── ssdlite_mobilenet_edgetpu_320x320_coco_quant.config</span><br><span class="line">├── ssdlite_mobilenet_v1_coco.config</span><br><span class="line">├── ssdlite_mobilenet_v2_coco.config</span><br><span class="line">├── ssdlite_mobilenet_v3_large_320x320_coco.config</span><br><span class="line">├── ssdlite_mobilenet_v3_small_320x320_coco.config</span><br><span class="line">├── ssd_mobilenet_v1_0.75_depth_300x300_coco14_sync.config</span><br><span class="line">├── ssd_mobilenet_v1_0.75_depth_quantized_300x300_coco14_sync.config</span><br><span class="line">├── ssd_mobilenet_v1_0.75_depth_quantized_300x300_pets_sync.config</span><br><span class="line">├── ssd_mobilenet_v1_300x300_coco14_sync.config</span><br><span class="line">├── ssd_mobilenet_v1_coco.config</span><br><span class="line">├── ssd_mobilenet_v1_focal_loss_pets.config</span><br><span class="line">├── ssd_mobilenet_v1_focal_loss_pets_inference.config</span><br><span class="line">├── ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync.config</span><br><span class="line">├── ssd_mobilenet_v1_pets.config</span><br><span class="line">├── ssd_mobilenet_v1_ppn_shared_box_predictor_300x300_coco14_sync.config</span><br><span class="line">├── ssd_mobilenet_v1_quantized_300x300_coco14_sync.config</span><br><span class="line">├── ssd_mobilenet_v2_coco.config</span><br><span class="line">├── ssd_mobilenet_v2_fpnlite_quantized_shared_box_predictor_256x256_depthmultiplier_75_coco14_sync.config</span><br><span class="line">├── ssd_mobilenet_v2_fullyconv_coco.config</span><br><span class="line">├── ssd_mobilenet_v2_oid_v4.config</span><br><span class="line">├── ssd_mobilenet_v2_pets_keras.config</span><br><span class="line">├── ssd_mobilenet_v2_quantized_300x300_coco.config</span><br><span class="line">├── ssd_resnet101_v1_fpn_shared_box_predictor_oid_512x512_sync.config</span><br><span class="line">└── ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync.config</span><br><span class="line"></span><br><span class="line">0 directories, 57 files</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li>Custom your own model config, ssd_moblienet_v1_coco.config for example</li>
<li>Open it and change the code.<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># SSD with Mobilenet v1 configuration for MSCOCO Dataset.</span><br><span class="line"># Users should configure the fine_tune_checkpoint field in the train config as</span><br><span class="line"># well as the label_map_path and input_path fields in the train_input_reader and</span><br><span class="line"># eval_input_reader. Search for &quot;PATH_TO_BE_CONFIGURED&quot; to find the fields that</span><br><span class="line"># should be configured.</span><br><span class="line"></span><br><span class="line">model &#123;</span><br><span class="line">  ssd &#123;</span><br><span class="line">    num_classes: 14  ## change here</span><br><span class="line">    box_coder &#123;</span><br><span class="line">      faster_rcnn_box_coder &#123;</span><br><span class="line">        y_scale: 10.0</span><br><span class="line">        x_scale: 10.0</span><br><span class="line">        height_scale: 5.0</span><br><span class="line">        width_scale: 5.0</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    matcher &#123;</span><br><span class="line">      argmax_matcher &#123;</span><br><span class="line">        matched_threshold: 0.5</span><br><span class="line">        unmatched_threshold: 0.5</span><br><span class="line">        ignore_thresholds: false</span><br><span class="line">        negatives_lower_than_unmatched: true</span><br><span class="line">        force_match_for_each_row: true</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    similarity_calculator &#123;</span><br><span class="line">      iou_similarity &#123;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    anchor_generator &#123;</span><br><span class="line">      ssd_anchor_generator &#123;</span><br><span class="line">        num_layers: 6</span><br><span class="line">        min_scale: 0.2</span><br><span class="line">        max_scale: 0.95</span><br><span class="line">        aspect_ratios: 1.0</span><br><span class="line">        aspect_ratios: 2.0</span><br><span class="line">        aspect_ratios: 0.5</span><br><span class="line">        aspect_ratios: 3.0</span><br><span class="line">        aspect_ratios: 0.3333</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    image_resizer &#123;</span><br><span class="line">      fixed_shape_resizer &#123;</span><br><span class="line">        height: 300</span><br><span class="line">        width: 300</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    box_predictor &#123;</span><br><span class="line">      convolutional_box_predictor &#123;</span><br><span class="line">        min_depth: 0</span><br><span class="line">        max_depth: 0</span><br><span class="line">        num_layers_before_predictor: 0</span><br><span class="line">        use_dropout: false</span><br><span class="line">        dropout_keep_probability: 0.8</span><br><span class="line">        kernel_size: 1</span><br><span class="line">        box_code_size: 4</span><br><span class="line">        apply_sigmoid_to_scores: false</span><br><span class="line">        conv_hyperparams &#123;</span><br><span class="line">          activation: RELU_6,</span><br><span class="line">          regularizer &#123;</span><br><span class="line">            l2_regularizer &#123;</span><br><span class="line">              weight: 0.00004</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">          initializer &#123;</span><br><span class="line">            truncated_normal_initializer &#123;</span><br><span class="line">              stddev: 0.03</span><br><span class="line">              mean: 0.0</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">          batch_norm &#123;</span><br><span class="line">            train: true,</span><br><span class="line">            scale: true,</span><br><span class="line">            center: true,</span><br><span class="line">            decay: 0.9997,</span><br><span class="line">            epsilon: 0.001,</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    feature_extractor &#123;</span><br><span class="line">      type: &#x27;ssd_mobilenet_v1&#x27;</span><br><span class="line">      min_depth: 16</span><br><span class="line">      depth_multiplier: 1.0</span><br><span class="line">      conv_hyperparams &#123;</span><br><span class="line">        activation: RELU_6,</span><br><span class="line">        regularizer &#123;</span><br><span class="line">          l2_regularizer &#123;</span><br><span class="line">            weight: 0.00004</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        initializer &#123;</span><br><span class="line">          truncated_normal_initializer &#123;</span><br><span class="line">            stddev: 0.03</span><br><span class="line">            mean: 0.0</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        batch_norm &#123;</span><br><span class="line">          train: true,</span><br><span class="line">          scale: true,</span><br><span class="line">          center: true,</span><br><span class="line">          decay: 0.9997,</span><br><span class="line">          epsilon: 0.001,</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    loss &#123;</span><br><span class="line">      classification_loss &#123;</span><br><span class="line">        weighted_sigmoid &#123;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      localization_loss &#123;</span><br><span class="line">        weighted_smooth_l1 &#123;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      hard_example_miner &#123;</span><br><span class="line">        num_hard_examples: 3000</span><br><span class="line">        iou_threshold: 0.99</span><br><span class="line">        loss_type: CLASSIFICATION</span><br><span class="line">        max_negatives_per_positive: 3</span><br><span class="line">        min_negatives_per_image: 0</span><br><span class="line">      &#125;</span><br><span class="line">      classification_weight: 1.0</span><br><span class="line">      localization_weight: 1.0</span><br><span class="line">    &#125;</span><br><span class="line">    normalize_loss_by_num_matches: true</span><br><span class="line">    post_processing &#123;</span><br><span class="line">      batch_non_max_suppression &#123;</span><br><span class="line">        score_threshold: 1e-8</span><br><span class="line">        iou_threshold: 0.6</span><br><span class="line">        max_detections_per_class: 100</span><br><span class="line">        max_total_detections: 100</span><br><span class="line">      &#125;</span><br><span class="line">      score_converter: SIGMOID</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">train_config: &#123;</span><br><span class="line">  batch_size: 24   ## change here</span><br><span class="line">  optimizer &#123;</span><br><span class="line">    rms_prop_optimizer: &#123;</span><br><span class="line">      learning_rate: &#123;</span><br><span class="line">        exponential_decay_learning_rate &#123;</span><br><span class="line">          initial_learning_rate: 0.0004</span><br><span class="line">          decay_steps: 800720</span><br><span class="line">          decay_factor: 0.95</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      momentum_optimizer_value: 0.9</span><br><span class="line">      decay: 0.9</span><br><span class="line">      epsilon: 1.0</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  fine_tune_checkpoint: &quot;object_detection/finetune_cpkt/ssd_mobilenet_v1_coco_2018_01_28/model.ckpt&quot;   ## change here</span><br><span class="line">  from_detection_checkpoint: true</span><br><span class="line">  # Note: The below line limits the training process to 200K steps, which we</span><br><span class="line">  # empirically found to be sufficient enough to train the pets dataset. This</span><br><span class="line">  # effectively bypasses the learning rate schedule (the learning rate will</span><br><span class="line">  # never decay). Remove the below line to train indefinitely.</span><br><span class="line">  num_steps: 10000    ## change here</span><br><span class="line">  data_augmentation_options &#123;</span><br><span class="line">    random_horizontal_flip &#123;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  data_augmentation_options &#123;</span><br><span class="line">    ssd_random_crop &#123;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">train_input_reader: &#123;</span><br><span class="line">  tf_record_input_reader &#123;</span><br><span class="line">    input_path: &quot;object_detection/data/dove_train.tfrecord&quot;   ## change here</span><br><span class="line">  &#125;</span><br><span class="line">  label_map_path: &quot;object_detection/data/dove_cholo_label_map.pbtxt&quot;   ## change here</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">eval_config: &#123;</span><br><span class="line">  num_examples: 3438    ## change here</span><br><span class="line">  # Note: The below line limits the evaluation process to 10 evaluations.</span><br><span class="line">  # Remove the below line to evaluate indefinitely.</span><br><span class="line">  max_evals: 10</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">eval_input_reader: &#123;</span><br><span class="line">  tf_record_input_reader &#123;</span><br><span class="line">    input_path: &quot;object_detection/data/dove_validation.tfrecord&quot;   ## change here</span><br><span class="line">  &#125;</span><br><span class="line">  label_map_path: &quot;object_detection/data/dove_cholo_label_map.pbtxt&quot;   ## change here</span><br><span class="line">  shuffle: false</span><br><span class="line">  num_readers: 1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>Download the pre-trained model<br>  <a class="link"   href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md" >modle zoo<i class="fas fa-external-link-alt"></i></a></li>
<li>fine_tune_checkpoint: “object_detection&#x2F;finetune_cpkt&#x2F;ssd_mobilenet_v1_coco_2018_01_28&#x2F;model.ckpt”   ## change here</li>
</ul>
</li>
</ul>
<h4 id="legacy-training-同时跑train-py和eval-py"><a href="#legacy-training-同时跑train-py和eval-py" class="headerlink" title="legacy training (同时跑train.py和eval.py)"></a>legacy training (同时跑train.py和eval.py)</h4><ul>
<li><p>旧的训练方法，path,  &#x2F;models&#x2F;research&#x2F;object_detection&#x2F;legacy&#x2F;train.py</p>
</li>
<li><p>旧的训练方法，path,  &#x2F;models&#x2F;research&#x2F;object_detection&#x2F;legacy&#x2F;eval.py</p>
</li>
<li><p><a class="link"   href="https://blog.csdn.net/zong596568821xp/article/details/84842688" >ref-eval的使用<i class="fas fa-external-link-alt"></i></a></p>
</li>
<li><p>–logtostderr, 日志保存</p>
</li>
<li><p>–train_dir, 训练模型保存的位置</p>
</li>
<li><p>–pipeline_config_path, 模型配置文件的路径</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">## 可用GPU训练，但常常会cuda out of memory</span><br><span class="line">## 先在trian.py和eval.py中加入以下代码控制gpu的内存使用</span><br><span class="line"></span><br><span class="line">import os</span><br><span class="line"> </span><br><span class="line">os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;0&quot;</span><br><span class="line">config = tf.ConfigProto(allow_soft_placement = True)</span><br><span class="line">gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction = 0.35)</span><br><span class="line">config.gpu_options.allow_growth = True</span><br><span class="line"> </span><br><span class="line">sess0 = tf.InteractiveSession(config = config)</span><br><span class="line"></span><br><span class="line"># 原文链接：https://blog.csdn.net/baidu_33597755/article/details/102311000</span><br><span class="line"></span><br><span class="line">cd models/research/</span><br><span class="line"></span><br><span class="line">python object_detection/legacy/train.py \</span><br><span class="line">    --pipeline_config_path=object_detection/dove_cholo_od/config/ssd_mobilenet_v2_coco.config \</span><br><span class="line">    --train_dir=object_detection/dove_cholo_od/dove_train_dir/ssd_m_v2/dove_train  \</span><br><span class="line">    --alsologtostderr</span><br><span class="line">    </span><br><span class="line"># 等train.py跑了一会之后，再运行eval.py</span><br><span class="line"></span><br><span class="line">python object_detection/legacy/eval.py \</span><br><span class="line">    --pipeline_config_path=object_detection/dove_cholo_od/config/ssd_mobilenet_v2_coco.config \</span><br><span class="line">    --checkpoint_dir=object_detection/dove_cholo_od/dove_train_dir/ssd_m_v2/dove_train  \</span><br><span class="line">    --eval_dir=object_detection/dove_cholo_od/dove_train_dir/ssd_m_v2/dove_eval  \</span><br><span class="line">    --logtostderr</span><br><span class="line">    </span><br></pre></td></tr></table></figure>
</li>
<li><p>Then open the tensorboard to watch the training and eval progress</p>
</li>
<li><p>Open two tensorboard at the same time</p>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tensorboard --logdir=object_detection/dove_cholo_od/dove_train_dir/ssd_m_v2/dove_train --port=6005</span><br><span class="line"></span><br><span class="line">tensorboard --logdir=object_detection/dove_cholo_od/dove_train_dir/ssd_m_v2/dove_eval</span><br></pre></td></tr></table></figure>

<h4 id="modern-training-暂不支持GPU"><a href="#modern-training-暂不支持GPU" class="headerlink" title="modern training(暂不支持GPU)"></a>modern training(暂不支持GPU)</h4><ul>
<li>新的训练方法，path,   &#x2F;models&#x2F;research&#x2F;object_detection&#x2F;model_main.py<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"># From the tensorflow/models/research/ directory</span><br><span class="line">python object_detection/model_main.py \</span><br><span class="line">    --pipeline_config_path=object_detection/training/ssd_mobilenet_v1_coco.config \</span><br><span class="line">    --model_dir=object_detection/training \</span><br><span class="line">    --num_train_steps=50000 \</span><br><span class="line">    --num_eval_steps=2000 \</span><br><span class="line">    --alsologtostderr</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="Model-evaluation"><a href="#Model-evaluation" class="headerlink" title="Model evaluation"></a>Model evaluation</h3><h3 id="Q-amp-A"><a href="#Q-amp-A" class="headerlink" title="Q&amp;A"></a>Q&amp;A</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. ImportError: cannot import name &#x27;input_reader_pb2&#x27; from &#x27;object_detection.protos&#x27;</span><br><span class="line">solution:</span><br><span class="line"># From tensorflow/models/research/</span><br><span class="line">protoc object_detection/protos/*.proto --python_out=.</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">2. from nets import inception_resnet_v2 ModuleNotFoundError: No module named &#x27;nets&#x27;</span><br><span class="line">solution:</span><br><span class="line">cd model/research/</span><br><span class="line">python setup.py build</span><br><span class="line">python setup.py install</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cd model/research/slim/</span><br><span class="line">python setup.py build</span><br><span class="line">python setup.py install</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">3. Not found: PATH_TO_BE_CONFIGURED; No such file or directory</span><br><span class="line">solution:</span><br><span class="line">download pre-trained cpkt model</span><br><span class="line">go into the config file and Search for &quot;PATH_TO_BE_CONFIGURED&quot; to find the fields that should be configured.</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">4. No module named &#x27;pycocotools&#x27;</span><br><span class="line">pip install git+https://github.com/philferriere/cocoapi.git#subdirectory=PythonAPI</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>技能-修行-进步-ML</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>tensorflow</tag>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>P，R，AP, mAP, AP@0.5, mAP@0.5:0.95</title>
    <url>/2022/05/28/ML/mAP-PR/</url>
    <content><![CDATA[<ul>
<li><a class="link"   href="https://kharshit.github.io/blog/2019/09/20/evaluation-metrics-for-object-detection-and-segmentation" >reference<i class="fas fa-external-link-alt"></i></a></li>
</ul>
<h2 id="IOU，Intersection-of-Union，两个框的交集-x2F-两个框的并集"><a href="#IOU，Intersection-of-Union，两个框的交集-x2F-两个框的并集" class="headerlink" title="IOU，Intersection of Union，两个框的交集&#x2F;两个框的并集"></a>IOU，Intersection of Union，两个框的交集&#x2F;两个框的并集</h2><h1 id=""><a href="#" class="headerlink" title=""></a><img src="/img/wuweiwu/obj_det_hw/iou.png"></h1><h1 id="GT，Ground-truth，真实的标注"><a href="#GT，Ground-truth，真实的标注" class="headerlink" title="GT，Ground-truth，真实的标注"></a>GT，Ground-truth，真实的标注</h1><h1 id="TP，True-Positive，检测结果是正确的，简称正检"><a href="#TP，True-Positive，检测结果是正确的，简称正检" class="headerlink" title="TP，True Positive，检测结果是正确的，简称正检"></a>TP，True Positive，检测结果是正确的，简称正检</h1><h1 id="FP，False-Positive，检测结果是错误的，简称误检"><a href="#FP，False-Positive，检测结果是错误的，简称误检" class="headerlink" title="FP，False Positive，检测结果是错误的，简称误检"></a>FP，False Positive，检测结果是错误的，简称误检</h1><h1 id="FN，False-Negative，没有检测到的目标，简称漏检"><a href="#FN，False-Negative，没有检测到的目标，简称漏检" class="headerlink" title="FN，False Negative，没有检测到的目标，简称漏检"></a>FN，False Negative，没有检测到的目标，简称漏检</h1><h1 id="P，Precison，精准率，检测结果中检测正确所占比例"><a href="#P，Precison，精准率，检测结果中检测正确所占比例" class="headerlink" title="P，Precison，精准率，检测结果中检测正确所占比例"></a>P，Precison，精准率，检测结果中检测正确所占比例</h1><h1 id="R，Recall，召回率，检测结果中正确检测个数占GT的比例"><a href="#R，Recall，召回率，检测结果中正确检测个数占GT的比例" class="headerlink" title="R，Recall，召回率，检测结果中正确检测个数占GT的比例"></a>R，Recall，召回率，检测结果中正确检测个数占GT的比例</h1><p>&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</p>
<h1 id="AP，Average-Precision，AP计算一个类别，一系列Precision点，Recall点组成一个P-R曲线图，P-R曲线图下的面积就是AP"><a href="#AP，Average-Precision，AP计算一个类别，一系列Precision点，Recall点组成一个P-R曲线图，P-R曲线图下的面积就是AP" class="headerlink" title="AP，Average Precision，AP计算一个类别，一系列Precision点，Recall点组成一个P-R曲线图，P-R曲线图下的面积就是AP"></a>AP，Average Precision，AP计算一个类别，一系列Precision点，Recall点组成一个P-R曲线图，P-R曲线图下的面积就是AP</h1><h1 id="mAP，mean-Average-Precision，多个AP求平均值"><a href="#mAP，mean-Average-Precision，多个AP求平均值" class="headerlink" title="mAP，mean Average Precision，多个AP求平均值"></a>mAP，mean Average Precision，多个AP求平均值</h1><p>&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</p>
<h1 id="x41-x50-x40-x30-46-x35-，计算一个类别的AP，0-5是IOU-thresh的阈值，用来过滤检测框和真实框之间的重叠度IOU，IOU-gt-0-5满足条件"><a href="#x41-x50-x40-x30-46-x35-，计算一个类别的AP，0-5是IOU-thresh的阈值，用来过滤检测框和真实框之间的重叠度IOU，IOU-gt-0-5满足条件" class="headerlink" title="&#x41;&#x50;&#x40;&#x30;&#46;&#x35;，计算一个类别的AP，0.5是IOU_thresh的阈值，用来过滤检测框和真实框之间的重叠度IOU，IOU&gt;0.5满足条件"></a><a class="link"   href="mailto:&#x41;&#x50;&#x40;&#x30;&#46;&#x35;" >&#x41;&#x50;&#x40;&#x30;&#46;&#x35;<i class="fas fa-external-link-alt"></i></a>，计算一个类别的AP，0.5是IOU_thresh的阈值，用来过滤检测框和真实框之间的重叠度IOU，IOU&gt;0.5满足条件</h1><h1 id="65-80-64-48-46-53-0-95，即-0-5-0-55-0-6-0-65-0-7-0-75-0-8-0-85-0-9-0-95-10个IOU-thresh阈值来画出10个P-R曲线，然后求平均值"><a href="#65-80-64-48-46-53-0-95，即-0-5-0-55-0-6-0-65-0-7-0-75-0-8-0-85-0-9-0-95-10个IOU-thresh阈值来画出10个P-R曲线，然后求平均值" class="headerlink" title="&#65;&#80;&#64;&#48;&#46;&#53;:0.95，即[0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95] 10个IOU_thresh阈值来画出10个P-R曲线，然后求平均值"></a><a class="link"   href="mailto:&#65;&#80;&#64;&#48;&#46;&#53;" >&#65;&#80;&#64;&#48;&#46;&#53;<i class="fas fa-external-link-alt"></i></a>:0.95，即[0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95] 10个IOU_thresh阈值来画出10个P-R曲线，然后求平均值</h1><h1 id="x6d-65-x50-x40-48-46-x35-，计算多个类别（AP）在IOU-thresh-x3D-0-5的阈值的情况下的平均值"><a href="#x6d-65-x50-x40-48-46-x35-，计算多个类别（AP）在IOU-thresh-x3D-0-5的阈值的情况下的平均值" class="headerlink" title="&#x6d;&#65;&#x50;&#x40;&#48;&#46;&#x35;，计算多个类别（AP）在IOU_thresh&#x3D;0.5的阈值的情况下的平均值"></a><a class="link"   href="mailto:&#x6d;&#65;&#x50;&#x40;&#48;&#46;&#x35;" >&#x6d;&#65;&#x50;&#x40;&#48;&#46;&#x35;<i class="fas fa-external-link-alt"></i></a>，计算多个类别（AP）在IOU_thresh&#x3D;0.5的阈值的情况下的平均值</h1><h1 id="x6d-x41-x50-x40-x30-46-53-0-95，计算多个类别（AP）在IOU-thresh-x3D-0-5-0-55-0-6-0-65-0-7-0-75-0-8-0-85-0-9-0-95-10个IOU-thresh阈值的情况下的平均值"><a href="#x6d-x41-x50-x40-x30-46-53-0-95，计算多个类别（AP）在IOU-thresh-x3D-0-5-0-55-0-6-0-65-0-7-0-75-0-8-0-85-0-9-0-95-10个IOU-thresh阈值的情况下的平均值" class="headerlink" title="&#x6d;&#x41;&#x50;&#x40;&#x30;&#46;&#53;:0.95，计算多个类别（AP）在IOU_thresh&#x3D;[0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95] 10个IOU_thresh阈值的情况下的平均值"></a><a class="link"   href="mailto:&#x6d;&#x41;&#x50;&#x40;&#x30;&#46;&#53;" >&#x6d;&#x41;&#x50;&#x40;&#x30;&#46;&#53;<i class="fas fa-external-link-alt"></i></a>:0.95，计算多个类别（AP）在IOU_thresh&#x3D;[0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95] 10个IOU_thresh阈值的情况下的平均值</h1><p>&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</p>
<h1 id="VOC2007，计算-0-0-1-1-11个recall-point下的Precision点和Recall点值，画P-R曲线，曲线下的面积就是AP"><a href="#VOC2007，计算-0-0-1-1-11个recall-point下的Precision点和Recall点值，画P-R曲线，曲线下的面积就是AP" class="headerlink" title="VOC2007，计算[0:0.1:1]11个recall-point下的Precision点和Recall点值，画P-R曲线，曲线下的面积就是AP"></a>VOC2007，计算[0:0.1:1]11个recall-point下的Precision点和Recall点值，画P-R曲线，曲线下的面积就是AP</h1><h1 id="VOC2010，计算检测值按confidence降序排序，所有confidence都当成recall-point计算Precision点和Recall点值，画P-R曲线，曲线下的面积就是AP"><a href="#VOC2010，计算检测值按confidence降序排序，所有confidence都当成recall-point计算Precision点和Recall点值，画P-R曲线，曲线下的面积就是AP" class="headerlink" title="VOC2010，计算检测值按confidence降序排序，所有confidence都当成recall-point计算Precision点和Recall点值，画P-R曲线，曲线下的面积就是AP"></a>VOC2010，计算检测值按confidence降序排序，所有confidence都当成recall-point计算Precision点和Recall点值，画P-R曲线，曲线下的面积就是AP</h1><h1 id="COCO，计算-0-0-01-1-101个recall-point下的Precision点和Recall点值，画P-R曲线，曲线下的面积就是AP"><a href="#COCO，计算-0-0-01-1-101个recall-point下的Precision点和Recall点值，画P-R曲线，曲线下的面积就是AP" class="headerlink" title="COCO，计算[0:0.01,1]101个recall-point下的Precision点和Recall点值，画P-R曲线，曲线下的面积就是AP"></a>COCO，计算[0:0.01,1]101个recall-point下的Precision点和Recall点值，画P-R曲线，曲线下的面积就是AP</h1><p>&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</p>
]]></content>
      <categories>
        <category>技能-修行-进步-ML</category>
      </categories>
      <tags>
        <tag>物体检测-metrics</tag>
      </tags>
  </entry>
  <entry>
    <title>monica AI GPT 总结视频内容2</title>
    <url>/2023/06/15/ML/monica-ai-exam2/</url>
    <content><![CDATA[<p>Sam Altman - How to Succeed with a Startup](<a class="link"   href="https://www.youtube.com/watch?v=0lJKucu6HJc&ab_channel=YCombinator)%E7%9A%84%E8%AF%A6%E7%BB%86%E6%91%98%E8%A6%81%EF%BC%9A" >https://www.youtube.com/watch?v=0lJKucu6HJc&amp;ab_channel=YCombinator)的详细摘要：<i class="fas fa-external-link-alt"></i></a> <a class="link"   href="https://monica.im/" >Monica<i class="fas fa-external-link-alt"></i></a></p>
<p><a class="link"   href="https://www.youtube.com/watch?v=0lJKucu6HJc&ab_channel=YCombinator&t=0.03" >00:00<i class="fas fa-external-link-alt"></i></a>打造一个人们自发告诉朋友的伟大产品是创业公司成功的关键。</p>
<ul>
<li>成功的程度与建立一个人们喜爱的伟大产品成正比。</li>
<li>像谷歌和Facebook这样成功的公司就是被人们通过口碑发现的。</li>
<li>一个简单易懂的产品是成功的重要指标。</li>
<li>初创企业需要寻找一个正在经历或即将经历指数级增长的市场。</li>
</ul>
<p><a class="link"   href="https://www.youtube.com/watch?v=0lJKucu6HJc&ab_channel=YCombinator&t=157.459" >02:37<i class="fas fa-external-link-alt"></i></a> 初创企业在下大赌注之前，需要有一个传道授业的创始人，一个雄心勃勃的愿景和每个用户的密集使用量。</p>
<ul>
<li>iPhone的成功表明，有些东西已经从根本上发生了变化，有一个新的计算平台将催生巨大的业务。</li>
<li>VR也许有一天会成为大生意，但目前，大多数拥有VR头盔的人从未或很少使用它。</li>
<li>初创企业至少需要一位传教士式的创始人，他可以用热情感染整个世界，让大家了解公司要做什么。</li>
<li>拥有一个雄心勃勃的愿景有助于建立一个团队和吸引投资者。</li>
</ul>
<p><a class="link"   href="https://www.youtube.com/watch?v=0lJKucu6HJc&ab_channel=YCombinator&t=317.21" >05:17<i class="fas fa-external-link-alt"></i></a>对未来有自信和明确的看法，有雄心勃勃的愿景，但如果成功的话，规模巨大的初创企业将吸引最好的人才。</p>
<ul>
<li>对未来有一个自信和明确的看法，并且是一个明确的领导者，这与成功相关。</li>
<li>建立一个伟大的团队是一个创始人可以做的最重要的事情之一。</li>
<li>创始人要经历一个从建立产品到建立公司的过渡。</li>
</ul>
<p><a class="link"   href="https://www.youtube.com/watch?v=0lJKucu6HJc&ab_channel=YCombinator&t=476.56" >07:56<i class="fas fa-external-link-alt"></i></a>让团队成员不断提出新的想法和 “我们会想出办法 “的精神对早期的创业团队很重要。</p>
<ul>
<li>初创企业通过快速行动和在事情不成功的情况下迅速调整来赢得胜利。</li>
<li>拥有说 “我知道了 “并偏重于行动的团队成员是很重要的。</li>
<li>没有经验的祝福会导致不可思议的事情，因为没有人告诉他们这很难。</li>
</ul>
<p><a class="link"   href="https://www.youtube.com/watch?v=0lJKucu6HJc&ab_channel=YCombinator&t=635.589" >10:35<i class="fas fa-external-link-alt"></i></a>初创企业需要保持势头，有竞争优势，有合理的商业模式，并有发展计划。</p>
<ul>
<li>势头对于初创企业继续提供超出预期的结果至关重要</li>
<li>长期竞争优势是成功的必要条件</li>
<li>合理的商业模式是很重要的，即使在开始时没有完全想好。</li>
<li>一个增长和获取用户的计划是成功的必要条件。</li>
</ul>
<p><a class="link"   href="https://www.youtube.com/watch?v=0lJKucu6HJc&ab_channel=YCombinator&t=793.58" >13:13<i class="fas fa-external-link-alt"></i></a>与大公司相比，初创企业在决策速度、在坏主意上取胜的能力以及在大平台转变上取胜方面具有优势。</p>
<ul>
<li>初创企业只需要一个人同意就可以追求一个想法，而大公司则需要所有人同意。</li>
<li>初创企业在不断变化的市场中具有敏捷性和速度的优势，使他们能够做出更好、更快的决定。</li>
<li>初创企业通常在大的平台转变中获胜，因为大公司在进行战略转移时比较慢。</li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步-AI助手</category>
      </categories>
      <tags>
        <tag>GPT</tag>
        <tag>monica-AI</tag>
      </tags>
  </entry>
  <entry>
    <title>monica AI GPT 总结视频内容1</title>
    <url>/2023/06/15/ML/monica-ai-exam1/</url>
    <content><![CDATA[<p>OpenAI Sam Altman &amp; Greg Brockman: Fireside Chat in Seoul, Korea | SoftBank Ventures Asia](<a class="link"   href="https://www.youtube.com/watch?v=_hpuPi7YZX8&ab_channel=SoftBankVenturesAsia)%E7%9A%84%E8%AF%A6%E7%BB%86%E6%91%98%E8%A6%81%EF%BC%9A%5BMonica%5D(https://monica.im)" >https://www.youtube.com/watch?v=_hpuPi7YZX8&amp;ab_channel=SoftBankVenturesAsia)的详细摘要：[Monica](https://monica.im)<i class="fas fa-external-link-alt"></i></a></p>
<p><a class="link"   href="https://www.youtube.com/watch?v=_hpuPi7YZX8&ab_channel=SoftBankVenturesAsia&t=0.9" >00:00<i class="fas fa-external-link-alt"></i></a> Sam Altman和Greg Brockman讨论了他们对韩国文化的尊重和钦佩，以及韩国的创新人工智能初创企业。</p>
<ul>
<li>萨姆会说韩语，他喜欢韩国文化中传统和新事物的结合</li>
<li>格雷格非常尊重韩国的技术，特别是在互联网接入方面。</li>
<li>两人都对韩国的人工智能初创企业的发展程度和对聊天GPT技术的热情印象深刻。</li>
</ul>
<p><a class="link"   href="https://www.youtube.com/watch?v=_hpuPi7YZX8&ab_channel=SoftBankVenturesAsia&t=435.9" >07:15<i class="fas fa-external-link-alt"></i></a>OpenAI不仅仅是一家语言模型公司，而是一家专注于深度学习和向AGI迈进的AI公司。</p>
<ul>
<li>OpenAI尝试了很多失败的东西，但只看到成功的东西。</li>
<li>实现AGI的进展可以用最大的项目规模来衡量。</li>
<li>OpenAI已经致力于不同的主题，包括机器人学和强化学习。</li>
</ul>
<p><a class="link"   href="https://www.youtube.com/watch?v=_hpuPi7YZX8&ab_channel=SoftBankVenturesAsia&t=870.6" >14:30<i class="fas fa-external-link-alt"></i></a>销售一个模糊的愿景需要自信心，并在从现实中学习时调整战术。</p>
<ul>
<li>在人工智能领域没有正确的答案，只有随着时间推移变得更加准确的答案。</li>
<li>相信技术并有一个基本的赌注是很重要的。</li>
<li>最初的战术可能经不起时间的考验，需要随着新挑战的出现进行调整。</li>
</ul>
<p><a class="link"   href="https://www.youtube.com/watch?v=_hpuPi7YZX8&ab_channel=SoftBankVenturesAsia&t=1306.919" >21:46<i class="fas fa-external-link-alt"></i></a>处理快速变化的技术的最佳建议是成为适应新技术的专家，并利用它来解决问题。</p>
<ul>
<li>具体的技术技能会很快变得过时。</li>
<li>适应新技术并找到使用它来解决问题的方法的元技能更重要。</li>
<li>不同的国家将以不同的方式监管人工智能的使用情况。</li>
</ul>
<p><a class="link"   href="https://www.youtube.com/watch?v=_hpuPi7YZX8&ab_channel=SoftBankVenturesAsia&t=1743" >29:03<i class="fas fa-external-link-alt"></i></a>OpenAI有失败的项目，也有成功的项目，一些项目由于技术还没有准备好而失败，而另一些项目尽管一开始就觉得注定要失败，但结果还是成功了。</p>
<ul>
<li>OpenAI Universe是一个由于技术还没有准备好而失败的项目。</li>
<li>另一方面，API项目最初感觉是注定要失败的，但最后却获得了巨大的成功。</li>
<li>对于API项目，OpenAI经历了与客户交谈的痛苦，并在推出之前获得了早期采用者。</li>
</ul>
<p><a class="link"   href="https://www.youtube.com/watch?v=_hpuPi7YZX8&ab_channel=SoftBankVenturesAsia&t=2178.78" >36:18<i class="fas fa-external-link-alt"></i></a> 人工智能将使人们更有生产力，并创造新的工作类型，但技术变革的速度是一个问题。</p>
<ul>
<li>许多领域对劳动力的需求过剩。</li>
<li>人工智能将创造出难以想象的新工作类别。</li>
<li>人类的创造力和能力将依然重要。</li>
<li>技术变革的速度是一个问题，UBI是潜在解决方案的一个有趣的组成部分。</li>
</ul>
<p><a class="link"   href="https://www.youtube.com/watch?v=_hpuPi7YZX8&ab_channel=SoftBankVenturesAsia&t=2615.46" >43:35<i class="fas fa-external-link-alt"></i></a> OpenAI认为，内容创作者应该从人工智能技术中获益，要找到补偿的机制，必须进行实验。</p>
<ul>
<li>OpenAI认为，内容创作者应该为他们帮助AI变得更好的工作得到补偿。</li>
<li>实验是必要的，以找到补偿的机制。</li>
<li>OpenAI直接与社区中正在创作的人接触。</li>
</ul>
<p><a class="link"   href="https://www.youtube.com/watch?v=_hpuPi7YZX8&ab_channel=SoftBankVenturesAsia&t=3051.24" >50:51<i class="fas fa-external-link-alt"></i></a>人工智能的进步是许多术语的乘法，计算硬件是一个重要因素，还有数据和工程口径。</p>
<ul>
<li>AI的进步是计算能力、数据和工程口径的产物。</li>
<li>为了优化人工智能的进展，所有因素都应该是相等的。</li>
<li>定制硅领域对建立新的架构很有意思。</li>
<li>定制硅领域的障碍是建立伟大的软件。</li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步-AI助手</category>
      </categories>
      <tags>
        <tag>GPT</tag>
        <tag>monica-AI</tag>
      </tags>
  </entry>
  <entry>
    <title>nms_and_iou</title>
    <url>/2020/06/23/ML/nms-and-iou/</url>
    <content><![CDATA[<h2 id="IOU-Intersection-of-Union-，交并比"><a href="#IOU-Intersection-of-Union-，交并比" class="headerlink" title="IOU(Intersection of Union)，交并比"></a>IOU(Intersection of Union)，交并比</h2><ul>
<li>给定2个框(bounding box)，计算其交集和并集的比例。</li>
<li>通常bounding box的坐标表示有2种，第一种是2点坐标(x1, y1, x2, y2); 第二种是中心坐标和宽高(x, y, w, h)。在编写代码时我们会把第二种转换成2点坐标的形式进行计算。</li>
<li>code</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># params: boxes1: [, [xmin, ymin, xmax, ymax]]</span></span><br><span class="line"><span class="comment"># params: boxes2: [num, [xmin, ymin, xmax, ymax]]</span></span><br><span class="line"><span class="comment"># returns: iou, [weights], length=len(boxes2)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">bboxes_iou</span>(<span class="params">boxes1, boxes2</span>):</span><br><span class="line">	boxes1 = np.array(boxes1)</span><br><span class="line">	boxes2 = np.array(boxes2)</span><br><span class="line">	</span><br><span class="line">	<span class="comment"># 计算各自面积</span></span><br><span class="line">	boxes1_area = (boxes1[..., <span class="number">2</span>] - boxes1[..., <span class="number">0</span>]) * (boxes1[..., <span class="number">3</span>] - boxes1[..., <span class="number">1</span>])</span><br><span class="line">	boxes2_area = (boxes2[..., <span class="number">2</span>] - boxes2[..., <span class="number">0</span>]) * (boxes2[..., <span class="number">3</span>] - boxes2[..., <span class="number">1</span>])</span><br><span class="line">	</span><br><span class="line">	<span class="comment"># 计算交集</span></span><br><span class="line">	left_up = np.maximum(boxes1[..., :<span class="number">2</span>], boxes2[..., :<span class="number">2</span>])</span><br><span class="line">	right_down = np.maximum(boxes1[..., <span class="number">2</span>:], boxes2[..., <span class="number">2</span>:])</span><br><span class="line">	</span><br><span class="line">	inter_section = np.maximum(right_down - left_up, <span class="number">0.0</span>)</span><br><span class="line">	inter_area = inter_section[..., <span class="number">0</span>] * inter_section[..., <span class="number">1</span>]</span><br><span class="line">	</span><br><span class="line">	<span class="comment"># 计算并集</span></span><br><span class="line">	union_area = boxes1_area + boxes2_area - inter_area</span><br><span class="line">	</span><br><span class="line">	<span class="comment"># 计算IOU</span></span><br><span class="line">	iou = np.maximum(<span class="number">1.0</span> * inter_area / union_area, np.finfo(np.float32).eps)</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">return</span> iou</span><br><span class="line">	</span><br></pre></td></tr></table></figure>


<h2 id="NMS-Non-Maximum-Suppression-极大值抑制"><a href="#NMS-Non-Maximum-Suppression-极大值抑制" class="headerlink" title="NMS(Non-Maximum Suppression), 极大值抑制"></a>NMS(Non-Maximum Suppression), 极大值抑制</h2><ul>
<li>通常在物体检测(object detection)中，在head中预测出了很多的框，每个框包含了物体的类别，类别得分和坐标信息。因为在检测过程产生很多冗余的预测框，那么这时候我们就会用到NMS来去除这些冗余。具体做法是：<ul>
<li>(1) 取得某一张图片上的某一类别的所有预测框</li>
<li>(2) 对其类别得分进行排序，取出得分最大的框做保留</li>
<li>(3) 拿得分最大的框作为基准(pivot)，和剩余的框的坐标信息做IOU的计算，并将得到的IOU进行排序</li>
<li>(4) 设定一个iou_threshold，把IOU大于iou_threshold过滤出来进行冗余处理</li>
<li>(5) 冗余处理方案有2种，hard NMS和soft NMS，前者是直接把所有过滤的框的得分置为0，后者是利用高斯函数对其得分进行抑制或者减小，IOU越大的得分减少越多或者抑制程度越大，反之就减少越少或者抑制程度越小</li>
<li>(6) soft NMS是为了防止2个同类密集的框被误删其中得分小的框</li>
</ul>
</li>
<li>code<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># params: bboxes: (xmin, ymin, xmax, ymax, score, class)</span></span><br><span class="line"><span class="comment"># params: iou_threshold, scale value</span></span><br><span class="line"><span class="comment"># params: method, &#x27;nms&#x27;, &#x27;soft-nms&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># return: best_bboxes</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">nms</span>(<span class="params">bboxes, iou_threshold, sigma=<span class="number">0.3</span>, method=<span class="string">&#x27;nms&#x27;</span></span>):</span><br><span class="line">	<span class="comment"># 找出所有类别的唯一值</span></span><br><span class="line">	classes_in_img = <span class="built_in">list</span>(<span class="built_in">set</span>(bboxes[:<span class="number">5</span>]))</span><br><span class="line">	</span><br><span class="line">	<span class="comment"># 保留的框</span></span><br><span class="line">	best_bboxes = []</span><br><span class="line">	</span><br><span class="line">	<span class="comment"># 按每个class进行for循环</span></span><br><span class="line">	<span class="keyword">for</span> cls <span class="keyword">in</span> classes_in_img:</span><br><span class="line">		<span class="comment"># 首先过滤当前class的bboxes，得到cls_bboxes</span></span><br><span class="line">		cls_mask = (bboxes[:<span class="number">5</span>] == cls)</span><br><span class="line">		cls_bboxes = bboxes[cls_mask]</span><br><span class="line">		</span><br><span class="line">		<span class="comment"># NMS开始</span></span><br><span class="line">		<span class="keyword">while</span> <span class="built_in">len</span>(cls_bboxes) &gt; <span class="number">0</span>:</span><br><span class="line">			<span class="comment"># 按照score排序得到最大score的bboxes</span></span><br><span class="line">			max_ind = np.argmax(cls_bboxes[:, <span class="number">4</span>])</span><br><span class="line">			best_bbox = cls_bboxes[max_ind]</span><br><span class="line">			</span><br><span class="line">			<span class="comment"># 从cls_bboxes中剔除最大score的bbox</span></span><br><span class="line">			cls_bboxes = np.concatenate([cls_bboxes[:max_ind], cls_bboxes[max_ind+<span class="number">1</span>:]])</span><br><span class="line">			</span><br><span class="line">			<span class="comment"># 计算IOU</span></span><br><span class="line">			iou = bboxes_iou(best_bbox[np.newaxis, : <span class="number">4</span>], cls_bboxes[:, :<span class="number">4</span>])</span><br><span class="line">			</span><br><span class="line">			<span class="comment"># 初始化weight</span></span><br><span class="line">			weight = np.ones(<span class="built_in">len</span>(iou), dtype=np.float32)</span><br><span class="line">			</span><br><span class="line">			<span class="keyword">assert</span> method <span class="keyword">in</span> [<span class="string">&#x27;nms&#x27;</span>, <span class="string">&#x27;sfot-nms&#x27;</span>]</span><br><span class="line">			</span><br><span class="line">			<span class="comment"># nms过滤冗余</span></span><br><span class="line">			<span class="keyword">if</span> method == <span class="string">&#x27;nms&#x27;</span>:</span><br><span class="line">				iou_mask = iou &gt; iou_threshold</span><br><span class="line">				<span class="comment"># 把满足冗余的weight设为0</span></span><br><span class="line">				weight[iou_mask] = <span class="number">0.0</span></span><br><span class="line">			</span><br><span class="line">			<span class="comment"># soft-nms		</span></span><br><span class="line">			<span class="keyword">if</span> method == <span class="string">&#x27;soft-nms&#x27;</span>:</span><br><span class="line">				<span class="comment"># 高斯函数</span></span><br><span class="line">				weight = np.exp(-(<span class="number">1.0</span> * iou **<span class="number">2</span> / sigma))</span><br><span class="line">			</span><br><span class="line">			<span class="comment"># 修改score的值</span></span><br><span class="line">			cls_bboxes[:, <span class="number">4</span>] *= weight</span><br><span class="line">			</span><br><span class="line">			<span class="comment"># 过滤score为0的预测框</span></span><br><span class="line">			score_mask = cls_bboxes[:, <span class="number">4</span>] &gt; <span class="number">0</span></span><br><span class="line">			cls_bboxes = cls_bboxes[score_mask]</span><br><span class="line">			</span><br><span class="line">		<span class="keyword">return</span> best_bboxes</span><br><span class="line">		</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="NMS另一种实现方法，from-B站Bubbling"><a href="#NMS另一种实现方法，from-B站Bubbling" class="headerlink" title="NMS另一种实现方法，from B站Bubbling.."></a>NMS另一种实现方法，from B站Bubbling..</h2><ul>
<li>(0) backbone输出的格式是，boxes: [bs, all_boxes, 4+1+num_classes]</li>
<li>(1) 先处理坐标转换</li>
<li>(2) 再拿出1张图片中的所有boxes，对conf_threshold进行过滤</li>
<li>(3) 处理每个box最后预测的结果num_classes，如共有20个分类，那么取20个分类中的max_score就是这个box预测的类别，在得到相应的下标index</li>
<li>(4) 按类别划分boxes，然后每个类别进行如下循环<ul>
<li>取得boxes的conf_score（正&#x2F;背分类得分），按从大到小进行排序</li>
<li>将得分最大的box保留，然后得分最大的box与剩余的boxes进行iou计算</li>
<li>nms_threshold就是iou得分的过滤，把iou得分高于nms_threshold的boxes去掉</li>
<li>直至处理玩当前class的所有boxes</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#coding=utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">nms</span>(<span class="params">boxes, conf_threshold=<span class="number">0.5</span>, nms_threshold=<span class="number">0.4</span></span>):</span><br><span class="line">    <span class="comment"># boxes: [bs, all_boxes, 4+1+num_classes]</span></span><br><span class="line">    bs = np.shape(boxes)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将中心宽高转换成左上角和右下角的形式</span></span><br><span class="line">    shape_boxes = np.zeros_like(boxes[:,:,:<span class="number">4</span>])</span><br><span class="line">    shape_boxes[:,:,<span class="number">0</span>] = boxes[:,:,<span class="number">0</span>] - boxes[:,:,<span class="number">2</span>] / <span class="number">2</span></span><br><span class="line">    shape_boxes[:,:,<span class="number">1</span>] = boxes[:,:,<span class="number">1</span>] - boxes[:,:,<span class="number">3</span>] / <span class="number">2</span></span><br><span class="line">    shape_boxes[:,:,<span class="number">2</span>] = boxes[:,:,<span class="number">2</span>] + boxes[:,:,<span class="number">2</span>] / <span class="number">2</span></span><br><span class="line">    shape_boxes[:,:,<span class="number">3</span>] = boxes[:,:,<span class="number">3</span>] + boxes[:,:,<span class="number">3</span>] / <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    boxes[:,:,:<span class="number">4</span>] = shape_boxes</span><br><span class="line">    output = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(bs):</span><br><span class="line">        <span class="comment"># 取每一张图片中的所有预测框prediction</span></span><br><span class="line">        prediction = boxes[i]</span><br><span class="line">        <span class="comment"># 取出每个预测框的前景的二分类得分</span></span><br><span class="line">        score = prediction[:, <span class="number">4</span>]</span><br><span class="line">        <span class="comment"># 过滤满足conf_threshold的框</span></span><br><span class="line">        mask = score &gt; conf_threshold</span><br><span class="line">        detections = prediction[mask]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 找出每个预测框box是属于哪个分类的，如80个分类中的哪一个分类label和score</span></span><br><span class="line">        class_conf = np.expand_dim(np.<span class="built_in">max</span>(detections[:,<span class="number">5</span>:], axis=-<span class="number">1</span>), axis=-<span class="number">1</span>)</span><br><span class="line">        class_pred = np.expand_dims(np.argmax(detections[:,<span class="number">5</span>:], axis=-<span class="number">1</span>), axis=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        detections = np.concatenate(detections[:,:,<span class="number">5</span>], class_conf, class_pred, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        unique_class = np.unique(detections[:, -<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(unique_class) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        best_box = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> unique_class:</span><br><span class="line">            cls_mask = detection[:, -<span class="number">1</span>] == c</span><br><span class="line">            detection = detections[cls_mask]</span><br><span class="line">            scores = detection[:, <span class="number">4</span>]</span><br><span class="line"></span><br><span class="line">            arg_sort = np.argsort(scores)[:,:,-<span class="number">1</span>]</span><br><span class="line">            detection = detection[arg_sort]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">while</span> <span class="built_in">len</span>(detection) != <span class="number">0</span>:</span><br><span class="line">                best_box.append(detection[<span class="number">0</span>])</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(detection) == <span class="number">1</span>:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                ious = iou(detection[<span class="number">0</span>], detection[<span class="number">1</span>:])</span><br><span class="line">                detection = detection[<span class="number">1</span>:][ious &lt; nms_threshold]</span><br><span class="line">        output.append(best_box)</span><br><span class="line">    <span class="keyword">return</span> np.array(output)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>技能-修行-进步</category>
      </categories>
      <tags>
        <tag>object detection</tag>
        <tag>nms</tag>
        <tag>iou</tag>
        <tag>soft-nms</tag>
      </tags>
  </entry>
  <entry>
    <title>simple pyopenpose usage</title>
    <url>/2019/08/01/ML/simple-pyopenpose-usage/</url>
    <content><![CDATA[<ul>
<li>Before last post, the introduction of <a href="chenyuqing.github.io/2019/07/02/how-to-install-openpose-in-ubuntu1604">installation of openpose</a> . For now, as you are a learner of python, so you should learn how to use the <a class="link"   href="https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/master/doc/modules/python_module.md" >python api of openpose<i class="fas fa-external-link-alt"></i></a>.</li>
</ul>
<h3 id="Test-your-pyopenpose"><a href="#Test-your-pyopenpose" class="headerlink" title="Test your pyopenpose"></a>Test your pyopenpose</h3><ul>
<li>Fisrt way (Recommand)<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python</span><br><span class="line">&gt;&gt;&gt; import openpose</span><br><span class="line">&gt;&gt;&gt; from openpose import pyopenpose as op </span><br></pre></td></tr></table></figure></li>
<li>Second way<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python</span><br><span class="line">&gt;&gt;&gt; import pyopenpose as op</span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure></li>
<li>So if that’s OK, then you are OK.</li>
</ul>
<h3 id="Simple-Usage-of-pyopenpose"><a href="#Simple-Usage-of-pyopenpose" class="headerlink" title="Simple Usage of pyopenpose"></a>Simple Usage of pyopenpose</h3><ul>
<li><p>Main Steps</p>
<ul>
<li><strong>Initializing</strong> the parameters, refer to <a class="link"   href="https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/master/include/openpose/flags.hpp" >include&#x2F;openpose&#x2F;flags.hpp<i class="fas fa-external-link-alt"></i></a> for more parameters</li>
<li>Process <strong>inputs</strong>  (images, videos etc.)</li>
<li>Get <strong>outputs</strong></li>
</ul>
</li>
<li><p>Example, <strong>hand detection from image, video or webcam.</strong></p>
</li>
<li><p>Remember to set the path of your openpose models</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/usr/bin/python3</span><br><span class="line">#!--*-- coding:utf-8 --*--</span><br><span class="line">#! Author: Tim Chan, motoleisure@gmail.com</span><br><span class="line"></span><br><span class="line">import cv2</span><br><span class="line">import time</span><br><span class="line">import os.path</span><br><span class="line">import sys</span><br><span class="line">import argparse</span><br><span class="line">import numpy as np</span><br><span class="line">from openpose import pyopenpose as op</span><br><span class="line"></span><br><span class="line">def readCap(args):</span><br><span class="line">    outputFile = &quot;openpose_out_py.mp4&quot;</span><br><span class="line"></span><br><span class="line">    if (args.image):</span><br><span class="line">        # Open the image file</span><br><span class="line">        if not os.path.isfile(args.image):</span><br><span class="line">            print(&quot;Input image file &quot;, args.image, &quot; doesn&#x27;t exist&quot;)</span><br><span class="line">            sys.exit(1)</span><br><span class="line">        cap = cv2.VideoCapture(args.image)</span><br><span class="line">        outputFile = args.image[:-4]+&#x27;_openpose_out_py.jpg&#x27;</span><br><span class="line">    elif (args.video):</span><br><span class="line">        # Open the video file</span><br><span class="line">        if not os.path.isfile(args.video):</span><br><span class="line">            print(&quot;Input video file &quot;, args.video, &quot; doesn&#x27;t exist&quot;)</span><br><span class="line">            sys.exit(1)</span><br><span class="line">        cap = cv2.VideoCapture(args.video)</span><br><span class="line">        outputFile = args.video[:-4]+&#x27;_openpose_out_py.mp4&#x27;</span><br><span class="line">    else:</span><br><span class="line">        # Webcam input</span><br><span class="line">        cap = cv2.VideoCapture(0)</span><br><span class="line"></span><br><span class="line">        cap.set(3, 720)</span><br><span class="line">        cap.set(4, 1280)</span><br><span class="line"></span><br><span class="line">    return cap, outputFile</span><br><span class="line"></span><br><span class="line">def processing_openpose(args):</span><br><span class="line"></span><br><span class="line">    # Initialize the openpose parameters</span><br><span class="line">    # Custom Params (refer to include/openpose/flags.hpp for more parameters)</span><br><span class="line">    params = &#123;&#125;</span><br><span class="line">    params[&quot;model_folder&quot;] = &quot;/home/ares2/openpose/models&quot;</span><br><span class="line">    params[&quot;hand&quot;] = True</span><br><span class="line"></span><br><span class="line">    # Starting OpenPose</span><br><span class="line">    opWrapper = op.WrapperPython()</span><br><span class="line">    opWrapper.configure(params)</span><br><span class="line">    opWrapper.start()</span><br><span class="line"></span><br><span class="line">    # cv2 display setups</span><br><span class="line">    winName = &#x27;Deep learning object detection in OpenCV&#x27;</span><br><span class="line">    cv2.namedWindow(winName, cv2.WINDOW_NORMAL)</span><br><span class="line"></span><br><span class="line">    cap, outputFile = readCap(args)</span><br><span class="line"></span><br><span class="line">    # Get the video writer initialized to save the output video</span><br><span class="line">    if (not args.image):</span><br><span class="line">        vid_writer = cv2.VideoWriter(outputFile, cv2.VideoWriter_fourcc(&#x27;M&#x27;, &#x27;J&#x27;, &#x27;P&#x27;, &#x27;G&#x27;),</span><br><span class="line">                                     30, (round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),</span><br><span class="line">                                          round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))</span><br><span class="line"></span><br><span class="line">    while cv2.waitKey(1) &lt; 0:</span><br><span class="line">        start_time = time.time()</span><br><span class="line">        # get frame from the video</span><br><span class="line">        hasFrame, frame = cap.read()</span><br><span class="line"></span><br><span class="line">        # Stop the program if reached end of video</span><br><span class="line">        if not hasFrame:</span><br><span class="line">            print(&quot;Done processing !!!&quot;)</span><br><span class="line">            print(&quot;Output file is stored as &quot;, outputFile)</span><br><span class="line">            cv2.waitKey(3000)</span><br><span class="line">            # Release device</span><br><span class="line">            cap.release()</span><br><span class="line">            break</span><br><span class="line"></span><br><span class="line">        # openpose input</span><br><span class="line">        datum = op.Datum()</span><br><span class="line">        datum.cvInputData = frame</span><br><span class="line">        opWrapper.emplaceAndPop([datum])</span><br><span class="line"></span><br><span class="line">        # openpose output</span><br><span class="line">        frame = datum.cvOutputData</span><br><span class="line">        end_time = time.time()</span><br><span class="line">        t = end_time - start_time</span><br><span class="line">        label = &#x27;Inference time: %.2f ms&#x27; % ( 1.0 / t)</span><br><span class="line">        cv2.putText(frame, label, (0, 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255))</span><br><span class="line"></span><br><span class="line">        # Write the frame with the detection boxes</span><br><span class="line">        if (args.image):</span><br><span class="line">            cv2.imwrite(outputFile, frame.astype(np.uint8))</span><br><span class="line">        else:</span><br><span class="line">            vid_writer.write(frame.astype(np.uint8))</span><br><span class="line"></span><br><span class="line">        cv2.imshow(winName, frame)</span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    parser = argparse.ArgumentParser(description=&#x27;Openpose Python API usage example&#x27;)</span><br><span class="line">    parser.add_argument(&#x27;--image&#x27;, help=&#x27;Path to image file.&#x27;)</span><br><span class="line">    parser.add_argument(&#x27;--video&#x27;, help=&#x27;Path to video file.&#x27;)</span><br><span class="line">    args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    processing_openpose(args)</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="Just-have-a-try-and-be-happy"><a href="#Just-have-a-try-and-be-happy" class="headerlink" title="Just have a try and be happy."></a>Just have a try and be happy.</h3><h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><ul>
<li><a class="link"   href="https://github.com/CMU-Perceptual-Computing-Lab/openpose" >Openpose Github<i class="fas fa-external-link-alt"></i></a> </li>
<li><a class="link"   href="https://www.aiuai.cn/aifarm1155.html" >Github 项目 - OpenPose Python API V1.5.0<i class="fas fa-external-link-alt"></i></a></li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步-ML</category>
      </categories>
      <tags>
        <tag>openpose</tag>
        <tag>pyopenpose</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>【基础】常用的机器学习&amp;数据挖掘知识点</title>
    <url>/2015/01/04/ML/%E3%80%90%E5%9F%BA%E7%A1%80%E3%80%91%E5%B8%B8%E7%94%A8%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%9F%A5%E8%AF%86%E7%82%B9/</url>
    <content><![CDATA[<h1 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h1><ul>
<li><img src="/img/repost/ml-basic.png"></li>
<li>转自：<a class="link"   href="http://www.36dsj.com/archives/20135#rd" >36大数据<i class="fas fa-external-link-alt"></i></a></li>
<li>本文总结了机器学习入门的基础知识的<font color="red"><strong>标题</strong></font>。相当于给我们入门者一个学习的架构。</li>
</ul>
<h2 id="Basis-基础"><a href="#Basis-基础" class="headerlink" title="Basis(基础)"></a>Basis(基础)</h2><ul>
<li>MSE(Mean Square Error (均方误差)</li>
<li>LMS(LeastMean Square (最小均方)</li>
<li>LSM(Least Square Methods (最小二乘法)</li>
<li>MLE(MaximumLikelihood Estimation (最大似然估计)</li>
<li>QP(Quadratic Programming (二次规划) </li>
<li>CP(Conditional Probability (条件概率)</li>
<li>JP(Joint Probability (联合概率)</li>
<li>MP(Marginal Probability (边缘概率)</li>
<li>Bayesian Formula (贝叶斯公式)</li>
<li>L1 &#x2F;L2Regularization (L1&#x2F;L2正则，以及更多的，现在比较火的L2.5正则等)</li>
<li>GD (GradientDescent 梯度下降)</li>
<li>SGD (Stochastic Gradient Descent 随机梯度下降)</li>
<li>Eigenvalue (特征值)</li>
<li>Eigenvector (特征向量)</li>
<li>QR-decomposition (QR分解)</li>
<li>Quantile (分位数)</li>
<li>Covariance (协方差矩阵)</li>
</ul>
<h2 id="Common-Distribution-常见分布"><a href="#Common-Distribution-常见分布" class="headerlink" title="Common Distribution(常见分布)"></a>Common Distribution(常见分布)</h2><h3 id="Discrete-Distribution-离散型分布"><a href="#Discrete-Distribution-离散型分布" class="headerlink" title="Discrete Distribution(离散型分布)"></a>Discrete Distribution(离散型分布)</h3><ul>
<li>BernoulliDistribution&#x2F;Binomial(贝努利分布&#x2F;二项分布)</li>
<li>Negative BinomialDistribution(负二项分布)</li>
<li>MultinomialDistribution(多项式分布)</li>
<li>Geometric Distribution(几何分布)</li>
<li>HypergeometricDistribution(超几何分布)</li>
<li>Poisson Distribution (泊松分布)</li>
</ul>
<h3 id="Continuous-Distribution-连续型分布"><a href="#Continuous-Distribution-连续型分布" class="headerlink" title="Continuous Distribution (连续型分布)"></a>Continuous Distribution (连续型分布)</h3><ul>
<li>UniformDistribution(均匀分布)</li>
<li>Normal Distribution &#x2F;Guassian Distribution(正态分布&#x2F;高斯分布)</li>
<li>ExponentialDistribution(指数分布)</li>
<li>Lognormal Distribution(对数正态分布)</li>
<li>GammaDistribution(Gamma分布)</li>
<li>Beta Distribution(Beta分布)</li>
<li>Dirichlet Distribution(狄利克雷分布)</li>
<li>Rayleigh Distribution(瑞利分布)</li>
<li>Cauchy Distribution(柯西分布)</li>
<li>Weibull Distribution (韦伯分布)</li>
</ul>
<h3 id="Three-Sampling-Distribution-三大抽样分布"><a href="#Three-Sampling-Distribution-三大抽样分布" class="headerlink" title="Three Sampling Distribution(三大抽样分布)"></a>Three Sampling Distribution(三大抽样分布)</h3><ul>
<li>Chi-squareDistribution(卡方分布)</li>
<li>t-distribution(t-分布)</li>
<li>F-distribution(F-分布)</li>
</ul>
<h2 id="Data-Pre-processing-数据预处理"><a href="#Data-Pre-processing-数据预处理" class="headerlink" title="Data Pre-processing(数据预处理)"></a>Data Pre-processing(数据预处理)</h2><ul>
<li>Missing Value Imputation(缺失值填充)</li>
<li>Discretization(离散化)</li>
<li>Mapping(映射)</li>
<li>Normalization(归一化&#x2F;标准化)</li>
</ul>
<h2 id="Sampling-采样"><a href="#Sampling-采样" class="headerlink" title="Sampling(采样)"></a>Sampling(采样)</h2><ul>
<li>Simple Random Sampling(简单随机采样)</li>
<li>OfflineSampling(离线等可能K采样)</li>
<li>Online Sampling(在线等可能K采样)</li>
<li>Ratio-based Sampling(等比例随机采样)</li>
<li>Acceptance-RejectionSampling(接受-拒绝采样)</li>
<li>Importance Sampling(重要性采样)</li>
<li>MCMC(MarkovChain Monte Carlo 马尔科夫蒙特卡罗采样算法：Metropolis-Hasting&amp; Gibbs)</li>
</ul>
<h2 id="Clustering-聚类"><a href="#Clustering-聚类" class="headerlink" title="Clustering(聚类)"></a>Clustering(聚类)</h2><ul>
<li>K-Means</li>
<li>K-Mediods</li>
<li>二分K-Means</li>
<li>FK-Means</li>
<li>Canopy</li>
<li>Spectral-KMeans(谱聚类)</li>
<li>GMM-EM(混合高斯模型-期望最大化算法解决)</li>
<li>K-Pototypes</li>
<li>CLARANS(基于划分)</li>
<li>BIRCH(基于层次)</li>
<li>CURE(基于层次)</li>
<li>DBSCAN(基于密度)</li>
<li>CLIQUE(基于密度和基于网格)</li>
</ul>
<h2 id="Classification-amp-Regression-分类-amp-回归"><a href="#Classification-amp-Regression-分类-amp-回归" class="headerlink" title="Classification&amp;Regression(分类&amp;回归)"></a>Classification&amp;Regression(分类&amp;回归)</h2><ul>
<li>LR(Linear Regression 线性回归)</li>
<li>LR(LogisticRegression逻辑回归)</li>
<li>SR(Softmax Regression 多分类逻辑回归)</li>
<li>GLM(GeneralizedLinear Model 广义线性模型)</li>
<li>RR(Ridge Regression 岭回归&#x2F;L2正则最小二乘回归)</li>
<li>LASSO(Least Absolute Shrinkage andSelectionator Operator L1正则最小二乘回归)</li>
<li>RF(随机森林)</li>
<li>DT(DecisionTree决策树)</li>
<li>GBDT(Gradient BoostingDecision Tree 梯度下降决策树)</li>
<li>CART(ClassificationAnd Regression Tree 分类回归树)</li>
<li>KNN(K-Nearest Neighbor K近邻)</li>
<li>SVM(Support VectorMachine)</li>
<li>KF(KernelFunction 核函数)</li>
<li>PolynomialKernel Function 多项式核函数</li>
<li>Guassian KernelFunction 高斯核函数</li>
<li>Radial BasisFunction RBF径向基函数</li>
<li>String KernelFunction (字符串核函数)</li>
<li>NB(Naive Bayes 朴素贝叶斯)</li>
<li>BN(Bayesian Network&#x2F;Bayesian Belief Network&#x2F; Belief Network 贝叶斯网络&#x2F;贝叶斯信度网络&#x2F;信念网络)</li>
<li>LDA(Linear Discriminant Analysis&#x2F;FisherLinear Discriminant 线性判别分析&#x2F;Fisher线性判别)</li>
<li>EL(Ensemble Learning集成学习Boosting，Bagging，Stacking)</li>
<li>AdaBoost(Adaptive Boosting 自适应增强)</li>
<li>MEM(MaximumEntropy Model最大熵模型)</li>
</ul>
<h2 id="Effectiveness-Evaluation-分类效果评估"><a href="#Effectiveness-Evaluation-分类效果评估" class="headerlink" title="Effectiveness Evaluation(分类效果评估)"></a>Effectiveness Evaluation(分类效果评估)</h2><ul>
<li>Confusion Matrix(混淆矩阵)</li>
<li>Precision(精确度)</li>
<li>Recall(召回率)</li>
<li>Accuracy(准确率)</li>
<li>F-score(F得分)</li>
<li>ROC Curve(ROC曲线)</li>
<li>AUC(AUC面积)</li>
<li>LiftCurve(Lift曲线) </li>
<li>KS Curve(KS曲线)</li>
</ul>
<h2 id="PGM-Probabilistic-Graphical-Models概率图模型"><a href="#PGM-Probabilistic-Graphical-Models概率图模型" class="headerlink" title="PGM(Probabilistic Graphical Models概率图模型)"></a>PGM(Probabilistic Graphical Models概率图模型)</h2><ul>
<li>BN(Bayesian Network&#x2F;Bayesian Belief Network&#x2F; BeliefNetwork 贝叶斯网络&#x2F;贝叶斯信度网络&#x2F;信念网络)</li>
<li>MC(Markov Chain 马尔科夫链)</li>
<li>HMM(HiddenMarkov Model 马尔科夫模型)</li>
<li>MEMM(Maximum Entropy Markov Model 最大熵马尔科夫模型)</li>
<li>CRF(ConditionalRandom Field 条件随机场)</li>
<li>MRF(MarkovRandom Field 马尔科夫随机场)</li>
</ul>
<h2 id="NN-Neural-Network神经网络"><a href="#NN-Neural-Network神经网络" class="headerlink" title="NN(Neural Network神经网络)"></a>NN(Neural Network神经网络)</h2><ul>
<li>ANN(Artificial Neural Network 人工神经网络)</li>
<li>BP(Error BackPropagation 误差反向传播)</li>
</ul>
<h2 id="Deep-Learning-深度学习"><a href="#Deep-Learning-深度学习" class="headerlink" title="Deep Learning(深度学习)"></a>Deep Learning(深度学习)</h2><ul>
<li>Auto-encoder(自动编码器)</li>
<li>SAE(Stacked Auto-encoders堆叠自动编码器：Sparse Auto-encoders稀疏自动编码器、Denoising Auto-encoders去噪自动编码器、Contractive Auto-encoders 收缩自动编码器)</li>
<li>RBM(RestrictedBoltzmann Machine 受限玻尔兹曼机)</li>
<li>DBN(Deep Belief Network 深度信念网络)</li>
<li>CNN(ConvolutionalNeural Network 卷积神经网络)</li>
<li>Word2Vec(词向量学习模型)</li>
</ul>
<h2 id="DimensionalityReduction-降维"><a href="#DimensionalityReduction-降维" class="headerlink" title="DimensionalityReduction(降维)"></a>DimensionalityReduction(降维)</h2><ul>
<li>LDA LinearDiscriminant Analysis&#x2F;Fisher Linear Discriminant 线性判别分析&#x2F;Fisher线性判别</li>
<li>PCA(Principal Component Analysis 主成分分析)</li>
<li>ICA(IndependentComponent Analysis 独立成分分析)</li>
<li>SVD(Singular Value Decomposition 奇异值分解)</li>
<li>FA(FactorAnalysis 因子分析法)</li>
</ul>
<h2 id="Text-Mining-文本挖掘"><a href="#Text-Mining-文本挖掘" class="headerlink" title="Text Mining(文本挖掘)"></a>Text Mining(文本挖掘)</h2><ul>
<li>VSM(Vector Space Model向量空间模型)</li>
<li>Word2Vec(词向量学习模型)</li>
<li>TF(Term Frequency词频)</li>
<li>TF-IDF(Term Frequency-Inverse DocumentFrequency 词频-逆向文档频率)</li>
<li>MI(MutualInformation 互信息)</li>
<li>ECE(Expected Cross Entropy 期望交叉熵)</li>
<li>QEMI(二次信息熵)</li>
<li>IG(InformationGain 信息增益)</li>
<li>IGR(Information Gain Ratio 信息增益率)</li>
<li>Gini(基尼系数)，x2 Statistic(x2统计量)</li>
<li>TEW(TextEvidence Weight文本证据权)</li>
<li>OR(Odds Ratio 优势率)</li>
<li>N-Gram Model，LSA(Latent Semantic Analysis 潜在语义分析)</li>
<li>PLSA(ProbabilisticLatent Semantic Analysis 基于概率的潜在语义分析)</li>
<li>LDA(Latent DirichletAllocation 潜在狄利克雷模型)</li>
</ul>
<h2 id="Association-Mining-关联挖掘"><a href="#Association-Mining-关联挖掘" class="headerlink" title="Association Mining(关联挖掘)"></a>Association Mining(关联挖掘)</h2><ul>
<li>Apriori</li>
<li>FP-growth(Frequency Pattern Tree Growth 频繁模式树生长算法)</li>
<li>AprioriAll</li>
<li>Spade</li>
</ul>
<h2 id="Recommendation-Engine-推荐引擎"><a href="#Recommendation-Engine-推荐引擎" class="headerlink" title="Recommendation Engine(推荐引擎)"></a>Recommendation Engine(推荐引擎)</h2><ul>
<li>DBR(Demographic-based Recommendation 基于人口统计学的推荐)</li>
<li>CBR(Context-basedRecommendation 基于内容的推荐)</li>
<li>CF(Collaborative Filtering协同过滤)</li>
<li>UCF(User-basedCollaborative Filtering Recommendation 基于用户的协同过滤推荐)</li>
<li>ICF(Item-basedCollaborative Filtering Recommendation 基于项目的协同过滤推荐)</li>
</ul>
<h2 id="Similarity-Measure-amp-Distance-Measure-相似性与距离度量-："><a href="#Similarity-Measure-amp-Distance-Measure-相似性与距离度量-：" class="headerlink" title="Similarity Measure&amp;Distance Measure(相似性与距离度量)："></a>Similarity Measure&amp;Distance Measure(相似性与距离度量)：</h2><ul>
<li>Euclidean Distance(欧式距离)</li>
<li>ManhattanDistance(曼哈顿距离)</li>
<li>Chebyshev Distance(切比雪夫距离)</li>
<li>MinkowskiDistance(闵可夫斯基距离)</li>
<li>Standardized Euclidean Distance(标准化欧氏距离)</li>
<li>MahalanobisDistance(马氏距离)</li>
<li>Cos(Cosine 余弦)</li>
<li>HammingDistance&#x2F;Edit Distance(汉明距离&#x2F;编辑距离)</li>
<li>JaccardDistance(杰卡德距离)</li>
<li>Correlation Coefficient Distance(相关系数距离)</li>
<li>InformationEntropy(信息熵)</li>
<li>KL(Kullback-Leibler Divergence KL散度&#x2F;Relative Entropy 相对熵)</li>
</ul>
<h2 id="Optimization-最优化"><a href="#Optimization-最优化" class="headerlink" title="Optimization(最优化)"></a>Optimization(最优化)</h2><ul>
<li>Heuristic Algorithm(启发式算法)</li>
<li>SA(SimulatedAnnealing，模拟退火算法)</li>
<li>GA(genetic algorithm遗传算法)</li>
</ul>
<h3 id="Non-constrainedOptimization-无约束优化"><a href="#Non-constrainedOptimization-无约束优化" class="headerlink" title="Non-constrainedOptimization(无约束优化)"></a>Non-constrainedOptimization(无约束优化)</h3><ul>
<li>Cyclic VariableMethods(变量轮换法)</li>
<li>Pattern Search Methods(模式搜索法)</li>
<li>VariableSimplex Methods(可变单纯形法)</li>
<li>Gradient Descent Methods(梯度下降法)</li>
<li>Newton Methods(牛顿法)</li>
<li>Quasi-NewtonMethods(拟牛顿法)</li>
<li>Conjugate Gradient Methods(共轭梯度法)</li>
</ul>
<h3 id="ConstrainedOptimization-有约束优化"><a href="#ConstrainedOptimization-有约束优化" class="headerlink" title="ConstrainedOptimization(有约束优化)"></a>ConstrainedOptimization(有约束优化)</h3><ul>
<li>Approximation Programming Methods(近似规划法)</li>
<li>FeasibleDirection Methods(可行方向法)</li>
<li>Penalty Function Methods(罚函数法)</li>
<li>Multiplier Methods(乘子法)</li>
</ul>
<h2 id="Feature-Selection-特征选择算法"><a href="#Feature-Selection-特征选择算法" class="headerlink" title="Feature Selection(特征选择算法)"></a>Feature Selection(特征选择算法)</h2><ul>
<li>Mutual Information(互信息)</li>
<li>DocumentFrequence(文档频率)</li>
<li>Information Gain(信息增益)</li>
<li>Chi-squared Test(卡方检验)</li>
<li>Gini(基尼系数)</li>
</ul>
<h2 id="Outlier-Detection-异常点检测算法"><a href="#Outlier-Detection-异常点检测算法" class="headerlink" title="Outlier Detection(异常点检测算法)"></a>Outlier Detection(异常点检测算法)</h2><ul>
<li>Statistic-based(基于统计)</li>
<li>Distance-based(基于距离)</li>
<li>Density-based(基于密度)</li>
<li>Clustering-based(基于聚类)</li>
</ul>
<h2 id="Learning-to-Rank-基于学习的排序"><a href="#Learning-to-Rank-基于学习的排序" class="headerlink" title="Learning to Rank(基于学习的排序)"></a>Learning to Rank(基于学习的排序)</h2><ul>
<li>Pointwise：McRank；</li>
<li>Pairwise：RankingSVM，RankNet，Frank，RankBoost；</li>
<li>Listwise：AdaRank，SoftRank，LamdaMART；</li>
</ul>
<h2 id="Tool-工具"><a href="#Tool-工具" class="headerlink" title="Tool(工具)"></a>Tool(工具)</h2><ul>
<li>MPI，Hadoop生态圈，Spark，BSP，Weka，Mahout，Scikit-learn，PyBrain…</li>
</ul>
<h1 id="End"><a href="#End" class="headerlink" title="End"></a>End</h1>]]></content>
      <categories>
        <category>技能-修行-进步</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>3天回顾web3学习3周(8/7-8/27)</title>
    <url>/2023/08/25/Web3/3day-renew-web3-august/</url>
    <content><![CDATA[<h2 id="Day-1"><a href="#Day-1" class="headerlink" title="Day 1"></a>Day 1</h2><h3 id="为什么我会学习这门课程？"><a href="#为什么我会学习这门课程？" class="headerlink" title="为什么我会学习这门课程？"></a>为什么我会学习这门课程？</h3><p>-《moledao基建之周8周课程》 因为我目前身处自我转型，我想学习Web3相关知识，加上自己AI的相关工作经验，为自己的未来做准备。以我在AI工作的经验中，越是基础的就越有话语权，越是基础的就越能够在未来的发展中有更多的选择。所以我入门web3首选的是基础设施，但是基础设施是一个很大的范畴，所以我希望从这门课程入手，了解web3的基础设施是什么，以及如何搭建基础设施。</p>
<h3 id="整个web3圈子的分类"><a href="#整个web3圈子的分类" class="headerlink" title="整个web3圈子的分类"></a>整个web3圈子的分类</h3><ul>
<li>矿圈：寻求基础算力的突破</li>
<li>币圈：资本的操作</li>
<li>链圈：寻求基础设施的突破</li>
<li>鄙视链：链圈（技术清高）-&gt; 矿圈（算力清高）-&gt; 币圈（资本清高），但是现实世界资本话语权最高，哈哈😄</li>
</ul>
<h3 id="web3存在的不可能三角关系"><a href="#web3存在的不可能三角关系" class="headerlink" title="web3存在的不可能三角关系"></a>web3存在的不可能三角关系</h3><ul>
<li>去中心化</li>
<li>高性能</li>
<li>高安全性</li>
</ul>
<h3 id="web3的系统架构"><a href="#web3的系统架构" class="headerlink" title="web3的系统架构"></a>web3的系统架构</h3><ul>
<li><img src="/img/wuweiwu/3day-renew-web3/web3-structure.png"></li>
</ul>
<h3 id="区块链基础"><a href="#区块链基础" class="headerlink" title="区块链基础"></a>区块链基础</h3><ul>
<li>区块链有下列特征：<ul>
<li>去中心化，分布式，数据库，账本 </li>
<li>区块链的本质是一个分布式的记账本</li>
<li>分布式P2P协议 </li>
<li>密码学：数字签名，哈希函数</li>
<li>共识算法：POW，POS，DPOS，PBFT，RAFT，POA，POE，POI，POB</li>
<li>分叉 &#x2F; 双花</li>
</ul>
</li>
<li>区块链有下列用途：<ul>
<li>信任</li>
<li>自治性</li>
<li>去中介化</li>
</ul>
</li>
</ul>
<h3 id="智能合约"><a href="#智能合约" class="headerlink" title="智能合约"></a>智能合约</h3><ul>
<li>什么是智能合约<ul>
<li>一段代码，部署到区块链上，可以实现自动化的执行，不可篡改，不可停止，不可拦截</li>
<li>代码部署到区块链上，就是智能合约</li>
<li>智能合约是一种特殊的账户，可以接收交易，可以发送交易，可以存储数据，可以执行代码</li>
<li>智能合约的代码是不可篡改的，一旦部署，就不可修改</li>
</ul>
</li>
<li>以太坊<ul>
<li>以太坊是第一个支持智能合约的区块链</li>
<li>以太坊的运作原理：以太坊虚拟机EVM，以太坊账户，以太坊交易，以太坊区块</li>
</ul>
</li>
</ul>
<h2 id="Day-2"><a href="#Day-2" class="headerlink" title="Day 2"></a>Day 2</h2><ul>
<li>do nothing,be happy !</li>
</ul>
<h2 id="Day-3"><a href="#Day-3" class="headerlink" title="Day 3"></a>Day 3</h2><h3 id="以太坊学习框架"><a href="#以太坊学习框架" class="headerlink" title="以太坊学习框架"></a>以太坊学习框架</h3><h4 id="以太坊白皮书"><a href="#以太坊白皮书" class="headerlink" title="以太坊白皮书"></a>以太坊白皮书</h4><ul>
<li>以太坊是对比特币区块链的拓展，它支持在链上运行智能合约，智能合约是一段代码，可以自动执行，不可篡改，不可停止，不可拦截，它可以实现更多的功能。</li>
<li>以太坊内置的加密货币是以太币（ETH）。</li>
<li>以太坊运行在一个去中心化的虚拟机上，这个虚拟机叫做以太坊虚拟机（EVM），EVM是一个图灵完备的虚拟机，它可以运行任何代码。</li>
<li>以太坊的共识算法是POS，它的区块时间是15秒，区块大小是1M，每个区块的gas限制是8M，gas是以太坊的计价单位，每个操作都需要消耗一定的gas，gas的价格是由矿工决定的，矿工可以自由决定每个gas的价格，矿工会优先打包gas价格高的交易。</li>
<li>上海升级：以太坊的拓展方案，创建了一个“上海分叉”，允许用户转移他们的ETH和通过解绑获得的奖励。简而言之，就是要让以太坊更加灵活、易用和用户友好。</li>
</ul>
<h4 id="智能合约部署的过程："><a href="#智能合约部署的过程：" class="headerlink" title="智能合约部署的过程："></a>智能合约部署的过程：</h4><ul>
<li>1.编写智能合约代码sol</li>
<li>2.编译智能合约代码 byte code + abi</li>
<li>3.ether.js &#x2F; web3.js 编写包装和运行程序</li>
<li>4.运行在EVM的实例中，部署并广播到以太坊网络中</li>
</ul>
<h4 id="EVM的运行原理"><a href="#EVM的运行原理" class="headerlink" title="EVM的运行原理"></a>EVM的运行原理</h4><ul>
<li>EVM &#x3D; 运行交易、执行操作和更新区块链状态的虚拟机，所有操作的通货是gas fee。</li>
<li>EVM 使用基于堆栈的虚拟机架构，这意味着它将数据存储在堆栈中，并使用堆栈中的数据执行指令。</li>
<li>EVM 有一组 256 位寄存器，用于存储当前程序计数器、堆栈指针和内存指针等数据。</li>
<li>EVM 使用一种名为 EVM bytecode 的字节码语言，这是一种专为 EVM 设计的高度优化的低级语言。</li>
<li><a class="link"   href="https://www.evm.codes/?fork=shanghai" >An Ethereum Virtual Machine Opcodes Interactive Reference<i class="fas fa-external-link-alt"></i></a></li>
<li>总结来说，我们编写的智能合约代码最终会变成一串opcode，每个opcode指定EVM的一种操作，EVM会根据这些操作来执行智能合约代码。</li>
</ul>
<h4 id="学习solidity编程语言，ehther-js-x2F-web3-js"><a href="#学习solidity编程语言，ehther-js-x2F-web3-js" class="headerlink" title="学习solidity编程语言，ehther.js&#x2F; web3.js"></a>学习solidity编程语言，ehther.js&#x2F; web3.js</h4><h4 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h4><ul>
<li>just do it and give birth a new production.</li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步-Web3</category>
      </categories>
      <tags>
        <tag>solidity</tag>
      </tags>
  </entry>
  <entry>
    <title>Notes on Chainlink Bootcamp 2024 (10 Days)</title>
    <url>/2024/03/12/Web3/chainlink_bootcamp2024/</url>
    <content><![CDATA[<ul>
<li>| <a class="link"   href="https://lu.ma/qoqfl19p?tk=9Sn8RD" >Chainlink Bootcamp 2024<i class="fas fa-external-link-alt"></i></a></li>
<li>Agenda</li>
<li><img src="/img/wuweiwu/chainlink/bootcamp-202401/agenda.png"></li>
<li>PPT</li>
<li><a class="link"   href="https://docs.google.com/presentation/d/e/2PACX-1vRQ5ssT21p2lr6vFgxD5_JUp3ZXePsjxVsi56ljD_UUbT2b5COSXXhDE0CsBjMBRPkVH9yofNUsvz-X/pub?start=false&loop=false&delayms=3000&slide=id.g2acdc1ce0f8_0_0" >Bootcamp 2024&#x2F;01<i class="fas fa-external-link-alt"></i></a></li>
</ul>
<h2 id="Day-1"><a href="#Day-1" class="headerlink" title="Day 1"></a>Day 1</h2><p>- </p>
]]></content>
      <categories>
        <category>技能-修行-进步-Web3</category>
      </categories>
      <tags>
        <tag>chainlink</tag>
      </tags>
  </entry>
  <entry>
    <title>可视化证明：神经网络可以计算任何函数</title>
    <url>/2017/06/14/ML/visual-proof-of-neural-networks/</url>
    <content><![CDATA[<ul>
<li><p><a class="link"   href="http://neuralnetworksanddeeplearning.com/chap4.html" >Original Post<i class="fas fa-external-link-alt"></i></a></p>
</li>
<li><p>神经网络当中一个最显著的事实是：神经网络能够计算任何的函数。也就是说，假如有人给你一个复杂的，波形弯弯曲曲的函数，$f(x):$</p>
<img src="/img/visual_proof_of_neural_networks/1_function.png" class="[class names]" title="[Function $f(x)$ []]">
</li>
<li><p>无论是什么的函数，我们都可以保证能找到一个网络，对于所有可能的输入，$x$，$f(x)$的值(或者其他的逼近)就是网络的输出，譬如：</p>
<img src="/img/visual_proof_of_neural_networks/2_network.png" class="[class names]" title="[Neural Network []]">
</li>
<li><p>这个网络即使是网络的输入很多的时候也是成立的。$f&#x3D;f(x_1,…,x_m)$，然后还有很多的输出。譬如，以下就是一个网络，计算的函数，输入$m&#x3D;3$和输出$n&#x3D;2$：</p>
<img src="/img/visual_proof_of_neural_networks/3_network.png" class="[class names]" title="[Neural Network []]">
</li>
<li><p>以上的网络告诉我们神经网络是有一种泛化性的。无论我们想要计算任何的函数，肯定存在一个网络可以满足我们的需求。</p>
</li>
<li><p>另外，更进一步，即使这个网络限制到只有一层隐含层，这个泛化理论也是成立的。这个网络就是所谓的单层隐含层。所以，即使是很简单的网络也是很厉害的。</p>
</li>
<li><p>搞神经网络的人都应该熟知这个泛化性理论，可是事实上它并没有让很多人能理解。大多数的解释都是偏技术性的。譬如，其中一篇原始的论文利用$Hahn-Banach$理论，$Riesz Representation$理论和一些傅里叶分析来证明这个泛化性理论。如果你不是一个数学家的话，你很难读懂里面的解释。很遗憾，这样很多人就很难懂这个泛化性理论了。但是其实背后的原理是非常简单和美好的。</p>
</li>
<li><p>在本章中，我会给出一个关于泛化性理论的简单的和非常可视化的解释。我们会循序渐进，一步一步来理解这个idea。你将会明白为什么神经网络能够计算任意的函数。你也会理解到这个理论的一些限制的地方。你会理解到这个理论和深度学习之间的关系。</p>
</li>
<li><p>要理解这章的内容，你并不需要读前面的内容。反而这一章是一个结构乐见和完整的文章。我会给你们讲一些神经网络的基本知识，这样你们会更容易看懂解释。我会提供一些临时的链接，以防填补你某一部分知识的缺口。</p>
</li>
<li><p>泛化性理论是计算机科学中一个老生常谈的东西，以至于我们有时候都忘记了它到底有多厉害了。但是我们应该时刻提醒自己：有能力去计算任意的函数真的是一件很厉害的事情。几乎你可以想象得到的任何进程都可以被认为是一个函数的计算。譬如，根据一些短的音乐片段去给一段音乐命名。这也是看作计算一个函数。又或者把中文翻译成英文，又或者给计算机一个mp4视频资料，它会生成一个关于视频的描绘图还有这个视频的拍摄质量。泛化性意味着，原则上，神经网络可以做任何的事情而且更多。</p>
</li>
<li><p>当然，仅仅因为我们知道存在一个网络能够把中文翻译成英文，那不意味着我们就很容易构造甚至识别出这个网络。这样的约束对于模型的传统的泛化性理论，譬如布尔回路，都是适用的。但是，像这本书前面所说的，神经网络对于学习函数有非常强的算法。学习算法和泛化性是一个绝妙的结合。直到现在，这本书还是关注在学习算法。在这一章，我们关注在泛化性理论，和它所代表的意思。</p>
</li>
</ul>
<h2 id="两个说明"><a href="#两个说明" class="headerlink" title="两个说明"></a>两个说明</h2><ul>
<li><p>在我们解释为什么泛化性理论成立之前，我想要提两个关于“一个神经网络能够计算任何的函数”的说明。</p>
</li>
<li><p>首先，并不是说一个神经网络被用来准确地计算任何的函数。而是，我们能够得到一个关于这个函数的一个很好的逼近。通过增加隐层神经元的个数，我们可以不断改进逼近的程度。譬如，前面我们谈到的神经网络，包含一个隐层。对于很多函数，只有3个隐层神经元的神经网络是一个并不好的逼近。通过增加隐层的神经元(假如，增加到5)，我们可以得到更好的逼近：</p>
<img src="/img/visual_proof_of_neural_networks/4_network.png" class="[class names]" title="[Neural Network []]">
</li>
<li><p>如果我们继续增加神经元的个数，这个逼近就能做得更好。</p>
</li>
<li><p>更精确的说，假如给定我们一个函数$f(x)$，我们想要计算它的误差$\epsilon &gt; 0$。只要我们增加足够的隐层神经元，我们就能找到一个神经网络，它的输出$g(x)$满足$g(x)-f(x) &lt; \epsilon$,对于所有的输入$x$。换句话说，这个逼近函数$g(x)$对于所有可能的输入都在可预计的准确度范围之内。</p>
</li>
<li><p>第二个说明是能够用逼近的方式的函数类型是连续函数。如果一个函数是不连续的，譬如，突然断开的，或者跳动的函数，然后是没法用神经网络来进行逼近的。这并没有什么奇怪的，因为我们的网络计算输入的连续函数。然而，即使我们想要计算不连续的函数，但是利用连续的逼近来的效果更好。既然这样，那么我们就可以用神经网络。实际上，这并不是一个很重要的限制。</p>
</li>
<li><p>总结一下，关于泛化性理论的一个精确的说法是一个单隐层的神经网络能够用来逼近任何的连续函数到任何想要的精度。在本章中，我们实际上证明了一个微弱版本的理论，用两个隐层的神经网络代替单隐层的神经网络。在以下的我们将要解释的问题中，利用一些小技巧，适合的给出了单隐层的神经网络的证明。</p>
</li>
</ul>
<h2 id="一个输入和一个输出的泛化理论"><a href="#一个输入和一个输出的泛化理论" class="headerlink" title="一个输入和一个输出的泛化理论"></a>一个输入和一个输出的泛化理论</h2><ul>
<li><p>要理解为什么泛化性理论是可行的，让我们从理解如何构造一个能够逼近函数的只包含一个输入和一个输出的神经网络说起：</p>
<img src="/img/visual_proof_of_neural_networks/5_network.png" class="[class names]" title="[Neural Network []]">
</li>
<li><p>其实最简单的神经网络(包含一个输入和一个输出)就是泛化性理论的核心。一旦我们能够理解这个简单的网络，那么我们也很容易扩展到其他的(包含多个输入和输出)复杂网络了。</p>
</li>
<li><p>想要深入理解如果构造能够计算函数$f$的网络，我们先来构造一个简单的神经网络，包含单个输入，一个包含2个神经元的隐层，单个输出的神经网络：</p>
</li>
</ul>
<img src="/img/visual_proof_of_neural_networks/6_network.png" class="[class names]" title="[Neural Network []]">

<ul>
<li>为了感受一下神经网络中的组件是如何工作的，让我们先看上面的隐层神经元。在下面的图中，用鼠标点击然后拖动来改变权重$w$的值。你就可以立刻看到右边的函数图是如何变化的(原网页才能操作)：<img src="/img/visual_proof_of_neural_networks/7_gif_pic.gif" class="[class names]" title="[Neural Network []]"></li>
<li>本书的前面讲过，$\sigma(wx+b)$是怎么计算的，其中$\sigma(z)&#x3D;1&#x2F;(1+e^{-z})$就是sigmoid函数。到现在，我们一直频繁的使用这种代数形式进行计算。但是要证明泛化性理论，我们应该忽视这种数学形式，然后通过通过操作和观察以上的图来获得更深的理解。</li>
<li>要开始证明这个理论，请试着用鼠标点击偏置$b$，然后往右拉来增加它的数值。你会看到增加偏置$b$只会把图像往左移动，而不会改变图像的形状。</li>
<li>接下来，你试着鼠标往左拉，偏置$b$的数值减小，你会看到图像是往右边移动的，同样的，图像的形状并没有改变。</li>
<li>然后，我们来改变权重$w$的数值，把它的值改变到2或者3。你会看到减小权重$w$，曲线变得更宽了。你可能需要同时改变一下偏置$b$，以免图像跑出了框内。</li>
<li>最后，把权重$w$的数值增加到100。你会发现，曲线变得更陡峭了，直到它看起来像一个step函数。可以观察一下下面的小视频：</li>
</ul>
<img src="/img/visual_proof_of_neural_networks/8_gif_pic.gif" class="[class names]" title="[Neural Network []]">

<ul>
<li>我们可以通过增加权重$w$直到它变成了一个step函数(逼近的精度越来越高)来简化我们的分析。下面右边的图像是当$w&#x3D;999$时的函数图。</li>
</ul>
<img src="/img/visual_proof_of_neural_networks/9_network.png" class="[class names]" title="[Neural Network []]">

<ul>
<li><p>其实step函数比一般的sigmoid函数表现更好。原因是输出层是前面所有的隐层的神经元计算来决定的。去分析一堆step函数的总和是件更容易的事，但是去分析一堆sigmoid函数的曲线计算后的结果就不是一件易事了。而且，把隐层的神经元输出step函数是一件更容易的事情。更确切的说，我们把权重$w$的值调得非常大，这样就可以得到了step函数了。然后通过调整偏置$b$来改变step(跃阶)的位置。当然，把输出当成一个step函数也是一种逼近，而且是一个很好的逼近，而现在我们正是这样做的。我稍后会再讨论这种逼近的求导的影响。</p>
</li>
<li><p>当$x$的数值是多少时达到跃阶(step)呢？换一种说法，step的位置是如何由权重$w$和偏置$b$来决定的？</p>
</li>
<li><p>要回答这个问题，我们再来试一下改变权重$w$和偏置$b$的数值。你可以弄清楚跃阶(step)和权重$w$与偏置$b$的关系吗？通过不断的观察图像的变化，你可能就会发现，跃阶(step)的位置是和偏置$b$成正比的，和权重$w$成反比的。</p>
</li>
<li><p>事实上，跃阶(step)的位置$s$满足$s&#x3D;-b&#x2F;w$.</p>
<img src="/img/visual_proof_of_neural_networks/10_gif_pic.gif" class="[class names]" title="[Neural Network []]">
</li>
<li><p>这会大大简化了我们的生活，如果我们只是单单利用一个参数$s$来描述隐层的神经元的话。$s$就是跃阶(step)的位置，$s&#x3D;-b&#x2F;w$。</p>
<img src="/img/visual_proof_of_neural_networks/11_gif_pic.gif" class="[class names]" title="[Neural Network []]">
</li>
<li><p>上面有提到，我们可以偷偷地把输入的权重$w$调到非常大，大到出来的step函数是一个很好的逼近。我们就可以很容易的在传统的模型当中把神经元参数按这样子来调整，偏置$b&#x3D;-ws$.</p>
</li>
<li><p>以上我们都是讨论上层神经元。现在我们来讨论一下整个网络。我们假设上层神经元通过step函数参数化跃阶(step)为$s_1$，下层神经元通过step函数参数化跃阶(step)为$s_2$.他们分别有输出权重$w_1$和$w_2$。以下就是网络：</p>
<img src="/img/visual_proof_of_neural_networks/12_gif_pic.gif" class="[class names]" title="[Neural Network []]">
</li>
<li><p>右上方的图像是输出权重$(w_1a_1+w_2a_2)$的结果。其中$a_1$和$a_2$分别是上层神经元和下层神经元的输出。输出用$a$来表示是因为神经元通常包含一个激活函数(activation)。</p>
</li>
<li><p>让我们来看一下$s_1$和$s_2$相遇时会发生什么情况呢？看图：</p>
<img src="/img/visual_proof_of_neural_networks/13_gif_pic.gif" class="[class names]" title="[Neural Network []]"></li>
<li><p>可以看到，当我们操作$s_1$时，$S_1$和$s_2$相遇时，$S_1$就会带动$s_2$走。所以，图像的变动，我们也要分是$s_1$先动还是$s_2$先动。</p>
</li>
<li><p>$h_t$</p>
</li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步-ML</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>可视化证明</tag>
      </tags>
  </entry>
  <entry>
    <title>EVM硬核底层原理</title>
    <url>/2023/08/16/Web3/evm-core/</url>
    <content><![CDATA[<h2 id="一问：智能合约是怎么部署到链上的？"><a href="#一问：智能合约是怎么部署到链上的？" class="headerlink" title="一问：智能合约是怎么部署到链上的？"></a>一问：智能合约是怎么部署到链上的？</h2><ul>
<li>字节码 bytecode：智能合约通过编译器编译后生成的二进制代码，它是一种中间代码，可以被EVM虚拟机执行。</li>
<li>操作码&#x2F;指令码 <a class="link"   href="https://www.ethervm.io/" >opcode<i class="fas fa-external-link-alt"></i></a>：操作码是一种特殊的字节码，它是EVM虚拟机的指令集，用于执行智能合约的逻辑。</li>
<li>GitHub Copilot的回答：<ul>
<li>GitHub Copilot: 您好！智能合约是通过将其编译为字节码(bytecode)，然后将字节码发送到区块链网络上的节点来部署的。一旦节点接收到字节码，它将创建一个合约地址，并将字节码存储在该地址下。这样，其他用户就可以通过调用该地址上的函数来与合约进行交互。</li>
</ul>
</li>
<li>ChatGPT的回答：</li>
</ul>
<h2 id="opcode的分类"><a href="#opcode的分类" class="headerlink" title="opcode的分类"></a>opcode的分类</h2><ul>
<li>GitHub Copilot: 您好！EVM虚拟机的操作码可以分为以下几类：<br>GitHub Copilot: 以下是EVM操作码按类分类的列表：</li>
</ul>
<h3 id="栈操作（Stack-Operations）17个"><a href="#栈操作（Stack-Operations）17个" class="headerlink" title="栈操作（Stack Operations）17个"></a>栈操作（Stack Operations）17个</h3><ul>
<li>0x80 - 0x8f: DUP1-DUP16</li>
<li>0x90 - 0x9f: SWAP1-SWAP16</li>
<li>0x58: POP</li>
<li>0x59: MLOAD</li>
<li>0x5a: MSTORE</li>
<li>0x5b: MSTORE8</li>
<li>0x50: PUSH1</li>
<li>0x51: PUSH2</li>
<li>…</li>
<li>0x5f: PUSH32</li>
<li>PUSH1 - PUSH32共32个</li>
</ul>
<h3 id="流程控制（Flow-Control）3个"><a href="#流程控制（Flow-Control）3个" class="headerlink" title="流程控制（Flow Control）3个"></a>流程控制（Flow Control）3个</h3><ul>
<li>0x56: JUMP</li>
<li>0x57: JUMPI</li>
<li>0x5b: JUMPDEST</li>
</ul>
<h3 id="环境信息（Environmental-Information）15个"><a href="#环境信息（Environmental-Information）15个" class="headerlink" title="环境信息（Environmental Information）15个"></a>环境信息（Environmental Information）15个</h3><ul>
<li>0x30: ADDRESS</li>
<li>0x31: BALANCE</li>
<li>0x32: ORIGIN</li>
<li>0x33: CALLER</li>
<li>0x34: CALLVALUE</li>
<li>0x35: CALLDATALOAD</li>
<li>0x36: CALLDATASIZE</li>
<li>0x37: CALLDATACOPY</li>
<li>0x38: CODESIZE</li>
<li>0x39: CODECOPY</li>
<li>0x3a: GASPRICE</li>
<li>0x3b: EXTCODESIZE</li>
<li>0x3c: EXTCODECOPY</li>
<li>0x3d: RETURNDATASIZE</li>
<li>0x3e: RETURNDATACOPY</li>
</ul>
<h3 id="存储和内存（Storage-and-Memory）4个"><a href="#存储和内存（Storage-and-Memory）4个" class="headerlink" title="存储和内存（Storage and Memory）4个"></a>存储和内存（Storage and Memory）4个</h3><ul>
<li>0x54: SLOAD</li>
<li>0x55: SSTORE</li>
<li>0x5a: MSTORE</li>
<li>0x5b: MSTORE8</li>
</ul>
<h3 id="数学运算（Mathematical-Operations）11个"><a href="#数学运算（Mathematical-Operations）11个" class="headerlink" title="数学运算（Mathematical Operations）11个"></a>数学运算（Mathematical Operations）11个</h3><ul>
<li>0x01: ADD</li>
<li>0x02: MUL</li>
<li>0x03: SUB</li>
<li>0x04: DIV</li>
<li>0x05: SDIV</li>
<li>0x06: MOD</li>
<li>0x07: SMOD</li>
<li>0x08: ADDMOD</li>
<li>0x09: MULMOD</li>
<li>0x0a: EXP</li>
<li>0x0b: SIGNEXTEND</li>
</ul>
<h3 id="比较和逻辑运算（Comparison-and-Bitwise-Logic-Operations）15个"><a href="#比较和逻辑运算（Comparison-and-Bitwise-Logic-Operations）15个" class="headerlink" title="比较和逻辑运算（Comparison and Bitwise Logic Operations）15个"></a>比较和逻辑运算（Comparison and Bitwise Logic Operations）15个</h3><ul>
<li>0x10: LT</li>
<li>0x11: GT</li>
<li>0x12: SLT</li>
<li>0x13: SGT</li>
<li>0x14: EQ</li>
<li>0x15: ISZERO</li>
<li>0x16: AND</li>
<li>0x17: OR</li>
<li>0x18: XOR</li>
<li>0x19: NOT</li>
<li>0x1a: BYTE</li>
<li>0x1b: SHL</li>
<li>0x1c: SHR</li>
<li>0x1d: SAR</li>
</ul>
<h3 id="加载和存储（Loading-and-Storing）14个"><a href="#加载和存储（Loading-and-Storing）14个" class="headerlink" title="加载和存储（Loading and Storing）14个"></a>加载和存储（Loading and Storing）14个</h3><ul>
<li>0x32: ORIGIN</li>
<li>0x33: CALLER</li>
<li>0x34: CALLVALUE</li>
<li>0x35: CALLDATALOAD</li>
<li>0x36: CALLDATASIZE</li>
<li>0x37: CALLDATACOPY</li>
<li>0x38: CODESIZE</li>
<li>0x39: CODECOPY</li>
<li>0x3a: GASPRICE</li>
<li>0x3b: EXTCODESIZE</li>
<li>0x3c: EXTCODECOPY</li>
<li>0x3d: RETURNDATASIZE</li>
<li>0x3e: RETURNDATACOPY</li>
</ul>
<h3 id="合约调用（Contract-Calls）10个"><a href="#合约调用（Contract-Calls）10个" class="headerlink" title="合约调用（Contract Calls）10个"></a>合约调用（Contract Calls）10个</h3><ul>
<li>0xf0: CREATE</li>
<li>0xf1: CALL</li>
<li>0xf2: CALLCODE</li>
<li>0xf3: RETURN</li>
<li>0xf4: DELEGATECALL</li>
<li>0xf5: CREATE2</li>
<li>0xfa: STATICCALL</li>
<li>0xfd: REVERT</li>
<li>0xff: SELFDESTRUCT</li>
</ul>
<h3 id="杂项（Miscellaneous）11个"><a href="#杂项（Miscellaneous）11个" class="headerlink" title="杂项（Miscellaneous）11个"></a>杂项（Miscellaneous）11个</h3><ul>
<li>0x00: STOP</li>
<li>0x0f: BREAKPOINT</li>
<li>0x3f: BLOCKHASH</li>
<li>0x40: COINBASE</li>
<li>0x41: TIMESTAMP</li>
<li>0x42: NUMBER</li>
<li>0x43: DIFFICULTY</li>
<li>0x44: GASLIMIT</li>
<li>0x45: CHAINID</li>
<li>0x46: SELFBALANCE</li>
<li>0x47: BASEFEE</li>
</ul>
<p>了解这些操作码的分类可以帮助开发者更好地理解EVM虚拟机的指令集，从而更好地编写和优化智能合约的代码。</p>
<h2 id="二问：如何写智能合约才能更省gas费用？"><a href="#二问：如何写智能合约才能更省gas费用？" class="headerlink" title="二问：如何写智能合约才能更省gas费用？"></a>二问：如何写智能合约才能更省gas费用？</h2><ul>
<li>GitHub Copilot: 在Solidity中，通常有以下几种省费用的操作码：</li>
</ul>
<ol>
<li><p>使用<code>view</code>和<code>pure</code>关键字：在Solidity中，如果一个函数不修改合约状态并且不访问合约存储，那么可以使用<code>view</code>或<code>pure</code>关键字来标记该函数。这样可以避免在执行函数时进行状态变更和存储访问，从而减少gas费用。</p>
</li>
<li><p>使用<code>memory</code>关键字：在Solidity中，如果一个函数需要使用临时内存来存储数据，那么可以使用<code>memory</code>关键字来标记该数据。这样可以避免在执行函数时将数据存储到合约存储中，从而减少gas费用。</p>
</li>
<li><p>使用<code>bytes32</code>类型：在Solidity中，如果一个变量需要存储一个固定长度的字节序列，那么可以使用<code>bytes32</code>类型来存储。这样可以避免使用动态数组或映射类型，从而减少gas费用。</p>
</li>
<li><p>避免重复计算和存储：在Solidity中，如果一个变量的值可以通过其他变量计算得出，那么可以避免重复计算和存储该变量的值。这样可以减少gas费用。</p>
</li>
<li><p>避免使用循环：在Solidity中，循环语句的执行会消耗大量的gas费用。因此，如果可以使用其他方式来实现相同的功能，那么应该避免使用循环语句。</p>
</li>
</ol>
<p>这些操作码可以帮助开发者减少智能合约的gas费用，从而提高智能合约的性能和可用性。</p>
]]></content>
      <categories>
        <category>技能-修行-进步-Web3</category>
      </categories>
      <tags>
        <tag>EVM</tag>
      </tags>
  </entry>
  <entry>
    <title>web3基础设施八周课程</title>
    <url>/2023/08/04/Web3/web3%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E5%85%AB%E5%91%A8%E8%AF%BE%E7%A8%8B/</url>
    <content><![CDATA[<ul>
<li>课程总览</li>
<li><img src="/img/wuweiwu/web3-8week/course-review.jpg"></li>
</ul>
<h2 id="week1a-基础知识"><a href="#week1a-基础知识" class="headerlink" title="week1a-基础知识"></a>week1a-基础知识</h2><ul>
<li>关键字<ul>
<li>中心化&#x2F;去中心化</li>
<li>区块链</li>
<li>共识机制</li>
<li>分叉&#x2F;之链</li>
<li>web3的商业：合作共赢，而是大小通吃。Inter-Operation。常言道：赢者垄断（Apple），输者竞争（卷起来）</li>
<li>web3的工作方式：多数是远程，以结果为导向，员工需要更多的自主性，沟通很重要</li>
<li>web3的运营：online，多人参与，DAO，抱着“信仰”而前进的。</li>
</ul>
</li>
</ul>
<h2 id="week1b-加密"><a href="#week1b-加密" class="headerlink" title="week1b-加密"></a>week1b-加密</h2><ul>
<li>全同态加密，FHE，Fully Homomorphic Encryption</li>
<li><img src="/img/wuweiwu/web3-8week/fhe-background.png"></li>
<li>zkPass，zk：zero knowledge，零知识证明</li>
</ul>
<h2 id="week1c-chainlink预言机"><a href="#week1c-chainlink预言机" class="headerlink" title="week1c-chainlink预言机"></a>week1c-chainlink预言机</h2><ul>
<li>关键字<ul>
<li>oracle，区块链上的智能合约</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步-Web3</category>
      </categories>
      <tags>
        <tag>web3基础设施</tag>
      </tags>
  </entry>
  <entry>
    <title>多线程笔记</title>
    <url>/2014/12/26/alogrithms/Multithreading-note/</url>
    <content><![CDATA[<h2 id="写在前面的话"><a href="#写在前面的话" class="headerlink" title="写在前面的话"></a>写在前面的话</h2><ul>
<li>Java中的多线程是一项非常重要的学习内容。多线程的引入强化了程序的执行能力，提高了程序的执行效率。那么多线程到底是神马呢？本文将更随毕向东老师的思路揭开多线程的谜底。</li>
<li>本文笔记是除了在《毕向东Java基础》视频的基础上所做的笔记之外，还做深层的扩展。</li>
</ul>
<h2 id="多线程概念"><a href="#多线程概念" class="headerlink" title="多线程概念"></a>多线程概念</h2><h3 id="认识进程"><a href="#认识进程" class="headerlink" title="认识进程"></a>认识进程</h3><ul>
<li>在认识多线程之前，我们需要先了解“进程”这个概念。那么什么是进程呢？进程是操作系统的基础，它是程序的一次执行。即是程序完成的一次由开始到结束的执行过程。进程包括运行中的程序和程序所使用到的内存和系统资源，而一个进程又是由多个线程所组成的。</li>
<li>参考：<a class="link"   href="http://baike.baidu.com/link?url=_1Vj9y9F_tqzEj4uDO7wAf16bBvg5x5FmWNjBgWUCjRP-tTqUIhO7MwZfQj3cBz6LaDHcnDh2uziXbVhVBEqbK" >进程<i class="fas fa-external-link-alt"></i></a></li>
</ul>
<h3 id="认识线程"><a href="#认识线程" class="headerlink" title="认识线程"></a>认识线程</h3><ul>
<li>那么什么又是线程呢？线程其实是进程当中的一个执行路径，它是进程中的一个独立的控制单元。每个进程都可以包含多个执行路径，每个进程必须包含一个线程，叫做进程的主线程。</li>
<li>参考：<a class="link"   href="http://baike.baidu.com/view/1053.htm" >线程<i class="fas fa-external-link-alt"></i></a></li>
</ul>
<h3 id="认识多线程"><a href="#认识多线程" class="headerlink" title="认识多线程"></a>认识多线程</h3><ul>
<li>多线程就是指一个进程中包含多个执行路径，即是在一个程序中可以同时运行多个不同的线程来执行不同的任务。最简单的例子就是JVM，JVM是一个多线程的进程，它启动之后不止一个线程，还包括了垃圾回收的线程。</li>
</ul>
<h3 id="为什么需要线程"><a href="#为什么需要线程" class="headerlink" title="为什么需要线程"></a>为什么需要线程</h3><ul>
<li>可以提高程序的运行效率</li>
<li>可以优化程序的执行能力</li>
</ul>
<h2 id="多线程的实现-Java"><a href="#多线程的实现-Java" class="headerlink" title="多线程的实现(Java)"></a>多线程的实现(Java)</h2><ul>
<li>查阅api文档，可以知道Java多线程的实现有2种方法。第一种是继承java.lang.Thread类；第二种是实现java.lang.Runnable接口。</li>
</ul>
<h3 id="继承java-lang-Thread类的多线程实现"><a href="#继承java-lang-Thread类的多线程实现" class="headerlink" title="继承java.lang.Thread类的多线程实现"></a>继承java.lang.Thread类的多线程实现</h3><ul>
<li>步骤：<ul>
<li>定义一个类，继承java.lang.Thread类</li>
<li>复写Thread类中的run()方法，目的：将自定义的代码存储在run方法中，让线程运行。</li>
<li>调用线程的start()方法，该类有2个作用：启动线程和调用run()方法。</li>
</ul>
</li>
<li>代码实现</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 定义一个类，继承java.lang.Thread类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Demo</span> <span class="keyword">extends</span> <span class="title class_">Thread</span> &#123;</span><br><span class="line">	<span class="comment">// 复写Thread类中的run()方法</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span> <span class="params">()</span> &#123;</span><br><span class="line">		<span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">60</span>; i++) &#123;</span><br><span class="line">			System.out.println(<span class="string">&quot;demo run!------&quot;</span>+i);</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ThreadDemo</span> &#123;</span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">		 <span class="type">Demo</span> <span class="variable">d</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Demo</span>();</span><br><span class="line">		<span class="comment">// 调用线程的start()方法</span></span><br><span class="line">		 d.start();</span><br><span class="line">		 <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">60</span>; i++) &#123;</span><br><span class="line">				System.out.println(<span class="string">&quot;Hello World run!---------&quot;</span>+i);</span><br><span class="line">			&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>运行结果<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">demo run!------0</span><br><span class="line">demo run!------1</span><br><span class="line">demo run!------2</span><br><span class="line">Hello World run!---------0</span><br><span class="line">demo run!------3</span><br><span class="line">Hello World run!---------1</span><br><span class="line">demo run!------4</span><br><span class="line">Hello World run!---------2</span><br><span class="line">demo run!------5</span><br><span class="line">demo run!------6</span><br><span class="line">demo run!------7</span><br><span class="line">demo run!------8</span><br><span class="line">....</span><br><span class="line">....</span><br><span class="line">Hello World run!---------31</span><br><span class="line">demo run!------29</span><br><span class="line">Hello World run!---------32</span><br><span class="line">demo run!------30</span><br><span class="line">Hello World run!---------33</span><br><span class="line">demo run!------31</span><br><span class="line">Hello World run!---------34</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">Hello World run!---------58</span><br><span class="line">Hello World run!---------59</span><br></pre></td></tr></table></figure></li>
<li>结果分析：发现每次运行的结果都不一样<ul>
<li>(单核CPU)某个时刻只能执行一个线程</li>
<li>不同的线程都在抢夺CPU的执行权，谁抢到谁执行</li>
<li>CPU做着快速的切换，所以看起来像是多个线程同时在运行</li>
<li>CPU的随机性，它想执行哪个线程，哪个线程才可以被执行</li>
</ul>
</li>
</ul>
<h4 id="为什么要复写Thread类当中的run-方法呢？"><a href="#为什么要复写Thread类当中的run-方法呢？" class="headerlink" title="为什么要复写Thread类当中的run()方法呢？"></a>为什么要复写Thread类当中的run()方法呢？</h4><h4 id="为什么是调用start-方法而不是run-方法呢？"><a href="#为什么是调用start-方法而不是run-方法呢？" class="headerlink" title="为什么是调用start()方法而不是run()方法呢？"></a>为什么是调用start()方法而不是run()方法呢？</h4><h3 id="实现java-lang-Runnable接口的多线程实现"><a href="#实现java-lang-Runnable接口的多线程实现" class="headerlink" title="实现java.lang.Runnable接口的多线程实现"></a>实现java.lang.Runnable接口的多线程实现</h3><h2 id="线程的运行状态"><a href="#线程的运行状态" class="headerlink" title="线程的运行状态"></a>线程的运行状态</h2><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li><a class="link"   href="http://blog.csdn.net/nidexuanzhe/article/details/6624444" >线程及多线程的作用-CSDN-blog<i class="fas fa-external-link-alt"></i></a></li>
<li><a class="link"   href="http://blog.csdn.net/caixiexin/article/details/6603061" >java 如何实现多线程-CSDN-blog<i class="fas fa-external-link-alt"></i></a></li>
<li><a class="link"   href="http://www.cnblogs.com/jbelial/archive/2013/03/17/2964472.html" >黑马程序员-JAVA基础-多线程（上）-cnblogs<i class="fas fa-external-link-alt"></i></a></li>
<li><a class="link"   href="http://www.blogjava.net/liver/archive/2009/06/04/279924.html" >线程7种状态的相互转换<i class="fas fa-external-link-alt"></i></a></li>
</ol>
]]></content>
      <categories>
        <category>技能-修行-进步</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title>leetcode_binary_tree_series</title>
    <url>/2020/03/09/alogrithms/leetcode-binary-tree-series/</url>
    <content><![CDATA[<h3 id="什么是树"><a href="#什么是树" class="headerlink" title="什么是树"></a>什么是树</h3><ul>
<li>**树(Tree)**是一种非线性结构，用来模拟具有树状结构性质的数据集合。它是由n(n&gt;0)个有限节点组成一个具有层次关系的集合。树是递归结构，在树的定义中又用到了树的概念。</li>
</ul>
<h3 id="什么是二叉树"><a href="#什么是二叉树" class="headerlink" title="什么是二叉树"></a>什么是二叉树</h3><ul>
<li>**二叉树(Binary tree)**是每个节点最多只有两个分支(即不存在分支度大于2的节点)的树结构。通常分支被称作“左子树”或者“右子树”。二叉树的分支具有左右次序，不能随意颠倒。二叉树可以为空。</li>
</ul>
<h3 id="完全二叉树"><a href="#完全二叉树" class="headerlink" title="完全二叉树"></a>完全二叉树</h3><ul>
<li>若设二叉树的深度为ℎ，除第ℎ层外，其它各层(1～ℎ−1)的结点数都达到最大个数，第ℎ层所有的结点都连续集中在最左边，这就是完全二叉树</li>
</ul>
<h3 id="什么是二叉搜索树"><a href="#什么是二叉搜索树" class="headerlink" title="什么是二叉搜索树"></a>什么是二叉搜索树</h3><ul>
<li>左子树的值都比根节点小，右子树的值都比根节点大。</li>
</ul>
<h3 id="树的定义-Python"><a href="#树的定义-Python" class="headerlink" title="树的定义(Python)"></a>树的定义(Python)</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Definition for a binary tree node.</span><br><span class="line">class TreeNode:</span><br><span class="line">	def __init__(self, x):</span><br><span class="line">		self.value = x</span><br><span class="line">		self.left = None</span><br><span class="line">		self.right = None</span><br></pre></td></tr></table></figure>

<h3 id="树的遍历"><a href="#树的遍历" class="headerlink" title="树的遍历"></a>树的遍历</h3><h4 id="深度优先，通常有前序-pre-order-，中序-in-order-，后序-post-order-3种遍历方法，每一种又分递归和迭代两种实现"><a href="#深度优先，通常有前序-pre-order-，中序-in-order-，后序-post-order-3种遍历方法，每一种又分递归和迭代两种实现" class="headerlink" title="深度优先，通常有前序(pre-order)，中序(in-order)，后序(post-order)3种遍历方法，每一种又分递归和迭代两种实现"></a>深度优先，通常有前序(pre-order)，中序(in-order)，后序(post-order)3种遍历方法，每一种又分递归和迭代两种实现</h4><ul>
<li><strong>3种遍历经过的路径都是一样的，而且每个节点都会被访问3次，当我们在第一次访问该节点就打印出来的话，那么这就是前序；当我们第二次访问该节点才打印出来的话，那么这就是中序；当我们第三次访问该节点才打印出来的话，那么这就是后序。</strong></li>
<li>伪代码，递归实现<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># pseudocode，递归</span><br><span class="line">## 前序</span><br><span class="line">func preorder(root):</span><br><span class="line">	if not root: return</span><br><span class="line">	**print(root.val)**</span><br><span class="line">	preorder(root.left)</span><br><span class="line">	preorder(root.right)</span><br><span class="line">	</span><br><span class="line"></span><br><span class="line">## 中序, 对于二叉搜索树，中序后的是一个排序数组</span><br><span class="line">func inorder(root):</span><br><span class="line">	if not root: return</span><br><span class="line">	inorder(root.left)</span><br><span class="line">	**print(root.val)**</span><br><span class="line">	inorder(root.right)</span><br><span class="line">	</span><br><span class="line">## 后序</span><br><span class="line">func postorder(root):</span><br><span class="line">	if not root: return</span><br><span class="line">	postorder(root.left)</span><br><span class="line">	postorder(root.right)</span><br><span class="line">	**print(root.val)**</span><br></pre></td></tr></table></figure></li>
<li><strong>Python 实现</strong><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">## 前序遍历</span><br><span class="line">### 1. 递归实现</span><br><span class="line">class Solution:</span><br><span class="line">	def preorderTraversal(self, root: TreeNode) -&gt; List[int]:</span><br><span class="line">		ans = []</span><br><span class="line">		if not root: return ans</span><br><span class="line">		self.preTraversal(root, ans)</span><br><span class="line">		return ans</span><br><span class="line">		</span><br><span class="line">	def preTraversal(self, t, ans):</span><br><span class="line">		ans.append(t.val)</span><br><span class="line">		if t.left:</span><br><span class="line">			self.preTraversal(t.left, ans)</span><br><span class="line">		if t.right:</span><br><span class="line">			self.preTraversal(t.right, ans)</span><br><span class="line">			</span><br><span class="line">### 2. 迭代实现，栈</span><br><span class="line">class Solution:</span><br><span class="line">	def preorderTraversal(self, root: TreeNode) -&gt; List[int]:</span><br><span class="line">		ans = []</span><br><span class="line">		stack = []</span><br><span class="line">		if not root:</span><br><span class="line">			return ans</span><br><span class="line">		p = root</span><br><span class="line">		while(p or len(stack)):</span><br><span class="line">			if p:</span><br><span class="line">				ans.append(p.val)</span><br><span class="line">				stack.append(p)</span><br><span class="line">				p = p.left</span><br><span class="line">			else:</span><br><span class="line">				p = stack[-1]</span><br><span class="line">				stack.pop(-1)</span><br><span class="line">				p = p.right</span><br><span class="line">		return ans</span><br><span class="line">		</span><br><span class="line">## ---------------split line-------------------</span><br><span class="line"></span><br><span class="line">## 中序序遍历</span><br><span class="line">### 1. 递归实现</span><br><span class="line">class Solution:</span><br><span class="line">	def inorderTraversal(self, root: TreeNode) -&gt; List[int]:</span><br><span class="line">		ans = []</span><br><span class="line">		if not root: return ans</span><br><span class="line">		self.inTraversal(root, ans)</span><br><span class="line">		return ans</span><br><span class="line">		</span><br><span class="line">	def inTraversal(self, t, ans):</span><br><span class="line">		ans.append(t.val)</span><br><span class="line">		if t.left:</span><br><span class="line">			self.inTraversal(t.left, ans)</span><br><span class="line">		if t.right:</span><br><span class="line">			self.inTraversal(t.right, ans)</span><br><span class="line">			</span><br><span class="line">### 2. 迭代实现</span><br><span class="line">class Solution:</span><br><span class="line">	def inorderTraversal(self, root: TreeNode) -&gt; List[int]:</span><br><span class="line">		ans = []</span><br><span class="line">		stack = []</span><br><span class="line">		if not root:</span><br><span class="line">			return ans</span><br><span class="line">		p = root</span><br><span class="line">		while(p or len(stack)):</span><br><span class="line">			if p:</span><br><span class="line">				stack.append(p)</span><br><span class="line">				p = p.left</span><br><span class="line">			else:</span><br><span class="line">				p = stack[-1]</span><br><span class="line">				ans.append(p.val)</span><br><span class="line">				stack.pop(-1)</span><br><span class="line">				p = p.right</span><br><span class="line">		return ans</span><br><span class="line">		</span><br><span class="line">## ---------------split line-------------------</span><br><span class="line"></span><br><span class="line">## 后序序遍历</span><br><span class="line">### 1. 递归实现</span><br><span class="line">class Solution:</span><br><span class="line">	def postorderTraversal(self, root: TreeNode) -&gt; List[int]:</span><br><span class="line">		ans = []</span><br><span class="line">		if not root: return ans</span><br><span class="line">		self.postTraversal(root, ans)</span><br><span class="line">		return ans</span><br><span class="line">		</span><br><span class="line">	def postTraversal(self, t, ans):</span><br><span class="line">		ans.append(t.val)</span><br><span class="line">		if t.left:</span><br><span class="line">			self.postTraversal(t.left, ans)</span><br><span class="line">		if t.right:</span><br><span class="line">			self.postTraversal(t.right, ans)</span><br><span class="line">	</span><br><span class="line">### 2. 迭代实现，因为前序是root-&gt;left-&gt;right, 而后序是left-&gt;right-&gt;root，刚好反过来</span><br><span class="line">class Solution:</span><br><span class="line">	def postorderTraversal(self, root: TreeNode) -&gt; List[int]:</span><br><span class="line">		ans = []</span><br><span class="line">		stack = []</span><br><span class="line">		if not root:</span><br><span class="line">			return ans</span><br><span class="line">		p = root</span><br><span class="line">		while(p or len(stack)):</span><br><span class="line">			if p:</span><br><span class="line">				ans.append(p.val)</span><br><span class="line">				stack.append(p)</span><br><span class="line">				p = p.right</span><br><span class="line">			else:</span><br><span class="line">				p = stack[-1]</span><br><span class="line">				stack.pop(-1)</span><br><span class="line">				p = p.left</span><br><span class="line">		return [val for val in reversed(ans)]</span><br><span class="line">		</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="广度优先"><a href="#广度优先" class="headerlink" title="广度优先"></a>广度优先</h4><ul>
<li>层次遍历(level-order)</li>
<li>利用队列(queue)来实现<ul>
<li><ol>
<li>根节点先入队列</li>
</ol>
</li>
<li><ol start="2">
<li>迭代当前队列上的所有元素</li>
</ol>
</li>
<li><ol start="3">
<li>若该元素所指节点的左右孩子节点非空，则将其左右孩子的指针入队列，把当前元素出队列，并保存其数值到结果数组中。</li>
</ol>
</li>
<li><ol start="4">
<li>循环重复2-4，直到队列为空。</li>
</ol>
</li>
</ul>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">	def levelOrder(self, root: TreeNode) -&gt; List[List[int]]:</span><br><span class="line">		queue = [root]</span><br><span class="line">		res = []</span><br><span class="line">		if not root:</span><br><span class="line">			return []</span><br><span class="line">		while queue:</span><br><span class="line">			templist = []</span><br><span class="line">			templen = len(queue)</span><br><span class="line">			for i in range(templen):</span><br><span class="line">				temp = queue.pop(0)</span><br><span class="line">				templist.append(temp.val)</span><br><span class="line">				if temp.left:</span><br><span class="line">					queue.append(temp.left)</span><br><span class="line">				if temp.right:</span><br><span class="line">					queue.append(temp.right)</span><br><span class="line">			res.append(templist)</span><br><span class="line">		return res</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="链表-Linked-list-，树-Tree-，图-Graph-的关系"><a href="#链表-Linked-list-，树-Tree-，图-Graph-的关系" class="headerlink" title="链表(Linked list)，树(Tree)，图(Graph)的关系"></a>链表(Linked list)，树(Tree)，图(Graph)的关系</h4><ul>
<li><strong>链表</strong>是特殊的<strong>树</strong>，<strong>树</strong>是特殊的<strong>图</strong>。</li>
</ul>
<h3 id="reference-参考"><a href="#reference-参考" class="headerlink" title="reference-参考"></a>reference-参考</h3><ul>
<li><a class="link"   href="https://suixinblog.cn/2019/02/binary-tree.html" >二叉树基础知识+Python实现<i class="fas fa-external-link-alt"></i></a></li>
<li><a class="link"   href="https://leetcode-cn.com/explore/learn/card/data-structure-binary-tree/2/traverse-a-tree/7/" >树的遍历 - 介绍<i class="fas fa-external-link-alt"></i></a></li>
<li><a class="link"   href="https://www.youtube.com/watch?v=fgEZMCrFrt4" >中国MOOC-二叉树的遍历-video<i class="fas fa-external-link-alt"></i></a></li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步</category>
      </categories>
      <tags>
        <tag>Tree</tag>
        <tag>binary tree</tag>
        <tag>binary search tree</tag>
        <tag>pre-order</tag>
        <tag>in-order</tag>
        <tag>post-order</tag>
      </tags>
  </entry>
  <entry>
    <title>单例设计模式</title>
    <url>/2014/12/25/alogrithms/Singleton-note/</url>
    <content><![CDATA[<h2 id="写在前面的话"><a href="#写在前面的话" class="headerlink" title="写在前面的话"></a>写在前面的话</h2><ul>
<li>本次笔记是在看了《毕向东Java基础》视频之后写的，对于毕老师讲课的优点，我想听过他的课的同学都应该知道的，所以我也不想多说了，但我还是忍不住再说一下，就是幽默风趣，讲课条理清晰，了解学生学习的难点，并能引领大家的思路。</li>
<li>另外，由于这是基础视频，所以讲的内容还是比较简单的。因此，我在课外进行了补充学习，希望能把这个单例模式问题学得更深更透！</li>
</ul>
<h2 id="什么是单例设计模式"><a href="#什么是单例设计模式" class="headerlink" title="什么是单例设计模式"></a>什么是单例设计模式</h2><h3 id="什么是设计模式？"><a href="#什么是设计模式？" class="headerlink" title="什么是设计模式？"></a>什么是设计模式？</h3><ul>
<li>首先第一个问题就是：什么是单例设计模式？要弄懂这个问题，我们首先要理解什么是<a class="link"   href="http://en.wikipedia.org/wiki/Software_design_pattern" >设计模式<i class="fas fa-external-link-alt"></i></a>。设计模式原本并不是软件开发领域首创的，它是建筑领域的一套理论知识。所谓设计模式，就是解决同一类问题的一种方法，它面向的是高层的抽象理念，和Java中的类和实例之间的关系有相似之处。</li>
</ul>
<h3 id="单例设计模式解决的问题"><a href="#单例设计模式解决的问题" class="headerlink" title="单例设计模式解决的问题"></a>单例设计模式解决的问题</h3><ul>
<li>单例设计模式面向的问题是什么呢？保证内存中某个类的实例的唯一性。即是说，无论什么时候，在内存中只能存在一个实例。</li>
</ul>
<h3 id="哪里应用了单例设计模式"><a href="#哪里应用了单例设计模式" class="headerlink" title="哪里应用了单例设计模式"></a>哪里应用了单例设计模式</h3><ul>
<li>这样的设计需要有哪些呢？举些例子来说吧，操作系统当中的垃圾桶，它在系统运行过程中都只有一个实例存在，无论你在C盘删除文件，还是在D盘删除文件，文件垃圾都是保存到同一个垃圾桶实例当中。这个最简单的验证就是：若果你把文件属性中的隐藏文件选择显示，那么你会在系统的任何地方都有一个垃圾桶文件夹，而这并不是说有多个垃圾桶实例，而是一个垃圾桶实例的多个引用。</li>
<li>另外的例子还包括软件的配置文件，其实也是应用了单例设计模式。试想下，若果软件的配置的配置有多个，那么软件在下次运行时应该选择哪么配置文件呢？比如eclipse，你在使用时发现没有显示行数，那么狠明显你是修改配置，行号就可以显示出来，而当你下次启动eclipse时，行号还是显示的。所有配置文件只有一个，你任何的修改都是对一个配置文件进行，这样才能保证下次启动软件时持续生效。</li>
</ul>
<h2 id="单例设计模式的实现-Java"><a href="#单例设计模式的实现-Java" class="headerlink" title="单例设计模式的实现(Java)"></a>单例设计模式的实现(Java)</h2><h3 id="单例设计模式的思路"><a href="#单例设计模式的思路" class="headerlink" title="单例设计模式的思路"></a>单例设计模式的思路</h3><ul>
<li>为了避免其他程序过多的建立该类对象。先禁止其他程序建立该类对象</li>
<li>为了让其他程序可以访问到该类对象，只好在本类中，自定义一个对象。</li>
<li>为了方便其他程序对自定义对象的访问，可以对外提供一些访问方式。</li>
</ul>
<h3 id="单例设计模式的代码实现步骤"><a href="#单例设计模式的代码实现步骤" class="headerlink" title="单例设计模式的代码实现步骤"></a>单例设计模式的代码实现步骤</h3><ul>
<li>将构造函数私有化</li>
<li>在类中创造一个本类对象</li>
<li>提供一个方法可以获取到该对象</li>
</ul>
<h3 id="实现代码"><a href="#实现代码" class="headerlink" title="实现代码"></a>实现代码</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SingletonDemo</span> &#123;</span><br><span class="line">	<span class="comment">// 将构造函数私有化 </span></span><br><span class="line">	<span class="keyword">private</span> <span class="title function_">SingletonDemo</span><span class="params">()</span> &#123;&#125;</span><br><span class="line">	<span class="comment">// 在类中创造一个本类对象</span></span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> <span class="type">SingletonDemo</span> <span class="variable">s</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SingletonDemo</span>();</span><br><span class="line">	<span class="comment">// 提供一个方法可以获取到该对象</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> SingletonDemo <span class="title function_">getInstance</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> s;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="单例设计模式就那么简单吗？"><a href="#单例设计模式就那么简单吗？" class="headerlink" title="单例设计模式就那么简单吗？"></a>单例设计模式就那么简单吗？</h2><ul>
<li>咋看，觉得代码那么简单，其实并不是那么简单，其中的坑还是不少的。让我们逐层逐层揭开它的神秘面纱吧。</li>
<li>单例设计模式一般有2种形式：懒汉式和饿汉式</li>
</ul>
<h3 id="懒汉式单例设计模式"><a href="#懒汉式单例设计模式" class="headerlink" title="懒汉式单例设计模式"></a>懒汉式单例设计模式</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 懒汉式</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Singleton</span> &#123;</span><br><span class="line">	<span class="comment">// 私有化构造函数</span></span><br><span class="line">	<span class="keyword">private</span> <span class="title function_">Singleton</span><span class="params">()</span> &#123;&#125;</span><br><span class="line">	<span class="comment">// 创建空引用</span></span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> <span class="type">Singleton</span> <span class="variable">instance</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">	<span class="comment">// 创建实例，并返回对象</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title function_">getInstance</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="keyword">if</span> (instance == <span class="literal">null</span>) &#123;</span><br><span class="line">			instance = <span class="keyword">new</span> <span class="title class_">Singleton</span>();</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span> instance;</span><br><span class="line">	&#125;	</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>上面的代码看上去似乎没什么问题？但其实暗藏了一个安全问题，因为在getInstance()的方法中包含2个语句，并不是原子操作，存在线程安全的问题，导致可能产生多个实例对象。</li>
<li>线程安全的懒汉式单例设计模式(只改getInstance方法)<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> Singleton <span class="title function_">getInstance</span><span class="params">()</span> &#123;</span><br><span class="line">	<span class="keyword">if</span> (instance == <span class="literal">null</span>) &#123;</span><br><span class="line">		instance = <span class="keyword">new</span> <span class="title class_">Singleton</span>();</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> instance;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>以上的代码，在方法前面加了synchronized关键字，表示了线程安全。但是把整个方法都同步了之后，程序的运行速度变得更慢了。为了解决慢的问题，又引出了双重检验锁。</li>
<li>双重检验锁(double checked locking pattern)的懒汉式单例设计模式(只改getInstance方法)<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title function_">getSingleton</span><span class="params">()</span> &#123;</span><br><span class="line">	<span class="keyword">if</span> (instance == <span class="literal">null</span>) &#123;		<span class="comment">// Single checked</span></span><br><span class="line">		<span class="keyword">synchronized</span> (Singleton.class) &#123;</span><br><span class="line">			<span class="keyword">if</span> (instance == <span class="literal">null</span>) &#123;		<span class="comment">// Double checked</span></span><br><span class="line">				instance = <span class="keyword">new</span> <span class="title class_">Singleton</span>();</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> instance;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li>这段代码貌似很完美了，但很遗憾地，它还是有问题的。主要是instance &#x3D; new Singleton()这句，这并非是一个原子操作，事实上在JVM中执行这个语句时做了以下3个事情。</li>
</ul>
<ol>
<li>给instance分配内存</li>
<li>调用Singleton的构造函数来初始化成员变量</li>
<li>将instance对象指向分配的内存空间(执行完这步instance才是非空)</li>
</ol>
<ul>
<li>但在JVM的即时编译器中存在指令重排序的优化。也就是上面的第2步和第3步的顺序是不能保证的，最终的执行顺序可能是1-2-3，也可能是1-3-2.如果是后者，则在3执行完毕、2未执行前，被线程二抢占了，这时的instance已经是非null(但却没有初始化)，所以线程二会直接返回instance，然后使用，然后顺理成章地报错了。（摘抄自大牛原文）</li>
<li>那我们应该怎么办呢？我们把instance变量声明为volatile就可以了。<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Singleton</span> &#123;</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">static</span> Singleton instance; </span><br><span class="line"></span><br><span class="line">	<span class="keyword">private</span> <span class="title function_">Singleton</span><span class="params">()</span> &#123;&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> Singleton <span class="title function_">getSingleton</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="keyword">if</span> (instance == <span class="literal">null</span>) &#123;</span><br><span class="line">			<span class="keyword">synchronized</span> (Singleton.class) &#123;</span><br><span class="line">				<span class="keyword">if</span> (instance == <span class="literal">null</span>) &#123;</span><br><span class="line">					instance = <span class="keyword">new</span> <span class="title class_">Singleton</span>();</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span> instance;</span><br><span class="line">	&#125;	</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li>(大牛解释）</li>
<li>有些人认为使用 volatile 的原因是可见性，也就是可以保证线程在本地不会存有 instance 的副本，每次都是去主内存中读取。但其实是不对的。使用 volatile 的主要原因是其另一个特性：禁止指令重排序优化。也就是说，在 volatile 变量的赋值操作后面会有一个内存屏障（生成的汇编代码上），读操作不会被重排序到内存屏障之前。比如上面的例子，取操作必须在执行完 1-2-3 之后或者 1-3-2 之后，不存在执行到 1-3 然后取到值的情况。从「先行发生原则」的角度理解的话，就是对于一个 volatile 变量的写操作都先行发生于后面对这个变量的读操作（这里的“后面”是时间上的先后顺序）。</li>
<li>但是特别注意在 Java 5 以前的版本使用了 volatile 的双检锁还是有问题的。其原因是 Java 5 以前的 JMM （Java 内存模型）是存在缺陷的，即时将变量声明成 volatile 也不能完全避免重排序，主要是 volatile 变量前后的代码仍然存在重排序问题。这个 volatile 屏蔽重排序的问题在 Java 5 中才得以修复，所以在这之后才可以放心使用 volatile。</li>
<li>相信你不会喜欢这种复杂又隐含问题的方式，当然我们有更好的实现线程安全的单例模式的办法。</li>
</ul>
<h3 id="饿汉式单例设计模式"><a href="#饿汉式单例设计模式" class="headerlink" title="饿汉式单例设计模式"></a>饿汉式单例设计模式</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 饿汉式</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Singleton</span> &#123;</span><br><span class="line">	<span class="comment">// 类加载时就初始化</span></span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">Singleton</span> <span class="variable">instance</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Singleton</span>();</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">private</span> <span class="title function_">Singleton</span><span class="params">()</span> &#123;&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title function_">getInstance</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> instance;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>这种方法非常简单，因为单例的实例被声明成static和final变量了，在第一次加载类到内存中时就会初始化，所以创建实例本身是线程安全的。</li>
<li>但是这种方法还是有问题的，它的缺点是它不是一种懒加载模式(lazy initialization)，单例会在加载类后一开始就被初始化，即使客户端没有调用getInstance()方法。饿汉式的创建方式在一些场景中将无法使用：譬如Singleton实例的创建时依赖参数或者配置文件的，在getInstance()之前必须调用某个方法设置参数给它，那么这种单例写法就无法使用了。</li>
</ul>
<h3 id="静态内部类的单例设计模式"><a href="#静态内部类的单例设计模式" class="headerlink" title="静态内部类的单例设计模式"></a>静态内部类的单例设计模式</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Singleton</span> &#123;</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">SingletonHolder</span> &#123;</span><br><span class="line">		<span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">Singleton</span> <span class="variable">INSTANCE</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Singleton</span>();</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">private</span> <span class="title function_">Singleton</span> <span class="params">()</span> &#123;&#125;</span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Singleton <span class="title function_">getInstance</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> SingletonHolder.INSTANCE;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>这种写法仍然使用JVM本身机制保证了线程安全问题；由于SingletonHolder 是私有的，除了getInstance()之外没有办法访问它，因此它是懒汉式的；同时读取实例的时候不会进行同步，没有性能缺陷；也不依赖JDK版本。</li>
</ul>
<h3 id="枚举Enum"><a href="#枚举Enum" class="headerlink" title="枚举Enum"></a>枚举Enum</h3><ul>
<li>用枚举来实现单例真的太简单了！<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">enum</span> <span class="title class_">EasySingleton</span> &#123;</span><br><span class="line">	INSTANCE;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>我们可以通过EasySingleton.INSTANCE来访问实例，这比调用getInstance()方法简单多了。创建枚举默认就是线程安全的，所以不需要担心double checked locking，而且还能防止反序列化导致重新创建新的对象。但是还是很少看到有人这样写，可能是因为不太熟悉吧。</li>
</ul>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><ul>
<li>一般来说，在开发中常用的是饿汉式的单例模式。</li>
<li>参考：<a class="link"   href="http://wuchong.me/blog/2014/08/28/how-to-correctly-write-singleton-pattern/" >如何正确地写出单例模式<i class="fas fa-external-link-alt"></i></a></li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步</category>
      </categories>
      <tags>
        <tag>单例设计模式</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>pa-prepare</title>
    <url>/2019/09/12/alogrithms/pa-prepare/</url>
    <content><![CDATA[<h3 id="数据结构与算法"><a href="#数据结构与算法" class="headerlink" title="数据结构与算法"></a>数据结构与算法</h3><ol>
<li>快排<ul>
<li>算法描述</li>
</ul>
<ol>
<li>先从序列中取出一个数作为基准数</li>
<li>分区过程, 将比这个数大的数全部放到它的右边, 小于或等于它的数全部放到它的左边</li>
<li>再对左右区间重复第二步, 直到各区间只有一个数</li>
</ol>
<ul>
<li>算法时间复杂度分析<ul>
<li>$$T(n) &#x3D; 2T(\frac{n}{2}) + f(n)$$</li>
<li>假设m次递归后结束，则<br>  $$T(n) &#x3D; 2^{m}T(1)+mn$$<br>  $$n &#x3D; 2^{m}T(1)$$</li>
<li>由于T(1)是常量，所以<br>  $$n &#x3D; 2^{m}, m &#x3D; log(n)$$</li>
<li>得到<br>  $$T(n) &#x3D; nT(1) + nlog(n)$$</li>
<li>因为n&gt;2时，nlog(n) &gt; n，所以快排最优情况下的时间复杂度是<br>  $$O(nlogn)$$ <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">quick_sort</span>(<span class="params">array, l, r</span>):</span><br><span class="line">    <span class="keyword">if</span> l &lt; r:</span><br><span class="line">        q = partition(array, l, r)</span><br><span class="line">        quick_sort(array, l, q-<span class="number">1</span>)</span><br><span class="line">        quick_sort(array, q+<span class="number">1</span>, r)</span><br><span class="line"></span><br><span class="line"><span class="comment"># partition algorithm</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">partition</span>(<span class="params">array, l, r</span>):</span><br><span class="line">    x = array[r]</span><br><span class="line">    i = l - <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(l, r):</span><br><span class="line">        <span class="keyword">if</span> array[j] &lt;= x:</span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">            array[i], array[j] = array[j], array[i]</span><br><span class="line">    array[i+<span class="number">1</span>], array[r] = array[r], array[i+<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span> i + <span class="number">1</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
</li>
<li>二分查找<ul>
<li>原数组必须是有序的 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">binary_search</span>(<span class="params">array, num</span>):</span><br><span class="line">    left = <span class="number">0</span></span><br><span class="line">    right = <span class="built_in">len</span>(array) - <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> left &lt;= right:</span><br><span class="line">        mid = (left + right) // <span class="number">2</span></span><br><span class="line">        <span class="keyword">if</span> num &lt; array[mid]:</span><br><span class="line">            right = mid - <span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span> num &gt; array[mid]:</span><br><span class="line">            left = mid + <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> mid</span><br><span class="line">    <span class="keyword">return</span> -<span class="number">1</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>最大堆和最小堆，一般求无序数组中最大(小)的K个数</li>
</ol>
<h3 id="计算机视觉图形学基础"><a href="#计算机视觉图形学基础" class="headerlink" title="计算机视觉图形学基础"></a>计算机视觉图形学基础</h3><ul>
<li>图像本身就是一个函数</li>
</ul>
<ol>
<li>low-level feature<ul>
<li>图片锐化，拉普拉斯</li>
<li>边缘检测，sobel</li>
<li>图片模糊，中值滤波&#x2F;高斯滤波</li>
<li>图像二值化，灰度图</li>
<li>图像resize，插值（临近插值，双线性插值）</li>
</ul>
</li>
</ol>
<h3 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h3><ol>
<li><p>Logistic regression</p>
</li>
<li><p>   SVM</p>
<ul>
<li>首先它是一个二类分类器，核心思想是在特征空间中寻找间隔最大化的分离超平面的线性分类器。<ul>
<li>当训练样本线性可分时，通过硬间隔最大化，学习一个线性分类器，即线性可分支持向量机；</li>
<li>当训练数据近似线性可分时，引入松弛变量，通过软间隔最大化，学习一个线性分类器，即线性支持向量机；</li>
<li>当训练数据线性不可分时，通过使用核技巧及软间隔最大化，学习非线性支持向量机。</li>
</ul>
</li>
<li>SVM 核函数之间的区别<ul>
<li>一般选择线性核和高斯核，也就是线性核与 RBF 核。 线性核：主要用于线性可分的情形，参数少，速度快，对于一般数据，分类效果已经很理想了。 RBF 核：主要用于线性不可分的情形，参数多，分类结果非常依赖于参数。有很多人是通过训练数据的交叉验证来寻找合适的参数，不过这个过程比较耗时。 如果 Feature 的数量很大，跟样本数量差不多，这时候选用线性核的 SVM。 如果 Feature 的数量比较小，样本数量一般，不算大也不算小，选用高斯核的 SVM。</li>
</ul>
</li>
</ul>
</li>
<li><p>   PCA</p>
</li>
<li><p>   Kmeans</p>
<ul>
<li>K-means的基本算法流程：<ol>
<li>初始化$k$个聚类中心$c1,c2,…,ck$</li>
<li>对于每个样本$x_i$和每个聚类中心$c_j$，计算样本与聚类中心之间的距离$d_{ij}$</li>
<li>对于每个样本$x_i$，基于其最小的$d_{ij}$把其分配到第$j$个类$C_j$</li>
<li>对于每个类$C_j$，计算其所有样本的均值作为新的聚类中心，重复步骤2和步骤3直至样本点所属的类不再变化或达到最大迭代次数</li>
</ol>
</li>
</ul>
</li>
<li><p>   L1和L2 regulation</p>
<ul>
<li>从参数W更新，即求梯度的角度来看，</li>
<li>L1是在原来式子上加多了一个$-\eta\frac{\lambda sgn(W)}{n}$</li>
<li>上式可知，当w大于0时，更新的参数w变小；当w小于0时，更新的参数w变大；所以，L1正则化容易使参数变为0，即特征稀疏化。</li>
<li>L2是在原来式子上加多了一个$-\eta\frac{\lambda}{n}W$</li>
<li>上式可知，当w趋向于0时，参数减小的非常缓慢，因此L2正则化使参数减小到很小的范围，但不为0。</li>
<li>L1使权重稀疏，L2使权重平滑，一句话总结就是：L1会趋向于产生少量的特征，而其他的特征都是0，而L2会选择更多的特征，这些特征都会接近于0</li>
</ul>
</li>
</ol>
<h3 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h3><ul>
<li>基础网络<ol>
<li>   VGG<ul>
<li>1*1</li>
<li>多个小卷积代替一个大的卷积</li>
<li>网络更深</li>
</ul>
</li>
<li>   Inception<ul>
<li>网络更宽</li>
<li>让网络自己选择合适的卷积核</li>
</ul>
</li>
<li>   ResNet<ul>
<li><p>解决网络加深时难以训练的问题</p>
</li>
<li><p>skip connection，计算残差</p>
</li>
<li><p>总结：</p>
</li>
<li><p>Inception V1——构建了1x1、3x3、5x5的 conv 和3x3的 pooling 的分支网络，同时使用 MLPConv 和全局平均池化，扩宽卷积层网络宽度，增加了网络对尺度的适应性；</p>
</li>
<li><p>Inception V2——提出了 Batch Normalization，代替 Dropout 和 LRN，其正则化的效果让大型卷积网络的训练速度加快很多倍，同时收敛后的分类准确率也可以得到大幅提高，同时学习 VGG 使用两个3´3的卷积核代替5´5的卷积核，在降低参数量同时提高网络学习能力；</p>
</li>
<li><p>Inception V3——引入了 Factorization，将一个较大的二维卷积拆成两个较小的一维卷积，比如将3´3卷积拆成1´3卷积和3´1卷积，一方面节约了大量参数，加速运算并减轻了过拟合，同时增加了一层非线性扩展模型表达能力，除了在 Inception Module 中使用分支，还在分支中使用了分支（Network In Network In Network）；</p>
</li>
<li><p>Inception V4——研究了 Inception Module 结合 Residual Connection，结合 ResNet 可以极大地加速训练，同时极大提升性能，在构建 Inception-ResNet 网络同时，还设计了一个更深更优化的 Inception v4 模型，能达到相媲美的性能。</p>
</li>
<li><p><a class="link"   href="https://blog.csdn.net/yato0514/article/details/81915800" >原文链接<i class="fas fa-external-link-alt"></i></a></p>
</li>
</ul>
</li>
<li>   1×1卷积的作用<ul>
<li>增加非线性, 实现跨通道的交互和信息整合</li>
<li>进行卷积核通道数的降维和升维</li>
</ul>
</li>
</ol>
</li>
<li>目标检测<ol>
<li>RCNN-series</li>
<li>Yolo-series</li>
<li>   SSD</li>
<li>   目标检测的一些发展趋势</li>
<li>在目标检测算法中，two stage的算法比one stage在检测小物体上更有效，此说法同意吗，为什么？<ul>
<li>基本上同意这个说法。</li>
<li>要说明这个问题主要从感受野的角度去看，one stage的方法，对于SSD，其采取多个特征图进行分类，但由于依赖网络中比较深的层（特征图），感受野很大，因而小物体检测不准确。同样，对于Yolo，由于在方法设计中就把原图分块，即设定了最后用于判断的特征图尺寸，其感受野也很大，因而对小物体判断也不准确。</li>
<li>相对于one stage方法要求同时分离前景和背景以及做出分类，two stage的方法由于proposal的存在可以先用简单的结构分出前景和背景（此时感受野小，特征图分辨率高），再通过深层网络做进一步分类和精修，提高准确率。</li>
<li>one stage的方法也有针对这个问题进行过优化，SSD增加相对不那么深的特征图层作判断，以减小感受野增加分辨率，但层数不深的特征图的判别能力有限，无法大幅增加准确率；Yolo v3增加了FPN，用多尺度特征来判断，增加了对小物体判别能力；RetinaNet也是one stage方法，用了FPN判别，此处对小物体检测更有效，另外其设计了focal loss的训练方式，此方式可认为把two stage中proposal达到的正负样本平衡以修改损失函数的方式达到类似效果，提高了训练效率和整体的准确率。</li>
</ul>
</li>
<li>MAP，mean average precision<ul>
<li><p>Precision &amp; Recall</p>
<ol>
<li>预测为Positive当中真正是Positivede比例<br>  $$Precision &#x3D; \frac{TP}{TP+FP}&#x3D;\frac{TP}{all-detections}$$</li>
<li>实际为Postivie当中被预测为Positive的比例<br>  $$Recall &#x3D; \frac{TP}{TP+FN}&#x3D;\frac{TP}{all-ground-truths}$$</li>
</ol>
</li>
<li><p>mAP的步骤</p>
<ol>
<li>对于某个类别$C$，在某一张图片上，首先计算$C$在一张图片上的$Precision$:</li>
</ol>
<ul>
<li>$$Precision &#x3D; 在一张图片上类别C识别正确的个数（也就是IoU&gt;0.5）&#x2F; 一张图片上类别C的总个数}$$</li>
</ul>
<ol start="2">
<li>依然对于某个类别$C$，可能在多张图片上有该类别，下面计算类别C的AP指数：</li>
</ol>
<ul>
<li>$$AP &#x3D; 每张图片上的Precision求和 &#x2F; 含有类别C的图片数目$$</li>
</ul>
<ol start="3">
<li>对于整个数据集，存在多个类别$C1、C2、C3$：</li>
</ol>
<ul>
<li>$$mAP &#x3D; 上一步计算的所有类别的AP和 &#x2F; 总的类别数目$$</li>
<li>相当于所有类别的AP的平均值</li>
</ul>
</li>
</ul>
</li>
</ol>
</li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步</category>
      </categories>
      <tags>
        <tag>interview</tag>
        <tag>computer vision</tag>
      </tags>
  </entry>
  <entry>
    <title>区块链白皮书与轶事</title>
    <url>/2023/09/04/Web3/%E5%8C%BA%E5%9D%97%E9%93%BE%E8%BD%B6%E4%BA%8B/</url>
    <content><![CDATA[<h2 id="比特币白皮书"><a href="#比特币白皮书" class="headerlink" title="比特币白皮书"></a>比特币白皮书</h2><ul>
<li><a class="link"   href="https://drive.google.com/file/d/1FHAEj23M1Lej80pKD_RBuwDcpcqbFaLK/view?usp=sharing" >比特币白皮书-中文<i class="fas fa-external-link-alt"></i></a></li>
<li></li>
</ul>
<h2 id="以太坊白皮书"><a href="#以太坊白皮书" class="headerlink" title="以太坊白皮书"></a>以太坊白皮书</h2><ul>
<li><a class="link"   href="https://ethereum.org/zh/whitepaper/" >以太坊白皮书-中文<i class="fas fa-external-link-alt"></i></a></li>
</ul>
<h2 id="比特币“冤大头”Laszlo-Hanyecz与披萨的故事"><a href="#比特币“冤大头”Laszlo-Hanyecz与披萨的故事" class="headerlink" title="比特币“冤大头”Laszlo Hanyecz与披萨的故事"></a>比特币“冤大头”Laszlo Hanyecz与披萨的故事</h2><ul>
<li>2010年5月22日，著名比特币“冤大头”Laszlo Hanyecz为表父爱，用1万个比特币给女儿买了两个披萨，披萨价值41美元。这是比特币第一次实现价值转移，也是比特币史上的第一次真实交易。这些比特币如果留到现在，价值约为4.5亿美元。</li>
</ul>
<h2 id="Mt-Gox交易所的故事"><a href="#Mt-Gox交易所的故事" class="headerlink" title="Mt.Gox交易所的故事"></a>Mt.Gox交易所的故事</h2><h2 id="2023-Web3-HK峰会"><a href="#2023-Web3-HK峰会" class="headerlink" title="2023 Web3 HK峰会"></a>2023 Web3 HK峰会</h2><ul>
<li><p>1月份：POW’ER 2023 香港 Web3 创新者峰会（1月9-10日）</p>
<ul>
<li>内容链接：<a class="link"   href="https://www.marsbit.cc/live/24313621" >https://www.marsbit.cc/live/24313621<i class="fas fa-external-link-alt"></i></a></li>
</ul>
</li>
<li><p>4月份：Foresight 2023 HK (4月10日)</p>
<ul>
<li>内容链接：<a class="link"   href="https://as.alltuu.com/album/1455240419/1350344075/" >https://as.alltuu.com/album/1455240419/1350344075/<i class="fas fa-external-link-alt"></i></a> <a class="link"   href="https://foresightnews.pro/event/event2023" >https://foresightnews.pro/event/event2023<i class="fas fa-external-link-alt"></i></a></li>
</ul>
</li>
<li><p>4月份：HK Web3 festival 2023(香港web3嘉年华)（4月12-15日）</p>
<ul>
<li>内容链接：<a class="link"   href="https://group.hashkey.com/cn/newsroom/hong-kong-web3-festival-2023-event-summary" >https://group.hashkey.com/cn/newsroom/hong-kong-web3-festival-2023-event-summary<i class="fas fa-external-link-alt"></i></a></li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步-Web3</category>
      </categories>
      <tags>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title>字符串-编程面试10大常考算法系列(1)</title>
    <url>/2015/01/05/alogrithms/%E5%AD%97%E7%AC%A6%E4%B8%B2-%E7%BC%96%E7%A8%8B%E9%9D%A2%E8%AF%9510%E5%A4%A7%E5%B8%B8%E8%80%83%E7%AE%97%E6%B3%95%E7%B3%BB%E5%88%97-1/</url>
    <content><![CDATA[<h2 id="题语"><a href="#题语" class="headerlink" title="题语"></a>题语</h2><ul>
<li>本文针对Java中字符串的常用操作进行整理，在原转载文章的基础上进行内容的补充。</li>
<li>出自：<a class="link"   href="http://chenyuqing.github.io/2015/01/05/%E7%BC%96%E7%A8%8B%E9%9D%A2%E8%AF%95%E7%9A%8410%E5%A4%A7%E7%AE%97%E6%B3%95%E6%A6%82%E5%BF%B5-%E5%B8%B8%E8%80%83/" >编程面试的10大算法概念-常考<i class="fas fa-external-link-alt"></i></a></li>
</ul>
<h2 id="字符串和数组"><a href="#字符串和数组" class="headerlink" title="字符串和数组"></a>字符串和数组</h2><h3 id="Original"><a href="#Original" class="headerlink" title="Original"></a>Original</h3><ul>
<li>如果IDE没有代码自动补全功能，那么你应该记住下面这些方法：<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 字符串</span></span><br><span class="line">charAt(<span class="type">int</span> x) <span class="comment">// 获得某个索引处的字符</span></span><br><span class="line">length() <span class="comment">// 字符串长度</span></span><br><span class="line">toCharArray() <span class="comment">// 获得字符串对应的char数组</span></span><br><span class="line"><span class="comment">// 数组</span></span><br><span class="line">length <span class="comment">// 数组大小</span></span><br><span class="line">Arrays.sort()  <span class="comment">// 数组排序</span></span><br><span class="line">Arrays.toString(<span class="type">char</span>[] a) <span class="comment">// 数组转成字符串</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="charAt-int-x"><a href="#charAt-int-x" class="headerlink" title="charAt(int x)"></a>charAt(int x)</h4><ul>
<li>它是属于字符串的方法，功能是根据字符串的下标(从0开始)取出当前的字符。</li>
<li>源代码：<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="type">char</span> <span class="title function_">charAt</span><span class="params">(<span class="type">int</span> index)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> ((index &lt; <span class="number">0</span>) || (index &gt;= value.length)) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">StringIndexOutOfBoundsException</span>(index);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> value[index];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>它的思路是：首先根据判断输入的下标是否合法，然后直接取value[index]，其中value是String类中的一个字符数组，它就是为了把字符串转为字符数组而设的。</li>
</ul>
<h4 id="length"><a href="#length" class="headerlink" title="length()"></a>length()</h4><ul>
<li>它是属于字符串的方法，功能是返回字符串的长度。</li>
<li>源代码：<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">length</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> value.length;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>不必多说，参考上文。</li>
</ul>
<h4 id="toCharArray"><a href="#toCharArray" class="headerlink" title="toCharArray()"></a>toCharArray()</h4><ul>
<li>它是属于字符串的方法，功能是把字符串转换成字符串数组。</li>
<li>源代码：<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Converts this string to a new character array.</span></span><br><span class="line"><span class="comment">  *</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span>  a newly allocated character array whose length is the length</span></span><br><span class="line"><span class="comment">  *          of this string and whose contents are initialized to contain</span></span><br><span class="line"><span class="comment">  *          the character sequence represented by this string.</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="keyword">public</span> <span class="type">char</span>[] toCharArray() &#123;</span><br><span class="line">     <span class="comment">// Cannot use Arrays.copyOf because of class initialization order issues</span></span><br><span class="line">     <span class="type">char</span> result[] = <span class="keyword">new</span> <span class="title class_">char</span>[value.length];</span><br><span class="line">     System.arraycopy(value, <span class="number">0</span>, result, <span class="number">0</span>, value.length);</span><br><span class="line">     <span class="keyword">return</span> result;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></li>
<li>它的思路是：先创建一个和原字符串长度一样的字符数组result[]，然后通过系统的arraycopy()方法把原字符串的每一个字符对应的复制到字符数组中。其中value是String类中的一个字符数组，它就是为了把字符串转为字符数组而设的，但为什么我们不直接返回value字符数组呢？因为value是private的，不可被调用。</li>
<li>自己实现：<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// toCharArraySelf</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="type">char</span>[] toCharArraySelf(String origin) &#123;</span><br><span class="line">	<span class="type">char</span>[] result = <span class="keyword">new</span> <span class="title class_">char</span>[origin.length()];</span><br><span class="line">	<span class="keyword">for</span>(<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; origin.length(); i++) &#123;</span><br><span class="line">		<span class="comment">// System.out.println(&quot;origin.index()&quot; +origin.charAt(i));</span></span><br><span class="line">		result[i] = (<span class="type">char</span>)origin.charAt(i);</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="length-1"><a href="#length-1" class="headerlink" title="length"></a>length</h4><ul>
<li>它是属于数组的一个属性，记录着数组的长度。</li>
</ul>
<h4 id="Arrays-sort"><a href="#Arrays-sort" class="headerlink" title="Arrays.sort()"></a>Arrays.sort()</h4><ul>
<li>Arrays是Java的一个工具包，专门针对数组的操作。sort()方法是数组的排序，传入的参数是一个数组，然后把数组进行排序后返回。</li>
<li>源代码：<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">sort</span><span class="params">(<span class="type">char</span>[] a)</span> &#123;</span><br><span class="line">    DualPivotQuicksort.sort(a);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>可以看到Java7中Arrays调用的是双基准快速排序算法(DualPivotQuicksort)。有兴趣的自行研究：<a class="link"   href="http://algs4.cs.princeton.edu/23quicksort/QuickDualPivot.java.html" >QuickDualPivot.java<i class="fas fa-external-link-alt"></i></a></li>
</ul>
<h4 id="Arrays-toString-char-a"><a href="#Arrays-toString-char-a" class="headerlink" title="Arrays.toString(char[] a)"></a>Arrays.toString(char[] a)</h4><ul>
<li>它是属于Arrays工具包的一个方法，功能刚好是把数组转化为字符串。</li>
<li>源代码：<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title function_">toString</span><span class="params">(<span class="type">char</span>[] a)</span> &#123;</span><br><span class="line">       <span class="keyword">if</span> (a == <span class="literal">null</span>)</span><br><span class="line">           <span class="keyword">return</span> <span class="string">&quot;null&quot;</span>;</span><br><span class="line">       <span class="type">int</span> <span class="variable">iMax</span> <span class="operator">=</span> a.length - <span class="number">1</span>;</span><br><span class="line">       <span class="keyword">if</span> (iMax == -<span class="number">1</span>)</span><br><span class="line">           <span class="keyword">return</span> <span class="string">&quot;[]&quot;</span>;</span><br><span class="line"></span><br><span class="line">       <span class="type">StringBuilder</span> <span class="variable">b</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StringBuilder</span>();</span><br><span class="line">       b.append(<span class="string">&#x27;[&#x27;</span>);</span><br><span class="line">       <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; ; i++) &#123;</span><br><span class="line">           b.append(a[i]);</span><br><span class="line">           <span class="keyword">if</span> (i == iMax)</span><br><span class="line">               <span class="keyword">return</span> b.append(<span class="string">&#x27;]&#x27;</span>).toString();</span><br><span class="line">           b.append(<span class="string">&quot;, &quot;</span>);</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="后话"><a href="#后话" class="headerlink" title="后话"></a>后话</h2>]]></content>
      <categories>
        <category>技能-修行-进步</category>
      </categories>
      <tags>
        <tag>字符串操作</tag>
      </tags>
  </entry>
  <entry>
    <title>数据挖掘-Aprior-Algorithm</title>
    <url>/2014/11/04/alogrithms/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-Aprior-Algorithm/</url>
    <content><![CDATA[<h1 id="写在前面的话"><a href="#写在前面的话" class="headerlink" title="写在前面的话"></a>写在前面的话</h1><ul>
<li>Aprior Algorithm(先验算法)，它是我在数据挖掘这门课学的第一个算法，由于当时觉得数据挖掘是一门很深奥的学科，所以在学习之前就对它心怀敬畏之心，学起来压力也是很大。不过后来弄懂了之后觉得理解思路也不是很难。</li>
</ul>
<h1 id="Aprior-Algorithm"><a href="#Aprior-Algorithm" class="headerlink" title="Aprior Algorithm"></a>Aprior Algorithm</h1><h2 id="算法背景"><a href="#算法背景" class="headerlink" title="算法背景"></a>算法背景</h2><ul>
<li>Aprior Algorithm是布尔关联规则里的一项基本算法，它是由<a class="link"   href="http://rakesh.agrawal-family.com/papers/vldb94apriori.pdf" >Rakesh Agrawal和Ramakrishnan Srikant<i class="fas fa-external-link-alt"></i></a>两位博士在1994年提出的。所谓关联，反映的是一个事件和其他事件之间的依赖或相关程度，它包括事件之间的频繁模式、相关性或因果结构，在数据挖掘中它通常也被称为“购物篮分析”(Market Basket analysis)。</li>
<li>关于“购物篮分析”还有一个很有名的故事：美国的妈妈经常叫丈夫到超市帮孩子买尿布，而作为一个男人，由于心理作用，他们觉得自己只是买了尿布就往家提总感觉有点别扭，所以在超市他们顺便提上啤酒这种看上去比较狼性的商品。这一有趣的现象慢慢被超市经理发现了，后来超市就在尿布的旁边摆上了啤酒，这样就省得丈夫们走来走去，可以随手一提就是自己想要的2样东西，结果超市的尿布和啤酒都大卖了。</li>
</ul>
<h2 id="算法原理"><a href="#算法原理" class="headerlink" title="算法原理"></a>算法原理</h2><h3 id="Aprior的基本思想"><a href="#Aprior的基本思想" class="headerlink" title="Aprior的基本思想"></a>Aprior的基本思想</h3><ul>
<li><strong>频繁项集的任何子集也一定是频繁的。</strong></li>
</ul>
<h3 id="基本概念和定义"><a href="#基本概念和定义" class="headerlink" title="基本概念和定义"></a>基本概念和定义</h3><ul>
<li>资料库(Transaction Database):存储着二维结构的记录集。定义为：D</li>
<li>所有项集(Items):所有项目的集合。定义为：I</li>
<li>记录(Transaction):资料库里的子集。定义为：T (T ∈ D)</li>
<li>项集(Itemset)：同时出现的项的集合。定义为：k-itemset(k项集)</li>
<li>支持度(Suppor)：定义为supp(X) &#x3D; occur(x) &#x2F; count(D) &#x3D; P(X)</li>
<li>置信度(Confidence):定义为conf(A-&gt;B) &#x3D; supp(A∪B)&#x2F;supp(A) &#x3D; P(B|A)</li>
</ul>
<h3 id="算法步骤："><a href="#算法步骤：" class="headerlink" title="算法步骤："></a>算法步骤：</h3><ul>
<li>Aprior Algorithm算法分2步进行：<ul>
<li>扫描数据库，累计每个项的计数，找出所有频繁数据项集，即找出所有支持度超过指定阈值的数据项集。</li>
<li>利用频繁数据项集，生成候选的关联规则，并验证其可信度。如果可信度超过指定阈值，则该候选关联规则为要找的关联规则。</li>
</ul>
</li>
</ul>
<h2 id="算法应用"><a href="#算法应用" class="headerlink" title="算法应用"></a>算法应用</h2><ul>
<li>例子：以下为AllElectronics的事务数据库D。该数据库有9个事务，即|D|&#x3D;9。<center>![](/img/DM_algo_junior/apriori/01_allElectronics.PNG)</center>

<ul>
<li>(1).在算法的第一次迭代时，每个项都是候选1项集的集合C1的成员。算法简单地扫描所有的事务，对每个项的出现次数进行计数。</li>
<li>(2).假设最小支持度计数为2，即min_sup &#x3D; 2，可以确定频繁1项集的集合L1.它由满足最小支持度的候选1项集组成。在我们的例子中，C1中的所有候选都满足最小支持度。</li>
<li>(3).为了发现频繁2项集的集合L2，算法使用连接L1∞L1产生候选2项集的集合C2.然后进行剪枝，在本例中，没有候选从C2中删除，因为这些候选的每个子集也是频繁的。</li>
<li>(4).扫描D中事务，累计C2中的每个候选项集的支持计数。</li>
<li>(5).然后，确定频繁2项集的集合L2，它由C2中满足最小支持度的候选2项集组成。</li>
<li>(6).如此循环，直到找出所有的频繁项集。</li>
</ul>
</li>
</ul>
<center>![找频繁项集](/img/DM_algo_junior/apriori/02_steps.PNG)</center>
<center>![剪枝过程](/img/DM_algo_junior/apriori/03_steps.PNG)</center>

<ul>
<li>算法的伪代码：<center>![伪代码1](/img/DM_algo_junior/apriori/04_psude_code.PNG)</center>
<center>![伪代码2](/img/DM_algo_junior/apriori/05_psude_code.PNG)</center></li>
</ul>
<h2 id="算法的不足与改进"><a href="#算法的不足与改进" class="headerlink" title="算法的不足与改进"></a>算法的不足与改进</h2><h3 id="算法的不足"><a href="#算法的不足" class="headerlink" title="算法的不足"></a>算法的不足</h3><ul>
<li>可能产生大量的候选集，没有排除不应该参与组合的元素</li>
<li>需要重复扫描数据库，因此如果挖掘数据仓库数据量很大，应用此算法每次迭代产生候选项集用来统计其支持度就需要花费很多时间，而这种代价是随着数据的记录数的增加呈现几何级数的增加。</li>
</ul>
<h3 id="算法的改进"><a href="#算法的改进" class="headerlink" title="算法的改进"></a>算法的改进</h3><ul>
<li>基于散列的技术</li>
<li>事务压缩</li>
<li>划分</li>
<li>抽样</li>
<li>动态项集计数</li>
<li><a class="link"   href="http://tim4chan.com/" >FP-growth tree<i class="fas fa-external-link-alt"></i></a></li>
</ul>
<h1 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h1><ul>
<li><p>后记我想首先叹一声：我的妈( ⊙ o ⊙ )啊！原来写一篇这样的算法总结是那么的累！！！我真的是累趴了！！！请叫我大四狗！</p>
</li>
<li><p>本次博文真所谓是我经历千辛万苦的心血，边写边哭，那资料东找西找，各种躁动，思路不断短路，终于还是OK的完成了。其实我想说，我太渣了。</p>
</li>
<li><p>还有一点，我发现我越来越喜欢抄教材的内容了。</p>
</li>
<li><p>参考链接<a class="link"   href="http://zh.wikipedia.org/wiki/%E5%85%88%E9%AA%8C%E7%AE%97%E6%B3%95" >wikipedia<i class="fas fa-external-link-alt"></i></a></p>
</li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步</category>
      </categories>
      <tags>
        <tag>Aprior Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title>认识塔罗牌</title>
    <url>/2024/03/01/taro_cards/00_%E8%AE%A4%E8%AF%86%E5%A1%94%E7%BD%97%E7%89%8C/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>技能-修行-塔罗</category>
      </categories>
      <tags>
        <tag>塔罗牌</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux_develop_C-我的第一篇博客</title>
    <url>/2012/06/27/%E5%B0%8F%E8%80%8C%E7%BE%8E-%E5%B7%A5%E5%85%B7/Linux-develop-C/</url>
    <content><![CDATA[<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><h3 id="在linux下编写C程序，必须要学会Vi编辑器的使用"><a href="#在linux下编写C程序，必须要学会Vi编辑器的使用" class="headerlink" title="在linux下编写C程序，必须要学会Vi编辑器的使用"></a>在linux下编写C程序，必须要学会Vi编辑器的使用</h3><ul>
<li>我的linux界面：<br><img src="/img/linux_C/01.jpg"></li>
</ul>
<h3 id="桌面单击右键，选择终端打开"><a href="#桌面单击右键，选择终端打开" class="headerlink" title="桌面单击右键，选择终端打开"></a>桌面单击右键，选择终端打开</h3><p><img src="/img/linux_C/02.jpg"></p>
<h3 id="便可进入终端界面"><a href="#便可进入终端界面" class="headerlink" title="便可进入终端界面"></a>便可进入终端界面</h3><p><img src="/img/linux_C/03.jpg"></p>
<h3 id="输入vi，便可以查看vi的版本信息，同时进入vi编辑器"><a href="#输入vi，便可以查看vi的版本信息，同时进入vi编辑器" class="headerlink" title="输入vi，便可以查看vi的版本信息，同时进入vi编辑器"></a>输入vi，便可以查看vi的版本信息，同时进入vi编辑器</h3><p><img src="/img/linux_C/04.jpg"><br><img src="/img/linux_C/05.jpg"></p>
<h3 id="因为当前文件未命名，故在编辑完成后无法保存，我们重新回到开始界面"><a href="#因为当前文件未命名，故在编辑完成后无法保存，我们重新回到开始界面" class="headerlink" title="因为当前文件未命名，故在编辑完成后无法保存，我们重新回到开始界面"></a>因为当前文件未命名，故在编辑完成后无法保存，我们重新回到开始界面</h3><p><img src="/img/linux_C/06.jpg"></p>
<h3 id="输入vi-a-c-，然后回车（表明进入vi编辑器的同时创建一个文件名为a-c的新文件）"><a href="#输入vi-a-c-，然后回车（表明进入vi编辑器的同时创建一个文件名为a-c的新文件）" class="headerlink" title="输入vi a.c ，然后回车（表明进入vi编辑器的同时创建一个文件名为a.c的新文件）"></a>输入vi a.c ，然后回车（表明进入vi编辑器的同时创建一个文件名为a.c的新文件）</h3><p><img src="/img/linux_C/07.jpg"></p>
<h3 id="输入i进入插入模式，左下角会出现“插入”2字（否则不能进行编辑）："><a href="#输入i进入插入模式，左下角会出现“插入”2字（否则不能进行编辑）：" class="headerlink" title="输入i进入插入模式，左下角会出现“插入”2字（否则不能进行编辑）："></a>输入i进入插入模式，左下角会出现“插入”2字（否则不能进行编辑）：</h3><p><img src="/img/linux_C/08.jpg"></p>
<h3 id="然后敲代码，例如："><a href="#然后敲代码，例如：" class="headerlink" title="然后敲代码，例如："></a>然后敲代码，例如：</h3><p><img src="/img/linux_C/09.jpg"></p>
<h3 id="代码输入完毕后，按esc键进入命令模式（左下角的“插入”2字会消失）："><a href="#代码输入完毕后，按esc键进入命令模式（左下角的“插入”2字会消失）：" class="headerlink" title="代码输入完毕后，按esc键进入命令模式（左下角的“插入”2字会消失）："></a>代码输入完毕后，按esc键进入命令模式（左下角的“插入”2字会消失）：</h3><p><img src="/img/linux_C/10.jpg"></p>
<h3 id="此时输入冒号”-”-接着可以输入2种命令（2选1）wq（保存，退出）；q-退出不保存-。"><a href="#此时输入冒号”-”-接着可以输入2种命令（2选1）wq（保存，退出）；q-退出不保存-。" class="headerlink" title="此时输入冒号”:”,接着可以输入2种命令（2选1）wq（保存，退出）；q!(退出不保存)。"></a>此时输入冒号”:”,接着可以输入2种命令（2选1）wq（保存，退出）；q!(退出不保存)。</h3><ul>
<li>因为我们输入的是”:wq”，即保存并退出。<br><img src="/img/linux_C/11.jpg"></li>
</ul>
<h3 id="按回车键后便回到开始界面，且在桌面上生成了a-c的文件"><a href="#按回车键后便回到开始界面，且在桌面上生成了a-c的文件" class="headerlink" title="按回车键后便回到开始界面，且在桌面上生成了a.c的文件"></a>按回车键后便回到开始界面，且在桌面上生成了a.c的文件</h3><p><img src="/img/linux_C/12.jpg"></p>
<h3 id="编译C程序"><a href="#编译C程序" class="headerlink" title="编译C程序"></a>编译C程序</h3><ul>
<li>编译C程序需要gcc编译器，我们可以输入gcc -v查看当前系统的gcc编译器信息<br><img src="/img/linux_C/13.jpg">   </li>
<li>ok，一切正常，可以对a.c文件进行编译了，接着输入gcc a.c,若什么也不提示，恭喜你编译成功了，且在桌面上生成了一个a.out文件。<br><img src="/img/linux_C/14.jpg"></li>
</ul>
<h3 id="运行a-c文件"><a href="#运行a-c文件" class="headerlink" title="运行a.c文件"></a>运行a.c文件</h3><ul>
<li>在终端输入.&#x2F;a.c点（不可漏），反斜杠，加文件名)，回车键后便可以看到结果：<br><img src="/img/linux_C/15.jpg"></li>
</ul>
<pre><code class="bash"> I love u！！！
</code></pre>
<ul>
<li>以上就是在Linux下编写C程序的简单步骤。希望能帮到你！Thanks for your reading !谢谢！！！</li>
</ul>
]]></content>
      <categories>
        <category>小而美-工具</category>
      </categories>
      <tags>
        <tag>C开发</tag>
      </tags>
  </entry>
  <entry>
    <title>排序算法总结</title>
    <url>/2017/05/06/alogrithms/sort-algorithms/</url>
    <content><![CDATA[<ul>
<li>排序算法是一个非常重要而且在日常生活中最常用的一种算法之一。面试官往往也是会常考的题目。所以，以下对排序算法做一下总结，而且排序顺序都是由小到大。</li>
</ul>
<h2 id="冒泡排序-Bubble-Sort"><a href="#冒泡排序-Bubble-Sort" class="headerlink" title="冒泡排序(Bubble Sort)"></a>冒泡排序(Bubble Sort)</h2><ul>
<li>核心思想：按从小到大的排序，前面一个数和后面一个数比较，大的永远靠后，每次可以确定一个最大的数排到了最后，然后下次比较就可以忽略这个排好的数。</li>
<li>伪代码<pre>
<code>
do
  swapped = false
  for i = 1 to indexOfLastUnsortedElement
      if leftElement > rightElement
          swap(leftElement, rightElement)
          swap = true</li>
</ul>
<p>while swapped<br></code><br></pre></p>
<ul>
<li>GIF process<img src="/img/sort_algorithms/bubble_sort.gif" class="[class names]" title="[Bubble sort process [https:&#x2F;&#x2F;visualgo.net&#x2F;en&#x2F;sorting]]"></li>
<li>Python code<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">bubbleSort</span>(<span class="params">alist</span>):  </span><br><span class="line">    <span class="keyword">for</span> passnum <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(alist)-<span class="number">1</span>,<span class="number">0</span>,-<span class="number">1</span>):  </span><br><span class="line">        <span class="comment">#print alist,passnum  </span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(passnum):  </span><br><span class="line">            <span class="keyword">if</span> alist[i]&gt;alist[i+<span class="number">1</span>]:  </span><br><span class="line">                temp = alist[i]  </span><br><span class="line">                alist[i] = alist[i+<span class="number">1</span>]  </span><br><span class="line">                alist[i+<span class="number">1</span>] = temp  </span><br><span class="line">    <span class="keyword">return</span> alist</span><br><span class="line"></span><br><span class="line">alist = [<span class="number">54</span>,<span class="number">26</span>,<span class="number">93</span>,<span class="number">17</span>,<span class="number">77</span>,<span class="number">31</span>,<span class="number">44</span>,<span class="number">55</span>,<span class="number">20</span>]  </span><br><span class="line"><span class="built_in">print</span>(bubbleSort(alist))</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="选择排序-Select-Sort"><a href="#选择排序-Select-Sort" class="headerlink" title="选择排序(Select Sort)"></a>选择排序(Select Sort)</h2><ul>
<li>核心思想：从左往右，设还没排序的数中的第一个数为最小的数(minimum)，并且记住最小数(minimum)的下标(index)，然后和它后面的所有数进行比较，如果发现有更小的数，就更新下标，比完一轮之后，如果下标有改变，就把下标位置上的数和第一个数进行交换，那么这个数就是已排序的了，往下移一个位置继续以上的动作，直到最后要给数为止。</li>
<li>伪代码<pre>
<code>
repeat (numOfElements - 1) times
set the first unsorted element as the minimum
for each of the unsorted elements
  if element < currentMinimum
    set element as new minimum
swap minimum with first unsorted position
</code>
</pre></li>
<li>GIF proce<img src="/img/sort_algorithms/select_sort.gif" class="[class names]" title="[Select sort process [https:&#x2F;&#x2F;visualgo.net&#x2F;en&#x2F;sorting]]"></li>
<li>Python code<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">selectionSort</span>(<span class="params">alist</span>):  </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(alist)-<span class="number">1</span>):  </span><br><span class="line">        minimun = i</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i, <span class="built_in">len</span>(alist)):</span><br><span class="line">            <span class="keyword">if</span> alist[j]&lt;alist[minimun]:  </span><br><span class="line">                minimun = j  </span><br><span class="line">        temp = alist[i]   </span><br><span class="line">        alist[i] = alist[minimun]  </span><br><span class="line">        alist[minimun] = temp   </span><br><span class="line">    <span class="keyword">return</span> alist</span><br><span class="line"></span><br><span class="line">alist = [<span class="number">54</span>,<span class="number">26</span>,<span class="number">93</span>,<span class="number">17</span>,<span class="number">77</span>,<span class="number">31</span>,<span class="number">44</span>,<span class="number">55</span>,<span class="number">20</span>]  </span><br><span class="line"><span class="built_in">print</span>(selectionSort(alist))</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="快速排序-Quick-sort"><a href="#快速排序-Quick-sort" class="headerlink" title="快速排序(Quick sort)"></a>快速排序(Quick sort)</h2><ul>
<li>核心思想：<ul>
<li>选定一个<strong>基准值(pivot)</strong></li>
<li>将比<strong>基准值(pivot)<strong>小的数移到它的左边，形成</strong>左子序列</strong></li>
<li>将比<strong>基准值(pivot)<strong>大的数移到它的右边，形成</strong>右子序列</strong></li>
<li>分别对<strong>左子序列</strong>、<strong>右子序列</strong>作上述三个步骤,直到<strong>左子序列</strong>和<strong>右子序列</strong>都只剩一个数为止&#x3D;&#x3D;》 递归(Recursive)</li>
</ul>
</li>
<li>伪代码：<pre><code>
for each (unsorted) partition
set first element as pivot
storeIndex = pivotIndex + 1
for i = pivotIndex + 1 to rightmostIndex
  if element[i] < element[pivot]
    swap(i, storeIndex); storeIndex++
swap(pivot, storeIndex - 1)
</code></pre></li>
<li>GIF process<img src="/img/sort_algorithms/quick_sort.gif" class="[class names]" title="[Quick sort process [https:&#x2F;&#x2F;visualgo.net&#x2F;en&#x2F;sorting]]"></li>
<li>Python code<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">quickSort</span>(<span class="params">arr, left, right</span>):</span><br><span class="line">    <span class="comment"># 只有left &lt; right 排序</span></span><br><span class="line">    <span class="keyword">if</span> left &lt; right:</span><br><span class="line">        pivot_index = partition(arr, left, right)</span><br><span class="line">        quickSort(arr, left, pivot_index - <span class="number">1</span>)</span><br><span class="line">        quickSort(arr, pivot_index + <span class="number">1</span>, right)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">partition</span>(<span class="params">arr, left, right</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;找到基准位置, 并返回&quot;&quot;&quot;</span></span><br><span class="line">    pivot_index = left</span><br><span class="line">    pivot = arr[left]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(left + <span class="number">1</span>, right + <span class="number">1</span>):</span><br><span class="line">        <span class="keyword">if</span> arr[i] &lt; pivot:</span><br><span class="line">            <span class="comment"># 如果此处索引的值小于基准值, 基准值的位置后移一位</span></span><br><span class="line">            <span class="comment"># 并将后移一位的值和这个值交换, 让基准位置及之前的始终小于基准值</span></span><br><span class="line">            pivot_index += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> pivot_index != i:</span><br><span class="line">                arr[pivot_index], arr[i] = arr[i], arr[pivot_index]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将基准值移动到正确的位置</span></span><br><span class="line">    arr[left], arr[pivot_index] = arr[pivot_index], arr[left]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> pivot_index</span><br><span class="line"></span><br><span class="line">alist = [<span class="number">54</span>,<span class="number">26</span>,<span class="number">93</span>,<span class="number">17</span>,<span class="number">77</span>,<span class="number">31</span>,<span class="number">44</span>,<span class="number">55</span>,<span class="number">20</span>] </span><br><span class="line">quickSort(alist, <span class="number">0</span>, <span class="built_in">len</span>(alist)-<span class="number">1</span>) </span><br><span class="line"><span class="built_in">print</span>(alist)</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="插入排序-Insert-sort"><a href="#插入排序-Insert-sort" class="headerlink" title="插入排序(Insert sort)"></a>插入排序(Insert sort)</h2><ul>
<li>核心思想：在已排序的数中插入一个未排序的数。</li>
<li>伪代码<pre><code>
mark first element as sorted
for each unsorted element
'extract' the element
for i = lastSortedIndex to 0
  if currentSortedElement > extractedElement
    move sorted element to the right by 1
  else: insert extracted element
</code></pre></li>
<li>GIF process<img src="/img/sort_algorithms/insert_sort.gif" class="[class names]" title="[Insert sort process [https:&#x2F;&#x2F;visualgo.net&#x2F;en&#x2F;sorting]]"></li>
<li>Python code<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">insertSort</span>(<span class="params">a</span>):  </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(a)-<span class="number">1</span>):  </span><br><span class="line">        <span class="comment">#print a,i    </span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i+<span class="number">1</span>,<span class="built_in">len</span>(a)):  </span><br><span class="line">            <span class="keyword">if</span> a[i]&gt;a[j]:  </span><br><span class="line">                temp = a[i]  </span><br><span class="line">                a[i] = a[j]  </span><br><span class="line">                a[j] = temp  </span><br><span class="line">    <span class="keyword">return</span> a</span><br><span class="line">alist = [<span class="number">54</span>,<span class="number">26</span>,<span class="number">93</span>,<span class="number">17</span>,<span class="number">77</span>,<span class="number">31</span>,<span class="number">44</span>,<span class="number">55</span>,<span class="number">20</span>]  </span><br><span class="line"><span class="built_in">print</span>(insertSort(alist))</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="归并排序"><a href="#归并排序" class="headerlink" title="归并排序"></a>归并排序</h2><ul>
<li>核心思想：把原始数组分成若干子数组,对每一个子数组进行排序,<br>继续把子数组与子数组合并,合并后仍然有序,直到全部合并完,形成有序的数组</li>
<li>伪代码：<pre><code>
split each element into partitions of size 1
recursively merge adjancent partitions
  for i = leftPartStartIndex to rightPartLastIndex
  inclusive
      if leftPartHeadValue <= rightPartHeadValue
          copy leftPartHeadValue
      else: copy rightPartHeadValue</li>
</ul>
<p>copy elements back to original array<br></code></pre></p>
<ul>
<li>GIF process</li>
<li><img src="/img/sort_algorithms/merge_sort.gif" class="[class names]" title="[Merge sort process [https:&#x2F;&#x2F;visualgo.net&#x2F;en&#x2F;sorting]]"></li>
<li>Python code<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">mergesort</span>(<span class="params">seq</span>):  </span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(seq)&lt;=<span class="number">1</span>:  </span><br><span class="line">        <span class="keyword">return</span> seq  </span><br><span class="line">    mid=<span class="built_in">int</span>(<span class="built_in">len</span>(seq)/<span class="number">2</span>)  </span><br><span class="line">    left=mergesort(seq[:mid])  </span><br><span class="line">    right=mergesort(seq[mid:])  </span><br><span class="line">    <span class="keyword">return</span> merge(left,right)  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">merge</span>(<span class="params">left,right</span>):  </span><br><span class="line">    result=[]  </span><br><span class="line">    i,j=<span class="number">0</span>,<span class="number">0</span>  </span><br><span class="line">    <span class="keyword">while</span> i&lt;<span class="built_in">len</span>(left) <span class="keyword">and</span> j&lt;<span class="built_in">len</span>(right):  </span><br><span class="line">        <span class="keyword">if</span> left[i]&lt;=right[j]:  </span><br><span class="line">            result.append(left[i])  </span><br><span class="line">            i+=<span class="number">1</span>  </span><br><span class="line">        <span class="keyword">else</span>:  </span><br><span class="line">            result.append(right[j])  </span><br><span class="line">            j+=<span class="number">1</span>  </span><br><span class="line">    result+=left[i:]  </span><br><span class="line">    result+=right[j:]  </span><br><span class="line">    <span class="keyword">return</span> result     </span><br><span class="line"></span><br><span class="line">alist = [<span class="number">54</span>,<span class="number">26</span>,<span class="number">93</span>,<span class="number">17</span>,<span class="number">77</span>,<span class="number">31</span>,<span class="number">44</span>,<span class="number">55</span>,<span class="number">20</span>] </span><br><span class="line"><span class="built_in">print</span>(mergesort(alist))</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul>
<li><a class="link"   href="http://notepad.yehyeh.net/Content/Algorithm/Sort/Quick/Quick.php" >http://notepad.yehyeh.net/Content/Algorithm/Sort/Quick/Quick.php<i class="fas fa-external-link-alt"></i></a></li>
<li><a class="link"   href="https://visualgo.net/en/sorting" >https://visualgo.net/en/sorting<i class="fas fa-external-link-alt"></i></a></li>
<li><a class="link"   href="http://www.jianshu.com/p/7ffa04799ab2" >http://www.jianshu.com/p/7ffa04799ab2<i class="fas fa-external-link-alt"></i></a></li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步</category>
      </categories>
      <tags>
        <tag>排序</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>conda docker git vim ssr</title>
    <url>/2023/06/12/%E5%B0%8F%E8%80%8C%E7%BE%8E-%E5%B7%A5%E5%85%B7/conda_docker_git_vim/</url>
    <content><![CDATA[<h1 id="自建ssr服务器"><a href="#自建ssr服务器" class="headerlink" title="自建ssr服务器"></a>自建ssr服务器</h1><ul>
<li><a class="link"   href="https://github.com/Alvin9999/new-pac/wiki/%E8%87%AA%E5%BB%BAss%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%99%E7%A8%8B" >https://github.com/Alvin9999/new-pac/wiki/%E8%87%AA%E5%BB%BAss%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%99%E7%A8%8B<i class="fas fa-external-link-alt"></i></a></li>
</ul>
<h1 id="conda的使用笔记"><a href="#conda的使用笔记" class="headerlink" title="conda的使用笔记"></a>conda的使用笔记</h1><ol>
<li>创建环境conda create -n name python&#x3D;3.8</li>
<li>激活环境conda activate name</li>
<li>关闭环境conda deactivate</li>
<li>查看当前环境conda env –list</li>
<li>查看前期环境中pip列表pip list</li>
<li>查看指定pip包的安装pip list | grep packagename</li>
<li>删除环境conda remove -n name –all</li>
<li>克隆环境conda create -n BBB –clone AAA，B是A的克隆</li>
<li>转移环境<ol>
<li>conda转移：conda env export &gt; name.yaml,然后新系统下执行conda env create -f name.yaml</li>
<li>pip转移：pip freeze &gt; requirements.txt,然后新系统下pip install -r requirements.txt</li>
</ol>
</li>
</ol>
<h1 id="docker的使用笔记，轻量化虚拟技术"><a href="#docker的使用笔记，轻量化虚拟技术" class="headerlink" title="docker的使用笔记，轻量化虚拟技术"></a>docker的使用笔记，轻量化虚拟技术</h1><ol start="0">
<li><p>缺点：争抢资源，权限过高；优点：可移植性高，环境封闭</p>
</li>
<li><p>基础概念：dockfile，images，container, volume</p>
<ol>
<li>dockfile：docker的配置文件</li>
<li>image：docker的镜像文件，用来创建container的母本</li>
<li>container：俗称容器，docker最终落地的形态，是一个运行程序的隔离环境。</li>
<li>volume：数据卷，</li>
</ol>
</li>
<li><p>dockerfile常见的命令(大写形式)：</p>
<ol>
<li>FROM：</li>
<li>WORKDIR：</li>
<li>COPY</li>
<li>RUN</li>
<li>CMD</li>
</ol>
</li>
<li><p>docker 常见命令</p>
<ol>
<li>docker create</li>
<li>docker ps -aq，查看所有的容器</li>
<li>docker images -q，查看所有的镜像</li>
<li>docker build</li>
<li>docker run -p -v<ol>
<li>数据和命令，通过映射的方式在宿主和容器之间进行传递，其中-p表示port，端口，-v表示volume，卷。 -d,daemon，在后台运行。–name，表示名字<figure class="highlight docker"><table><tr><td class="code"><pre><span class="line">docker <span class="keyword">run</span><span class="language-bash"> -d --name music -p 264:264 -v /opt/musciplayer:/var/www/html/cache/music-player-docker</span></span><br></pre></td></tr></table></figure></li>
<li>例子：通过冒号作为宿主和容器之间的分隔符!<figure class="highlight docker"><table><tr><td class="code"><pre><span class="line">宿主 : 容器</span><br></pre></td></tr></table></figure></li>
<li></li>
</ol>
</li>
<li>docker stop <container id>，停止指定容器，docker stop $(docker ps -aq)，停止所有容器</li>
<li>docker restart <container id></li>
<li>docker rm <container id>，删除指定容器，docker rm $(docker ps -aq)，删除所有容器</li>
<li>docker rmi <container id>，删除指定镜像，docker rmi $(docker images -q)，删除所有镜像</li>
<li>docker exec -it <container id> &#x2F;bin&#x2F;bash</li>
<li>docker volume create </li>
<li>docker cp <container id>:&#x2F;opt&#x2F;file.txt &#x2F;opt&#x2F;local&#x2F;</li>
<li>docker cp &#x2F;opt&#x2F;local&#x2F;file.txt <container id>:&#x2F;opt&#x2F;</li>
<li>docker有了专门清理资源(container、image、网络)的命令，docker system prune</li>
<li>docker image prune –force –all 或者docker image prune -f -a 删除所有不使用的镜像</li>
<li>docker container prune -f 删除所有停止的容器</li>
</ol>
</li>
<li><p>docker compose</p>
<ol>
<li>docker compose up</li>
<li>docker compose down</li>
</ol>
</li>
</ol>
<h1 id="git的使用笔记"><a href="#git的使用笔记" class="headerlink" title="git的使用笔记"></a>git的使用笔记</h1><h1 id="vim的使用笔记"><a href="#vim的使用笔记" class="headerlink" title="vim的使用笔记"></a>vim的使用笔记</h1><h1 id="ssh知识和问题集"><a href="#ssh知识和问题集" class="headerlink" title="ssh知识和问题集"></a>ssh知识和问题集</h1><ol>
<li><p>ssh连接发生错误信息：kex_exchange_identification: Connection closed by remote host</p>
<ul>
<li>解决方法：可能是认证的key失效了，进入~&#x2F;.ssh，删除know_hosts目录，重新连接一下</li>
</ul>
</li>
<li><p>基本命令<br>pwd 打印当前文件夹的路径<br>cd  改变目录, 相当于 windows 下的打开文件夹<br>ls  展示当前目录下的所有文件内容<br>mkdir 创建目录, 创建文件夹<br>rmdir 删除文件夹<br>touch 创建文件<br>rm 删除文件<br>cat 原意是指将文件与终端输出流连接, 通俗的说输出文件内容<br>less 或 more( Unix ) 命令可以分页的打开文件, 注意使用 q 退出<br>echo 命令 打印</p>
<blockquote>
<p>重定向, 如果文件存在, 则将文件截断, 并重新输入.</p>
<blockquote>
<p> 重定向. 不截断重定向<br>ipconfig&#x2F;all  查看ip信息<br>ping IP地址    查看是否连接成功<br>tips:<br>注意: 换行问题:在 linux 中使用 \n 表示换行;在 windows 中使用 \r\n 表示换行<br>注意:文件截断是指将文件的所有内容删除, 但是文件的创建时间等信息不更改</p>
</blockquote>
</blockquote>
</li>
<li><p>查看某一目录下所有文件夹的内存占用</p>
</li>
</ol>
<ul>
<li>du -sh .&#x2F;* –exclude proc</li>
</ul>
<ol start="4">
<li>查看各磁盘内存情况</li>
</ol>
<ul>
<li>df -h</li>
</ul>
<ol start="5">
<li><p>开启ssh远程连接服务</p>
<ol>
<li>测试是否安装了openssh server，sudo service ssh start</li>
<li>如果没有安装，则安装，sudo apt update &amp;&amp; sudo apt install openssh-server</li>
<li>安装完毕则可以开始连接了</li>
</ol>
</li>
<li><p>本地机器和远程服务器之间传送文件</p>
<ol>
<li>scp命令，scp  [参数] &lt;源地址（用户名@IP地址或主机名）&gt;:&lt;文件路径&gt; &lt;目的地址（用户名 @IP 地址或主机名）&gt;:&lt;文件路径&gt;</li>
<li>#拷贝文件夹，加-r参数</li>
<li>例子；scp -r &#x2F;home&#x2F;tim&#x2F;workspace&#x2F;github&#x2F;style <a class="link"   href="mailto:&#x74;&#105;&#109;&#x40;&#x31;&#x39;&#x32;&#46;&#x31;&#x36;&#56;&#x2e;&#120;&#120;&#x78;&#x2e;&#120;&#x78;" >&#x74;&#105;&#109;&#x40;&#x31;&#x39;&#x32;&#46;&#x31;&#x36;&#56;&#x2e;&#120;&#120;&#x78;&#x2e;&#120;&#x78;<i class="fas fa-external-link-alt"></i></a>:&#x2F;home&#x2F;tim&#x2F;github&#x2F;style</li>
</ol>
</li>
</ol>
]]></content>
      <categories>
        <category>小而美-工具</category>
      </categories>
      <tags>
        <tag>conda-docker-git-vim-ssr</tag>
      </tags>
  </entry>
  <entry>
    <title>概率论基本概念1</title>
    <url>/2014/11/06/alogrithms/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B51/</url>
    <content><![CDATA[<h1 id="定量数据的统计特征"><a href="#定量数据的统计特征" class="headerlink" title="定量数据的统计特征"></a>定量数据的统计特征</h1><ul>
<li>在对一组统计数据的分布变化进行深入研究之前，我们首先研究一组数据的特征。为了比较精确地描述一组统计资料的特征，需要使用一些统计指标来描述它。下面我们讨论一下数据统计特征的四个方面。</li>
</ul>
<h2 id="集中趋势"><a href="#集中趋势" class="headerlink" title="集中趋势"></a>集中趋势</h2><ul>
<li>集中趋势，也称做中心位置。即表示一组数据的中心位置的数据是在什么地方，也就是数据集中分布的位置。</li>
<li>一组数据的集中趋势通常用<strong>平均数</strong>、<strong>中位数</strong>和<strong>众数</strong>等来表示。这些统计量均称为平均指标。平均指标的特点是将一组数据中各个数据之间的差异抽象化，用一个指标来代表各个数据的一般水平，它反映了一组数据中各个数据的代表水平、中心位置或集中趋势。</li>
</ul>
<h3 id="均数"><a href="#均数" class="headerlink" title="均数"></a>均数</h3><ul>
<li>均数是算术均数的简称。常用表示样本均数，表示总体均数。均数用于反映一组同质观测值的平均水平，适用于正态或近似正态分布的数值变量资料。其计算方法有：<ul>
<li><font color=" #0000FF">直接法</font><ul>
<li>用于样本含量较少时，其公式为：</li>
<li><img src="/img/probability-theory-basic-conception/01/01_arithmetic_mean.PNG"></li>
<li>式中，希腊字母∑（读作sigma）表示求和；X1,X2…,Xn为观察值；n为样本含量，即观测值的个数。</li>
</ul>
</li>
<li><font color=" #0000FF">加权法</font><ul>
<li>用于频数表资料或样本中相同观察值较多时，其公式为：</li>
<li><img src="/img/probability-theory-basic-conception/01/02_weighted_mean.PNG"></li>
<li>式中，X1,X2,…,Xn与f1,f2,…,fk分别为相同观察值与其对应的频数（或频数表资料中个组段的组中值和相应组段的频数）。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="几何均数"><a href="#几何均数" class="headerlink" title="几何均数"></a>几何均数</h3><ul>
<li>适用于对数正态分布，即数据经过对数变换后呈正态分布的资料；等比级数资料，即观测值之间呈倍数或近似倍数变化的资料。如抗体滴度、平均效价等。其计算方法有：<ul>
<li><font color=" #0000FF">直接法</font><ul>
<li>适用于样本含量n较小时</li>
<li><img src="/img/probability-theory-basic-conception/01/03_geometric_mean.PNG"><br>  或<br>  <img src="/img/probability-theory-basic-conception/01/04_geometric_mean.PNG"></li>
</ul>
</li>
<li><font color=" #0000FF">加权法</font><ul>
<li>频数表资料或样本中相同观察值较多时</li>
<li><img src="/img/probability-theory-basic-conception/01/05_geometric_weighted_mean.PNG"></li>
</ul>
</li>
<li><strong>注意：</strong>计算几何均数时观察值中不能有0，因为0不能取对数；一组观察值中不能同时又正值和负值。</li>
</ul>
</li>
</ul>
<h3 id="中位数"><a href="#中位数" class="headerlink" title="中位数"></a>中位数</h3><ul>
<li>一组由小到大按顺序排列的观察值中位次居中的数值。</li>
<li>中位数可用于描述：<ul>
<li>非正态分布资料（对数正态分布除外）；</li>
<li>频数分布的一端或两端无确切数据的资料；</li>
<li>总体分布不清楚的资料</li>
</ul>
</li>
<li>在全部观察中，小于和大于中位数的观察值个数相等。其计算方法也包括：<ul>
<li><font color=" #0000FF">直接法</font><ul>
<li>适用于样本含量n较小的资料</li>
<li>把数从小到大排成一列</li>
<li><img src="/img/probability-theory-basic-conception/01/06_median.PNG"></li>
</ul>
</li>
<li><font color=" #0000FF">频数表法</font><ul>
<li>适用于样本含量n较大的资料</li>
<li><img src="/img/probability-theory-basic-conception/01/07_median.PNG"></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="离散趋势"><a href="#离散趋势" class="headerlink" title="离散趋势"></a>离散趋势</h2><ul>
<li>在统计学上描述观察值偏离中心位置的趋势，反映了所有观察值偏离中心的分布情况。</li>
<li>描述一组计量资料离散趋势的常用指标有极差、四分位数间距、方差、标准差、标准误差和变异系数等，其中方差和标准差最常用。</li>
</ul>
<h3 id="极差"><a href="#极差" class="headerlink" title="极差"></a>极差</h3><ul>
<li>极差(range,简记为R)亦称全距。</li>
<li>定义：值一组同质观察值中最大值和最小值之差。极差反映了个体差异的范围：极差大，说明变异度大；反之，极差小，说明变异度小。</li>
<li>公式：R &#x3D; Xmax - Xmin</li>
<li>不足：<ul>
<li><ol>
<li>仅考虑了最大值和最小值之差，不能反映组内其他观察值的变异度；</li>
</ol>
</li>
<li><ol start="2">
<li>样本含量越大，抽到较大或较小的观察值的可能性越大，故极差可能越大。因此，样本含量相差悬殊时不宜用极差比较。</li>
</ol>
</li>
</ul>
</li>
</ul>
<h3 id="平均差"><a href="#平均差" class="headerlink" title="平均差"></a>平均差</h3><ul>
<li>定义：平均差是指一组数据中的各数据对平均数的离差绝对值的平均数。</li>
<li>一组数据中的各数据对平均数的离差有正有负，其和等于0，因此平均差必须用离差的绝对值来计算。</li>
<li>平均差越大，表示数据之间的变异程度越大，反之，则变异程度越小。</li>
<li>公式：<img src="/img/probability-theory-basic-conception/01/08_mean_deviation.PNG"></li>
</ul>
<h3 id="百分位数"><a href="#百分位数" class="headerlink" title="百分位数"></a>百分位数</h3><ul>
<li><p>定义：百分位数(percentile)用Px表示，0&lt;x&lt;100，是描述一组数据某百分位的位置指标。Px将全部观察值分为两部分，理论上有x%的观察值比它小，有(100-x%)的观察值比它大。</p>
</li>
<li><p>最常用的百分位数是P50,即中位数。</p>
</li>
<li><p>应用</p>
<ul>
<li><p>1.常与中位数结合应用，可以描述一组资料在某百分位置上的水平，也可以描述资料的分布特征。</p>
<ul>
<li><img src="/img/probability-theory-basic-conception/01/09_percentile.PNG"></li>
<li>M - P5 &#x3D; P95 - M, 分布近似对称</li>
<li>M - P5 &lt; P95 - M, 分布呈正偏态</li>
<li>M - P5 &gt; P95 - M, 分布呈负偏态</li>
</ul>
</li>
<li><p><img src="/img/probability-theory-basic-conception/01/10_percentile.PNG"></p>
</li>
<li><p>2.也可用多个百分位数的结合来描述一组观察值的分布特征，如P25和P75合用时，反映中间50%观察值的分布情况；</p>
</li>
<li><p>3.百分位数可用于确定非正态分布资料的医学参考值范围。</p>
</li>
</ul>
</li>
<li><p>计算公式：</p>
<ul>
<li><img src="/img/probability-theory-basic-conception/01/11_percentile.PNG"></li>
<li>Lx,i,fx分别为Px所在组段的下限、组距和频数；∑fL为小于L的各组段的累计频数。</li>
</ul>
</li>
<li><p>注意：应用百分位数，样本含量要足够大，否则不宜取靠近两端的百分位数。</p>
</li>
</ul>
<h3 id="四分位数间距"><a href="#四分位数间距" class="headerlink" title="四分位数间距"></a>四分位数间距</h3><ul>
<li>定义：四分位数间距(quartile interval, Q)为上四分位数与下四分位数之差(或P75与P25之差)。</li>
<li>计算公式：<img src="/img/probability-theory-basic-conception/01/12_quartile_interval.PNG"></li>
<li>应用：用于描述偏态分布以及分布的一端或两端无确切数值资料或分布类型未知资料的离散程度。</li>
<li><img src="/img/probability-theory-basic-conception/01/13_quartile_interval.PNG"></li>
<li>四分位数间距包括了一组观察值的一半，故可把四分位数间距看成是中间50%观察值的极差。</li>
<li>意义：Q越大，变异度越大；反之，Q越小，变异度越小。</li>
<li>特点：由于四分位数间距不受两端个别极大值或极小值的影响，因而它较极差稳定，但仍未考虑全部观察值的变异度。</li>
</ul>
<h3 id="方差"><a href="#方差" class="headerlink" title="方差"></a>方差</h3><ul>
<li>极差和四分位数间距都只考虑了个别观察值的大小差异，没有全面反映每个观察值的变异程度。</li>
<li>就总体而言，即应考虑总体中每个观察值X与总体均数μ的差值(X - μ)，即离均差。</li>
<li>因离均差之和∑(X - μ) &#x3D; 0,不能反映变异度的大小，故用例均差平方和∑(X - μ)^2 (sum of squares of deviations from mean)反映之。离均差平方和的大小除与变异度有关外，还与变量值的个数N有关。为了消除这一影响，取离均差平方和的均数，称方差(variance)或均方(mean of squares)。</li>
<li>计算公式：<ul>
<li>总体方差：<img src="/img/probability-theory-basic-conception/01/14_population_variance.PNG"></li>
<li>样本方差：<img src="/img/probability-theory-basic-conception/01/15_sample_variance.PNG"></li>
</ul>
</li>
<li>n-1为自由度(degree of freedom),一般用ν(niu)表示。</li>
<li>因方差的度量单位是原度量单位的平方，故计算结果难以解释。</li>
</ul>
<h3 id="标准差"><a href="#标准差" class="headerlink" title="标准差"></a>标准差</h3><ul>
<li>为了使统计量的单位同观察值单位相一致，通常将方差开平方，即得到标准差，标准差也称为均方差。</li>
<li>计算公式：<ul>
<li>总体标准差：<img src="/img/probability-theory-basic-conception/01/16_standard_deviation.PNG"></li>
<li>样本标准差：<img src="/img/probability-theory-basic-conception/01/17_standard_deviation.PNG"></li>
</ul>
</li>
<li>意义：标准差大，表示观察值的变异度大；反之，标准差小，表示观察值的变异度小。</li>
<li>应用：<ul>
<li><ol>
<li>适用于描述对称分布资料尤其是正态分布资料的离散程度；</li>
</ol>
</li>
<li><ol start="2">
<li>结合均数，描述正态分布资料的频数分布规律，用于估计医学参考值范围；</li>
</ol>
</li>
<li><ol start="3">
<li>结合均数，计算变异系数；</li>
</ol>
</li>
<li><ol start="4">
<li>结合样本含量，计算标准误差，估计抽样误差，用于统计推断。</li>
</ol>
</li>
</ul>
</li>
</ul>
<h3 id="变异系数"><a href="#变异系数" class="headerlink" title="变异系数"></a>变异系数</h3><ul>
<li>变异系数(coefficient of variation, CV)，是标准差与均数的比值，用百分数表示，没有单位。</li>
<li>计算公式：<img src="/img/probability-theory-basic-conception/01/18_coefficient_variation.PNG"></li>
<li>应用：常用于比较度量单位不同或均数相差悬殊的两组(或多组)资料的变异度。</li>
</ul>
<h2 id="偏度"><a href="#偏度" class="headerlink" title="偏度"></a>偏度</h2><ul>
<li>定义：偏度是指次数分布非对称的偏态方向程度。为了精确测定次数分布的偏斜状况，统计上采用偏斜度指标。</li>
</ul>
<h2 id="峰度"><a href="#峰度" class="headerlink" title="峰度"></a>峰度</h2>]]></content>
      <categories>
        <category>技能-修行-进步</category>
      </categories>
      <tags>
        <tag>概率论基本概念</tag>
      </tags>
  </entry>
  <entry>
    <title>how to use git quickly Part 1</title>
    <url>/2017/03/02/%E5%B0%8F%E8%80%8C%E7%BE%8E-%E5%B7%A5%E5%85%B7/how-to-use-git-quickly-part1/</url>
    <content><![CDATA[<ul>
<li>Suppose you are new to git and github and you want to use it quickly. This is the situation I write this post. <ol>
<li>Get a free account of github, that’s easy for you guys.</li>
<li>Install the git on Windows or Linux, that’s easy too.</li>
<li>Then I use the Ubuntu as an example.</li>
</ol>
</li>
</ul>
<h2 id="configure-your-git-local"><a href="#configure-your-git-local" class="headerlink" title="configure your git local"></a>configure your git local</h2><ul>
<li>After you install git, open git bash and configure you git, like your user name and email of your github account.<a class="link"   href="https://git-scm.com/book/en/v2/Getting-Started-First-Time-Git-Setup" >git official tutorial<i class="fas fa-external-link-alt"></i></a><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ git config --global user.name &quot;John Doe&quot;</span><br><span class="line">$ git config --global user.email johndoe@example.com</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="Generating-a-new-SSH-key"><a href="#Generating-a-new-SSH-key" class="headerlink" title="Generating a new SSH key"></a>Generating a new SSH key</h2><ul>
<li>Then get your local ssh key and copy it to your github account, <a class="link"   href="https://help.github.com/articles/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent/" >git official tutorial<i class="fas fa-external-link-alt"></i></a><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ ssh-keygen -t rsa -b 4096 -C &quot;your_email@example.com&quot;</span><br></pre></td></tr></table></figure></li>
<li>This creates a new ssh key, using the provided email as a label.<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Generating public/private rsa key pair.</span><br></pre></td></tr></table></figure></li>
<li>When you’re prompted to “Enter a file in which to save the key,” press Enter. This accepts the default file location.<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Enter a file in which to save the key (/Users/you/.ssh/id_rsa): [Press enter]</span><br></pre></td></tr></table></figure></li>
<li>At the prompt, type a secure passphrase. And if you want to skip the password, just press Enter twice and it will be done.<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Enter passphrase (empty for no passphrase): [Type a passphrase]</span><br><span class="line">Enter same passphrase again: [Type passphrase again]</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="Adding-your-SSH-key-to-the-ssh-agent"><a href="#Adding-your-SSH-key-to-the-ssh-agent" class="headerlink" title="Adding your SSH key to the ssh-agent"></a>Adding your SSH key to the ssh-agent</h2><ul>
<li>After you generate your ssh key, go to the destination and open the <strong>id_rsa.pub</strong> and copy the contents like this:<br><img src="/img/git-tuto/part1/ssh-key.png"> </li>
<li>Then log in your github account and find the setting part<br><img src="/img/git-tuto/part1/set.png"> </li>
<li>And then from the left menu to find the <strong>SSH and GPG Keys</strong><br><img src="/img/git-tuto/part1/ssh.png"> </li>
<li>Click the right button and add new ssh key<br><img src="/img/git-tuto/part1/newssh.png"> </li>
<li>You will be asked add the title and ssh key<br><img src="/img/git-tuto/part1/title-key.png"></li>
</ul>
<h2 id="Testing-your-ssh-connection-with-github"><a href="#Testing-your-ssh-connection-with-github" class="headerlink" title="Testing your ssh connection with github"></a>Testing your ssh connection with github</h2><ul>
<li>Now go back to your git bash, and type into <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ssh -T git@github.com</span><br></pre></td></tr></table></figure></li>
<li>You will get the response like this<br><img src="/img/git-tuto/part1/check.png"> </li>
<li>That means you connect to your github successfully! Congratuations!</li>
</ul>
<h2 id="Next-step"><a href="#Next-step" class="headerlink" title="Next step"></a>Next step</h2><ul>
<li>Since you have configured your git and github, let’s do a simple practice now.  Go to Part2 <a href="/2017/03/02/%E5%B0%8F%E8%80%8C%E7%BE%8E-%E5%B7%A5%E5%85%B7/how-to-use-git-quickly-part2/" title="how to use git quickly part 2">how to use git quickly part 2</a></li>
</ul>
]]></content>
      <categories>
        <category>小而美-工具</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title>程序员必须知道的10大基础实用算法及其讲解-@慕可网制作</title>
    <url>/2015/02/08/alogrithms/%E7%A8%8B%E5%BA%8F%E5%91%98%E5%BF%85%E9%A1%BB%E7%9F%A5%E9%81%93%E7%9A%8410%E5%A4%A7%E5%9F%BA%E7%A1%80%E5%AE%9E%E7%94%A8%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E8%AE%B2%E8%A7%A3-%E6%85%95%E5%8F%AF%E7%BD%91%E5%88%B6%E4%BD%9C/</url>
    <content><![CDATA[<h2 id="算法一：快速排序算法"><a href="#算法一：快速排序算法" class="headerlink" title="算法一：快速排序算法"></a>算法一：快速排序算法</h2><ul>
<li>快速排序算法是由东尼.霍尔所发展的一种排序算法。在平均状况下，排序n个项目要O(nlog n)次比较。在最坏状况下则需要O(n2)次比较，但这种状况并不常见。事实上，快速排序O(n log n)通常明显比其他算法更快，因为它的内部循环结构(inner loop)可以在大部分的架构上很有效率地被实现出来。</li>
<li>快速排序使用分治法(Divide and conquer)策略来把一个串行(list)分为两个子串行(sub-lists)。</li>
<li>gif动图</li>
<li>算法步骤：<ol>
<li>从数列中挑出一个元素，称为“基准”(pivot)。</li>
<li>重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆放基准的后面(相同的数可以到任一边)。在这个分区退出之后，该基准就处在数列的中间位置。这个称为分区(partition)操作。</li>
<li>递归地(recursive)把小于基准值元素的子数列和大于基准值元素的子数列排序。</li>
</ol>
</li>
<li>递归的最底部情形，数列的大小是零或者一，也就是永远都已经被排序好了。虽然一直递归下去，但是这个算法总会退出，因为在每次的迭代(iteration)中，它至少会把一个元素摆到它最后的位置去。</li>
</ul>
<h2 id="算法二：堆排序算法"><a href="#算法二：堆排序算法" class="headerlink" title="算法二：堆排序算法"></a>算法二：堆排序算法</h2><ul>
<li>堆排序(Heapsort)是指利用堆这种数据结构所设计的一种排序算法。堆积是一个近似完全二叉树的结构，并同时满足堆积的性质：即子节点的键值或索引总是小于(或者大于)它的父节点。</li>
<li>堆排序的平均时间复杂度为O(nlog n)。</li>
<li>gif动图</li>
<li>算法步骤：<ol>
<li>创建一个堆H[0…n-1]。</li>
<li>把堆首(最大值)和堆尾互换。</li>
<li>把堆的尺寸缩小1，并调用shift_down(0)，目的是把新的数组顶端数据调整到相应位置。</li>
<li>重复步骤2，直到堆的尺寸为1。</li>
</ol>
</li>
</ul>
<h2 id="算法三：归并排序"><a href="#算法三：归并排序" class="headerlink" title="算法三：归并排序"></a>算法三：归并排序</h2><ul>
<li>归并排序(Merge sort，台湾译作：合并排序)是建立在归并操作上的一种有限的排序算法。该算法是采用分治法(Divide and conquer)的一个非常典型的应用。</li>
<li>算法步骤：<ol>
<li>申请空间，使其大小为两个已经排序序列之和，该空间用来存放合并后的序列。</li>
<li>设定两个指针，最初位置分别为两个已经排序序列的起始位置。</li>
<li>比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置。</li>
<li>重复步骤3直到某一指针达到序列尾。</li>
<li>将另一序列剩下的所有元素直接复制到合并序列尾。</li>
</ol>
</li>
<li>gif动图</li>
</ul>
<h2 id="算法四：二分查找算法"><a href="#算法四：二分查找算法" class="headerlink" title="算法四：二分查找算法"></a>算法四：二分查找算法</h2><ul>
<li>二分查找算法是一种在有序数组中查找某一特定元素的搜索算法。搜索过程从数组的中间元素开始，如果中间元素正好是要查找的元素，则搜索过程结束；如果某一特定元素大于或小于中间元素，则在数组大于或者小于中间元素的那一半查找，而且跟开始一样从中间元素开始比较。如果在某一步骤数组为空，则代表找不到。这种搜索算法每一次比较都使搜索范围缩小一半。折半搜索每次把搜索区域减少一半，时间复杂度为O(log n)。</li>
</ul>
<h2 id="算法五：BFPRT-线性查找算法"><a href="#算法五：BFPRT-线性查找算法" class="headerlink" title="算法五：BFPRT(线性查找算法)"></a>算法五：BFPRT(线性查找算法)</h2><ul>
<li>BFPRT算法解决的问题十分经典，即从某n个元素的序列中选出第k大(第k小)的元素，通过巧妙的分析，BFPRT可以保证在最坏情况下仍为线性时间复杂度。该算法的思想与快速排序思想相似，当然，为使得算法在最坏情况下，依然能达到O(n)的时间复杂度，五位算法作者做了精妙的处理。</li>
<li>算法步骤：<ol>
<li>将n个元素每5个一组，分成n&#x2F;5(上界)组。</li>
<li>取出每一组的中位数，任意排序方法，比如插入排序。</li>
<li>递归地调用selection算法查找上一步中所有中位数的中位数，设为x，偶数个中位数的情况下设定为选取中间小的一个。</li>
<li>用x来分割数组，设小于等于x的个数为k，大于x的个数即为n-k。</li>
<li>用i &#x3D;&#x3D; k， 返回x;若i&gt;k，在大于x的元素中递归查找第i-k的元素。终止条件：n &#x3D; 1时，返回的即使i小元素。</li>
</ol>
</li>
</ul>
<h2 id="算法六：DES-深度优先搜索"><a href="#算法六：DES-深度优先搜索" class="headerlink" title="算法六：DES(深度优先搜索)"></a>算法六：DES(深度优先搜索)</h2><ul>
<li>深度优先搜索算法(Depth-First-Search)，是搜索算法的一种。它沿着树的深度遍历 树的节点，尽可能深的搜索树的分支。当节点v的所有边都已被探寻过，搜索将回溯到发现节点v的那条边的起始节点。这一过程一直进行到已发现从源节点可达的所有节点为止。如果还存在未被发现的节点，则选择其中一个作为源节点并重复以上过程，整个进程反复进行直到所有节点都被访问为止。DFS属于盲目搜索。</li>
<li>深度优先搜索是图论中的经典算法，利用深度优先搜索算法可以产生目标图的相应拓扑排序表，利用拓扑排序表可以方便的解决很多相关的图论问题，如最大路径问题等等。一般用堆数据结构来辅助实现DFS算法。</li>
<li>深度优先遍历图算法步骤：<ol>
<li>访问顶点v。</li>
<li>依次从v的未被访问的临接点出发，对图进行深度优先遍历；直至图中和v有路径相通的顶点都被访问。</li>
<li>若此时图中尚有顶点未被访问，则从一个未被访问的顶点出发，重新进行深度优先遍历，直到图中所有顶点均被访问过为止。</li>
</ol>
</li>
<li>上述描述可能比较抽象，举个例子：<ul>
<li>DFS在访问途中某一起始顶点v后，由v出发，访问它的任一邻接顶点w1;再从w1出发，访问与w1邻接但还没有访问过的顶点w2；然后再从w2出发，进行类似的访问，。。。如此进行下去，直至到达所有的邻接顶点都被访问过的顶点u为止。</li>
<li>接着，退回一步，退回前一次刚访问过的顶点，看是否还有其他没有被访问的邻接顶点。如果有，则访问此顶点，之后再从此顶点出发，进行与前述类似的访问；如果没有，就再退回一步进行搜索。重复上述过程，直到连通图中所有顶点都被访问过为止。</li>
</ul>
</li>
</ul>
<h2 id="算法七：BFS-广度优先搜索"><a href="#算法七：BFS-广度优先搜索" class="headerlink" title="算法七：BFS(广度优先搜索)"></a>算法七：BFS(广度优先搜索)</h2><ul>
<li>广度优先搜索算法(Breadth-First-Search),是一种图形搜索算法。简单的说，BFS是从跟节点开始，沿着树(图)的宽度遍历树(图)的节点。如果所有节点均未被访问，则算法终止。BFS同样属于盲目搜索。一般用队列数据结构来辅助实现BFS算法。</li>
<li>算法步骤：<ol>
<li>首先将根节点放入队列中。</li>
<li>从队列中取出第一个节点，并检验它是否为目标。如果找到目标，则结束搜寻并回传结果，否则将它所有尚未检验过的直接子节点加入队列中。</li>
<li>若队列为空，表示整张图都检查过了–亦即图中没有欲搜寻的目标。结束搜寻并回传“找不到目标”。</li>
<li>重复步骤2.</li>
</ol>
</li>
<li>gif动图。</li>
</ul>
<h2 id="算法八：Dijkstra算法"><a href="#算法八：Dijkstra算法" class="headerlink" title="算法八：Dijkstra算法"></a>算法八：Dijkstra算法</h2><ul>
<li>戴克斯特拉算法(Dijkstra’s algorithm)是有荷兰计算机科学家艾兹赫尔.戴克斯特拉提出。迪克斯切算法使用了广度优先搜索解决非负权有向图的单源最短路径问题，算法最终得到了一个最短路径树。该算法常用于路由算法或者作为其他图算法的一个子模块。</li>
<li>该算法的输入包含了一个有权重的有向图G，以及G中的一个来源顶点S。我们以V表示G中所有顶点的集合。每一个图中的边，都是两个顶点所形成的有序元素树。(u, v)表示从顶点u到v有路径相连。我们以E表示G中所有边的集合，而边的权重则由权重函数w: E –&gt; [0, 无穷大]定义。因此，w(u, v)就是从顶点u到顶点v的非负权重(weight)。边的权重可以想象成两个顶点之间的距离。任何两点间的路径的权重，就是该路径上所有边的权重总和。已知有V中有顶点s及t,Dijkstra算法可以找到s到t的最低权重路径(例如，最短路径)。这个路径也可以在一个图中，找到从一个顶点s到任何其他顶点的最短路径。对于不含负权的有向图，Dijkstra算法是目前已知的最快的单源最短路径算法。</li>
<li>算法步骤：<ol>
<li>初始时令 S&#x3D;{V0}，T&#x3D;{其他顶点}，T中为顶点对应的距离值，若存在，d(V0,Vi)为弧上的权值，若不存在，d(V0,Vi)为无穷大。</li>
<li>从T中选取一个其距离值为最小的顶点W且其不再S中，加入S。</li>
<li>对其余T中顶点的距离值进行修改：若加进W作中间顶点，从V0到Vi的距离值缩短，则修改此距离值。</li>
<li>重复上述步骤2，3，直到S中包含所有顶点，即W&#x3D;Vi为止。</li>
</ol>
</li>
<li>图片</li>
</ul>
<h2 id="算法九：动态规划算法"><a href="#算法九：动态规划算法" class="headerlink" title="算法九：动态规划算法"></a>算法九：动态规划算法</h2><ul>
<li>动态规划(Dynamic Programming)是一种在数学，计算机科学和经济学中使用的，通过把原问题分解为相对简单的子问题求解复杂问题的方法。动态规划常常适用于重叠子问题和最优子结构性质的问题，动态规划方法所耗时间往往少于朴素解法。</li>
<li>动态规划背后的基本思想非常简单。大致上，若要了解一个给定问题，我们需要解其不同的部分(即子问题)，再合并子问题的解以得出原问题的解。通常许多子问题非常相似，为此动态规划试图仅仅解决每个子问题一次，从而减少计算量：一旦某个给定子问题的解已经算出，则将其记忆化存储，以便下次需要同一个子问题解之时直接查表。这种做法在重复子问题的数目关于输入的规模呈指数增长时特别有用。</li>
<li>关于动态规划最经典的问题当属背包问题。</li>
<li>算法步骤：<ol>
<li>最优子结构性质。如果问题的最优解所包含的子问题也是最优的，我们就称该问题具有最优子结构性质(即满足最优化原理)。最优子结构性质为动态规划算法解决问题提供了重要线索。</li>
<li>子问题重叠性质。子问题重叠性质是指在用递归算法自顶向下对问题进行求解时，每次产生的子问题并不总是新问题，有些子问题会被重复计算多次。动态规划算法正是利用了这种子问题的重叠性质，对美一个子问题只计算一次，然后将子问题时，只是在表格中简单地查看一下结果，从而获得较高的效率。</li>
</ol>
</li>
</ul>
<h2 id="算法十：朴素贝叶斯分类算法"><a href="#算法十：朴素贝叶斯分类算法" class="headerlink" title="算法十：朴素贝叶斯分类算法"></a>算法十：朴素贝叶斯分类算法</h2><ul>
<li>朴素贝叶斯分类算法是一种基于贝叶斯定理的简单概率分类算法。贝叶斯分类的基础是概率推理，就是在各种条件的存在不确定，仅知其出现概率的情况下，如何完成推理和决策任务。概率推理是与确定性推理相对应的。而朴素贝叶斯分类器是基于独立假设的，即假设样本每个特征与其他特征都不相关。</li>
<li>朴素贝叶斯分类器依靠精确的自然概率模型，在有监督学习的样本集中能获得非常好的分类效果。在许多实际应用中，朴素贝叶斯模型参数估计使用最大似然估计方法，换言之朴素贝叶斯模型能工作并没有用到贝叶斯概率或者任何贝叶斯模型。</li>
<li>尽管是带着这些朴素思想和过于简单化的假设，但朴素贝叶斯分类器在很多复杂的现实情形中仍能够取得相当好的效果。</li>
<li>文章来源：36大数据</li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步</category>
      </categories>
      <tags>
        <tag>10大基础实用算法</tag>
      </tags>
  </entry>
  <entry>
    <title>linux shell常用的指令功能</title>
    <url>/2021/02/03/%E5%B0%8F%E8%80%8C%E7%BE%8E-%E5%B7%A5%E5%85%B7/linux_shell_cmd/</url>
    <content><![CDATA[<ul>
<li>Linux shell的三剑客grep, sed, awk</li>
</ul>
<h1 id="find命令"><a href="#find命令" class="headerlink" title="find命令"></a>find命令</h1><ol>
<li><p>find把某个文件夹下的所有文件名称重定向到txt中，例子：把某个文件下的所有jpg文件名（绝对路径）重定向到savetext.txt中。</p>
 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ find abs_path <span class="string">&quot;*.jpg&quot;</span> &gt; savetext.txt</span><br></pre></td></tr></table></figure>
</li>
<li><p>文件数量太多，无法mv，报</p>
</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ bash: /bin/mv: Argument list too long</span><br></pre></td></tr></table></figure>

<ul>
<li><p>解决方法</p>
  <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ find <span class="built_in">source</span>/ -name <span class="string">&quot;*.txt&quot;</span> | xargs -i <span class="built_in">mv</span> &#123;&#125; target/</span><br></pre></td></tr></table></figure></li>
</ul>
<ol start="3">
<li>统计文件夹下文件数量</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">ls</span> -l | <span class="built_in">wc</span> -l</span><br></pre></td></tr></table></figure>

<ol>
<li>查看当前系统运行的python程序</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ ps -ef |grep python </span><br></pre></td></tr></table></figure>

<ol start="5">
<li>复制文件夹</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">cp</span> -r srt_folder dest_folder</span><br></pre></td></tr></table></figure>

<ol start="6">
<li>查看当前目录占用空间</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">du</span> -sh</span><br></pre></td></tr></table></figure>

<ol start="7">
<li>当前目录文件占用空间按序排列</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">du</span> -s * | <span class="built_in">sort</span> -nr | <span class="built_in">head</span></span><br></pre></td></tr></table></figure>

<h1 id="sed命令"><a href="#sed命令" class="headerlink" title="sed命令"></a>sed命令</h1><ol start="8">
<li>批量修改</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ sed -i <span class="string">&#x27;s///g&#x27;</span> file.txt</span><br></pre></td></tr></table></figure>

<ol>
<li>批量修改字符串中包含路径分隔符斜杆，用^分割</li>
</ol>
<figure class="highlight jsx"><table><tr><td class="code"><pre><span class="line">$ sed -i <span class="string">&#x27;s^/data1/images^/data2/images/^g&#x27;</span> test.<span class="property">txt</span></span><br></pre></td></tr></table></figure>

<ol>
<li>批量修改带空格的字符串</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ sed -i <span class="string">&#x27;s#0 #1 #g&#x27;</span> *.txt</span><br></pre></td></tr></table></figure>

<h1 id="修改文件权限"><a href="#修改文件权限" class="headerlink" title="修改文件权限"></a>修改文件权限</h1><ul>
<li><a class="link"   href="https://blog.csdn.net/mzy202/article/details/7178586" >https://blog.csdn.net/mzy202/article/details/7178586<i class="fas fa-external-link-alt"></i></a></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">chmod</span> o+w -R folder/file</span><br></pre></td></tr></table></figure>

<h3 id="meld，文件内容比对软件"><a href="#meld，文件内容比对软件" class="headerlink" title="meld，文件内容比对软件"></a>meld，文件内容比对软件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ sudo apt install meld</span><br></pre></td></tr></table></figure>

<h2 id="cat-x2F-sed-查看文件"><a href="#cat-x2F-sed-查看文件" class="headerlink" title="cat &#x2F;sed 查看文件"></a>cat &#x2F;sed 查看文件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ sed -n <span class="string">&#x27;5,10p&#x27;</span> filename 这样你就可以只查看文件的第5行到第10行。</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ 【一】从第3000行开始，显示1000行。即显示3000~3999行</span><br><span class="line"></span><br><span class="line"><span class="built_in">cat</span> filename | <span class="built_in">tail</span> -n +3000 | <span class="built_in">head</span> -n 1000</span><br><span class="line"></span><br><span class="line">【二】显示1000行到3000行</span><br><span class="line"></span><br><span class="line"><span class="built_in">cat</span> filename| <span class="built_in">head</span> -n 3000 | <span class="built_in">tail</span> -n +1000 </span><br><span class="line"></span><br><span class="line">*注意两种方法的顺序</span><br><span class="line"></span><br><span class="line">分解：</span><br><span class="line"></span><br><span class="line">    <span class="built_in">tail</span> -n 1000：显示最后1000行</span><br><span class="line"></span><br><span class="line">    <span class="built_in">tail</span> -n +1000：从1000行开始显示，显示1000行以后的</span><br><span class="line"></span><br><span class="line">    <span class="built_in">head</span> -n 1000：显示前面1000行</span><br></pre></td></tr></table></figure>

<h1 id="文件夹卡住了怎么办"><a href="#文件夹卡住了怎么办" class="headerlink" title="文件夹卡住了怎么办"></a>文件夹卡住了怎么办</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># can kill the folder process</span></span><br><span class="line">$ pkill -f nautilus</span><br></pre></td></tr></table></figure>

<h2 id="FileZilla遇到编码问题"><a href="#FileZilla遇到编码问题" class="headerlink" title="FileZilla遇到编码问题"></a>FileZilla遇到编码问题</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">FileZilla Please make sure the LC_CTYPE (or LC_ALL) environment variable is <span class="built_in">set</span> correctly</span><br></pre></td></tr></table></figure>

<p><a class="link"   href="https://serverok.in/filezilla-please-make-sure-the-lc_ctype" >https://serverok.in/filezilla-please-make-sure-the-lc_ctype<i class="fas fa-external-link-alt"></i></a></p>
<h2 id="内存查看"><a href="#内存查看" class="headerlink" title="内存查看"></a>内存查看</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">procrank | grep benchmark(程序名)</span><br></pre></td></tr></table></figure>

<p><a class="link"   href="https://blog.csdn.net/qinhai1989/article/details/88112715" >https://blog.csdn.net/qinhai1989/article/details/88112715<i class="fas fa-external-link-alt"></i></a></p>
]]></content>
      <categories>
        <category>小而美-工具</category>
      </categories>
      <tags>
        <tag>linux shell命令</tag>
      </tags>
  </entry>
  <entry>
    <title>how to use git quickly part 2</title>
    <url>/2017/03/02/%E5%B0%8F%E8%80%8C%E7%BE%8E-%E5%B7%A5%E5%85%B7/how-to-use-git-quickly-part2/</url>
    <content><![CDATA[<h2 id="One-simple-example-to-push-your-code-to-your-github-account"><a href="#One-simple-example-to-push-your-code-to-your-github-account" class="headerlink" title="One simple example to push your code to your github account"></a>One simple example to push your code to your github account</h2><ul>
<li>After you’re done with <a class="link"   href="http://chenyuqing.github.com/2017/03/02/how-to-use-git-quickly-part1/" >Part 1<i class="fas fa-external-link-alt"></i></a> , Let’s practice now.</li>
</ul>
<h2 id="Create-a-new-repository-in-your-github"><a href="#Create-a-new-repository-in-your-github" class="headerlink" title="Create a new repository in your github"></a>Create a new repository in your github</h2><ul>
<li>Just log into your github account and create a new repository<br><img src="/img/git-tuto/part2/new-repo.png"></li>
</ul>
<h2 id="Clone-the-repository-to-local"><a href="#Clone-the-repository-to-local" class="headerlink" title="Clone the repository to local"></a>Clone the repository to local</h2><ul>
<li>After that, you go to the new repository page to copy the SSH or HTTPS url to clone the repository into local<br><img src="/img/git-tuto/part2/url.png"> </li>
<li>Then go back to git bash and type <strong>git clone url</strong><br><img src="/img/git-tuto/part2/clone.png"> </li>
<li>The repository is in your local destination now.</li>
</ul>
<h2 id="Edit-your-code-on-local"><a href="#Edit-your-code-on-local" class="headerlink" title="Edit your code on local"></a>Edit your code on local</h2><ul>
<li>Like you can add a new python script<br><img src="/img/git-tuto/part2/test-file.png"></li>
</ul>
<h2 id="Push-your-code-to-github"><a href="#Push-your-code-to-github" class="headerlink" title="Push your code to github"></a>Push your code to github</h2><ol>
<li>Add the code into buffering<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ git add .</span><br></pre></td></tr></table></figure></li>
</ol>
<ul>
<li>Notice there is a dot in the end of the command. It means add all things into the buffer. And there is a frequently-used command <strong>git status</strong>. It can check the status of your local repository now.<br><img src="/img/git-tuto/part2/status1.png"> </li>
<li>Now commit your buffer<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ git commit -m &quot;first commit&quot;</span><br></pre></td></tr></table></figure></li>
<li><strong>-m</strong> means the message you can record here.<br><img src="/img/git-tuto/part2/commit1.png"> </li>
<li>Now you can push your code into your github now<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ git push origin main</span><br></pre></td></tr></table></figure></li>
<li>And you can see the response message like this<br><img src="/img/git-tuto/part2/push.png"> </li>
<li>That means you push your local code into your github repository. And you can you can check your websit repository right now.<br><img src="/img/git-tuto/part2/res.png"></li>
</ul>
<h2 id="Congratulations-You-finished-the-simple-use-of-git-and-github-Try-to-play-it-to-get-more-fun-yourself-good-luck"><a href="#Congratulations-You-finished-the-simple-use-of-git-and-github-Try-to-play-it-to-get-more-fun-yourself-good-luck" class="headerlink" title="Congratulations ! You finished the simple use of git and github. Try to play it to get more fun yourself, good luck!!!"></a>Congratulations ! You finished the simple use of git and github. Try to play it to get more fun yourself, good luck!!!</h2>]]></content>
      <categories>
        <category>小而美-工具</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title>rebuild my own blog after system changed - Ubuntu</title>
    <url>/2020/02/03/%E5%B0%8F%E8%80%8C%E7%BE%8E-%E5%B7%A5%E5%85%B7/rebuild-my-own-blog-after-system-changed/</url>
    <content><![CDATA[<h2 id="System-info"><a href="#System-info" class="headerlink" title="System info"></a>System info</h2><ul>
<li>Ubuntu 16.04</li>
<li>Git </li>
<li>Node</li>
</ul>
<h2 id="Todos"><a href="#Todos" class="headerlink" title="Todos"></a>Todos</h2><h3 id="install-nodeks-and-npm"><a href="#install-nodeks-and-npm" class="headerlink" title="install nodeks and npm"></a>install nodeks and npm</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 更新</span><br><span class="line">sudo apt-get update</span><br><span class="line"># 安装低版本的node，然后再升级最新</span><br><span class="line">sudo apt-get install nodejs</span><br><span class="line">sudo apt install nodejs-legacy</span><br><span class="line">sudo apt install npm</span><br><span class="line">#安装更新版本的工具N，执行：</span><br><span class="line">sudo npm install n -g</span><br><span class="line">#跟新node版本，执行：</span><br><span class="line">sudo n stable</span><br><span class="line">sudo node -v</span><br><span class="line"></span><br><span class="line"># install hexo-cli</span><br><span class="line">sudo npm install -g hexo-cli</span><br></pre></td></tr></table></figure>
<h3 id="install-and-config-git"><a href="#install-and-config-git" class="headerlink" title="install and config git"></a>install and config git</h3><ul>
<li>ref1, <a href="/2017/03/02/%E5%B0%8F%E8%80%8C%E7%BE%8E-%E5%B7%A5%E5%85%B7/how-to-use-git-quickly-part1/" title="how to use git quickly Part 1">how to use git quickly Part 1</a></li>
<li>ref2, <a href="/2017/03/02/%E5%B0%8F%E8%80%8C%E7%BE%8E-%E5%B7%A5%E5%85%B7/how-to-use-git-quickly-part2/" title="how to use git quickly part 2">how to use git quickly part 2</a></li>
</ul>
<h3 id="install-hexo-with-npm"><a href="#install-hexo-with-npm" class="headerlink" title="install hexo with npm"></a>install hexo with npm</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-(1) delete origiginal your own github.io repository</span><br><span class="line">-(2) create the new one</span><br><span class="line">-(3) git clone to local</span><br><span class="line">-(4) hexo init &lt;folder&gt;, and move the contents into local github.io repository</span><br><span class="line">-(5) move your own theme files and confg.yaml file to the proper location</span><br><span class="line">-(6) install the node libs what your theme needs to satisfy</span><br><span class="line"></span><br><span class="line">- for example, I use the indigo theme, I should run below commands</span><br><span class="line">cd &lt;github.io folder&gt;</span><br><span class="line"># 主题默认使用 less 作为 css 预处理工具。</span><br><span class="line">npm install hexo-renderer-less --save</span><br><span class="line"># 用于生成 rss。</span><br><span class="line">npm install hexo-generator-feed --save</span><br><span class="line"># 用于生成静态站点数据，用作站内搜索的数据源。</span><br><span class="line">npm install hexo-generator-json-content --save</span><br><span class="line"># 用于生成微信分享二维码。</span><br><span class="line">npm install hexo-helper-qrcode --save</span><br><span class="line"># error, hexo d后 ERROR Deployer not found: git</span><br><span class="line">npm install --save hexo-deployer-git</span><br></pre></td></tr></table></figure>

<h3 id="write-posts-and-deploy"><a href="#write-posts-and-deploy" class="headerlink" title="write posts and deploy"></a>write posts and deploy</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo g</span><br><span class="line">hexo s</span><br><span class="line">hexo d</span><br><span class="line"></span><br><span class="line"># only fit for me to update my own blog.</span><br></pre></td></tr></table></figure>

<h3 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h3><ul>
<li><a class="link"   href="http://www.longmuchen.cn/2019/04/18/tools/2019-04-18-zai-ubuntu-14.04-fu-wu-qi-shang-bu-shu-hexo-bo-ke/" >http://www.longmuchen.cn/2019/04/18/tools/2019-04-18-zai-ubuntu-14.04-fu-wu-qi-shang-bu-shu-hexo-bo-ke/<i class="fas fa-external-link-alt"></i></a></li>
</ul>
]]></content>
      <categories>
        <category>小而美-工具</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>blog</tag>
        <tag>rebuild</tag>
        <tag>myself</tag>
      </tags>
  </entry>
  <entry>
    <title>Mac上通过airas2无限速下载网盘文件</title>
    <url>/2023/05/03/%E5%B0%8F%E8%80%8C%E7%BE%8E-%E5%B7%A5%E5%85%B7/mac-ariel/</url>
    <content><![CDATA[<ul>
<li><a class="link"   href="https://www.mintimate.cn/2019/06/21/Aria2/" >参考<i class="fas fa-external-link-alt"></i></a></li>
</ul>
<h2 id="度盘"><a href="#度盘" class="headerlink" title="度盘"></a>度盘</h2><ol>
<li>使用浏览器：chrome，科学上网，安装插件Tampermonkey，</li>
<li>安装前前下载插件，地址<a class="link"   href="https://greasyfork.org/zh-CN/scripts/463171-%E7%99%BE%E5%BA%A6%E7%BD%91%E7%9B%98%E5%8D%83%E5%8D%83%E4%B8%8B%E8%BD%BD%E5%8A%A9%E6%89%8B" >https://greasyfork.org/zh-CN/scripts/463171-%E7%99%BE%E5%BA%A6%E7%BD%91%E7%9B%98%E5%8D%83%E5%8D%83%E4%B8%8B%E8%BD%BD%E5%8A%A9%E6%89%8B<i class="fas fa-external-link-alt"></i></a></li>
<li>mac上安装aria2<ol>
<li>安装brew</li>
<li>通过brew安装aria2，brew install aria2</li>
<li>aira2.conf配置，附件</li>
<li>启动aira2后端程序</li>
</ol>
</li>
<li>mac上安装ariaNg，地址<a class="link"   href="https://github.com/mayswind/AriaNg-Native/releases" >https://github.com/mayswind/AriaNg-Native/releases<i class="fas fa-external-link-alt"></i></a></li>
<li>配置ariaRPC密码，连接成功</li>
<li>打开度盘网页页面，勾选单个你需要下载的文件，点击上方的千千下载插件按钮，进入获取下载链接页面，关注公共号，获取验证码，点击aira下载，并且输入你的token，就是上面设置的airaRCP密码，就可以高速下载了</li>
</ol>
<h2 id="雷盘"><a href="#雷盘" class="headerlink" title="雷盘"></a>雷盘</h2><ol>
<li>在greasyFork安装网盘下载助手，地址<a class="link"   href="https://greasyfork.org/zh-CN/scripts/436446-%E7%BD%91%E7%9B%98%E7%9B%B4%E9%93%BE%E4%B8%8B%E8%BD%BD%E5%8A%A9%E6%89%8B" >https://greasyfork.org/zh-CN/scripts/436446-%E7%BD%91%E7%9B%98%E7%9B%B4%E9%93%BE%E4%B8%8B%E8%BD%BD%E5%8A%A9%E6%89%8B<i class="fas fa-external-link-alt"></i></a></li>
<li>进入迅雷下载页面，勾选单个下载文件，点击上方的下载助手，选择RPC下载，填写你的配置端口和token后便可以成功下载</li>
</ol>
]]></content>
      <categories>
        <category>小而美-工具</category>
      </categories>
      <tags>
        <tag>下载工具</tag>
      </tags>
  </entry>
  <entry>
    <title>markdown书写规则</title>
    <url>/2023/07/20/%E5%B0%8F%E8%80%8C%E7%BE%8E-%E5%B7%A5%E5%85%B7/markdown-usage/</url>
    <content><![CDATA[<ul>
<li>Markdown是一个清亮的书写文章的小工具。</li>
<li>tabel表格<table>
<thead>
<tr>
<th>日期</th>
<th>銘言</th>
</tr>
</thead>
<tbody><tr>
<td>8月12号</td>
<td>不计回报的付出，最终得益的是自己！</td>
</tr>
</tbody></table>
</li>
</ul>
]]></content>
      <categories>
        <category>小而美-工具</category>
      </categories>
      <tags>
        <tag>markdown用法</tag>
      </tags>
  </entry>
  <entry>
    <title>拍照原理 Photography Theory</title>
    <url>/2024/02/24/%E6%8A%80%E8%83%BD-%E4%BF%AE%E8%A1%8C-%E8%BF%9B%E6%AD%A5-%E5%BD%B1%E8%A7%86%E5%9B%BE%E5%83%8F/%E6%8B%8D%E7%85%A7%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<ul>
<li><em><strong>拍照的核心：对光线的控制和管理，就是曝光的程度。</strong></em></li>
</ul>
<h2 id="曝光-Exposure"><a href="#曝光-Exposure" class="headerlink" title="曝光-Exposure"></a>曝光-Exposure</h2><ul>
<li>曝光越多，进光量越大，画面越亮。</li>
<li>曝光越少，进光量越小，画面越暗。</li>
<li>曝光的单位是EV，EV&#x3D;光圈值+快门值+ISO值。</li>
</ul>
<h2 id="曝光三要素-Exposure-Triangle"><a href="#曝光三要素-Exposure-Triangle" class="headerlink" title="曝光三要素-Exposure Triangle"></a>曝光三要素-Exposure Triangle</h2><h3 id="快门-Shutter-Speed"><a href="#快门-Shutter-Speed" class="headerlink" title="快门-Shutter Speed"></a>快门-Shutter Speed</h3><ul>
<li><img src="/img/wuweiwu/photography/three-ele/shutter-speed.jpeg"></li>
<li>光线通过镜头进入相机的过程中，经过3个部分：镜头-&gt;快门-&gt;感光元件，而控制快门就是控制感光元件接收光线的时间。</li>
<li>快门越快，进光量越小，运动越清晰。</li>
<li>快门越慢，进光量越大，运动越模糊。</li>
<li>快门速度的单位是秒，1&#x2F;1000秒是快门速度，1秒是慢门速度。</li>
</ul>
<h3 id="光圈-Aperture"><a href="#光圈-Aperture" class="headerlink" title="光圈-Aperture"></a>光圈-Aperture</h3><ul>
<li><img src="/img/wuweiwu/photography/three-ele/aperture.jpeg"></li>
<li>“景深”是指当焦距对准某一点时，其前后都仍可清晰的范围。通常肖像需要小景深，风景需要大景深。</li>
<li>光圈越大，进光量越大，景深越小。</li>
<li>光圈越小，进光量越小，景深越大。</li>
<li>光圈大小的单位是F，F越小，光圈越大。</li>
<li>光圈大小的单位是F，F越大，光圈越小。</li>
<li>光圈大小的单位是F，F&#x3D;焦距&#x2F;光圈直径。</li>
</ul>
<h3 id="感光度-ISO"><a href="#感光度-ISO" class="headerlink" title="感光度-ISO"></a>感光度-ISO</h3><ul>
<li><img src="/img/wuweiwu/photography/three-ele/ISO.jpeg"></li>
<li>ISO越高，进光量越大，画质越差。</li>
<li>ISO越低，进光量越小，画质越好。</li>
<li>ISO的单位是ISO，100是低感光度，1600是高感光度。</li>
</ul>
<h2 id="三要素的关系"><a href="#三要素的关系" class="headerlink" title="三要素的关系"></a>三要素的关系</h2><ul>
<li>在快门和光圈都调正确的情况下，ISO越低，画质越好。所以通常情况下，先调快门和光圈，再调ISO。</li>
<li>拍照通常考虑问题的顺序：<ul>
<li>首先确定拍摄画面是动态的还是静态的，调节快门。</li>
<li>然后考虑景深的问题，如果需要大景深，就调小光圈，如果需要小景深，就调大光圈。</li>
<li>最后考虑画质的问题，调节ISO。</li>
</ul>
</li>
</ul>
<h2 id="Trouble-Shooting"><a href="#Trouble-Shooting" class="headerlink" title="Trouble Shooting"></a>Trouble Shooting</h2><ul>
<li>如果光线太暗，可以调大光圈，调慢快门，调高ISO。</li>
<li>如果光线太亮，可以调小光圈，调快快门，调低ISO。</li>
</ul>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a class="link"   href="https://www.sony.com/zh-cn/electronics/support/articles/00081746" >镜头的基础知识系列：光圈和景深-sony China<i class="fas fa-external-link-alt"></i></a></li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步-影视图像</category>
      </categories>
      <tags>
        <tag>摄影</tag>
        <tag>影像</tag>
      </tags>
  </entry>
  <entry>
    <title>Django-1.7.3-Tutorial-Part-1-模型</title>
    <url>/2015/01/16/%E6%8A%80%E8%83%BD-%E4%BF%AE%E8%A1%8C-%E8%BF%9B%E6%AD%A5-Django/Django-1-7-3-Tutorial-Part-1-%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h1 id="创建你的第一个Django-app-Part-1"><a href="#创建你的第一个Django-app-Part-1" class="headerlink" title="创建你的第一个Django app-Part 1"></a>创建你的第一个Django app-Part 1</h1><ul>
<li>让我们从简单的例子开始吧。</li>
<li>通过这个教程，我们将快速学习投票(poll)应用的创建。</li>
<li>环境：windows 8 32 bits + Python 2.7.5 + Django 1.7.3</li>
<li>它包含两个部分：<ul>
<li>一个供人们查看和进行投票的公开的站点。</li>
<li>一个管理员站点，可以让你进行添加，修改和查询投票。</li>
</ul>
</li>
<li>我们假设你已经装好了Django.你可以通过以下命令查看你安装的版本。<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$ python -c <span class="string">&quot;import django; print(django.get_version())&quot;</span></span><br></pre></td></tr></table></figure></li>
<li>如果你成功安装了Django，你就会看到版本号，否则，你就会得到一个错误信息：”No module named django”.</li>
<li>我的Django信息如下：<br><img src="/img/Django-1-7-3-tutorial/get_version.png"></li>
</ul>
<h2 id="创建项目"><a href="#创建项目" class="headerlink" title="创建项目"></a>创建项目</h2><ul>
<li>如果你是第一次使用Django，那么你应该注意一些初始化的设置。也就是说，你需要一些自生成的代码来构建一个Django项目，包括Django实例的设置文件，譬如数据库配置文件，Django指定选项和应用指定的设置。</li>
<li>从命令行中切换到你想把项目存储的目录，然后输入以下命令:<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$ django-admin.py startproject mysite</span><br></pre></td></tr></table></figure></li>
<li>在当前目录下就会生成一个mysite的目录。如果没有，请查看<a class="link"   href="https://docs.djangoproject.com/en/1.7/faq/troubleshooting/#troubleshooting-django-admin-py" >问题反馈<i class="fas fa-external-link-alt"></i></a></li>
</ul>
<blockquote>
<p><strong>笔记</strong><br>请注意命名，不能和Python或者Django组件中的关键字重名，特别的，你不能使用django或者test。</p>
</blockquote>
<ul>
<li>通过startproject命令创建的目录如下：<br><img src="/img/Django-1-7-3-tutorial/dir-startproject.png"></li>
</ul>
<blockquote>
<p><strong>和你建的目录不同？</strong><br>默认项目布局最近有所改变。如果你看到一个’flat’布局(里面没有mysite&#x2F;目录)，你可能使用的Django和本教程的版本不同。请移步。</p>
</blockquote>
<ul>
<li>目录路径解释：<ul>
<li>外层mysite&#x2F;：你的项目的根目录。它的名字可以随意更改。</li>
<li>manage.py文件：它是一个和Django进行多样化交互的命令行工具。你可以从以下链接查看详细内容<a class="link"   href="https://docs.djangoproject.com/en/1.7/ref/django-admin/" >django-admin.py and manage.py<i class="fas fa-external-link-alt"></i></a></li>
<li>内层mysite&#x2F;：它是项目的真正的python包。名字不可随意更改，因为它是在其他地方可供导入的(例如：mysite.urls)</li>
<li>mysite&#x2F;<strong>init</strong>.py：一个空文件，它的作用是标注自己是一个python包。</li>
<li>mysite&#x2F;settings.py：Django项目的设置或配置。详细可查看<a class="link"   href="https://docs.djangoproject.com/en/1.7/topics/settings/" >Django settings<i class="fas fa-external-link-alt"></i></a></li>
<li>mysite&#x2F;urls.py：对Django项目的URL声明，就像是你的Django网站的目录列表。详细可查看<a class="link"   href="https://docs.djangoproject.com/en/1.7/topics/http/urls/" >URL dispatcher<i class="fas fa-external-link-alt"></i></a></li>
<li>mysite&#x2F;wsgi.py：它是配置WSGI服务器的入口点。详细可见：<a class="link"   href="https://docs.djangoproject.com/en/1.7/howto/deployment/wsgi/" >How to deploy with WSGI<i class="fas fa-external-link-alt"></i></a></li>
</ul>
</li>
</ul>
<h2 id="数据库配置"><a href="#数据库配置" class="headerlink" title="数据库配置"></a>数据库配置</h2><ul>
<li><p>现在，编辑mysite&#x2F;settings.py文件。它是一个普通的Python模块，用模块级变量表示Django设置。</p>
</li>
<li><p>默认情况下，配置是用SQLite。如果你不熟悉数据库，或者你只想玩玩Django,这是最快捷的选择。SQLite包含在Python中，所以不需要你安装。</p>
</li>
<li><p>如果你想用其他数据库，安装相应<a class="link"   href="https://docs.djangoproject.com/en/1.7/topics/install/#database-installation" >数据库绑定<i class="fas fa-external-link-alt"></i></a>,然后修改DATABASES中的默认选项来匹配你的数据库连接设置：</p>
<ul>
<li><strong>ENGINE</strong>-数据库引擎，SQLite(默认)：**’django.db.backends.sqlite3’<strong>;postgresql：</strong>‘django.db.backends.postgresql_psycopg2’<strong>；mysql：</strong>‘django.db.backends.mysql’**；Oracle： **’django.db.backends.oracle’**，或其他。</li>
<li><strong>NAME</strong>-数据库名称。如果你用SQLite,那么他是电脑上的一个文件，这样的话，<strong>NAME</strong>应该是一个绝对路径，包括文件名。默认值是**os.path.join(BASE_DIR, ‘db.sqlite3’)**，它是存储在项目路径下的文件。</li>
</ul>
</li>
<li><p>如果你不用SQLite，那么你需要添加<strong>USER</strong>,<strong>PASSWORD</strong>,<strong>HOST</strong>。详细可见：<a class="link"   href="https://docs.djangoproject.com/en/1.7/ref/settings/#std:setting-DATABASES" >DATABASES<i class="fas fa-external-link-alt"></i></a>。</p>
</li>
</ul>
<blockquote>
<p><strong>笔记</strong><br>如果你在使用PostgreSQL或者MySQL，你必须要创建好数据库。通过命令**CREATE DATABASE database_name;**。<br>如果你在使用SQLite,那么它会自动创建，必须手动创建。</p>
</blockquote>
<ul>
<li><p>当你在编辑mysite&#x2F;settings.py时，请把<strong>TIME_ZONE</strong>设置为自己的时区。</p>
</li>
<li><p>另外，文件开头的<strong>INSTALLED_APPS</strong>配置，它Django实例中被激活的Django应用的名字。Apps可以被多个项目使用，你可以把Apps打包和发布给其他项目使用。</p>
</li>
<li><p>默认情况下，<strong>INSTALLED_APPS</strong>配置包含Django中的apps，如下：</p>
<ul>
<li><strong>django.contrib.admin</strong>-管理员站点，你在Part2中会用到。</li>
<li><strong>django.contrib.auth</strong>-认证系统</li>
<li><strong>django.contrib.contenttypes</strong>-一个内容类型的框架</li>
<li><strong>django.contrib.sessions</strong>-session框架</li>
<li><strong>django.contrib.messages</strong>-messaging框架</li>
<li><strong>django.contrib.staticfiles</strong>-管理静态文件的框架</li>
</ul>
</li>
<li><p>这些apps默认添加的，你可以根据自己需求修改。</p>
</li>
<li><p>这些apps中可能要用到数据库表，所以，我们应该先要在数据库中创建表，然后再使用。命令如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$ python manage.py migrate</span><br></pre></td></tr></table></figure></li>
<li><p><strong>migrate</strong>命令会查看<strong>INSTALLED_APPS</strong>配置，然后根据<strong>mysite&#x2F;settings.py</strong>文件创建一些需要的数据库表，并把数据库迁移到相应的应用中。n你可以查看信息：运行数据库客户端，在命令行中输入\dt (PostgreSQL), SHOW TABLES; (MySQL), or .schema (SQLite)。</p>
</li>
</ul>
<h2 id="发布到服务器"><a href="#发布到服务器" class="headerlink" title="发布到服务器"></a>发布到服务器</h2><ul>
<li>验证你的项目是否可运行，在外层mysite目录下，运行一下命令：<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$ python manage.py runserver</span><br></pre></td></tr></table></figure></li>
<li>你可以看到以下输出(我的版本如下)：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">January 16, 2015 - 14:18:47</span><br><span class="line">Django version 1.7.3, using settings &#x27;mysite.settings&#x27;</span><br><span class="line">Starting development server at http://127.0.0.1:8000/</span><br><span class="line">Quit the server with CTRL-BREAK.</span><br></pre></td></tr></table></figure></li>
<li>你已经把项目成功发布到服务器上了，它是一个用纯python实现的轻量级的Web server。它已经被包含到Django当中，方便我们进行快速的开发。</li>
<li>它不可以用于商用，因为能力有限。我们是开发框架而不是服务器。</li>
<li>现在打开浏览器，输入”127.0.0.1:8000&#x2F;“，你就可以访问到你的项目页面了。效果如下：<br><img src="/img/Django-1-7-3-tutorial/worked.png"></li>
</ul>
<blockquote>
<p><strong>修改端口</strong><br>默认端口是8000，如果你想修改，可以按如下格式发布项目</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$ python mange.py runserver <span class="number">8080</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>如果你想修改服务器的IP，如下格式：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$ python manage.py runserver <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>:<span class="number">8000</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>详细文档参考<a class="link"   href="https://docs.djangoproject.com/en/1.7/ref/django-admin/#django-admin-runserver" >runserver<i class="fas fa-external-link-alt"></i></a></p>
</blockquote>
<blockquote>
<p>服务器自动加载，不用重新发布项目。</p>
</blockquote>
<h2 id="创建模型-models"><a href="#创建模型-models" class="headerlink" title="创建模型(models)"></a>创建模型(models)</h2><ul>
<li><p>现在你项目的基本环境已经搭建好，你可以开始做事了。</p>
</li>
<li><p>在Django中创建的app都有相同的目录结构，但是Django已经用过工具自动生成了，而不必你操心，你只要专注于写代码就好了。</p>
<blockquote>
<p>Projects VS apps<br>项目和app之间有什么不同呢？一个app表示网站程序中的一个功能，譬如，一个网路博客系统，一个公开记录或公共投票的数据库应用。而一个项目(project)往往是app的集合，几个app组成一个project，另外，一个app可以被多个项目包含。</p>
</blockquote>
</li>
<li><p>如果你的python环境已经配置好，那么你的app可以在任何地方创建。这里我们把polls应用创建在manage.py的旁边，所以，它可以被当成自己的顶级模块导入，而不是mysite的子模块。</p>
</li>
<li><p>创建app,请到manage.py所在目录下，执行命令：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$ python manage.py startapp polls</span><br></pre></td></tr></table></figure></li>
<li><p>创建了一个polls目录，结构如下：<br><img src="/img/Django-1-7-3-tutorial/dir-polls.png"></p>
</li>
<li><p>这个目录包含polls应用。</p>
</li>
<li><p>通过Django写数据库网页应用的第一步是定义自己的模块(models)-主要的是，你的数据库布局，加上额外的元数据。</p>
</li>
</ul>
<blockquote>
<p>哲学<br>一个模型是一个独立的，明确的数据资源。它包含主要的字段和你存储的数据的行为。Django遵循<a class="link"   href="https://docs.djangoproject.com/en/1.7/misc/design-philosophies/#dry" >DRY原则<i class="fas fa-external-link-alt"></i></a>。目的是从一个地方定义和导出数据。<br>还包括迁移，不像Ruby On Rails，例如，模型中的数据可以全部迁移，但它只不过是Django中的一个历史记录，可以随时回滚到当前适应的模型。</p>
</blockquote>
<ul>
<li>在简单的投票(polls)应用中，我们创建2个模型：<strong>Question</strong>和<strong>Choice</strong>。<strong>Question</strong>有一个问题和发表日期。<strong>Choice</strong>有两个域：选择文本和投票计数器。每一个<strong>Choice</strong>关联一个<strong>Question</strong>。</li>
<li>这些概念都能通过简单的Python类实现。编辑<strong>polls&#x2F;models.py</strong>文件，如下：</li>
<li><font color="green">polls&#x2F;models.py</font><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> django.db <span class="keyword">import</span> models</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Question</span>(models.Model):</span><br><span class="line">    question_text = models.CharField(max_length=<span class="number">200</span>)</span><br><span class="line">    pub_date = models.DateTimeField(<span class="string">&#x27;date published&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Choice</span>(models.Model):</span><br><span class="line">    question = models.ForeignKey(Question)</span><br><span class="line">    choice_text = models.CharField(max_length=<span class="number">200</span>)</span><br><span class="line">    votes = models.IntegerField(default=<span class="number">0</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li>代码非常简单明了。每个<strong>模型</strong>都是继承类**<a class="link"   href="https://docs.djangoproject.com/en/1.7/ref/models/instances/#django.db.models.Model" >django.db.models.Model<i class="fas fa-external-link-alt"></i></a><strong>。每个</strong>模型<strong>都有一些类变量，其中每个变量都代表数据库中的一个</strong>字段**。</li>
<li>每个<strong>字段</strong>都是一个<strong>字段<a class="link"   href="https://docs.djangoproject.com/en/1.7/ref/models/fields/#django.db.models.Field" >(Field)<i class="fas fa-external-link-alt"></i></a>类</strong>的实例–譬如，<a class="link"   href="https://docs.djangoproject.com/en/1.7/ref/models/fields/#django.db.models.CharField" >CharField<i class="fas fa-external-link-alt"></i></a>代表字符域，<a class="link"   href="https://docs.djangoproject.com/en/1.7/ref/models/fields/#django.db.models.DateTimeField" >DateTimeField<i class="fas fa-external-link-alt"></i></a>代表数据库实时间。这样Django就知道每个字段是什么类型的。</li>
<li>每个域实例的名字(譬如<strong>question_text</strong>或者<strong>pub_date</strong>)就是字段名称，它是机器能够识别的形式。字段的值会用python代码表示，数据库就会把字段名称当成一个列名。</li>
<li>你还可以为每个字段起一个易于让人读懂的名字。在Django中是支持的，而且也可以记录到文档中。如果你美誉定义这个名字，那么Django就会用机器识别的名字。例如，我们只为<strong>Question.pub_date</strong>定义一个易于让人都懂的名字。对于模型中的其他字段，机读和人读的名字是一样的。</li>
<li>一些字段类中有写必需的参数，例如<strong>CharField</strong>，我们必须给它指定一个最大长度**(max_length)**。它不仅仅需要数据库模式，还需要验证的，后面我们就会将到。</li>
<li>一个字段还可以有多个可选的参数，譬如，我们把vote的默认值设为0.</li>
<li>最后，要定义一个关系，用<strong>ForeignKey</strong>，即是外键。它向Django表明每个<strong>Choice</strong>关联一个<strong>Question</strong>。Django支持多种数据库映射关系：多对一，多对多，一对一。</li>
</ul>
<h2 id="激活模型-Activating-models"><a href="#激活模型-Activating-models" class="headerlink" title="激活模型(Activating models)"></a>激活模型(Activating models)</h2><ul>
<li><p>上面一小段代码给了Django很多的信息。通过代码，Django可以做到：</p>
<ul>
<li>为这个app创建一个数据库模式(<strong>CREATE TABLE 语句</strong>)</li>
<li>创建一个Python数据库可用API，用于使用<strong>Question</strong>和<strong>Choice</strong>对象。</li>
</ul>
</li>
<li><p>但是我们先要告知项目polls已经安装了。</p>
<blockquote>
<p><strong>哲学</strong><br>Django的app是可插的(像USB一样，适配多台电脑)：你的app可以插入到多个项目当中，你也可以发布app，这样它(app)就不用绑定到Django中用于安装了。</p>
</blockquote>
</li>
<li><p>再一次编辑<strong>mysite&#x2F;settings.py</strong>文件，然后修改<strong>INSTALLED_APPS</strong>的内容，让它包含’<strong>polls</strong>‘，修改后的文件是：</p>
</li>
<li><p><font color="green">mysite&#x2F;settings.py</font></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">INSTALLED_APPS = (</span><br><span class="line">    <span class="string">&#x27;django.contrib.admin&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;django.contrib.auth&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;django.contrib.contenttypes&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;django.contrib.sessions&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;django.contrib.messages&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;django.contrib.staticfiles&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;polls&#x27;</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure></li>
<li><p>现在Django知道应该包含polls这个app了。让我们运行另外一个命令：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$ python manage.py makemigrations polls</span><br></pre></td></tr></table></figure></li>
<li><p>你应该看到以下的输出：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Migrations for &#x27;polls&#x27;:</span><br><span class="line">  0001_initial.py:</span><br><span class="line">    - Create model Choice</span><br><span class="line">    - Create model Question</span><br><span class="line">    - Add field question to choice</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>通过<strong>makemigrations</strong>口令，你在告诉Django你的模型有了修改(这样，你就新建了一个模型)，你希望修改转存的过程当成迁移。</p>
</li>
<li><p>Migrations记录着你对模型做了什么修改(也即是数据库模式)-它们只是硬盘上的文件。你可以读取你新模型的migration如果你喜欢，它保存在<strong>polls&#x2F;migrations&#x2F;0001_initial.py</strong>文件当中。不要担心，你不需要每当Django创建一个的时候就读取一次，但它还是可编辑的，当你想对它进行修改的时候。</p>
</li>
<li><p>有一个口令可以帮你运行migration并且自动管理你的数据库模式，它是<strong>migrate</strong>，我们就要将到它了，但首先，让我们看一下migration会运行什么样的SQL代码。<strong>sqlmigrate</strong>口令得到migration的名字并且返回它们的SQL。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$ python manage.py sqlmigrate polls 0001</span><br></pre></td></tr></table></figure></li>
<li><p>你应该会看到以下相似的代码：(我们已经把代码格式化了，为了让我们更易读懂它)</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">BEGIN</span>;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> polls_question (</span><br><span class="line">    &quot;id&quot; serial <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">PRIMARY</span> KEY,</span><br><span class="line">    &quot;question_text&quot; <span class="type">varchar</span>(<span class="number">200</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    &quot;pub_date&quot; <span class="type">timestamp</span> <span class="keyword">with</span> <span class="type">time</span> zone <span class="keyword">NOT</span> <span class="keyword">NULL</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> polls_choice (</span><br><span class="line">    &quot;id&quot; serial <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">PRIMARY</span> KEY,</span><br><span class="line">    &quot;question_id&quot; <span class="type">integer</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    &quot;choice_text&quot; <span class="type">varchar</span>(<span class="number">200</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    &quot;votes&quot; <span class="type">integer</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> INDEX polls_choice_7aa0f6ee <span class="keyword">ON</span> &quot;polls_choice&quot; (&quot;question_id&quot;);</span><br><span class="line"></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> &quot;polls_choice&quot;</span><br><span class="line">  <span class="keyword">ADD</span> <span class="keyword">CONSTRAINT</span> polls_choice_question_id_246c99a640fbbd72_fk_polls_question_id</span><br><span class="line">    <span class="keyword">FOREIGN</span> KEY (&quot;question_id&quot;)</span><br><span class="line">    <span class="keyword">REFERENCES</span> &quot;polls_question&quot; (&quot;id&quot;)</span><br><span class="line">    DEFERRABLE INITIALLY DEFERRED;</span><br><span class="line"><span class="keyword">COMMIT</span>;</span><br></pre></td></tr></table></figure></li>
<li><p>注意一下内容：</p>
<ul>
<li>确切的输出会和你用的数据库而有所不同。上面的例子是用PostgreSQL生成的。</li>
<li>表名是自动取app的名字加上模型的名字(小写格式)，如polls_question和polls_choice。(你可以自己更改)</li>
<li>主见(IDs)是自增长的，你也可以自行修改。</li>
<li>按照惯例，Django会在外键字段名字后面加上**_id**,(当然这个你也可以修改)。</li>
<li>外键关系是通过<strong>FOREIGN KEY</strong>这个约束来清晰定义的。不要担心不同的部分，它仅仅是告知PostgreSQL在结束事务之前不要强行实施外键。</li>
<li>它是根据你用的数据库来适配的，所以数据库指定的域类型，好像，自动适配<strong>auto_increment</strong>(MySQL),<strong>serial</strong>(PostgreSQL)，或者<strong>integer primary key autoincrement</strong>(SQLite)，给字段名加引号是一样的，加单引号或双引号。</li>
<li><strong>sqlmigrate</strong>口令并不会真正在你的数据库上运行migtaration-只是把它打印到屏幕上，让你知道Django需要什么SQL。知道Django正在做什么或者你拥有可以修改SQL资格的数据库管理员是非常有用的。</li>
</ul>
</li>
<li><p>如果你有兴趣，你也可以运行<strong>python manage.py check</strong>口令，它会检测你的项目是否有问题或者创建数据库是否顺利。</p>
</li>
<li><p>现在，再次运行<strong>migrate</strong>来创建你数据库上的模型：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Operations to perform:</span><br><span class="line">  Apply <span class="built_in">all</span> migrations: admin, contenttypes, polls, auth, sessions</span><br><span class="line">Running migrations:</span><br><span class="line">  Applying polls<span class="number">.0001</span>_initial... OK</span><br></pre></td></tr></table></figure></li>
<li><p><strong>migrate</strong>口令处理所有那些没被处理的migrations。(Django通过你数据库当中的特殊表<strong>django_migrations</strong>来跟踪那些被处理了或者那些没有处理)</p>
</li>
<li><p><strong>migrations</strong>非常强大，而且当你在开发你的项目时，它可以让你随着时间变化修改你的模型，而不需要删除当前的数据库去创建一个新的。我们稍后再对这部分做深入研究，现在，请记住以下三步来对你的模型进行修改：</p>
<ul>
<li>修改模型(在<strong>models.py</strong>文件中)</li>
<li>运行<strong>python manage.py makemigrations</strong>来为这些修改创建migrations</li>
<li>运行<strong>python manage.py migrate</strong>把这些修改应用(apply)到数据库</li>
</ul>
</li>
<li><p>为什么make和apply这两步要分开执行呢？原因是你要首先提交migrations到你的版本控制系统，然后在把它们和你的app一起执行。这样会不仅会令你的开发更容易，还便于其他的开发者使用和再次开发。</p>
</li>
<li><p>阅读<a class="link"   href="https://docs.djangoproject.com/en/1.7/ref/django-admin/" >django-admin.py documentation<i class="fas fa-external-link-alt"></i></a>得到<strong>manage.py</strong>工具类的更详细的信息。</p>
</li>
</ul>
<h2 id="玩转API"><a href="#玩转API" class="headerlink" title="玩转API"></a>玩转API</h2><ul>
<li>现在，让我们投进可交互的Python shell，玩一下Django提供给我们的免费的API。进入Python Shell，用这个命令：<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$ python manage.py shell</span><br></pre></td></tr></table></figure></li>
<li>我们用python manage.py而不用python的原因是<strong>manage.py</strong>设置了<strong>DJANGO_SETTINGS_MODULE</strong>的环境变量，也就是说，Django和python的路径都加入了你的<strong>mysite&#x2F;settings.py</strong>文件中。</li>
</ul>
<blockquote>
<p><strong>跳过manage.py(Bypassing manage.py)</strong><br>如果你不想使用<strong>manage.py</strong>，没问题，只需要把<strong>DJANGO_SETTINGS_MODULE</strong>的环境变量设置到<strong>mysite.settings</strong>中，新开一个纯净的Python shell，然后设置Django：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> django</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>django.setup()</span><br></pre></td></tr></table></figure>

<blockquote>
<p>如果这样报了一个<strong>AttributeError</strong>错误，那么你现在使用的是一个不匹配的Django版本。请更换不同的Django版本。<br>你必须在manage.py的目录下运行<strong>python</strong>，或者确保你的目录加入了Python路径，这样<strong>import mysite</strong>才起作用。<br>更多详情，请看<a class="link"   href="https://docs.djangoproject.com/en/1.7/ref/django-admin/" >django-admin.py documentation<i class="fas fa-external-link-alt"></i></a></p>
</blockquote>
<ul>
<li><p>当你进入了shell，可以探索[database API](database API:)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">In [<span class="number">1</span>]: <span class="keyword">from</span> polls.models <span class="keyword">import</span> Question, Choice <span class="comment"># Import the model classes we just wrote</span></span><br><span class="line"><span class="comment"># No questions are in the system yet.</span></span><br><span class="line">In [<span class="number">2</span>]: Question.objects.<span class="built_in">all</span>()</span><br><span class="line">Out[<span class="number">2</span>]: []</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a new Question.</span></span><br><span class="line"><span class="comment"># Support for time zones is enabled in the default settings file, so Django experts a datatime with tzinfo for </span></span><br><span class="line"><span class="comment"># pub_date.Use timezone.now()</span></span><br><span class="line"><span class="comment"># Instead of datatime.datetime.now() and it will do the right thing. </span></span><br><span class="line">In [<span class="number">3</span>]: <span class="keyword">from</span> django.utils <span class="keyword">import</span> timezone</span><br><span class="line"></span><br><span class="line">In [<span class="number">4</span>]: q = Question(question_text=<span class="string">&quot;What&#x27;s new?&quot;</span>, pub_date = timezone.now())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Save the object into the database. You have to call save() explicitly.</span></span><br><span class="line">In [<span class="number">5</span>]: q.save()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now it has an ID. Note that this might say &quot;1L&quot; instead of &quot;1&quot;, depending on which database you&#x27;re using. That&#x27;s no biggie; </span></span><br><span class="line"><span class="comment"># it just means your database backend prefers to returns to return integers as Python long integer objects.</span></span><br><span class="line">In [<span class="number">6</span>]: q.<span class="built_in">id</span></span><br><span class="line">Out[<span class="number">6</span>]: <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Access model field values via Python attributes.</span></span><br><span class="line">In [<span class="number">7</span>]: q.question_text</span><br><span class="line">Out[<span class="number">7</span>]: <span class="string">&quot;What&#x27;s new?&quot;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">8</span>]: q.pub_date</span><br><span class="line">Out[<span class="number">8</span>]: datetime.datetime(<span class="number">2015</span>, <span class="number">1</span>, <span class="number">18</span>, <span class="number">2</span>, <span class="number">22</span>, <span class="number">53</span>, <span class="number">431000</span>, tzinfo=&lt;UTC&gt;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Change values by changing the attributes, then calling save().</span></span><br><span class="line">In [<span class="number">9</span>]: q.question_text = <span class="string">&quot;What&#x27;s up?&quot;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">10</span>]: q.save()</span><br><span class="line"></span><br><span class="line"><span class="comment"># objects.all() displays all the questions in the database.</span></span><br><span class="line">In [<span class="number">11</span>]: Question.objects.<span class="built_in">all</span>()</span><br><span class="line">Out[<span class="number">11</span>]: [&lt;Question: Question <span class="built_in">object</span>&gt;]</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>等一下，**&lt;Question: Question object&gt;<strong>似乎对这个对象来说表现很差。我们可以这样来修正它，修改</strong>Question<strong>模型(在</strong>polls&#x2F;models.py<strong>文件中)，为</strong>Question<strong>和</strong>Choice<strong>分别添加一个</strong><strong>unicode</strong>**方法(就像java中重写toString()方法一样)。</p>
</li>
<li><p><font color="green">polls&#x2F;models.py</font></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> django.db <span class="keyword">import</span> models</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Question</span>(models.Model):</span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__unicode__</span>(<span class="params">self</span>):              <span class="comment"># __str__ on Python 3</span></span><br><span class="line">        <span class="keyword">return</span> self.question_text</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Choice</span>(models.Model):</span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__unicode__</span>(<span class="params">self</span>):              <span class="comment"># __str__ on Python 3</span></span><br><span class="line">        <span class="keyword">return</span> self.choice_text</span><br></pre></td></tr></table></figure></li>
<li><p>为你的模型添加__unicode__()方法非常重要，不仅仅方便于你和Python进行交互，还方便通过Django自动生成的管理员对对象的展现。</p>
<blockquote>
<p><strong><strong>str</strong>()方法还是__unicode__()方法</strong><br>在Python 3，就简单的用**<strong>str</strong>()<strong>方法<br>在Python 2中，你应该定义</strong><strong>unicode</strong>()<strong>方法返回的是</strong>unicode<strong>值。Django模型有一个默认的</strong><strong>str</strong>()<strong>方法，它调用了</strong><strong>unicode</strong>()<strong>方法并且把结果转化成了一个UTF-8字节型字符串。也就是说</strong><strong>unicode</strong>(p)<strong>方法返回的是一个Unicode字符串，而</strong>str(p)<strong>返回的是一个字节型的字符串，编码格式是UTF-8。Python刚好相反：</strong>object<strong>有一个</strong><strong>unicode</strong>()<strong>方法，它调用了</strong><strong>str</strong>()**方法，并把结果解释成一个ASCII的字节型的字符串。这些不同很容易混淆。<br>如果你觉得以上内容很混乱，那请直接用Python 3吧。</p>
</blockquote>
</li>
<li><p>看完了一般的Python方法，让我们添加一个自定义的方法，说明一下：</p>
</li>
<li><p><font color="green">polls&#x2F;models.py</font></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> django.db <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> django.utils <span class="keyword">import</span> timezone</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Question</span>(models.Model):</span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">was_published_recently</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.pub_date &gt;= timezone.now() - datetime.timedelta(days=<span class="number">1</span>)</span><br></pre></td></tr></table></figure></li>
<li><p>注意到加入了<strong>import datetime</strong>和<strong>from django.utils import timezone</strong>，请参考Python的标准<strong>datetime</strong>模型和从<strong>django.utils.timezone</strong>中了解到Django相关的时区工具类。如果你还没熟悉控制Python中的时区，你可以参考这里<a class="link"   href="https://docs.djangoproject.com/en/1.7/topics/i18n/timezones/" >time zone support docs<i class="fas fa-external-link-alt"></i></a>。</p>
</li>
<li><p>保存修改后，通过<strong>python manage.py shell</strong>打开一个新的Python shell交互:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> polls.models <span class="keyword">import</span> Question, Choice</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make sure our __str__() addition worked.</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Question.objects.<span class="built_in">all</span>()</span><br><span class="line">[&lt;Question: What<span class="string">&#x27;s up?&gt;]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># Django provides a rich database lookup API that&#x27;</span>s entirely driven by</span><br><span class="line"><span class="comment"># keyword arguments.</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Question.objects.<span class="built_in">filter</span>(<span class="built_in">id</span>=<span class="number">1</span>)</span><br><span class="line">[&lt;Question: What<span class="string">&#x27;s up?&gt;]</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; Question.objects.filter(question_text__startswith=&#x27;</span>What<span class="string">&#x27;)</span></span><br><span class="line"><span class="string">[&lt;Question: What&#x27;</span>s up?&gt;]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get the question that was published this year.</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> django.utils <span class="keyword">import</span> timezone</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>current_year = timezone.now().year</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Question.objects.get(pub_date__year=current_year)</span><br><span class="line">&lt;Question: What<span class="string">&#x27;s up?&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># Request an ID that doesn&#x27;</span>t exist, this will <span class="keyword">raise</span> an exception.</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Question.objects.get(<span class="built_in">id</span>=<span class="number">2</span>)</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">    ...</span><br><span class="line">DoesNotExist: Question matching query does <span class="keyword">not</span> exist.</span><br><span class="line"></span><br><span class="line"><span class="comment"># Lookup by a primary key is the most common case, so Django provides a</span></span><br><span class="line"><span class="comment"># shortcut for primary-key exact lookups.</span></span><br><span class="line"><span class="comment"># The following is identical to Question.objects.get(id=1).</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Question.objects.get(pk=<span class="number">1</span>)</span><br><span class="line">&lt;Question: What<span class="string">&#x27;s up?&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># Make sure our custom method worked.</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; q = Question.objects.get(pk=1)</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; q.was_published_recently()</span></span><br><span class="line"><span class="string">True</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># Give the Question a couple of Choices. The create call constructs a new</span></span><br><span class="line"><span class="string"># Choice object, does the INSERT statement, adds the choice to the set</span></span><br><span class="line"><span class="string"># of available choices and returns the new Choice object. Django creates</span></span><br><span class="line"><span class="string"># a set to hold the &quot;other side&quot; of a ForeignKey relation</span></span><br><span class="line"><span class="string"># (e.g. a question&#x27;</span>s choice) which can be accessed via the API.</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>q = Question.objects.get(pk=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Display any choices from the related object set -- none so far.</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>q.choice_set.<span class="built_in">all</span>()</span><br><span class="line">[]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create three choices.</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>q.choice_set.create(choice_text=<span class="string">&#x27;Not much&#x27;</span>, votes=<span class="number">0</span>)</span><br><span class="line">&lt;Choice: Not much&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>q.choice_set.create(choice_text=<span class="string">&#x27;The sky&#x27;</span>, votes=<span class="number">0</span>)</span><br><span class="line">&lt;Choice: The sky&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = q.choice_set.create(choice_text=<span class="string">&#x27;Just hacking again&#x27;</span>, votes=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Choice objects have API access to their related Question objects.</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c.question</span><br><span class="line">&lt;Question: What<span class="string">&#x27;s up?&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># And vice versa: Question objects get access to Choice objects.</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; q.choice_set.all()</span></span><br><span class="line"><span class="string">[&lt;Choice: Not much&gt;, &lt;Choice: The sky&gt;, &lt;Choice: Just hacking again&gt;]</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; q.choice_set.count()</span></span><br><span class="line"><span class="string">3</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># The API automatically follows relationships as far as you need.</span></span><br><span class="line"><span class="string"># Use double underscores to separate relationships.</span></span><br><span class="line"><span class="string"># This works as many levels deep as you want; there&#x27;</span>s no limit.</span><br><span class="line"><span class="comment"># Find all Choices for any question whose pub_date is in this year</span></span><br><span class="line"><span class="comment"># (reusing the &#x27;current_year&#x27; variable we created above).</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Choice.objects.<span class="built_in">filter</span>(question__pub_date__year=current_year)</span><br><span class="line">[&lt;Choice: Not much&gt;, &lt;Choice: The sky&gt;, &lt;Choice: Just hacking again&gt;]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Let&#x27;s delete one of the choices. Use delete() for that.</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = q.choice_set.<span class="built_in">filter</span>(choice_text__startswith=<span class="string">&#x27;Just hacking&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c.delete()</span><br></pre></td></tr></table></figure></li>
<li><p>关于更多信息，请看</p>
</li>
<li><p>[Accessing related objects](Accessing related objects),</p>
</li>
<li><p><a class="link"   href="https://docs.djangoproject.com/en/1.7/topics/db/queries/#field-lookups-intro" >Field lookups<i class="fas fa-external-link-alt"></i></a>,</p>
</li>
<li><p><a class="link"   href="https://docs.djangoproject.com/en/1.7/topics/db/queries/" >Database API reference<i class="fas fa-external-link-alt"></i></a>.</p>
</li>
<li><p>如果你熟悉了API，那么请读下一篇<a href="">Part2-Django’s automatic admin working</a>.</p>
</li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步-Django</category>
      </categories>
      <tags>
        <tag>Django-Models</tag>
      </tags>
  </entry>
  <entry>
    <title>什么是视觉语言？</title>
    <url>/2024/02/27/%E6%8A%80%E8%83%BD-%E4%BF%AE%E8%A1%8C-%E8%BF%9B%E6%AD%A5-%E5%BD%B1%E8%A7%86%E5%9B%BE%E5%83%8F/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%BC%8F/</url>
    <content><![CDATA[<h2 id="视觉语言-Visual-Language"><a href="#视觉语言-Visual-Language" class="headerlink" title="视觉语言-Visual Language"></a>视觉语言-Visual Language</h2><ul>
<li>定义：视觉语言和书面语言一样，是一种传达信息的方式，是一种视觉传达的方式。</li>
<li>人们常说没有既定的规则，因为通常规则都是用来打破的。(“Rules are meant to be broken.”)，但这是一个谎言，因为在视觉语言中，有很多规则是可以遵循的，这就是所谓的模式(pattern)。</li>
<li>Patterns have implied meanings. 模式是有隐含意义的。</li>
<li>视觉模式的本质就是拍摄的规则的组合。</li>
</ul>
<h2 id="视觉语言的基本元素"><a href="#视觉语言的基本元素" class="headerlink" title="视觉语言的基本元素"></a>视觉语言的基本元素</h2><h3 id="Frame-框架"><a href="#Frame-框架" class="headerlink" title="Frame - 框架"></a>Frame - 框架</h3><ul>
<li>正方形，三角形，圆形等各种框框用来突出主题，这就是框架。</li>
</ul>
<h3 id="Negative-Space-负空间"><a href="#Negative-Space-负空间" class="headerlink" title="Negative Space - 负空间"></a>Negative Space - 负空间</h3><ul>
<li>既然有负空间，那么就有正空间，positive space，正空间是指画面中有主题的地方。</li>
<li>负空间是指画面中除了主题以外的地方，有空白空间(empty space)和填充空间(fulfill space)2种，负空间可以用来辅助突出主题，这就是负空间。</li>
</ul>
<h3 id="Leading-lines-引导线"><a href="#Leading-lines-引导线" class="headerlink" title="Leading lines - 引导线"></a>Leading lines - 引导线</h3><ul>
<li>定义：引导线是指画面中的线条，用来引导观众的视线，这就是引导线。(Elements in your image that direct the viewer’s eye to where you want them to look.)</li>
</ul>
<h3 id="Color-Theory-颜色理论"><a href="#Color-Theory-颜色理论" class="headerlink" title="Color Theory - 颜色理论"></a>Color Theory - 颜色理论</h3><ul>
<li>Hue Saturation Luminosity Temperature (HSL) - 色相 饱和度 亮度 冷暖色 </li>
<li>color model - 色彩模型<ul>
<li>YMCK 通常在打印时使用 - 黄 青 洋红 黑</li>
<li>RGB 通常在数位显示器上使用 - 红 绿 蓝</li>
<li>sRGB 标准RGB</li>
</ul>
</li>
<li>由于不同文化对颜色的理解不同，所以颜色的意义也不同。以下是一些常见的颜色的意义：</li>
<li><img src="/img/wuweiwu/photography/visual-lang/01-color-meaning.jpg" alt="general color meaning"></li>
<li>Color harmoney - 色彩和谐 <a class="link"   href="https://color.adobe.com/create/color-wheel" >adobe color<i class="fas fa-external-link-alt"></i></a><ul>
<li>Analogous - 相似色</li>
<li>Complementary - 互补色</li>
<li>Monochromatic - 单色</li>
</ul>
</li>
</ul>
<h3 id="Constract-对比度"><a href="#Constract-对比度" class="headerlink" title="Constract - 对比度"></a>Constract - 对比度</h3><ul>
<li>tonal contrast - 色调对比</li>
<li>color contrast - 色彩对比</li>
<li>conceptual contrast - 概念对比</li>
</ul>
<h3 id="Visual-hierarchy-视觉层次"><a href="#Visual-hierarchy-视觉层次" class="headerlink" title="Visual hierarchy - 视觉层次"></a>Visual hierarchy - 视觉层次</h3><ul>
<li>内容异常的主观</li>
</ul>
<h3 id="Scale-尺度"><a href="#Scale-尺度" class="headerlink" title="Scale - 尺度"></a>Scale - 尺度</h3><ul>
<li>参考点</li>
</ul>
<h3 id="Composition-and-position-构图和位置"><a href="#Composition-and-position-构图和位置" class="headerlink" title="Composition and position - 构图和位置"></a>Composition and position - 构图和位置</h3><ul>
<li>the rule of thirds - 三分法</li>
<li>angle - 角度</li>
<li>golden ratio - 黄金比例</li>
</ul>
<h3 id="Balance-平衡"><a href="#Balance-平衡" class="headerlink" title="Balance - 平衡"></a>Balance - 平衡</h3><ul>
<li>可以令人放松的组合</li>
</ul>
<h3 id="Pattern-Analysis-模式分析"><a href="#Pattern-Analysis-模式分析" class="headerlink" title="Pattern Analysis - 模式分析"></a>Pattern Analysis - 模式分析</h3><p>- </p>
]]></content>
      <categories>
        <category>技能-修行-进步-影视图像</category>
      </categories>
      <tags>
        <tag>摄影</tag>
        <tag>视觉语言</tag>
      </tags>
  </entry>
  <entry>
    <title>DMwR-note-01-预测海藻数量(二)</title>
    <url>/2014/10/26/%E6%8A%80%E8%83%BD-%E4%BF%AE%E8%A1%8C-%E8%BF%9B%E6%AD%A5-R%E8%AF%AD%E8%A8%80/DMwR-note-01-%E9%A2%84%E6%B5%8B%E6%B5%B7%E8%97%BB%E6%95%B0%E9%87%8F(%E4%BA%8C)/</url>
    <content><![CDATA[<h2 id="写在开头的话"><a href="#写在开头的话" class="headerlink" title="写在开头的话"></a>写在开头的话</h2><hr>
<p>上次的笔记讲了数据的读取，窥探和可视化，这次我们来分析一下数据当中的缺失值。对于缺失值的正确处理也是数据分析当中很重要的一步。</p>
<h2 id="数据缺失"><a href="#数据缺失" class="headerlink" title="数据缺失"></a>数据缺失</h2><hr>
<ul>
<li><p>数据缺失是一种非常普遍的情形，但是有些数据分析的方法无法对缺失值进行处理，这样就会带来问题。</p>
</li>
<li><p>当我们处理含有缺失值的数据时，可以运用一下几种最常见的策略：</p>
<ul>
<li>将含有缺失值的案例剔除</li>
<li>根据变量之间的相关关系填补缺失值</li>
<li>根据案例之间的相似性填补缺失值</li>
<li>使用能够处理缺失值数据的工具</li>
</ul>
</li>
<li><p>在开始之前，我们先在Rstudio中载入包和数据</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">library(DMwR)</span><br><span class="line">data(algae)</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="将缺失部分剔除"><a href="#将缺失部分剔除" class="headerlink" title="将缺失部分剔除"></a>将缺失部分剔除</h3><hr>
<ul>
<li><p>剔除缺失值的操作非常容易实现，特别当缺失值在数据当中所占的比例比较小的时候，这个选择比较合理。</p>
</li>
<li><p>在剔除缺失值之前，我们勿急，最好先检查观测值，或者至少得到这些观测值的个数，</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">algae[!complete.cases(algae),]</span><br><span class="line">    season   size  speed mxPH mnO2    Cl   NO3 NH4    oPO4     PO4  Chla   a1</span><br><span class="line">28  autumn  small   high 6.80 11.1 9.000 0.630  20   4.000      NA  2.70 30.3</span><br><span class="line">38  spring  small   high 8.00   NA 1.450 0.810  10   2.500   3.000  0.30 75.8</span><br><span class="line">48  winter  small    low   NA 12.6 9.000 0.230  10   5.000   6.000  1.10 35.5</span><br><span class="line">55  winter  small   high 6.60 10.8    NA 3.245  10   1.000   6.500    NA 24.3</span><br><span class="line">56  spring  small medium 5.60 11.8    NA 2.220   5   1.000   1.000    NA 82.7</span><br><span class="line">57  autumn  small medium 5.70 10.8    NA 2.550  10   1.000   4.000    NA 16.8</span><br><span class="line">58  spring  small   high 6.60  9.5    NA 1.320  20   1.000   6.000    NA 46.8</span><br><span class="line">59  summer  small   high 6.60 10.8    NA 2.640  10   2.000  11.000    NA 46.9</span><br><span class="line">60  autumn  small medium 6.60 11.3    NA 4.170  10   1.000   6.000    NA 47.1</span><br><span class="line">61  spring  small medium 6.50 10.4    NA 5.970  10   2.000  14.000    NA 66.9</span><br><span class="line">62  summer  small medium 6.40   NA    NA    NA  NA      NA  14.000    NA 19.4</span><br><span class="line">63  autumn  small   high 7.83 11.7 4.083 1.328  18   3.333   6.667    NA 14.4</span><br><span class="line">116 winter medium   high 9.70 10.8 0.222 0.406  10  22.444  10.111    NA 41.0</span><br><span class="line">161 spring  large    low 9.00  5.8    NA 0.900 142 102.000 186.000 68.05  1.7</span><br><span class="line">184 winter  large   high 8.00 10.9 9.055 0.825  40  21.083  56.091    NA 16.8</span><br><span class="line">199 winter  large medium 8.00  7.6    NA    NA  NA      NA      NA    NA  0.0</span><br><span class="line">      a2  a3   a4  a5  a6  a7</span><br><span class="line">28   1.9 0.0  0.0 2.1 1.4 2.1</span><br><span class="line">38   0.0 0.0  0.0 0.0 0.0 0.0</span><br><span class="line">48   0.0 0.0  0.0 0.0 0.0 0.0</span><br><span class="line">55   0.0 0.0  0.0 0.0 0.0 0.0</span><br><span class="line">56   0.0 0.0  0.0 0.0 0.0 0.0</span><br><span class="line">57   4.6 3.9 11.5 0.0 0.0 0.0</span><br><span class="line">58   0.0 0.0 28.8 0.0 0.0 0.0</span><br><span class="line">59   0.0 0.0 13.4 0.0 0.0 0.0</span><br><span class="line">60   0.0 0.0  0.0 0.0 1.2 0.0</span><br><span class="line">61   0.0 0.0  0.0 0.0 0.0 0.0</span><br><span class="line">62   0.0 0.0  2.0 0.0 3.9 1.7</span><br><span class="line">63   0.0 0.0  0.0 0.0 0.0 0.0</span><br><span class="line">116  1.5 0.0  0.0 0.0 0.0 0.0</span><br><span class="line">161 20.6 1.5  2.2 0.0 0.0 0.0</span><br><span class="line">184 19.6 4.0  0.0 0.0 0.0 0.0</span><br><span class="line">199 12.5 3.7  1.0 0.0 0.0 4.9</span><br><span class="line"></span><br><span class="line">nrow(algae[!complete.cases(algae),])</span><br><span class="line">[1] 16</span><br></pre></td></tr></table></figure>
</li>
<li><p>函数complete.cases()产生一个布尔值向量，该向量的元素个数与algae数据框中的行数相同，如果数据框的相应行中不含NA值(即为一个完整的观测值)，函数返回值就是TRUE。“！”逻辑非，因此上述指令显示了含有缺失值的水样记录。</p>
</li>
<li><p>为了从数据框中剔除这16个样本，我们可以这样简单的输入：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">algae1 &lt;- na.omit(algae)</span><br></pre></td></tr></table></figure>
</li>
<li><p>这样我们就剔除了源数据中的所有含有缺失值的记录。但同时问题也浮出来了：数据分析的前提是有效数据越多越好。若果数据中含有缺失值的记录比例不低，那么这种做法会导致剩余数据的分析结果出现很大的偏差；或者另外一种情况，虽然缺失值的记录比例低，但是缺失值记录当中有很多是只是含有一个缺失值的，这样的剔除有点浪费数据，所以，下面我们利用函数找到缺失值记录当中含有缺失值最多的来进行剔除。</p>
</li>
<li><p>例如，观察样本中的数据，我们可以看到第62条和第199条记录中的11个解释变量中有6个是缺失值。我们就来剔除它们。</p>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">algae2 &lt;- algae[-c(62,199),]</span><br></pre></td></tr></table></figure>

<ul>
<li>更进一步的，如果数据量大，单凭肉眼观察是不合理的，所以我们需要找出缺失值较多的记录的下标。下面的代码可以找出海藻数据集中每行数据的缺失值个数：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">algae3 &lt;- apply(algae, 1, <span class="keyword">function</span>(x) <span class="built_in">sum</span>(is.na(x)))</span><br><span class="line">algae3</span><br><span class="line">  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0</span><br><span class="line"> [37] 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 2 2 2 2 2 2 2 6 1 0 0 0 0 0 0 0 0 0</span><br><span class="line"> [73] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</span><br><span class="line">[109] 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</span><br><span class="line">[145] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</span><br><span class="line">[181] 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 6 0</span><br></pre></td></tr></table></figure>

<ul>
<li><p>函数apply()属于R中功能非常强大的一类函数。这类函数又称为元函数，它们可以在某些条件下对对象应用其他函数。对函数apply()而言，它可以把任何其他函数应用到一个多维对象的各个维度上。使用函数apply()时，它把一个函数应用到数据框的每一行。这个被应用的函数在apply()函数的第三个参数给出，对数据框的每一个行都分别调用该函数。</p>
</li>
<li><p>在这个案例中我们使用一个临时函数。它只在调用apply()函数时才存在。另外，函数apply()的第三个也可以是一个“正常”函数的函数名。临时函数的功能室计算对象x中NA的数量。在R中逻辑值TRUE等于数值1，逻辑值FALSE等于0，这意味着当加一个布尔值向量时，得到向量中取值为TRUE的元素的个数。</p>
</li>
<li><p>根据以上代码，可以编写一个程序找出algae中含有给定数目缺失值的行。在本书提供的添加包中有这个函数。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">manyNAs(algae, 0.2)</span><br><span class="line">[1]  62 199</span><br></pre></td></tr></table></figure>
</li>
<li><p>函数manyNAs()的功能是找出缺失值个数大于20%的行。在第二个参数中可以设置一个精确的列数作为界限。因此，用下面的代码就无须知道含有缺失值较多的行的具体数量：</p>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">algae4 &lt;- algae[-manyNAs(algae),]</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>manyNAs()函数的第二个参数的默认值是0.2。</li>
</ul>
<h3 id="用最高频率值来填补缺失值"><a href="#用最高频率值来填补缺失值" class="headerlink" title="用最高频率值来填补缺失值"></a>用最高频率值来填补缺失值</h3><hr>
<ul>
<li><p>填补含有缺失值的记录的另一个方法就是尝试找到这些缺失值最可能的值。同样的，这里有多种策略可供选择，不同策略对逼近程度和算法复杂度的权衡不同。</p>
</li>
<li><p>填补缺失数据最简单和快捷的方法是使用一些代表中心趋势的值。代表中心趋势的值反映了变量分布的最常见值，因此中心趋势值是最自然的选择。有多个代表数据中心趋势的指标，例如，平均值、中位数、众数等。最合适的选择由变量的分布决定。对于接近正态分布来说，所有的观测值都较好地集中在平均值周围，平均值就是最佳的选择。然而，对于偏态分布，或者有离群值的变量来说，选择平均值不好。偏态分布的大部分值都聚集在变量分布的一侧，因此平均值不能作为最常见值的代表。另一方面，离群值(极值)的存在会扭曲平均值，这就导致了平均值不具有代表性的问题。因此，在对变量分布进行检查之前选择平均值作为中心趋势的代表是不明智的例如，某些R的绘图工具。对偏态分布或者有离群值的分布而言，中位数是更好的代表数据中心趋势的指标。</p>
</li>
<li><p>比如，样本algae[48,]中的变量mxPH有缺失值。由于该变量分布近似正态分布，见<a class="link"   href="http://chenyuqing.github.io/2014/10/23/DMwR-note-01-%E9%A2%84%E6%B5%8B%E6%B5%B7%E8%97%BB%E6%95%B0%E9%87%8F/" >DMwR-note-01-预测海藻数量(一)<i class="fas fa-external-link-alt"></i></a>，我们可以选用平均值来填补这个“洞”，计算方法如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">temp &lt;- algae</span><br><span class="line">temp[48,<span class="string">&quot;mxPH&quot;</span>] &lt;- mean(algae<span class="variable">$mxPH</span>, na.rm=T)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p>这里，函数mean()计算数值向量的平均值，参数na.rm&#x3D;T使计算时忽略缺失数据。</p>
</li>
<li><p>大多数时候采用一次填补一列中的所有缺失值而不是像上面那样一行一行地逐个填补。以变量Chla为例，这个变量在第12行上有缺失值。另外，这也是平均值不能代表大多数变量值的一种情况。事实上，Chla的分布偏向较低的数值，并且它有几个极端值，这些都使得平均值不能代表大多数的变量值。因此，我们使用中位数来填补这一类的缺失值：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">temp &lt;- algae</span><br><span class="line">temp[is.na(algae<span class="variable">$Chla</span>), <span class="string">&quot;Chla&quot;</span>] &lt;- median(algae<span class="variable">$Chla</span>, na.rm=T)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p>本书插件包中提供的函数centralInputation()可以用数据的中心趋势值来填补数据集的所有缺失值。岁数值型变量，该函数用中位数；对名义变量，它采用众数。该函数的应用如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">temp &lt;- algae</span><br><span class="line">temp &lt;- temp[-manyNAs(algae),]</span><br><span class="line">temp &lt;- centralInputation(temp)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p>使用无偏方法来寻找最佳数据填补值复杂，对于大型数据挖掘问题可能并不适用。</p>
</li>
</ul>
<h3 id="通过变量的相关关系来填补缺失值"><a href="#通过变量的相关关系来填补缺失值" class="headerlink" title="通过变量的相关关系来填补缺失值"></a>通过变量的相关关系来填补缺失值</h3><hr>
<ul>
<li><p>另一种获取缺失值较少偏差估计值的方法是探寻变量之间的相关关系。比如，听过变量值之间的相关关系，能够发现某变量与mxPH高度相关。这可以使我们得到含有缺失值的第48条样本更可能的填补值。这比之前使用平均值的方法将更胜一筹。</p>
</li>
<li><p>应用如下命令来得到变量间的相关值：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">temp &lt;- algae</span><br><span class="line">cor(temp[, 4:18], use = <span class="string">&quot;complete.obs&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p>函数cor()的功能室产生变量之间的相关值矩阵(因为前3个变量时名义变量，所以计算相关值时不考虑它们)。设定参数use &#x3D; “complete.obs”时，R在计算相关值时忽略含有NA的记录。相关值在1（或-1）周围表示相应的两个变量之间的强正（或负）线性相关关系。然后其他R函数可以得到变量间相关的近似函数形式，它可以让我们通过一个变量的值计算出另一个变量的值</p>
</li>
<li><p>函数cor()的输出结果并不是很清晰，但可以通过symnum()来改善结果的输出形式，例如：</p>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">temp &lt;- algae</span><br><span class="line">symnum(cor(temp[, 4:18], use = <span class="string">&quot;complete.obs&quot;</span>))</span><br><span class="line">     mP mO Cl NO NH o P Ch a1 a2 a3 a4 a5 a6 a7</span><br><span class="line">mxPH 1                                         </span><br><span class="line">mnO2    1                                      </span><br><span class="line">Cl         1                                   </span><br><span class="line">NO3           1                                </span><br><span class="line">NH4           ,  1                             </span><br><span class="line">oPO4    .  .        1                          </span><br><span class="line">PO4     .  .        * 1                        </span><br><span class="line">Chla .                  1                      </span><br><span class="line">a1         .        . .    1                   </span><br><span class="line">a2   .                  .     1                </span><br><span class="line">a3                               1             </span><br><span class="line">a4      .           . .             1          </span><br><span class="line">a5                                     1       </span><br><span class="line">a6            .  .                     .  1    </span><br><span class="line">a7                                           1 </span><br><span class="line">attr(,<span class="string">&quot;legend&quot;</span>)</span><br><span class="line">[1] 0 <span class="string">&#x27; &#x27;</span> 0.3 <span class="string">&#x27;.&#x27;</span> 0.6 <span class="string">&#x27;,&#x27;</span> 0.8 <span class="string">&#x27;+&#x27;</span> 0.9 <span class="string">&#x27;*&#x27;</span> 0.95 <span class="string">&#x27;B&#x27;</span> 1</span><br></pre></td></tr></table></figure>

<ul>
<li>这种用符号表示相关值的方法更为清晰，特别是对于大的相关矩阵。</li>
<li>在本案例中，大多数变量之间是不相关的。然而，有2个例外：变量NH4和NO3之间，变量PO4和oPO4之间。后两者之间的相关值很高（大于0.9）。变量NH4和NO3之间的相关性不是特别明显（为0.72），因此根据他们来确定缺失数据是很危险的。此外，因为样本62和样本199有太多的变量含有缺失值，所以如果剔除它们，样本中的变量NH4和NO3就没有缺失值了。至于变量PO4和oPO4，它们之间相关性可以帮助填补这两个变量的缺失值。为了达到这个目标，我们需要找到这两个变量之间的线性关系，方法如下：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">temp &lt;- algae</span><br><span class="line">temp &lt;- temp[-manyNAs(temp),]</span><br><span class="line">lm(PO4 ~ oPO4, data = temp)</span><br><span class="line"></span><br><span class="line">Call:</span><br><span class="line">lm(formula = PO4 ~ oPO4, data = temp)</span><br><span class="line"></span><br><span class="line">Coefficients:</span><br><span class="line">(Intercept)         oPO4  </span><br><span class="line">     42.897        1.293 </span><br></pre></td></tr></table></figure>

<ul>
<li><p>函数lm()可以用来获取形如Y&#x3D;β0+β1χ1+…+βnχn的线性模型。上述结果得到的线性模型是：PO4 &#x3D; 42.897 + 1.293 * oPO4。如果这两个变量不是同是有缺失值，那么通过这个模型计算这些变量的缺失值。</p>
</li>
<li><p>在剔除样本62和样本199后，还剩下一个样本（样本28）在变量PO4上有缺失值，可以简单地使用上面的线性关系计算缺失值的填补值：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">temp &lt;- algae</span><br><span class="line">temp[28, <span class="string">&quot;PO4&quot;</span>] &lt;- 42.897 + 1.293 * temp[28, <span class="string">&quot;oPO4&quot;</span>]</span><br></pre></td></tr></table></figure>
</li>
<li><p>然而，为了说明这个方法，我们假设变量PO4有很多个缺失值。如何使用上述的线性关系计算所有的缺失值呢？最好的方法就是构造一个函数，它可以根据给定的oPO4的值就是PO4的值，然后对所有缺失值应用这个函数。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">temp &lt;- algae</span><br><span class="line">temp &lt;- temp[-manyNAs(temp),]</span><br><span class="line">fillPO4 &lt;- <span class="keyword">function</span>(oP) &#123;</span><br><span class="line">	<span class="keyword">if</span>(is.na(oP))</span><br><span class="line">		<span class="built_in">return</span>(NA)</span><br><span class="line">	<span class="keyword">else</span> <span class="built_in">return</span>(42.897+1.293*oP)</span><br><span class="line">&#125;</span><br><span class="line">temp[is.na(temp<span class="variable">$PO4</span>), <span class="string">&quot;PO4&quot;</span>] &lt;- sapply(temp[is.na(temp<span class="variable">$PO4</span>),<span class="string">&quot;PO4&quot;</span>], fillPO4)</span><br></pre></td></tr></table></figure>
</li>
<li><p>上面代码中创建了一个叫做fillPO4()的函数，该函数有一个参数来接受变量oPO4的值，通过这个值，根据模型计算对应的PO4的值。然后，将这个函数应用到变量PO4有缺失值的所有样本中。这个过程可以通过另外一个元函数sapply()来实现。函数sapply()的第一个参数是一个向量，第二个参数为一个函数，返回的结果是另一个向量，该向量和第一个参数有相同的长度，向量中的元素为sapply()中第一个向量中的每一个元素作为参数传递到第二个函数后返回的结果。这意味着sapply()的结果将是填补变量PO4缺失值的向量。</p>
</li>
<li><p>对线性关系的研究使我们能够填充一些新的缺失值。然而，还有几个观测值含有缺失值。可以试探着探索案例数据中含有缺失值的变量和名义变量之间的关系。这可以通过应用R添加包lattice中的函数来绘制条件直方图来进行。代码如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">temp &lt;- algae</span><br><span class="line">histogram(~mxPH|season, data = temp)</span><br></pre></td></tr></table></figure>
<p>Pot:<br><img src="/img/DMwR/02_algae_NA/01_mxPH_season.PNG"></p>
</li>
<li><p>上面代码绘制在不同季节变量mxPH的直方图。每个直方图对应于某个季节的观测值数据。注意，上图的季节顺序不是按照自然的时间顺序，可以转换数据框中因子季节标签的顺序，这样可以使图形中的季节值为自然顺序。代码如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">temp &lt;- algae</span><br><span class="line">temp<span class="variable">$season</span> &lt;- <span class="built_in">factor</span>(temp<span class="variable">$season</span>, levels = c(<span class="string">&quot;spring&quot;</span>, <span class="string">&quot;summer&quot;</span>, <span class="string">&quot;autumn&quot;</span>, <span class="string">&quot;winter&quot;</span>))</span><br><span class="line">histogram(~mxPH|season, data = temp)</span><br></pre></td></tr></table></figure>
<p>Pot:<br><img src="/img/DMwR/02_algae_NA/02_mxPH_season.PNG"></p>
</li>
<li><p>由图看出，季节对mxPH的值没有显著的影响。</p>
</li>
</ul>
<h3 id="通过探索案例之间的相似性来填补缺失值"><a href="#通过探索案例之间的相似性来填补缺失值" class="headerlink" title="通过探索案例之间的相似性来填补缺失值"></a>通过探索案例之间的相似性来填补缺失值</h3><ul>
<li><p>不同于探索数据集列（变量）之间的相关性，本节尝试使用行（观测值）之间的相似性来填补缺失值。我们可以使用这种方法来填补除去那两个含有太多NA值的样本外的其他缺失数据。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">temp &lt;- algae</span><br><span class="line">temp &lt;- temp[-manyNAs(temp),]</span><br></pre></td></tr></table></figure>
</li>
<li><p>本节所描述的方法假设如果两个水样是相似的，其中一个水样在某些变量上有缺失值，那么该缺失值很可能与另外一个水样的值是相似的。为了使用这种直观的方法，首先定义相似性的概念。相似性经常由描述观察值的多元度量空间的变量所定义。在文献中有许多度量相似性的指标，常用的就是欧氏距离。这个距离可以非正式地定义为任何两个案例的观测值之差的平方和。计算公式如下：<br><img src="/img/DMwR/02_algae_NA/03_formular.PNG"></p>
</li>
<li><p>下面描述的方法将使用这种度量来寻找与任何含有缺失值的案例最相似的10个水样，并用它们来填补缺失值。我们考虑两种应用这些值的方法。第一种方法简单地计算着10个最相近的案例的中位数并用这个中位数来填补缺失值。如果缺失值是名义变量（本案例的algae数据不存在这种情况），我们采用这10个最相似数据中出现次数最多的值（众数）。第二种方法采用这些相似数据的加权均值。权重的大小随着距待填补缺失值的个案的距离增大而减小。这里用高斯核函数从距离获得权重。如果相邻个案距待填补缺失值的个案的距离为d，则它的值在加权平均重的权重为：<br><img src="/img/DMwR/02_algae_NA/04_formular.PNG"></p>
</li>
<li><p>上面的方法可以通过本书添加包中的函数knnImputation()来实现。这个函数用一个欧氏距离的变种来找到距任何个案最近的k个邻居。这个变种的欧氏距离可以应用于同时含有名义变量和数值变量的数据集中。计算公式如下：<br><img src="/img/DMwR/02_algae_NA/05_formular.PNG"></p>
</li>
<li><p>其中δi是变量i的两个值之间的距离，即<br><img src="/img/DMwR/02_algae_NA/06_formular.PNG"></p>
</li>
<li><p>在计算距离时，一般要对数值变量进行标准化，即<br><img src="/img/DMwR/02_algae_NA/07_formular.PNG"></p>
</li>
<li><p>下面说明如何使用knnImputation()函数。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">temp &lt;- algae</span><br><span class="line">temp &lt;- knnImputation(temp, k -10)</span><br></pre></td></tr></table></figure>
</li>
<li><p>吐过用中位数来填补缺失值，可以使用如下代码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">temp &lt;- algae</span><br><span class="line">temp &lt;- knnImputation(temp, k = 10, meth = <span class="string">&quot;median&quot;</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>总之，通过这些简单的操作，数据集中不在含有NA值（缺失值），为使用R的其他函数进行分析做好充分的准备工作。</p>
</li>
</ul>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><hr>
<ul>
<li>本节主要讨论了数据缺失值的处理，缺失值少的时候可以直接删除，但是当缺失值比较多的时候，然后会影响到整个数据集的正确性时，就要考虑用相关性或相似性来处理了。</li>
<li>本次博文是根据《数据挖掘与R语言(Luis Torgo著)》这本书的内容而写的笔记，本博文中所涉及的内容版权均归原作者所有。</li>
<li>下节讨论的主题是数据的建模。</li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步-R语言</category>
      </categories>
      <tags>
        <tag>数据挖掘与R语言-案例学习</tag>
      </tags>
  </entry>
  <entry>
    <title>DMwR-note-01-预测海藻数量(一)</title>
    <url>/2014/10/23/%E6%8A%80%E8%83%BD-%E4%BF%AE%E8%A1%8C-%E8%BF%9B%E6%AD%A5-R%E8%AF%AD%E8%A8%80/DMwR-note-01-%E9%A2%84%E6%B5%8B%E6%B5%B7%E8%97%BB%E6%95%B0%E9%87%8F(%E4%B8%80)/</url>
    <content><![CDATA[<h2 id="问题描述与目标"><a href="#问题描述与目标" class="headerlink" title="问题描述与目标"></a>问题描述与目标</h2><hr>
<p><strong>描述：</strong>有害藻类的高浓度会对河流生态环境造成强大的破坏，所以对有害藻类的数量进行预测对提高河流质量有很重要的意义。   </p>
<p><strong>目标：</strong>影响藻类繁殖的因素有什么特征。  </p>
<h2 id="数据说明"><a href="#数据说明" class="headerlink" title="数据说明"></a>数据说明</h2><hr>
<p>本案例有2个数据集：训练集和测试集</p>
<p>变量说明： </p>
<ul>
<li><p><strong>名义变量</strong></p>
<ul>
<li>season ： 季节</li>
<li>size : 河流规模</li>
<li>speed ： 流速</li>
</ul>
</li>
<li><p><strong>数值变量</strong></p>
<ul>
<li>mxPH : 最大PH值</li>
<li>mnO2 : 最小含氧量</li>
<li>Cl : 平均氯化物含量</li>
<li>NO3 ： 平均硝酸盐含量</li>
<li>NH4 ： 平均氨含量</li>
<li>oPO4 ： 平均正磷酸盐含量</li>
<li>PO4 ： 平均硝酸盐含量</li>
<li>Chla ： 平均叶绿素含量</li>
</ul>
</li>
</ul>
<p><a class="link"   href="https://archive.ics.uci.edu/ml/datasets/Coil+1999+Competition+Data" >UCI机器学习algae数据说明链接<i class="fas fa-external-link-alt"></i></a></p>
<h2 id="数据加载到R"><a href="#数据加载到R" class="headerlink" title="数据加载到R"></a>数据加载到R</h2><hr>
<p>本例直接下载”DMwR”包，然后载入R空间，就可以得到一个algae的数据框。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&gt; library(<span class="string">&quot;DMwR&quot;</span>, lib.loc=<span class="string">&quot;e:/R/R-3.1.1/library&quot;</span>)</span><br><span class="line">Loading required package: lattice</span><br><span class="line">Loading required package: grid</span><br><span class="line">&gt; <span class="built_in">head</span>(algae)</span><br><span class="line">  season  size  speed mxPH mnO2     Cl    NO3     NH4</span><br><span class="line">1 winter small medium 8.00  9.8 60.800  6.238 578.000</span><br><span class="line">2 spring small medium 8.35  8.0 57.750  1.288 370.000</span><br><span class="line">3 autumn small medium 8.10 11.4 40.020  5.330 346.667</span><br><span class="line">4 spring small medium 8.07  4.8 77.364  2.302  98.182</span><br><span class="line">5 autumn small medium 8.06  9.0 55.350 10.416 233.700</span><br><span class="line">6 winter small   high 8.25 13.1 65.750  9.248 430.000</span><br><span class="line">     oPO4     PO4 Chla   a1   a2   a3  a4   a5   a6  a7</span><br><span class="line">1 105.000 170.000 50.0  0.0  0.0  0.0 0.0 34.2  8.3 0.0</span><br><span class="line">2 428.750 558.750  1.3  1.4  7.6  4.8 1.9  6.7  0.0 2.1</span><br><span class="line">3 125.667 187.057 15.6  3.3 53.6  1.9 0.0  0.0  0.0 9.7</span><br><span class="line">4  61.182 138.700  1.4  3.1 41.0 18.9 0.0  1.4  0.0 1.4</span><br><span class="line">5  58.222  97.580 10.5  9.2  2.9  7.5 0.0  7.5  4.1 1.0</span><br><span class="line">6  18.250  56.667 28.4 15.1 14.6  1.4 0.0 22.5 12.6 2.9</span><br></pre></td></tr></table></figure>

<ul>
<li>数据框可以看做一种有列名称的矩阵或者表格，它是存储R数据表的一种理想的数据结构。函数head讲显示数据框的前6行。</li>
</ul>
<h2 id="数据可视化和摘要"><a href="#数据可视化和摘要" class="headerlink" title="数据可视化和摘要"></a>数据可视化和摘要</h2><hr>
<h3 id="探索性数据分析-summary"><a href="#探索性数据分析-summary" class="headerlink" title="探索性数据分析-summary"></a>探索性数据分析-summary</h3><p>在没有充分了解数据之前，我们可以首先了解一下数据的统计特性。R中提供了一个非常便利的函数summary，下面我们从探索性数据分析着手进行分析。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&gt; summary(algae)</span><br><span class="line">    season       size       speed         mxPH      </span><br><span class="line"> autumn:40   large :45   high  :84   Min.   :5.600  </span><br><span class="line"> spring:53   medium:84   low   :33   1st Qu.:7.700  </span><br><span class="line"> summer:45   small :71   medium:83   Median :8.060  </span><br><span class="line"> winter:62                           Mean   :8.012  </span><br><span class="line">                                     3rd Qu.:8.400  </span><br><span class="line">                                     Max.   :9.700  </span><br><span class="line">                                     NA<span class="string">&#x27;s   :1      </span></span><br><span class="line"><span class="string">      mnO2              Cl               NO3        </span></span><br><span class="line"><span class="string"> Min.   : 1.500   Min.   :  0.222   Min.   : 0.050  </span></span><br><span class="line"><span class="string"> 1st Qu.: 7.725   1st Qu.: 10.981   1st Qu.: 1.296  </span></span><br><span class="line"><span class="string"> Median : 9.800   Median : 32.730   Median : 2.675  </span></span><br><span class="line"><span class="string"> Mean   : 9.118   Mean   : 43.636   Mean   : 3.282  </span></span><br><span class="line"><span class="string"> 3rd Qu.:10.800   3rd Qu.: 57.824   3rd Qu.: 4.446  </span></span><br><span class="line"><span class="string"> Max.   :13.400   Max.   :391.500   Max.   :45.650  </span></span><br><span class="line"><span class="string"> NA&#x27;</span>s   :2        NA<span class="string">&#x27;s   :10        NA&#x27;</span>s   :2       </span><br><span class="line">      NH4                oPO4             PO4        </span><br><span class="line"> Min.   :    5.00   Min.   :  1.00   Min.   :  1.00  </span><br><span class="line"> 1st Qu.:   38.33   1st Qu.: 15.70   1st Qu.: 41.38  </span><br><span class="line"> Median :  103.17   Median : 40.15   Median :103.29  </span><br><span class="line"> Mean   :  501.30   Mean   : 73.59   Mean   :137.88  </span><br><span class="line"> 3rd Qu.:  226.95   3rd Qu.: 99.33   3rd Qu.:213.75  </span><br><span class="line"> Max.   :24064.00   Max.   :564.60   Max.   :771.60  </span><br><span class="line"> NA<span class="string">&#x27;s   :2          NA&#x27;</span>s   :2        NA<span class="string">&#x27;s   :2       </span></span><br><span class="line"><span class="string">      Chla               a1              a2        </span></span><br><span class="line"><span class="string"> Min.   :  0.200   Min.   : 0.00   Min.   : 0.000  </span></span><br><span class="line"><span class="string"> 1st Qu.:  2.000   1st Qu.: 1.50   1st Qu.: 0.000  </span></span><br><span class="line"><span class="string"> Median :  5.475   Median : 6.95   Median : 3.000  </span></span><br><span class="line"><span class="string"> Mean   : 13.971   Mean   :16.92   Mean   : 7.458  </span></span><br><span class="line"><span class="string"> 3rd Qu.: 18.308   3rd Qu.:24.80   3rd Qu.:11.375  </span></span><br><span class="line"><span class="string"> Max.   :110.456   Max.   :89.80   Max.   :72.600  </span></span><br><span class="line"><span class="string"> NA&#x27;</span>s   :12                                        </span><br><span class="line">       a3               a4               a5        </span><br><span class="line"> Min.   : 0.000   Min.   : 0.000   Min.   : 0.000  </span><br><span class="line"> 1st Qu.: 0.000   1st Qu.: 0.000   1st Qu.: 0.000  </span><br><span class="line"> Median : 1.550   Median : 0.000   Median : 1.900  </span><br><span class="line"> Mean   : 4.309   Mean   : 1.992   Mean   : 5.064  </span><br><span class="line"> 3rd Qu.: 4.925   3rd Qu.: 2.400   3rd Qu.: 7.500  </span><br><span class="line"> Max.   :42.800   Max.   :44.600   Max.   :44.400  </span><br><span class="line">                                                   </span><br><span class="line">       a6               a7        </span><br><span class="line"> Min.   : 0.000   Min.   : 0.000  </span><br><span class="line"> 1st Qu.: 0.000   1st Qu.: 0.000  </span><br><span class="line"> Median : 0.000   Median : 1.000  </span><br><span class="line"> Mean   : 5.964   Mean   : 2.495  </span><br><span class="line"> 3rd Qu.: 6.925   3rd Qu.: 2.400  </span><br><span class="line"> Max.   :77.600   Max.   :31.600  </span><br></pre></td></tr></table></figure>

<ul>
<li>由结果可知，summary的作用是：<ul>
<li>名义变量（R中用因子来表示）：统计数据中该变量某个值的频数。譬如，季节(season)当中秋季(autumn)出现的次数是40。</li>
<li>数值变量：summary为我们提供了均值、中位数、四分位数、极值等一系列的统计信息。譬如，最大的PH值(mxPH)当中，最小值是5.600，最大值是9.700，中位数是8.060，第一个四分位数(1st Qu)，即数据排序后25%的地方，是7.700，第三个四分位数(3st Qu)，即数据排序后75%的地方，是8.400，还有缺失值(NA)的个数是1.000。</li>
</ul>
</li>
</ul>
<h3 id="数据分布状况-hist"><a href="#数据分布状况-hist" class="headerlink" title="数据分布状况-hist"></a>数据分布状况-hist</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&gt; hist(algae<span class="variable">$mxPH</span>, prob = T)</span><br></pre></td></tr></table></figure>
<p>plot：<br><img src="/img/DMwR/02_algae/01-hist.PNG"></p>
<ul>
<li>该指令绘制变量mxPH的直方图。设置参数pro&#x3D;T，我们可以得到每个取值区间的概率，如果该参数设置为FALSE或者忽略该参数，它将给出频数。</li>
<li>由图中观察，变量mxPH的分布非常接近正态分布，它的值大部分聚集在该均值的周围。我们通过QQ图来检验该变量是否为正态分布。</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">library(<span class="string">&quot;car&quot;</span>, lib.loc=<span class="string">&quot;e:/R/R-3.1.1/library&quot;</span>)</span><br><span class="line">par(mfrow=c(1,2))</span><br><span class="line">hist(algae<span class="variable">$mxPH</span>,prob = T, xlab=<span class="string">&#x27;&#x27;</span>,</span><br><span class="line">     main=<span class="string">&quot;Histogram of maximun pH value&quot;</span>, ylim=0:1)</span><br><span class="line">lines(density(algae<span class="variable">$mxPH</span>, na.rm = T))</span><br><span class="line">rug(jitter(algae<span class="variable">$mxPH</span>))</span><br><span class="line">qqplot(algae<span class="variable">$mxPH</span>, main=<span class="string">&quot;Normal QQ plot of maximum pH&quot;</span>)</span><br><span class="line">par(mfrow=c(1,1))</span><br></pre></td></tr></table></figure>
<p>plot：<br><img src="/img/DMwR/02_algae/02-hist-qqplot.PNG"></p>
<ul>
<li>左图中的曲线是平滑版本的直方图，而在X轴上密密麻麻的小直线就是变量的实际值，利用它我们可以识别出离群点。譬如，小于6的两个奇异点。</li>
<li>右图是<a class="link"   href="http://en.wikipedia.org/wiki/Q%E2%80%93Q_plot" >Q-Q图<i class="fas fa-external-link-alt"></i></a>，图中黑色实线是正态分布的理论分位数，而散点图就是实际变量值的描述。另外，虚线组成的区域就是符合正态分布的95%置信区间的带状图。由图可知，变量有几个小的值明显在95%的置信区间之外，它们不服从正态分布。</li>
</ul>
<h3 id="数据分布状况的另一种展示-箱型图"><a href="#数据分布状况的另一种展示-箱型图" class="headerlink" title="数据分布状况的另一种展示-箱型图"></a>数据分布状况的另一种展示-箱型图</h3><p>百度百科：<a class="link"   href="http://baike.baidu.com/view/1376547.htm?fr=aladdin" >箱型图<i class="fas fa-external-link-alt"></i></a></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">boxplot(algae<span class="variable">$oPO4</span>, ylab = <span class="string">&quot;Orthophosphate(oPO4)&quot;</span>)</span><br><span class="line">rug(jitter(algae<span class="variable">$oPO4</span>),side=2)</span><br><span class="line">abline(h = mean(algae<span class="variable">$oPO4</span>, na.rm = T), lty = 2)</span><br></pre></td></tr></table></figure>
<p>plot:<br><img src="/img/DMwR/02_algae/03-boxplot.PNG"></p>
<h3 id="lattice版本的箱图-bwplot"><a href="#lattice版本的箱图-bwplot" class="headerlink" title="lattice版本的箱图-bwplot"></a>lattice版本的箱图-bwplot</h3><p>条件绘图室依赖于某个特定因子的图形表示。因子是一个取值为有限集合的名义的变量。例如，对于变量size的不同取值，可以绘制变量a1的一组箱图。每个箱图是对应于变量size的某个特定值的水样子集。通过这些箱图可以研究名义变量size如何影响变量a1值的分布。   </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">library(lattice)</span><br><span class="line">bwplot(size ~ a1, data = algae, ylab=<span class="string">&#x27;River Size&#x27;</span>, xlab=<span class="string">&#x27;Algal A1&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>plot：<br><img src="/img/DMwR/02_algae/04-bwplot.PNG"></p>
<ul>
<li>由上图可知，在规模较小的河流中，海藻a1的频率较高，这是很有用的信息。</li>
</ul>
<h3 id="Hmisc版本的箱图-bwplot"><a href="#Hmisc版本的箱图-bwplot" class="headerlink" title="Hmisc版本的箱图-bwplot"></a>Hmisc版本的箱图-bwplot</h3><p>分位箱图</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">library(Hmisc)</span><br><span class="line">bwplot(size ~ a1, data = algae, panel = panel.bpplot,</span><br><span class="line">       probs=<span class="built_in">seq</span>(.01,.49,by=.01), datadensity = TRUE,</span><br><span class="line">       ylab = <span class="string">&#x27;River Size&#x27;</span>, xlab = <span class="string">&#x27;Algal A1&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>plot：<br><img src="/img/DMwR/02_algae/05-bwplot.PNG"></p>
<ul>
<li>图中的点代表均值，而图中的竖线分别代表变量的第一个分位数、中位数和第三个分位数。图中的小竖线代表数据的真实取值，这些值的分布则由分位数图来体现。分位数箱图比上一个箱图提供了更多的信息。</li>
<li>我们可以得到以下结论：小型的河流有更高频率的海藻，但我们也观察到小型河流的海藻频率的分布比其他类型的河流频率的分布分散。</li>
</ul>
<h3 id="Hmisc版本的升级箱图-多个变量"><a href="#Hmisc版本的升级箱图-多个变量" class="headerlink" title="Hmisc版本的升级箱图-多个变量"></a>Hmisc版本的升级箱图-多个变量</h3><p>这种类型的条件绘图不局限于名义变量，也不局限于单个因子。只要先把连续变量“离散化”，也同样可以进行条件绘图。下面给出一个两个因子条件绘图的例子。考虑变量a3在给定变量season和变量mnO2下的条件绘图，变量mnO2是一个连续变量，绘图代码如下所示：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">minO2 &lt;- equal.count(na.omit(algae<span class="variable">$mnO2</span>),number=4, overlap=1/5)</span><br><span class="line">stripplot(season ~ a3|minO2,</span><br><span class="line">          data = algae[!is.na(algae<span class="variable">$mnO2</span>),])</span><br></pre></td></tr></table></figure>
<p>plot：<br><img src="/img/DMwR/02_algae/06-stripplot.PNG"></p>
<ul>
<li>第一行调用equal.count()对连续变量mnO2离散化，把该变量转换为因子类型。参数number设置需要的区间个数，参数overlap设置两个区间之间的靠近边界的重合(这意味着某些观测值将被分配到相邻的区间中)。每个区间的观测值的个数相等。注意，变量algae$mnO2中含有NA值，所以上面的指令中没有直接应用该变量，否则会导致其后的绘图函数出错。函数na.omit()可以用来剔除向量中的任何NA值。</li>
<li>第二行调用绘图函数stripplot()，该函数是lattice包中的一个绘图函数，它根据另一个变量(这里是season)把变量的实际值绘制到不同的图形。这些区间按照从左到右，从下到上的顺序排列。即与左下方的图形相对应的是较小的mnO2值。变量mnO2中的NA值也会对图形的绘制产生影响。不能像绘制上图中那样直接应用参数data&#x3D;algae，而应该先剔除水样中变量mnO2含有NA值才行。</li>
<li>所以，下一次的笔记是针对缺失值的处理的。</li>
</ul>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><hr>
<p>本次博文是根据《数据挖掘与R语言(Luis Torgo著)》这本书的内容而写的笔记，本博文中所涉及的内容版权均归原作者所有。</p>
<ul>
<li>下节讨论的主题是数据缺失值的处理。</li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步-R语言</category>
      </categories>
      <tags>
        <tag>数据挖掘与R语言-案例学习</tag>
      </tags>
  </entry>
  <entry>
    <title>DMwR-note-01-预测海藻数量(四)</title>
    <url>/2014/10/28/%E6%8A%80%E8%83%BD-%E4%BF%AE%E8%A1%8C-%E8%BF%9B%E6%AD%A5-R%E8%AF%AD%E8%A8%80/DMwR-note-01-%E9%A2%84%E6%B5%8B%E6%B5%B7%E8%97%BB%E6%95%B0%E9%87%8F(%E5%9B%9B)/</url>
    <content><![CDATA[<h2 id="写在开头的话"><a href="#写在开头的话" class="headerlink" title="写在开头的话"></a>写在开头的话</h2><hr>
<ul>
<li>Ok，上一节我们利用多元回归和回归树两种方法建立了数据模型，那么数据模型可不可靠呢？这一节的任务就是对模型进行评估。</li>
</ul>
<h2 id="模型的评价和选择"><a href="#模型的评价和选择" class="headerlink" title="模型的评价和选择"></a>模型的评价和选择</h2><hr>
<ul>
<li>上一节给出了本案例的两个预测模型的例子。最明显的问题是，应该使用哪一个模型来获得7种海藻的140个测试样品的预测。为了回答这个问题，需要在可供选择的模型空间中指定一些模型的偏好标准，也就是说，需要详细说明应该如何评价模型的性能。</li>
<li>有多种评价(和比较)模型的标准。其中最流行的标准是计算模型的预测性能。当然还有其他衡量的标准，例如模型的可解释性，还有对大型数据挖掘特别重要的标准，即模型的计算效率。</li>
</ul>
<h3 id="预测函数predict"><a href="#预测函数predict" class="headerlink" title="预测函数predict()"></a>预测函数predict()</h3><ul>
<li>回归模型的预测性能是通过将目标变量的预测值与实际值进行比较得到的，并从这些比较中计算某些平均误差的度量。一种度量方法是平均绝对误差(MAE)。下面描述如何获得线性回归和回归树的平均绝对误差。第一步，获取需要评价模型预测性能的测试集个案的预测值。在R中，要获得任何模型的预测，就要使用函数predict()进行预测。函数predict()是一个泛型函数，它的一个参数为需要应用的模型，另一个参数为数据的测试集，输出结果为相应的模型预测值：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lm.predictions.a1 &lt;- predict(final.lm, clean.algae)</span><br><span class="line">rt.predictions.a1 &lt;- predict(rt.a1, algae)</span><br></pre></td></tr></table></figure></li>
<li>上面连个命令得到预测海藻a1的两个模型的预测值。注意，因为原始训练集数据含有缺失值，所以在线性回归模型中使用的是数据框clean.algae。</li>
</ul>
<h3 id="平均绝对误差-MAE"><a href="#平均绝对误差-MAE" class="headerlink" title="平均绝对误差(MAE)"></a>平均绝对误差(MAE)</h3><ul>
<li>得到模型的预测值后，就可以计算出其平均绝对误差：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 计算平均绝对误差</span></span><br><span class="line">(mae.a1.lm &lt;- mean(abs(lm.predictions.a1 - algae[,<span class="string">&quot;a1&quot;</span>])))</span><br><span class="line">[1] 13.10681</span><br><span class="line"></span><br><span class="line">(mae.a1.rt &lt;- mean(abs(rt.predictions.a1 - algae[,<span class="string">&quot;a1&quot;</span>])))</span><br><span class="line">[1] 10.36242</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="均方误差-MSE"><a href="#均方误差-MSE" class="headerlink" title="均方误差(MSE)"></a>均方误差(MSE)</h3><ul>
<li>另一种流行的误差度量是均方误差(MSE)。可以由下列代码计算均方误差：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 计算均方误差(MSE)</span></span><br><span class="line">(mse.a1.lm &lt;- mean((lm.predictions.a1 - algae[,&quot;a1&quot;])^<span class="number">2</span>))</span><br><span class="line">[1] 295.5407</span><br><span class="line"></span><br><span class="line">(mse.a1.rt &lt;- mean((rt.predictions.a1 - algae[,&quot;a1&quot;])^<span class="number">2</span>))</span><br><span class="line">[1] 227.0339</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="标准化的平均绝对误差-NMSE"><a href="#标准化的平均绝对误差-NMSE" class="headerlink" title="标准化的平均绝对误差(NMSE)"></a>标准化的平均绝对误差(NMSE)</h3><ul>
<li>以上后一种误差度量方法的不足之处是：误差值和目标值变量的目标不统一，因此从用户的角度看，这种误差不好解释。即使应用平均绝对误差(MAE)来度量误差，问题是如何判断模型的得分是好还是差。能够解决这一问题的误差度量是标准化后的平均绝对误差(NMSE)。这一统计量是计算模型预测性能和基准模型的预测性能之间的比率。通常采用目标变量的平均值来作为基准模型，代码如下：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 计算标准化后的平均绝对误差(NMSE)</span></span><br><span class="line">(nmse.a1.lm &lt;- mean((lm.predictions.a1 - algae[,&#x27;a1&#x27;])^<span class="number">2</span> / mean((mean(algae[,&#x27;a1&#x27;])-algae[,&#x27;a1&#x27;])^<span class="number">2</span>)))</span><br><span class="line">[1] 0.6473034</span><br><span class="line"></span><br><span class="line">(nmse.a1.rt &lt;- mean(rt.predictions.a1-algae[,<span class="string">&#x27;a1&#x27;</span>])^2 / mean((mean(algae[,&#x27;a1&#x27;])-algae[,&#x27;a1&#x27;])^<span class="number">2</span>))</span><br><span class="line">[1] 3.121937e-34</span><br></pre></td></tr></table></figure></li>
<li>NMSE是一个比值，其取值范围通常为0-1。如果模型表现优于这个非常简单基准模型预测，那么NMSE应明显小于1。NMSE的值越小，模型的性能就越好。NMSE的值大于1，意味着模型预测还不如简单地把所有个案的平均值作为预测值。</li>
<li>在本书提供的R添加包中，函数regr.eval()用来计算线性回归模型的性能度量指标。下面给出应用该函数一个例子。可以查找该函数的帮助文档来获取这个函数的不同用法。<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">regr.eval(algae[,<span class="string">&#x27;a1&#x27;</span>], rt.predictions.a1, train.y = algae[,<span class="string">&#x27;a1&#x27;</span>])</span><br><span class="line">       mae         mse        rmse        mape        nmse        nmae </span><br><span class="line">10.3624227 227.0338940  15.0676439         Inf   0.4972574   0.6202654 </span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="可视化比较模型"><a href="#可视化比较模型" class="headerlink" title="可视化比较模型"></a>可视化比较模型</h3><ul>
<li>可视化地查看模型的预测值将更加有趣。一种方法是绘制误差的散点图。代码如下：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 可视化查看模型的预测值</span></span><br><span class="line">old.par &lt;- par(mfrow = c(1,2))</span><br><span class="line">plot(lm.predictions.a1, algae[,<span class="string">&#x27;a1&#x27;</span>], main=<span class="string">&quot;Linear Model&quot;</span>, xlab=<span class="string">&quot;Predictions&quot;</span>, ylab=<span class="string">&quot;True Values&quot;</span>)</span><br><span class="line">abline(0,1,lty=2)</span><br><span class="line">plot(rt.predictions.a1, algae[,<span class="string">&#x27;a1&#x27;</span>], main=<span class="string">&quot;Regression Tree&quot;</span>, xlab=<span class="string">&quot;Predictions&quot;</span>, ylab=<span class="string">&quot;True Values&quot;</span>)</span><br><span class="line">abline(0,1,lty=2)</span><br><span class="line">par(old.par)</span><br></pre></td></tr></table></figure></li>
<li>plot:<br> <img src="/img/DMwR/02_algae_model_judge/01_prediction_true.PNG"></li>
<li>由上图可以看出，这两个模型在许多个案上的性能比较差。在理想的情况下，模型对所有的个案做出正确的预测时，图中的所有圈应该在虚线上，这条虚线是通过函数abline(0,1,lty&#x3D;2)来绘制的。这条虚线穿过坐标系的原点，代表x坐标和y坐标相等的点集。图中圆圈的x坐标和y坐标分别代表目标变量的预测值和真实值，如果他们相等，那么这些圆圈就会落在这条理想的直线上。但从上图可以看到，情况并非如此！可以用函数identify()来检查哪些预测特别差的样本点，该函数可以让用户通过互动方式点击图形中的点，代码如下：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># identify()</span></span><br><span class="line">plot(lm.predictions.a1, algae[,<span class="string">&#x27;a1&#x27;</span>],main=<span class="string">&quot;Linear Model&quot;</span>, xlab=<span class="string">&quot;Predictions&quot;</span>, ylab=<span class="string">&quot;True Values&quot;</span>)</span><br><span class="line">abline(0,1,lty=2)</span><br><span class="line">algae[identify(lm.predictions.a1, algae[,<span class="string">&#x27;a1&#x27;</span>]),]</span><br></pre></td></tr></table></figure></li>
<li>运行上面的代码，并在图形上点击，然后右击结束交互过程后，应该看到相应于所点击的圆圈的海藻数据框的行数据–因为这里用函数identify()得到的向量来索引海藻数据框。</li>
<li>观察上图的左图，他对应的是线性回归模型。注意，有一些个案的海藻频率的预测值为负值。在本案例中，海藻在出现频率为负值时没有意义(至少是0个)。因此，可以用以上知识和海藻频率的最小可能取值来优化上面的线性回归模型。<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sensible.lm.predictions.a1 &lt;- ifelse(lm.predictions.a1 &lt;0,0,lm.predictions.a1)</span><br><span class="line">regr.eval(algae[,<span class="string">&#x27;a1&#x27;</span>], lm.predictions.a1,stats = c(<span class="string">&quot;mae&quot;</span>,<span class="string">&quot;mse&quot;</span>))</span><br><span class="line">     mae       mse </span><br><span class="line">13.10681 295.54069 </span><br><span class="line">regr.eval(algae[,<span class="string">&#x27;a1&#x27;</span>], sensible.lm.predictions.a1, stats = c(<span class="string">&quot;mae&quot;</span>,<span class="string">&quot;mse&quot;</span>))</span><br><span class="line">     mae       mse </span><br><span class="line">12.48276 286.28541</span><br></pre></td></tr></table></figure></li>
<li>上面代码应用函数ifelse()来改进模型的预测结果。该函数有三个参数，第一个参数是逻辑条件，第二个参数是当逻辑条件为真时函数的取值，第三个参数是当逻辑条件为假时的取值。注意，通过这一小的细节就提高了模型的性能。</li>
</ul>
<h3 id="k折交叉验证"><a href="#k折交叉验证" class="headerlink" title="k折交叉验证"></a>k折交叉验证</h3><ul>
<li><p>根据以上计算出的模型的性能指标，我们倾向于选择回归树模型来预测140个测试样品的频率值，因为该模型有较低的NMSE值。然而，这种推理有一种那个缺陷。我们的分析目标是获得能够对140个测试样品的频率进行预测的最佳模型。由于不知道这些测试样本的目标变量值，所以我们需要估计哪一个模型将在这些测试样本上有较好的性能。这里的关键问题是在不知道数据集真实的目标变量取值时，要获得模型在该数据集上可靠的性能估计。使用已有的训练数据获得模型的性能指标(如前面获得模型的过程)是不可靠的，因为这些计算是有偏的。</p>
</li>
<li><p>实际上，有的模型可以很容易地获得训练数据的零误差预测。然而，模型的这一优秀性能很难推广到目标变量值未知的心样本上。正如之前所述，这种现象通常称为过拟合训练数据。因为，为了选择一个合适的模型，我们需要获得模型在未知数据上预测性能的更加可靠的估计。k折交叉验证是获得模型性能可靠估计的一种常用方法，它适用于像本案例这样的小数据集。这种方法可以简要介绍如下。</p>
<ul>
<li>首先获取k个同样大小的随机训练数据子集。</li>
<li>对于这k个子集的每一个子集，用除去它之外的其余k-1个子集建立模型，然后用第k个子集来评估这个模型，最后存储模型的性能指标</li>
<li>对其余的每个子集重复以上过程，最后有K个性能指标的测量值，这些性能指标是通过在没有用于建模的数据上计算得到，这也是关键之处。</li>
</ul>
</li>
<li><p>k折交叉验证估计是这k个性能指标的平均。常见的k&#x3D;10.有时我们会重复进行多次k折交叉验证以获得更加可靠的估计。</p>
<ul>
<li>总之，党对一项预测任务时，需要作出以下决策：<ul>
<li>为预测任务选择模型(同一算法的不同参数设定也可以认为是不同的模型)。</li>
<li>选择比较模型性能的评估指标</li>
<li>选择获取评估指标的可靠估计的实验方法。</li>
</ul>
</li>
</ul>
</li>
<li><p>在本书提供的R包中，提供了函数experimentalComparison()，它用来进行模型的选择和比较任务。它可以和不同的估计方法一起使用，如交叉验证法。这个函数有三个参数：1.用于比较的数据集，2.需要比较的可选模型，3.实验过程中的系数。我们以海藻数据集为例，用它来比较线性回归模型和几个不同回归树模型。</p>
</li>
<li><p>函数experimentalComparison()使用于任何模型和任何数据，在这个意义上，它是一个泛型函数。使用者提供一组实现待比较的模型的函数。其中每一个函数应该对训练集和测试集实现一个完整的“训练+测试+评估”周期。在评估过程的每一次迭代中，调用这些函数。这些函数应该返回一个向量，其元素为交叉验证中用户需要的性能评估指标值。下面给出两个目标模型的函数：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cv.rpart &lt;- <span class="keyword">function</span>(form,train,<span class="built_in">test</span>,...)&#123;</span><br><span class="line">  m &lt;- rpartXse(from,train,...)</span><br><span class="line">  p &lt;- predict(m,<span class="built_in">test</span>)</span><br><span class="line">  mse &lt;- mean((p-resp(form,test))^2)</span><br><span class="line">  c(nmse = mse/mean((mean(resp(form,train))-resp(form,<span class="built_in">test</span>))^2))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">cv.lm &lt;- <span class="keyword">function</span>(form, train, <span class="built_in">test</span>,...)&#123;</span><br><span class="line">  m &lt;- lm(form,train,...)</span><br><span class="line">  p &lt;- predict(m,<span class="built_in">test</span>)</span><br><span class="line">  p &lt;- ifelse(p&lt;0,0,p)</span><br><span class="line">  mse &lt;- mean((p-resp(form,test))^2)</span><br><span class="line">  c(nmse=mse/mean((mean(resp(form,train))-resp(form,<span class="built_in">test</span>))^2))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>在这个示例中，假设用NMSE作为线性回归模型和回归树模型的性能评估指标。所有这些用户定义的函数的前三个参数应该是公式、训练数据和测试数据。实验过程调用函数时可以应用的其他参数包括要评估模型所需要的参数。虽然所评估的两个模型应用了完全不同的学习算法，但是两个模型函数都有同样的“训练+测试+评估”周期。函数的定义还包括一个特殊参数“…”。这个特殊参数可以用在任意的R函数中，它允许一个特定函数具有可变的参数。这个结构用于给实际模型传递所需要的额外参数(例如在函数rpartXse()中和函数lm()中)。这些函数的另一个特殊之处是应用本书添加包提供的函数resp()，它用于根据公式获得数据集的目标变量值。</p>
</li>
<li><p>在定义好用于模型学习和测试的函数后，就可以按下列代码进行模型的交叉验证比较：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">res &lt;- experimentalComparison(</span><br><span class="line">  c(dataset(a1~.,clean.algae[,1:12],<span class="string">&quot;a1&quot;</span>)),</span><br><span class="line">  c(variants(<span class="string">&#x27;cv.lm&#x27;</span>),</span><br><span class="line">    variants(<span class="string">&#x27;cv.rpart&#x27;</span>,se=c(0,0.5,1))),</span><br><span class="line">    cvSettings(3,10,1234)</span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#####  CROSS VALIDATION  EXPERIMENTAL COMPARISON #####</span></span><br><span class="line"></span><br><span class="line">** DATASET :: a1</span><br><span class="line"></span><br><span class="line">++ LEARNER :: cv.lm  variant -&gt;  cv.lm.v1 </span><br><span class="line"></span><br><span class="line"> 3 x 10 - Fold Cross Validation run with seed =  1234 </span><br><span class="line">Repetition  1 </span><br><span class="line">Fold:  1  2  3  4  5  6  7  8  9  10</span><br><span class="line">Repetition  2 </span><br><span class="line">Fold:  1  2  3  4  5  6  7  8  9  10</span><br><span class="line">Repetition  3 </span><br><span class="line">Fold:  1  2  3  4  5  6  7  8  9  10</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">++ LEARNER :: cv.rpart  variant -&gt;  cv.rpart.v1 </span><br><span class="line"></span><br><span class="line"> 3 x 10 - Fold Cross Validation run with seed =  1234 </span><br><span class="line">Repetition  1 </span><br><span class="line">Fold:  1  2  3  4  5  6  7  8  9  10</span><br><span class="line">Repetition  2 </span><br><span class="line">Fold:  1  2  3  4  5  6  7  8  9  10</span><br><span class="line">Repetition  3 </span><br><span class="line">Fold:  1  2  3  4  5  6  7  8  9  10</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">++ LEARNER :: cv.rpart  variant -&gt;  cv.rpart.v2 </span><br><span class="line"></span><br><span class="line"> 3 x 10 - Fold Cross Validation run with seed =  1234 </span><br><span class="line">Repetition  1 </span><br><span class="line">Fold:  1  2  3  4  5  6  7  8  9  10</span><br><span class="line">Repetition  2 </span><br><span class="line">Fold:  1  2  3  4  5  6  7  8  9  10</span><br><span class="line">Repetition  3 </span><br><span class="line">Fold:  1  2  3  4  5  6  7  8  9  10</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">++ LEARNER :: cv.rpart  variant -&gt;  cv.rpart.v3 </span><br><span class="line"></span><br><span class="line"> 3 x 10 - Fold Cross Validation run with seed =  1234 </span><br><span class="line">Repetition  1 </span><br><span class="line">Fold:  1  2  3  4  5  6  7  8  9  10</span><br><span class="line">Repetition  2 </span><br><span class="line">Fold:  1  2  3  4  5  6  7  8  9  10</span><br><span class="line">Repetition  3 </span><br><span class="line">Fold:  1  2  3  4  5  6  7  8  9  10</span><br></pre></td></tr></table></figure></li>
<li><p>像先前提到的那样，第一个参数是含有在实验比较中所应用数据集的一个向量。每个数据集的声明形式为dataset(<formular>,<data frame>,<label>)。函数experimentalComparison()的第二个参数包含要研究的可选的模型方法。每个模型方法通过函数variant()来指定，该函数的第一个参数是用户定义的用于“学习+测试+评估”周期的函数名称。其余的可选参数用来给出估计方法的其他参数的可选值。函数variantes()根据所有参数值的组合生成一组可选模型。在上面的例子代码中，模型“cv.lm”采用了默认参数值，而模型“cv.rpart”的参数se则给出了不同的取值。这意味着实验将包含回归树的三个版本，这点可以在上面的函数输出中得到确认。函数experimentalComparison()的第三个参数是设定交叉验证实验的参数，即k折交叉验证实验过程重复的次数(这里设为3)、k的取值(10)、随机数生成器的种子。最后的参数(随机数种子)设定可以保证在必要的情况之下可以重视我们的实验(例如更换了训练模型系统)。</p>
</li>
<li><p>这个代码调用的结果是一个复杂的对象，它包含实验比较的所有信息。在本书的R添加包中提供了多种获取这些信息的函数。例如，下面代码提供了比较结果的概要：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">summary(res)</span><br><span class="line"></span><br><span class="line">== Summary of a  Cross Validation  Experiment ==</span><br><span class="line"></span><br><span class="line"> 3 x 10 - Fold Cross Validation run with seed =  1234 </span><br><span class="line"></span><br><span class="line">* Data sets ::  a1</span><br><span class="line">* Learners  ::  cv.lm.v1, cv.rpart.v1, cv.rpart.v2, cv.rpart.v3</span><br><span class="line"></span><br><span class="line">* Summary of Experiment Results:</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">-&gt; Datataset:  a1 </span><br><span class="line"></span><br><span class="line">	*Learner: cv.lm.v1 </span><br><span class="line">             nmse</span><br><span class="line">avg     0.7196105</span><br><span class="line">std     0.1833064</span><br><span class="line">min     0.4678248</span><br><span class="line">max     1.2218455</span><br><span class="line">invalid 0.0000000</span><br><span class="line"></span><br><span class="line">	*Learner: cv.rpart.v1 </span><br><span class="line">             nmse</span><br><span class="line">avg     0.6440843</span><br><span class="line">std     0.2521952</span><br><span class="line">min     0.2146359</span><br><span class="line">max     1.1712674</span><br><span class="line">invalid 0.0000000</span><br><span class="line"></span><br><span class="line">	*Learner: cv.rpart.v2 </span><br><span class="line">             nmse</span><br><span class="line">avg     0.6873747</span><br><span class="line">std     0.2669942</span><br><span class="line">min     0.2146359</span><br><span class="line">max     1.3356744</span><br><span class="line">invalid 0.0000000</span><br><span class="line"></span><br><span class="line">	*Learner: cv.rpart.v3 </span><br><span class="line">             nmse</span><br><span class="line">avg     0.7167122</span><br><span class="line">std     0.2579089</span><br><span class="line">min     0.3476446</span><br><span class="line">max     1.3356744</span><br><span class="line">invalid 0.0000000</span><br></pre></td></tr></table></figure></li>
<li><p>从结果中可知，其中的一个回归树有最优的NMSE值。这个NMSE值是否明显优于其他模型，目前还不明显，本节的后面将回到这个问题。可以得到这些结果的可视化图形:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">plot(res)</span><br></pre></td></tr></table></figure></li>
<li><p>plot:<br><img src="/img/DMwR/02_algae_model_judge/02_nmse.PNG"></p>
</li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步-R语言</category>
      </categories>
      <tags>
        <tag>数据挖掘与R语言-案例学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Django-1-7-3-Tutorial-Part-3-视图和模板</title>
    <url>/2015/01/27/%E6%8A%80%E8%83%BD-%E4%BF%AE%E8%A1%8C-%E8%BF%9B%E6%AD%A5-Django/Django-1-7-3-Tutorial-Part-3-%E8%A7%86%E5%9B%BE%E5%92%8C%E6%A8%A1%E6%9D%BF/</url>
    <content><![CDATA[<ul>
<li>本教程是接着上一节教程继续的。我们继续讨论网页投票(Web-poll)应用程序，然后关注与创建公共接口–“视图”。</li>
</ul>
<h2 id="哲学"><a href="#哲学" class="headerlink" title="哲学"></a>哲学</h2><ul>
<li><p>一个视图是在你的Django应用中一种有特定应用功能和有一个模板的网页的“类型”。譬如，在一个博客应用中，你可能需要以下视图：</p>
<ul>
<li>博客首页–显示最新的博客</li>
<li>“具体”页面的入口–单独入口的固定链接</li>
<li>把博客按照年排序的架构页面–给定年份，按月列出所有的文章</li>
<li>把博客按照月排序的架构页面–给定月份，按日列出所有的文章</li>
<li>把博客按照日排序的架构页面–给定日期，列出所有的文章</li>
<li>评论操作–给指定的文章下评论</li>
</ul>
</li>
<li><p>在我们的投票应用中(poll)，我们已经有了以下四个页面：</p>
<ul>
<li>问题“首页”–显示最新的问题</li>
<li>问题“具体页”–显示一个问题文本，不能显示结果，但是提供投票表格</li>
<li>问题“结果页”–为指定的问题显示投票结果</li>
<li>投票操作–在给定的问题中投给定的选项</li>
</ul>
</li>
<li><p>在Django中，网页和其他的内容页是通过视图展示的。每一个视图是通过一个简单的Python功能展示的(或者方法，如果在基于类的视图下)。Django通过测试请求的URL而选择视图(更准确的说，是跟在域名后面的URL部分)。</p>
</li>
<li><p>现在你在浏览网页的时候可能看过这样的网页链接：<strong>“ME2&#x2F;Sites&#x2F;dirmod.asp?sid&#x3D;&amp;type&#x3D;gen&amp;mod&#x3D;Core+Pages&amp;gid&#x3D;A6CD4967199A42D9B65B1B”</strong>。但是更值得我们高兴的是，Django允许我们使用比以上更优雅的链接模式。</p>
</li>
<li><p>一个URL模式是一个简单的URL通常格式–譬如：<img src="/img/Django-1-7-3-tutorial/url-01.png"></p>
</li>
<li><p>要从一个URL得到一个视图，Django利用了我们熟知的’URLconfs’。一个URLconf把一个URL模式(通常被描述为正则表达式)映射到一个视图。</p>
</li>
<li><p>本节教程提供了URLconfs的基本用法，然后你可以参考<strong>django.core.urlresolvers</strong>得到更多信息。</p>
</li>
</ul>
<h2 id="写你的第一个视图"><a href="#写你的第一个视图" class="headerlink" title="写你的第一个视图"></a>写你的第一个视图</h2><ul>
<li><p>让我们开始写第一个视图吧。打开文件<strong>polls&#x2F;views.py</strong>然后写入以下python代码：</p>
</li>
<li><p><font color="green"><strong>polls&#x2F;views.py</strong></font></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> django.http <span class="keyword">import</span> HttpResponse</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">index</span>(<span class="params">request</span>):</span><br><span class="line">	<span class="keyword">return</span> HttpResponse(<span class="string">&quot;Hello, world. You&#x27;re at the polls index.&quot;</span>)</span><br></pre></td></tr></table></figure></li>
<li><p>这可能是Django中最简单的视图了。要调用这个视图，我们需要把它映射到一个URL–然后我们就需要一个URLconf。</p>
</li>
<li><p>在polls目录下创建一个URLconf，创建一个<strong>urls.py</strong>文件。你的app目录应该看起来是这样：<br><img src="/img/Django-1-7-3-tutorial/polls-urls.png"></p>
</li>
<li><p>在<strong>polls&#x2F;urls.py</strong>文件中加入以下代码：</p>
</li>
<li><p><font color="green"><strong>polls&#x2F;urls.py</strong></font></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> django.conf.urls <span class="keyword">import</span> patterns, url</span><br><span class="line"><span class="keyword">from</span> polls <span class="keyword">import</span> views</span><br><span class="line"></span><br><span class="line">urlpatterns = patterns(<span class="string">&#x27;&#x27;</span>,</span><br><span class="line">	url(<span class="string">r&#x27;^$&#x27;</span>, views.index, name=<span class="string">&#x27;index&#x27;</span>),</span><br><span class="line">)</span><br></pre></td></tr></table></figure></li>
<li><p>下一步就是在<strong>polls.urls</strong>模块中指定根URLconf。在<strong>mysite&#x2F;urls.py</strong>中插入一个**include()**，像这样：</p>
</li>
<li><p><font color="green"><strong>mysite&#x2F;urls.py</strong></font></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> django.conf.urls <span class="keyword">import</span> patterns, include, url</span><br><span class="line"><span class="keyword">from</span> django.contrib <span class="keyword">import</span> admin</span><br><span class="line"></span><br><span class="line">urlpatterns = patterns(<span class="string">&#x27;&#x27;</span>, </span><br><span class="line">	url(<span class="string">r&#x27;^polls/&#x27;</span>, include(<span class="string">&#x27;polls.urls&#x27;</span>)),</span><br><span class="line">	url(<span class="string">r&#x27;^admin/&#x27;</span>, include(admin.site.urls)),</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>和你所见的不匹配吗？</strong><br>如果你在<strong>urlpatterns</strong>定义之前就看见了**admin.autodiscover()**，你可能是在用一个和本教程不匹配的版本，你应该更改Django的版本。</p>
</blockquote>
</li>
<li><p>你现在可以把**首页(index)<strong>视图转换为URLconf。在你的浏览器中输入<a class="link"   href="http://localhost:8000/polls/" >http://localhost:8000/polls/<i class="fas fa-external-link-alt"></i></a>，按下Enter键，你应该可以看到文本“Hello, world. You’re at the polls index.”，它是在</strong>首页(index)**视图所定义的。</p>
</li>
<li><p><strong>url()<strong>函数有四个参数，其中两个是必须的：</strong>regex(正则表达式)<strong>和</strong>view(视图)</strong>,两个是可选的：<strong>kwargs</strong>和**name(名字)**。现在，让我们来了解一下这些参数具体是什么来的。</p>
</li>
</ul>
<h3 id="url-参数：regex"><a href="#url-参数：regex" class="headerlink" title="url()参数：regex"></a><strong>url()参数：regex</strong></h3><ul>
<li>术语<strong>regex</strong>通常是**regular expression(正则表达式)**的缩写，它是一个字符串匹配的语法规则，在这里，它是url模式的匹配。Django从第一个正则表达式开始，然后把它们造一个列表，把请求的URL和每一个正则表达式单元进行比较，然后找到匹配的那一个。</li>
<li>请注意，这些正则表达式不会搜寻GET和POST的参数或者域名。譬如，在请求URL<strong><a class="link"   href="http://www.example.com/myapp/**%E4%B8%AD%EF%BC%8CURLconf%E4%BC%9A%E5%AF%BB%E6%89%BE**myapp/**%E3%80%82%E8%80%8C%E5%9C%A8%E8%AF%B7%E6%B1%82URL**http://www.example.com/myapp/?page=3" >http://www.example.com/myapp/**中，URLconf会寻找**myapp/**。而在请求URL**http://www.example.com/myapp/?page=3<i class="fas fa-external-link-alt"></i></a></strong>中，URLconf也会寻找**myapp&#x2F;**。</li>
<li>如果你不了解正则表达式，请看<a class="link"   href="http://en.wikipedia.org/wiki/Regular_expression" >Wikipedia’s entry<i class="fas fa-external-link-alt"></i></a>或者<a href="http://docs.python.org/3/library/re.html#module-re"><strong>re</strong></a>模块的文档。另外，O’Reilly的书–Jeffrey Friedl著的《Mastering Regular Expressions》非常不错。实际上，你不需要成为<strong>正则表达式</strong>方面的专家，如果你仅仅需要知道一些简单的模式匹配的话。事实上，复杂的正则表达式有比较弱的检查能力，所以，你不太可能依赖正则表达式。</li>
<li>最后，性能笔记：这些正则表达式在URLconf模块加载时会被首次编译。它们非常快(只要查找的不是太复杂的正则表达式)。</li>
</ul>
<h3 id="url-参数：view"><a href="#url-参数：view" class="headerlink" title="url()参数：view"></a><strong>url()参数：view</strong></h3><ul>
<li>当Django匹配到了正则表达式时，Django调用指定的视图函数，第一个参数是一个<strong>HttpRequest</strong>对象，其他的参数是根据需要从正则表达式中捕捉的任意值。如果正则表达式是用简单的捕捉，值就会当成位置参数来传递；如果正则表达式是用命名捕捉，值就会被当成关键字参数来传递。我们稍后会给出例子进行说明。</li>
</ul>
<h3 id="url-参数：kwargs"><a href="#url-参数：kwargs" class="headerlink" title="url()参数：kwargs"></a><strong>url()参数：kwargs</strong></h3><ul>
<li>任意的关键字参数都可以传递到目标视图中的字典。在这个教程中我们不会讨论这个特性。</li>
</ul>
<h3 id="url-参数：name"><a href="#url-参数：name" class="headerlink" title="url()参数：name"></a><strong>url()参数：name</strong></h3><ul>
<li>对你的URL命名可以让你清楚地从Django中的任何地方中引用，特别是在模板中。这个有力的特性让你对项目中的url模式做全局的修改，当你仅仅创建了单个文件时。</li>
</ul>
<h2 id="写更多的视图"><a href="#写更多的视图" class="headerlink" title="写更多的视图"></a>写更多的视图</h2><ul>
<li><p>现在让我们在<strong>polls&#x2F;views.py</strong>文件中添加更多的视图。这些视图可能有小小的不同，因为它们有一个参数。</p>
</li>
<li><p><font color="green"><strong>polls&#x2F;views.py</strong></font></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">detail</span>(<span class="params">request, question_id</span>):</span><br><span class="line">	<span class="keyword">return</span> HttpResponse(<span class="string">&quot;You&#x27;re looking at question %s.&quot;</span> % question_id)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">results</span>(<span class="params">request, question_id</span>):</span><br><span class="line">	response = <span class="string">&quot;You&#x27;re looking at the results of question %s.&quot;</span></span><br><span class="line">	<span class="keyword">return</span> HttpResponse(response % question_id)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vote</span>(<span class="params">request, question_id</span>):</span><br><span class="line">	<span class="keyword">return</span> HttpResponse(<span class="string">&quot;You&#x27;re voting on question %s.&quot;</span> % question_id)</span><br></pre></td></tr></table></figure></li>
<li><p>把这些新的视图通过添加以下的<strong>url()<strong>调用写进</strong>polls.urls</strong>模块：</p>
</li>
<li><p><font color="green"><strong>polls&#x2F;urls.py</strong></font></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> django.conf.urls <span class="keyword">import</span> patterns, url</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> polls <span class="keyword">import</span> views</span><br><span class="line"></span><br><span class="line">urlpatterns = patterns(<span class="string">&#x27;&#x27;</span>,</span><br><span class="line">	<span class="comment"># ex: /polls/</span></span><br><span class="line">	url(<span class="string">r&#x27;^$&#x27;</span>, views.index, name=<span class="string">&#x27;index&#x27;</span>),</span><br><span class="line">	<span class="comment"># ex: /polls/5/</span></span><br><span class="line">	url(<span class="string">r&#x27;^(?P&lt;question_id&gt;\d+)/$&#x27;</span>, views.detail, name=<span class="string">&#x27;detail&#x27;</span>),</span><br><span class="line">	<span class="comment"># ex: /polls/5/results/</span></span><br><span class="line">	url(<span class="string">r&#x27;^(?P&lt;question_id&gt;\d+)/results/$&#x27;</span>, views.results, name=<span class="string">&#x27;results&#x27;</span>),</span><br><span class="line">	<span class="comment"># ex: /polls/5/vote/</span></span><br><span class="line">	url(<span class="string">r&#x27;^(?P&lt;question_id&gt;\d+)/vote/$&#x27;</span>, views.vote, name=<span class="string">&#x27;vote&#x27;</span>),</span><br><span class="line">	)</span><br></pre></td></tr></table></figure></li>
<li><p>在浏览器中打开**”&#x2F;polls&#x2F;34&#x2F;“<strong>浏览一下。它运行</strong>detail()<strong>方法并且根据你的URL提供的ID显示你的东西。试一下</strong>“&#x2F;polls&#x2F;34&#x2F;results&#x2F;”<strong>和</strong>&#x2F;polls&#x2F;34&#x2F;vote&#x2F;**–这些会显示占位符结果和投票页面。</p>
</li>
<li><p>当某人从你的网站请求网页时–譬如，**&#x2F;polls&#x2F;34&#x2F;<strong>,Django将会加载</strong>mysite.urls<strong>模块，因为它是被</strong>ROOT_URLCONF<strong>设置所指向的。它找到名叫</strong>urlpatterns<strong>的变量然后遍历正则表达式。</strong>include()<strong>函数只是引用了其他的URLconfs。注意到关于</strong>include()<strong>方法的正则表达式没有</strong>$<strong>(字符串匹配的结束符)而只有末尾斜杠。无论何时Django遇上了</strong>include()**方法，它会发送剩余的字符串到包含的URLconf给下一步做准备，而砍掉其他的部分。</p>
</li>
<li><p>**include()<strong>背后的思想是使得URLs即插即用，用起来非常简单。由于polls在它们自己的URLconf(<strong>polls&#x2F;urls.py</strong>)中，它们可以被放在</strong>&#x2F;polls&#x2F;<strong>或者</strong>&#x2F;fun_polls&#x2F;<strong>或者</strong>&#x2F;content&#x2F;polls&#x2F;**或者其它的根路径后面，应用还是可以运行的。</p>
</li>
<li><p>如果用户去到系统中的**&#x2F;polls&#x2F;34&#x2F;**，它会发生以下事情：</p>
<ul>
<li>Django会对**^polls&#x2F;**进行匹配</li>
<li>然后，Django会去掉匹配的文本(<strong>“polls&#x2F;”</strong>)并且把剩下的文本<strong>34&#x2F;<strong>发送到</strong>polls.urls</strong>URLconf作进一步的操作，**34&#x2F;<strong>是匹配<img src="/img/Django-1-7-3-tutorial/reg-1.png">,然后对</strong>detail()**视图进行调用：</li>
<li><img src="/img/Django-1-7-3-tutorial/reg-4.png"></li>
</ul>
</li>
<li><p>**question_id&#x3D;’34’<strong>是来自<img src="/img/Django-1-7-3-tutorial/reg-2.png">。用圆括号把匹配到的模式文本括起来当成一个参数传到视图函数；<img src="/img/Django-1-7-3-tutorial/reg-3.png">定义了将要确定匹配模式的名字；而</strong>\d+**是一个匹配一串数字的正则表达式。</p>
</li>
<li><p>因为URL模式是一个正则表达式，它们没有任何限制。没必要添加URL烂尾，譬如**.html**,除非你想要加，然后你可以这样做：</p>
</li>
<li><p><img src="/img/Django-1-7-3-tutorial/reg-5.png"></p>
</li>
<li><p>但是不要这样做，它看起来傻傻的。</p>
</li>
</ul>
<h2 id="写一些起作用的视图"><a href="#写一些起作用的视图" class="headerlink" title="写一些起作用的视图"></a>写一些起作用的视图</h2><ul>
<li>每一个视图都应该做一到两样事情：返回一个包含请求页的内容的<strong>HttpResponse</strong>对象，或者产生一个像<strong>Http404</strong>这样的异常。剩下的就由你决定。</li>
<li>你的视图能够从数据库中读取记录，或者不读。它能够使用一个像Django这样的模板系统，或者第三方模板系统，又或者不用。它能够生成一个PDF文件，输出XML，飞速创建一个ZIP文件，或者任何你想要的文件，使用任何你想要的Python库。</li>
<li>Django想做的就是一个<strong>HttpResponse</strong>，或者一个异常。</li>
<li>由于方便，我们使用Django默认的数据库API，就是我们在教程1当中介绍的。下面是我们在**index()**视图中插入新的东西，它显示了系统中最新的5个投票问题，根据发布日期通过逗号隔开：</li>
<li><font color="green"><strong>polls&#x2F;views.py</strong></font><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> django.http <span class="keyword">import</span> HttpResponse</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> polls.models <span class="keyword">import</span> Question</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">index</span>(<span class="params">request</span>):</span><br><span class="line">	latest_question_list = Question.objects.order_by(<span class="string">&#x27;-pub_date&#x27;</span>)[:<span class="number">5</span>]</span><br><span class="line">	output = <span class="string">&#x27;,&#x27;</span>.join([p.question_text <span class="keyword">for</span> p <span class="keyword">in</span> latest_question_list])</span><br><span class="line"></span><br><span class="line"><span class="comment"># leave the rest of views (detail, results, vote) unchanged</span></span><br></pre></td></tr></table></figure></li>
<li>但还有一个问题：页面的设计是在视图硬性写定了。如果你像更改页面的设计，你需要重新编辑Python 代码。所以让我们使用Django的模板系统把设计和Python代码通过创建一个视图可调用的模板来分开。</li>
<li>首先，在你的<strong>polls</strong>目录下创建一个名为<strong>templates</strong>的文件。Django会在那里进行搜寻的。</li>
<li>Django的<strong>TEMPLATE_LOADERS</strong>设置包含一系列知道如何从不同资源中导入模板的可调用方法。其中默认的方法是<strong>django.template.loaders.app_directories.Loader</strong>，它在每一个<strong>INSTALLED_APPS</strong>中寻找一个“模板”子目录。这就是为什么Django在没有修改<strong>TEMPLATE_DIRS</strong>的情况下知道怎么找到poll模板的原因。</li>
</ul>
<blockquote>
<p><strong>组织模板</strong><br>我们可以把所有的模板放在一起，在一个大的模板目录中，而且它可以工作的很顺利。但是，这个模板是属于polls应用的，所以不像上一个教程中我们介绍的管理员模板那样，我们把它放在程序的模板目录而不是项目的模板目录。我们会讨论更多关于这个更多的可重用的app教程，并对其进行解释。</p>
</blockquote>
<ul>
<li>在你刚刚创建的<strong>template</strong>模板目录中，创建另外一个叫做<strong>polls</strong>的目录，然后再里面创建一个<strong>index.html</strong>文件。换句话说，你的模板应该是在<strong>polls&#x2F;templates&#x2F;polls&#x2F;index.html</strong>目录中。正是由于上面我们讨论的关于<strong>app_directories</strong>模板加载器是如何工作的，你可以像<strong>polls&#x2F;index.html</strong>一样通过Django简单的找到模板文件。</li>
</ul>
<blockquote>
<p><strong>模板命名空间</strong><br>现在我们可能不需要把我们的模板放进<strong>polls&#x2F;templates</strong>目录(而不是在<strong>polls</strong>的子目录下新建一个)，但这确实是一个坏主意。Django会选择它第一个匹配到的模板名字，如果你在不同的目录下有相同的名字的应用，Django就不会对它们进行分辨。我们应该要为Django正确指定哪一个模板，最简单的方法来保证这样的事情就是通过给它们创建命名空间。也就是说，把那些模板放进另一个为本应用命名的目录。</p>
</blockquote>
<ul>
<li>在模板中写进以下代码：</li>
<li><font color="green"><strong>polls&#x2F;templates&#x2F;polls&#x2F;index.html</strong></font><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&#123;% <span class="keyword">if</span> latest_question_list %&#125;</span><br><span class="line">	&lt;ul&gt;</span><br><span class="line">	&#123;% <span class="keyword">for</span> question <span class="keyword">in</span> latest_question_list %&#125;</span><br><span class="line">		&lt;li&gt;&lt;a href=<span class="string">&quot;/polls.&#123;&#123; question.id &#125;&#125;/&quot;</span>&gt;&#123;&#123; question.question_text &#125;&#125;&lt;/a&gt;&lt;/li&gt;</span><br><span class="line">	&#123;% endfor %&#125;</span><br><span class="line">	&lt;/ul&gt;</span><br><span class="line">&#123;% <span class="keyword">else</span> %&#125;</span><br><span class="line">	&lt;p&gt;No polls are available.&lt;/p&gt;</span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure></li>
<li>现在让我们更新<strong>polls&#x2F;views.py</strong>中的视图来使用模板：</li>
<li><font color="green"><strong>polls&#x2F;views.py</strong></font><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> django.http <span class="keyword">import</span> HttpResponse</span><br><span class="line"><span class="keyword">from</span> django.template <span class="keyword">import</span> RequestContext, loader</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> polls.models <span class="keyword">import</span> Question</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">index</span>(<span class="params">request</span>):</span><br><span class="line">	latest_question_list = Question.objects.order_by(<span class="string">&#x27;-pub_date&#x27;</span>)[:<span class="number">5</span>]</span><br><span class="line">	template = loader.get_template(<span class="string">&#x27;polls/index.html&#x27;</span>)</span><br><span class="line">	context = RequestionContext(request, &#123;</span><br><span class="line">		<span class="string">&#x27;latest_question_list&#x27;</span>: latest_question_list,</span><br><span class="line">	&#125;)</span><br><span class="line">	<span class="keyword">return</span> HttpResponse(template.render(context))</span><br></pre></td></tr></table></figure></li>
<li>上面的代码加载了<strong>polls&#x2F;index.html</strong>模板，然后传递了一个context。context是一个匹配模板变量名到Python对象的字典。</li>
<li>在你的浏览器里点击**”&#x2F;polls&#x2F;“<strong>加载页面，你会看到包含Tutorial_1中的</strong>“What’s up”**问题的无序列表。这个链接指向问题详细内容页。</li>
</ul>
<h2 id="一个快捷键-render"><a href="#一个快捷键-render" class="headerlink" title="一个快捷键:render()"></a>一个快捷键:render()</h2><ul>
<li>这是一种常用的语法：加载一个模板，传递一个context，然后返回一个对显示模板结果的<strong>HttpResponse</strong>对象。Django提供一个快捷键。下面是完整的**index()**视图，重写：</li>
<li><font color="green"><strong>polls&#x2F;views.py</strong></font><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> django.shortcuts <span class="keyword">import</span> render</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> polls.models <span class="keyword">import</span> Question</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">index</span>(<span class="params">request</span>):</span><br><span class="line">	lastest_question_list = Question.objects.order_by(<span class="string">&#x27;-pub_date&#x27;</span>)[:<span class="number">5</span>]</span><br><span class="line">	context = &#123;<span class="string">&#x27;lastest_question_list&#x27;</span>: lastest_question_list&#125;</span><br><span class="line">	<span class="keyword">return</span> render(request, <span class="string">&#x27;polls/index.html&#x27;</span>, context)</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li>既然我们搞好了所有的视图，我们不需要去导入<strong>loader,RequestContext</strong>和<strong>HttpResponse</strong>(如果你需要<strong>detail</strong>和<strong>results</strong>，<strong>vote</strong>的根方法，你需要保留<strong>HttpResponse</strong>对象)。</li>
<li><strong>render()<strong>方法的第一个参数是</strong>Request</strong>对象，第二个参数是一个模板名，然后第三参数是可选的，它是一个字典类型。方法返回的是一个带根据给定的context而呈现的给定的模板的<strong>HttpResponse</strong>对象。</li>
</ul>
<h2 id="报告404错误"><a href="#报告404错误" class="headerlink" title="报告404错误"></a>报告404错误</h2><ul>
<li>现在，让我们浏览一下问题详细视图-根据给定的poll显示问题文本的页面。这就是视图：</li>
<li><font color="green"><strong>polls&#x2F;views.py</strong></font><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> django.http <span class="keyword">import</span> Http404</span><br><span class="line"><span class="keyword">from</span> djang.shortcuts <span class="keyword">import</span> render</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> polls.models <span class="keyword">import</span> Question</span><br><span class="line"><span class="comment"># ...</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">detail</span>(<span class="params">request, question_id</span>):</span><br><span class="line">	<span class="keyword">try</span>:</span><br><span class="line">		question = Question.objects.get(pk = question_id)</span><br><span class="line">	<span class="keyword">except</span> Question.DoesNotExist:</span><br><span class="line">		<span class="keyword">raise</span> Http404(<span class="string">&quot;Question does not exist&quot;</span>)</span><br><span class="line">	<span class="keyword">return</span> render(request, <span class="string">&#x27;polls/detail.html&#x27;</span>, &#123;<span class="string">&#x27;question&#x27;</span>: question&#125;)</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li>新的概念：如果问题的请求ID不存在，那么视图就会产生要给404异常。</li>
<li>我们会在稍后讨论你能够在<strong>polls&#x2F;detail.html</strong>模板中放入什么，但是如果你想快速地运行上面的例子，文件应该包含如下：</li>
<li><font color="green"><strong>polls&#x2F;templates&#x2F;polls&#x2F;detail.html</strong></font><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&#123;&#123; question &#125;&#125;</span><br></pre></td></tr></table></figure></li>
<li>会让你现在开始。</li>
</ul>
<h3 id="快捷键：get-object-or-404"><a href="#快捷键：get-object-or-404" class="headerlink" title="快捷键：get_object_or_404()"></a>快捷键：get_object_or_404()</h3><ul>
<li>这是一种常用的语法：如果对象不存在，利用<strong>get()<strong>方法报告一个</strong>Http404</strong>异常。Django提供一个快捷键。下面是<strong>detial</strong>视图，重写：</li>
<li><font color="green"><strong>polls&#x2F;views.py</strong></font><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> django.shortcuts <span class="keyword">import</span> get_object_or_404, render</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> polls.models <span class="keyword">import</span> Question</span><br><span class="line"><span class="comment"># ...</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">detail</span>(<span class="params">request, question_id</span>):</span><br><span class="line">	question = get_object_or_404(Question, pk = question_id)</span><br><span class="line">	<span class="keyword">return</span> render(request, <span class="string">&#x27;polls/detail.html&#x27;</span>, &#123;<span class="string">&#x27;question&#x27;</span>:question&#125;)</span><br></pre></td></tr></table></figure></li>
<li><strong>get_object_or_404()<strong>函数的第一个参数是要给Django模型，然后有数个关键字参数，它们是被传递到模型管理的</strong>get()<strong>函数。如果对象不存在，它会报告</strong>Http404</strong>异常。</li>
</ul>
<blockquote>
<p><strong>Philosophy</strong><br>为什么我们在更高的水平上使用帮助函数<strong>get_object_or_404()<strong>而不是自动获取</strong>ObjectDoesNotExist</strong>异常，或者通过模型API报告<strong>Http404</strong>异常而不是<strong>ObjectDoesNotExist</strong>异常。<br>因为这样会把模型层结合视图层。Django的一个最重要的设计目标是保持低耦合。在Django.shortcuts模型中引入了一些强耦合。</p>
</blockquote>
<ul>
<li>还有一个<strong>get_list_or_404()<strong>函数，它就像</strong>get_object_or_404()<strong>函数一样工作。用</strong>filter()<strong>而不是</strong>get()<strong>方法。它会报告</strong>Http404</strong>异常，如果列表是空的话。</li>
</ul>
<h2 id="使用模板系统"><a href="#使用模板系统" class="headerlink" title="使用模板系统"></a>使用模板系统</h2><ul>
<li>回到我们的poll应用的<strong>detail()<strong>视图。给定context变量</strong>question</strong>，这就是<strong>polls&#x2F;detail.html</strong>模板的代码：<br> <img src="/img/Django-1-7-3-tutorial/detail-01.png"></li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步-Django</category>
      </categories>
      <tags>
        <tag>Django-Models</tag>
      </tags>
  </entry>
  <entry>
    <title>DMwR-note-01-预测海藻数量(三)</title>
    <url>/2014/10/28/%E6%8A%80%E8%83%BD-%E4%BF%AE%E8%A1%8C-%E8%BF%9B%E6%AD%A5-R%E8%AF%AD%E8%A8%80/DMwR-note-01-%E9%A2%84%E6%B5%8B%E6%B5%B7%E8%97%BB%E6%95%B0%E9%87%8F(%E4%B8%89)/</url>
    <content><![CDATA[<h2 id="写在开头的话"><a href="#写在开头的话" class="headerlink" title="写在开头的话"></a>写在开头的话</h2><hr>
<p>讨论了缺失值的处理，相当于对数据进行了简单的预处理，今天我们来继续探讨数据集模型的建立。</p>
<h2 id="数据的模型"><a href="#数据的模型" class="headerlink" title="数据的模型"></a>数据的模型</h2><hr>
<ul>
<li>数据的模型简单的说就是一个函数，输入就是我们之前的数据algae，而输出就是我们预期的一些值。</li>
<li>本案例的主要研究目的是预测140个水样中7种海藻的出现频率。假设海藻频率是数值型数据，因此可以考虑进行回归分析。简单地说，预测任务是建立一个模型来找到一个数值变量和一组解释变量的关系。这个模型既可以根据未来解释变量的值来预测目标变量，也可以帮助更好地理解问题中各个变量之间的相互联系。</li>
</ul>
<h3 id="多元化线性回归"><a href="#多元化线性回归" class="headerlink" title="多元化线性回归"></a>多元化线性回归</h3><hr>
<ul>
<li><p>多元线性回归模型是最常用的统计数据分析方法，该模型给出了一个有关目标变量与一组解释变量关系的线性函数。</p>
</li>
<li><p>数据缺失值的处理：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">library(DMwR)</span><br><span class="line">data(algae)</span><br><span class="line">temp &lt;- algae</span><br><span class="line">temp &lt;- temp[-manyNAs(temp),]</span><br><span class="line">clean.algae &lt;- knnImputation(temp, k = 10)</span><br></pre></td></tr></table></figure>
</li>
<li><p>上面的代码首先移除了第62条和第199条水样记录，因为在这两条记录的11个预测变量中有6个是有缺失值的。然后利用数据集个案的相似性来填补缺失值。以上代码运行之后，得到的数据框将不含缺失值。</p>
</li>
<li><p>接下来，将建立一个用于预测海藻频率的线性回归模型：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">summary(lm.a1)</span><br></pre></td></tr></table></figure>
</li>
<li><p>函数lm()建立一个线性回归模型，其中的第一个参数给出了模型的函数形式。在这个例子中，函数的形式是用数据中其他所有变量来预测变量a1，第一个参数中的点”.”代表数据框中除了a1之外的变量。如果需要用预测变量mxPH和NH4来预测变量a1，就要定义模型为“a1~mxPH + NH4”。还有很多其他定义模型的方式，这都称为R公式，后边用到时进行介绍。参数data是用来设定建模所用的数据集。</p>
</li>
<li><p>函数lm()的结果是一个含有线性模型信息的对象。可以通过下列代码获取更多线性模型的信息：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lm.a1 &lt;- lm(a1~., data = clean.algae[,1:12])</span><br><span class="line"></span><br><span class="line">Call:</span><br><span class="line">lm(formula = a1 ~ ., data = clean.algae[, 1:12])</span><br><span class="line"></span><br><span class="line">Residuals:</span><br><span class="line">    Min      1Q  Median      3Q     Max </span><br><span class="line">-37.679 -11.893  -2.567   7.410  62.190 </span><br><span class="line"></span><br><span class="line">Coefficients:</span><br><span class="line">              Estimate Std. Error t value Pr(&gt;|t|)   </span><br><span class="line">(Intercept)  42.942055  24.010879   1.788  0.07537 . </span><br><span class="line">seasonspring  3.726978   4.137741   0.901  0.36892   </span><br><span class="line">seasonsummer  0.747597   4.020711   0.186  0.85270   </span><br><span class="line">seasonwinter  3.692955   3.865391   0.955  0.34065   </span><br><span class="line">sizemedium    3.263728   3.802051   0.858  0.39179   </span><br><span class="line">sizesmall     9.682140   4.179971   2.316  0.02166 * </span><br><span class="line">speedlow      3.922084   4.706315   0.833  0.40573   </span><br><span class="line">speedmedium   0.246764   3.241874   0.076  0.93941   </span><br><span class="line">mxPH         -3.589118   2.703528  -1.328  0.18598   </span><br><span class="line">mnO2          1.052636   0.705018   1.493  0.13715   </span><br><span class="line">Cl           -0.040172   0.033661  -1.193  0.23426   </span><br><span class="line">NO3          -1.511235   0.551339  -2.741  0.00674 **</span><br><span class="line">NH4           0.001634   0.001003   1.628  0.10516   </span><br><span class="line">oPO4         -0.005435   0.039884  -0.136  0.89177   </span><br><span class="line">PO4          -0.052241   0.030755  -1.699  0.09109 . </span><br><span class="line">Chla         -0.088022   0.079998  -1.100  0.27265   </span><br><span class="line">---</span><br><span class="line">Signif. codes:  0 ?**?0.001 ?*?0.01 ??0.05 ??0.1 ??1</span><br><span class="line"></span><br><span class="line">Residual standard error: 17.65 on 182 degrees of freedom</span><br><span class="line">Multiple R-squared:  0.3731,	Adjusted R-squared:  0.3215 </span><br><span class="line">F-statistic: 7.223 on 15 and 182 DF,  p-value: 2.444e-12</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p>在解释函数summary()应用到线性模型对象所得到的信息之前，先介绍R如何处理3个名义变量。当像上面一样进行模型构建时，R会生成一组的辅助变量，即对每一个有k个水平的因子变量，R会生成k-1个辅助变量。这些辅助变量的值为0或者1.当辅助变量的值为1，表明该因子出现，同时表明其他所有辅助变量的值为0。如果所有的k-1个变量的值都是0，则表明因子变量的取值为第k个剩余的值。在以上的汇总结果中，可以看到R为因子变量season生成了3个辅助变量(seasonspring, seasonsummer和seasonwinter)。如果某个水样的season变量的取值为”autumn”，则所有3个赋值变量的值将全部为零。</p>
</li>
<li><p>对得到的线性模型对象应用函数summary()，将给出所建立模型的一些诊断信息。首先是有关线性模型中数据拟合的残差(residual)。残差应该是均值为0并且为正态分布。（显然残差最好尽可能的小！）</p>
</li>
<li><p>对于每个多元线性回归方程的系数(变量)，R显示它的估计值和标准误差(这些系数变化程度的估计)。为了检验这些系数的重要性，可以进行这些系数为0的假设检验，即<img src="/img/DMwR/02_algae_model/01_formula.PNG">。通常使用t检验来验证这些假设。R计算t值，该值定义为估计系数值与其标准误差的比，即<img src="/img/DMwR/02_algae_model/02_formula.PNG">。R将显示与系数相关联的一列(Pr(&gt; |t|))表示系数为0这一假设被拒绝的概率。因此，该值为0.0001表明有99.99%的置信度认为这个系数并非为0。对于每个测试，R都给出一个标志来表示相应的测试置信度水平。总之，仅对于这些前面有标志的系数，我们至少有90%的置信度来拒绝系数为0的一个假设。</p>
</li>
<li><p>另一个由R输出的模型诊断信息是R^2(或者多元R^2或调整R^2)。R^2表明模型与数据的吻合度，即数据所能解释的数据变差的比例。R^2越接近1(几乎100%地解释模型数据的变差)就说模型模拟得很好；R^2越小，说明模型拟合得越差。调整系数则更严格，它考虑回归模型中参数的数量。</p>
</li>
<li><p>最后，我们还可以检验任何解释变量和目标变量没有哦依赖这一原假设，即<img src="/img/DMwR/02_algae_model/03_formula.PNG">。可以通过把R给出的F统计值与一个临界值进行比较来进行检验。R提供一个拒绝原假设的置信度水平。因此p值为0.0001表示99.99%的置信度确定原假设是错误的。通常，如果一个模型不能通过这个检验(即得到的p值被认为太大，例如大于0.1)，则单个系数的t检验没有意义。</p>
</li>
<li><p>有些诊断信息也可以通过绘制线性模型来进行检验。实际上，可以用一个类似plot(lm.al)的命令得到一系列的线性模型图，它们有助于了解模型的性能。其中的一个图形绘制拟合的目标变量值和模型残差的散点图。误差相对较大时，R通常在该散点图中添加相应的行数，这样就可以方便地检查这些误差较大的记录。R给出的另一个图形是误差的正态Q-Q图，通过它可以检查误差是否符合应有的正态分布。</p>
</li>
<li><p>该模型解释的方差比例还不是很理想(大约32%)。还可以拒绝目标变量不依赖于预测变量的假设(F检验的p值很小)。检查某些系数的显著性，可能会质疑有些变量是否应该进入模型中。有多种方法可以用来精简回归模型。本节将介绍<strong>向后消元法</strong>。</p>
</li>
<li><p>首先用函数anova()来精简线性模型。当将anova()应用到简单线性模型时，这个函数提供一个模型拟合的方差序贯分析。也就是说，随着公式中项数的增加，模型的残差平方和减少。对前面的模型进行方差分析，结果如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">anova(lm.a1)</span><br><span class="line"></span><br><span class="line">Analysis of Variance Table</span><br><span class="line"></span><br><span class="line">Response: a1</span><br><span class="line">           Df Sum Sq Mean Sq F value    Pr(&gt;F)    </span><br><span class="line">season      3     85    28.2  0.0905 0.9651944    </span><br><span class="line">size        2  11401  5700.7 18.3088  5.69e-08 ***</span><br><span class="line">speed       2   3934  1967.2  6.3179 0.0022244 ** </span><br><span class="line">mxPH        1   1329  1328.8  4.2677 0.0402613 *  </span><br><span class="line">mnO2        1   2287  2286.8  7.3444 0.0073705 ** </span><br><span class="line">Cl          1   4304  4304.3 13.8239 0.0002671 ***</span><br><span class="line">NO3         1   3418  3418.5 10.9789 0.0011118 ** </span><br><span class="line">NH4         1    404   403.6  1.2963 0.2563847    </span><br><span class="line">oPO4        1   4788  4788.0 15.3774 0.0001246 ***</span><br><span class="line">PO4         1   1406  1405.6  4.5142 0.0349635 *  </span><br><span class="line">Chla        1    377   377.0  1.2107 0.2726544    </span><br><span class="line">Residuals 182  56668   311.4                      </span><br><span class="line">---</span><br><span class="line">Signif. codes:  0 ?**?0.001 ?*?0.01 ??0.05 ??0.1 ??1</span><br></pre></td></tr></table></figure></li>
<li><p>上面结果表明变量season对减少模型拟合误差的贡献度最小下面将它从模型中剔除：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lm2.a1 = update(lm.a1, .~.-season)</span><br></pre></td></tr></table></figure></li>
<li><p>函数update()用于对已有的线性模型进行微小的调整。在上面的代码中，应用函数update()从模型lm.a1中移除变量season以得到一个新的模型。新的模型的汇总信息如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">summary(lm2.a1)</span><br><span class="line"></span><br><span class="line">Call:</span><br><span class="line">lm(formula = a1 ~ size + speed + mxPH + mnO2 + Cl + NO3 + NH4 + </span><br><span class="line">    oPO4 + PO4 + Chla, data = clean.algae[, 1:12])</span><br><span class="line"></span><br><span class="line">Residuals:</span><br><span class="line">    Min      1Q  Median      3Q     Max </span><br><span class="line">-36.460 -11.953  -3.044   7.444  63.730 </span><br><span class="line"></span><br><span class="line">Coefficients:</span><br><span class="line">              Estimate Std. Error t value Pr(&gt;|t|)   </span><br><span class="line">(Intercept) 44.9532874 23.2378377   1.934  0.05458 . </span><br><span class="line">sizemedium   3.3092102  3.7825221   0.875  0.38278   </span><br><span class="line">sizesmall   10.2730961  4.1223163   2.492  0.01358 * </span><br><span class="line">speedlow     3.0546270  4.6108069   0.662  0.50848   </span><br><span class="line">speedmedium -0.2976867  3.1818585  -0.094  0.92556   </span><br><span class="line">mxPH        -3.2684281  2.6576592  -1.230  0.22033   </span><br><span class="line">mnO2         0.8011759  0.6589644   1.216  0.22561   </span><br><span class="line">Cl          -0.0381881  0.0333791  -1.144  0.25407   </span><br><span class="line">NO3         -1.5334300  0.5476550  -2.800  0.00565 **</span><br><span class="line">NH4          0.0015777  0.0009951   1.586  0.11456   </span><br><span class="line">oPO4        -0.0062392  0.0395086  -0.158  0.87469   </span><br><span class="line">PO4         -0.0509543  0.0305189  -1.670  0.09669 . </span><br><span class="line">Chla        -0.0841371  0.0794459  -1.059  0.29096   </span><br><span class="line">---</span><br><span class="line">Signif. codes:  0 ?**?0.001 ?*?0.01 ??0.05 ??0.1 ??1</span><br><span class="line"></span><br><span class="line">Residual standard error: 17.57 on 185 degrees of freedom</span><br><span class="line">Multiple R-squared:  0.3682,	Adjusted R-squared:  0.3272 </span><br><span class="line">F-statistic: 8.984 on 12 and 185 DF,  p-value: 1.762e-13</span><br></pre></td></tr></table></figure></li>
<li><p>新模型的拟合指标R^2提高到了32.8%，仍然不是太理想。下面使用anova()函数对两个模型进行正式的比较，但这次使用两个模型作为参数：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">anova(lm.a1, lm2.a1)</span><br><span class="line"></span><br><span class="line">Analysis of Variance Table</span><br><span class="line"></span><br><span class="line">Model 1: a1 ~ season + size + speed + mxPH + mnO2 + Cl + NO3 + NH4 + oPO4 + </span><br><span class="line">    PO4 + Chla</span><br><span class="line">Model 2: a1 ~ size + speed + mxPH + mnO2 + Cl + NO3 + NH4 + oPO4 + PO4 + </span><br><span class="line">    Chla</span><br><span class="line">  Res.Df   RSS Df Sum of Sq      F Pr(&gt;F)</span><br><span class="line">1    182 56668                           </span><br><span class="line">2    185 57116 -3   -447.62 0.4792 0.6971</span><br></pre></td></tr></table></figure></li>
<li><p>上面的函数通过F检验对两个模型进行方差分析，据此评估两个模型是否有显著不同。这种情况下，尽管误差平方和减少了(-448),但是比较结果说明两者的差距并不显著(显著性值0.6971说明两个模型不同的可能性有30%)。注意，新模型比较简单。为了检查能否移除更多的系数，我们再次讨论对lm2.a1模型使用anova()函数。不断重复这个过程知道没有可剔除的候选系数。为了简化向后消元过程，R有一个函数来执行上面所有过程。</p>
</li>
<li><p>下面的代码对初始模型(lm.a1)用向后消元方法得到一个新的线性模型。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">final.lm = step(lm.a1)</span><br><span class="line"></span><br><span class="line">Start:  AIC=1152.03</span><br><span class="line">a1 ~ season + size + speed + mxPH + mnO2 + Cl + NO3 + NH4 + oPO4 + </span><br><span class="line">    PO4 + Chla</span><br><span class="line"></span><br><span class="line">         Df Sum of Sq   RSS    AIC</span><br><span class="line">- season  3    447.62 57116 1147.6</span><br><span class="line">- speed   2    269.60 56938 1149.0</span><br><span class="line">- oPO4    1      5.78 56674 1150.0</span><br><span class="line">- Chla    1    376.96 57045 1151.3</span><br><span class="line">- Cl      1    443.46 57112 1151.6</span><br><span class="line">- mxPH    1    548.76 57217 1151.9</span><br><span class="line">&lt;none&gt;                56668 1152.0</span><br><span class="line">- mnO2    1    694.11 57363 1152.4</span><br><span class="line">- NH4     1    825.67 57494 1152.9</span><br><span class="line">- PO4     1    898.42 57567 1153.1</span><br><span class="line">- size    2   1857.16 58526 1154.4</span><br><span class="line">- NO3     1   2339.36 59008 1158.0</span><br><span class="line"></span><br><span class="line">Step:  AIC=1147.59</span><br><span class="line">a1 ~ size + speed + mxPH + mnO2 + Cl + NO3 + NH4 + oPO4 + PO4 + </span><br><span class="line">    Chla</span><br><span class="line"></span><br><span class="line">        Df Sum of Sq   RSS    AIC</span><br><span class="line">- speed  2    210.64 57327 1144.3</span><br><span class="line">- oPO4   1      7.70 57124 1145.6</span><br><span class="line">- Chla   1    346.27 57462 1146.8</span><br><span class="line">- Cl     1    404.10 57520 1147.0</span><br><span class="line">- mnO2   1    456.37 57572 1147.2</span><br><span class="line">- mxPH   1    466.95 57583 1147.2</span><br><span class="line">&lt;none&gt;               57116 1147.6</span><br><span class="line">- NH4    1    776.11 57892 1148.3</span><br><span class="line">- PO4    1    860.62 57977 1148.5</span><br><span class="line">- size   2   2175.59 59292 1151.0</span><br><span class="line">- NO3    1   2420.47 59537 1153.8</span><br><span class="line"></span><br><span class="line">Step:  AIC=1144.31</span><br><span class="line">a1 ~ size + mxPH + mnO2 + Cl + NO3 + NH4 + oPO4 + PO4 + Chla</span><br><span class="line"></span><br><span class="line">       Df Sum of Sq   RSS    AIC</span><br><span class="line">- oPO4  1     16.29 57343 1142.4</span><br><span class="line">- Chla  1    223.29 57550 1143.1</span><br><span class="line">- mnO2  1    413.77 57740 1143.7</span><br><span class="line">- Cl    1    472.70 57799 1143.9</span><br><span class="line">- mxPH  1    483.56 57810 1144.0</span><br><span class="line">&lt;none&gt;              57327 1144.3</span><br><span class="line">- NH4   1    720.19 58047 1144.8</span><br><span class="line">- PO4   1    809.30 58136 1145.1</span><br><span class="line">- size  2   2060.95 59388 1147.3</span><br><span class="line">- NO3   1   2379.75 59706 1150.4</span><br><span class="line"></span><br><span class="line">Step:  AIC=1142.37</span><br><span class="line">a1 ~ size + mxPH + mnO2 + Cl + NO3 + NH4 + PO4 + Chla</span><br><span class="line"></span><br><span class="line">       Df Sum of Sq   RSS    AIC</span><br><span class="line">- Chla  1     207.7 57551 1141.1</span><br><span class="line">- mnO2  1     402.6 57746 1141.8</span><br><span class="line">- Cl    1     470.7 57814 1142.0</span><br><span class="line">- mxPH  1     519.7 57863 1142.2</span><br><span class="line">&lt;none&gt;              57343 1142.4</span><br><span class="line">- NH4   1     704.4 58047 1142.8</span><br><span class="line">- size  2    2050.3 59393 1145.3</span><br><span class="line">- NO3   1    2370.4 59713 1148.4</span><br><span class="line">- PO4   1    5818.4 63161 1159.5</span><br><span class="line"></span><br><span class="line">Step:  AIC=1141.09</span><br><span class="line">a1 ~ size + mxPH + mnO2 + Cl + NO3 + NH4 + PO4</span><br><span class="line"></span><br><span class="line">       Df Sum of Sq   RSS    AIC</span><br><span class="line">- mnO2  1     435.3 57986 1140.6</span><br><span class="line">- Cl    1     438.1 57989 1140.6</span><br><span class="line">&lt;none&gt;              57551 1141.1</span><br><span class="line">- NH4   1     746.9 58298 1141.6</span><br><span class="line">- mxPH  1     833.1 58384 1141.9</span><br><span class="line">- size  2    2217.5 59768 1144.6</span><br><span class="line">- NO3   1    2667.1 60218 1148.1</span><br><span class="line">- PO4   1    6309.7 63860 1159.7</span><br><span class="line"></span><br><span class="line">Step:  AIC=1140.58</span><br><span class="line">a1 ~ size + mxPH + Cl + NO3 + NH4 + PO4</span><br><span class="line"></span><br><span class="line">       Df Sum of Sq   RSS    AIC</span><br><span class="line">- NH4   1     531.0 58517 1140.4</span><br><span class="line">- Cl    1     584.9 58571 1140.6</span><br><span class="line">&lt;none&gt;              57986 1140.6</span><br><span class="line">- mxPH  1     819.1 58805 1141.4</span><br><span class="line">- size  2    2478.2 60464 1144.9</span><br><span class="line">- NO3   1    2251.4 60237 1146.1</span><br><span class="line">- PO4   1    9097.9 67084 1167.4</span><br><span class="line"></span><br><span class="line">Step:  AIC=1140.38</span><br><span class="line">a1 ~ size + mxPH + Cl + NO3 + PO4</span><br><span class="line"></span><br><span class="line">       Df Sum of Sq   RSS    AIC</span><br><span class="line">&lt;none&gt;              58517 1140.4</span><br><span class="line">- mxPH  1     784.1 59301 1141.0</span><br><span class="line">- Cl    1     835.6 59353 1141.2</span><br><span class="line">- NO3   1    1987.9 60505 1145.0</span><br><span class="line">- size  2    2664.3 61181 1145.2</span><br><span class="line">- PO4   1    8575.8 67093 1165.5</span><br></pre></td></tr></table></figure></li>
<li><p>函数step()使用Akaike信息标准进行模型搜索。默认情况下，搜索使用向后消元方法，但通过设置参数direction，可以采用其他的方法(参考该函数的帮助文档以获取更多信息)。</p>
</li>
<li><p>可以通过下面的代码来获得最后模型的信息：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">summary(final.lm)</span><br><span class="line"></span><br><span class="line">Call:</span><br><span class="line">lm(formula = a1 ~ size + mxPH + Cl + NO3 + PO4, data = clean.algae[, </span><br><span class="line">    1:12])</span><br><span class="line"></span><br><span class="line">Residuals:</span><br><span class="line">    Min      1Q  Median      3Q     Max </span><br><span class="line">-28.874 -12.732  -3.741   8.424  62.926 </span><br><span class="line"></span><br><span class="line">Coefficients:</span><br><span class="line">            Estimate Std. Error t value Pr(&gt;|t|)    </span><br><span class="line">(Intercept) 57.28555   20.96132   2.733  0.00687 ** </span><br><span class="line">sizemedium   2.80050    3.40190   0.823  0.41141    </span><br><span class="line">sizesmall   10.40636    3.82243   2.722  0.00708 ** </span><br><span class="line">mxPH        -3.97076    2.48204  -1.600  0.11130    </span><br><span class="line">Cl          -0.05227    0.03165  -1.651  0.10028    </span><br><span class="line">NO3         -0.89529    0.35148  -2.547  0.01165 *  </span><br><span class="line">PO4         -0.05911    0.01117  -5.291 3.32e-07 ***</span><br><span class="line">---</span><br><span class="line">Signif. codes:  0 ?**?0.001 ?*?0.01 ??0.05 ??0.1 ??1</span><br><span class="line"></span><br><span class="line">Residual standard error: 17.5 on 191 degrees of freedom</span><br><span class="line">Multiple R-squared:  0.3527,	Adjusted R-squared:  0.3324 </span><br><span class="line">F-statistic: 17.35 on 6 and 191 DF,  p-value: 5.554e-16</span><br></pre></td></tr></table></figure></li>
<li><p>这个模型所解释的方差比例(R^2)仍然不是很可观，这样的R^2表明对海藻案例应用假定的线性模型是不合适的。</p>
</li>
</ul>
<h3 id="回归树"><a href="#回归树" class="headerlink" title="回归树"></a>回归树</h3><hr>
<ul>
<li><p>本节给出R中的另一种回归模型。即本节描述了如何通过建立回归树来预测海藻a1出现的频率。由于这类模型能够处理缺失值，所以这里只需要如前面所述移除62号和199号水样。</p>
</li>
<li><p>建立回归树模型如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">library(rpart)</span><br><span class="line">data(algae)</span><br><span class="line">algae = algae[-manyNAs(algae),]</span><br><span class="line">rt.a1 = rpart(a1~., data = algae[,1:12])</span><br></pre></td></tr></table></figure></li>
<li><p>对象rt.a1的内容如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rt.a1</span><br><span class="line">n= 198 </span><br><span class="line"></span><br><span class="line">node), <span class="built_in">split</span>, n, deviance, yval</span><br><span class="line">      * denotes terminal node</span><br><span class="line"></span><br><span class="line"> 1) root 198 90401.290 16.996460  </span><br><span class="line">   2) PO4&gt;=43.818 147 31279.120  8.979592  </span><br><span class="line">     4) Cl&gt;=7.8065 140 21622.830  7.492857  </span><br><span class="line">       8) oPO4&gt;=51.118 84  3441.149  3.846429 *</span><br><span class="line">       9) oPO4&lt; 51.118 56 15389.430 12.962500  </span><br><span class="line">        18) mnO2&gt;=10.05 24  1248.673  6.716667 *</span><br><span class="line">        19) mnO2&lt; 10.05 32 12502.320 17.646880  </span><br><span class="line">          38) NO3&gt;=3.1875 9   257.080  7.866667 *</span><br><span class="line">          39) NO3&lt; 3.1875 23 11047.500 21.473910  </span><br><span class="line">            78) mnO2&lt; 8 13  2919.549 13.807690 *</span><br><span class="line">            79) mnO2&gt;=8 10  6370.704 31.440000 *</span><br><span class="line">     5) Cl&lt; 7.8065 7  3157.769 38.714290 *</span><br><span class="line">   3) PO4&lt; 43.818 51 22442.760 40.103920  </span><br><span class="line">     6) mxPH&lt; 7.87 28 11452.770 33.450000  </span><br><span class="line">      12) mxPH&gt;=7.045 18  5146.169 26.394440 *</span><br><span class="line">      13) mxPH&lt; 7.045 10  3797.645 46.150000 *</span><br><span class="line">     7) mxPH&gt;=7.87 23  8241.110 48.204350  </span><br><span class="line">      14) PO4&gt;=15.177 12  3047.517 38.183330 *</span><br><span class="line">      15) PO4&lt; 15.177 11  2673.945 59.136360 *</span><br></pre></td></tr></table></figure>
</li>
<li><p>回归树是对某些解释变量分层次的逻辑测试。基于树的模型自动筛选某些相关的变量，这样就会对树进行剪枝，减去某些变量。树从R标为1的根结点开始读，R在这个结点中提供相关的信息。即，可以再该结点中看到一共有198个水样（用于构建树的训练集数据样本量），在这198个水样中，海藻a1出现的平均频率为16.99，相对平均值的偏差为90401.29。树的每个结点有两个分支，这与预测变量的检验结果有关。例如，在根结点中有一个相应于测试“PO4&gt;&#x3D;43.818”为真（含有147个水样）的个案分支（R输出中标为2），同时也有另一个分支包含剩余的51个不满足这个测试的水样（R标记为3）。从结点2有两个分支分布连接到结点4和结点5，具体到哪个结点由对变量CI的检验来确定。不断进行以上的检验，直到达到某一个叶结点，这些叶结点在R中由星号标记出来。那么我们只要从根结点开始根据对该水样的检验结果，追踪某个分支，直到叶结点，我们就可以预测某个水样的频率。叶结点目标变量的平均值就是树的预测值。</p>
</li>
<li><p>我们也可以得到回归树的图形表示。可以用函数plot()和函数text()对树对象绘图即可。这两个函数有多个参数来控制树的可视化。为了方便地得到漂亮的树的可视化图形，本书的R添加包中提供了函数prettyTree()。对上面得到的树对象应用该函数，得到图形如图所示：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">prettyTree(rt.a1)</span><br></pre></td></tr></table></figure></li>
<li><p><img src="/img/DMwR/02_algae_model/04_plot.PNG"></p>
</li>
<li><p>函数summary()也可以用于树对象。此函数将给出许多有关于树的测试信息、其他可能考虑的测试以及中间分割等。这里的中间分割是R回归树处理缺失值的一种方法。</p>
</li>
<li><p>通常分两步来建立回归树。最初，生成一棵较大的树，然后通过统计估计删除底部的一些结点来对树进行修剪。这个过程的目的是繁殖过度拟合。事实上，一个过度大的树一般会很好地对训练数据集数据进行拟合，但是它会拟合给定数据集中的一写虚假的关系，因此当把该模型用于新数据的预测时，预测性能很差。在许多建模技术中存在过度拟合问题，尤其是当需要逼近的函数的假设条件不是很严格的时候。对于要求不严格的模型，虽然它们的要求不高，有广泛的应用范围，但却存在过度拟合问题，所以它需要一个事后统计估计步骤来避免过度拟合问题。</p>
</li>
<li><p>上面使用rpart()函数构建树，在构建树的过程中，当给定条件满足时构建过程就停止。当下列条件满足时，树就构建结束：</p>
<ul>
<li><ol>
<li>偏差的减少小于某一个给定的界限值时；</li>
</ol>
</li>
<li><ol start="2">
<li>当结点中的样本数量小于某个给定界限值时；</li>
</ol>
</li>
<li><ol start="3">
<li>当树的深度大于一个给定的界限值。</li>
</ol>
</li>
</ul>
</li>
<li><p>上面3个界限值分别由rpart()函数的三个参数（cp, minsplit, maxdepth）来确定。它们的默认值分别为0.01、20和30。如果要避免树的过度拟合问题，就要经常检查这些默认值的有效性。这可以通过对得到的树采取事后修剪过程来进行。</p>
</li>
<li><p>rpart()添加包实现了一种称为“复杂度损失修剪”的修剪方法（Breiman et al., 1984）。这个方法使用R在每个树结点计算的参数值cp。这种修剪方法试图估计cp值以确保达到预测的准确性和树的大小之间的最佳折中。给出一个由函数rpart()建立的回归树，R可以生成这棵树的一些子树，并估计这些树的性能。这些信息可以通过函数printcp()得到：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">printcp(rt.a1)</span><br><span class="line"></span><br><span class="line">Regression tree:</span><br><span class="line">rpart(formula = a1 ~ ., data = algae[, 1:12])</span><br><span class="line"></span><br><span class="line">Variables actually used <span class="keyword">in</span> tree construction:</span><br><span class="line">[1] Cl   mnO2 mxPH NO3  oPO4 PO4 </span><br><span class="line"></span><br><span class="line">Root node error: 90401/198 = 456.57</span><br><span class="line"></span><br><span class="line">n= 198 </span><br><span class="line"></span><br><span class="line">        CP nsplit rel error  xerror    xstd</span><br><span class="line">1 0.405740      0   1.00000 1.00909 0.13028</span><br><span class="line">2 0.071885      1   0.59426 0.72655 0.11938</span><br><span class="line">3 0.030887      2   0.52237 0.67966 0.11487</span><br><span class="line">4 0.030408      3   0.49149 0.70176 0.11781</span><br><span class="line">5 0.027872      4   0.46108 0.69623 0.11628</span><br><span class="line">6 0.027754      5   0.43321 0.69623 0.11628</span><br><span class="line">7 0.018124      6   0.40545 0.67679 0.11052</span><br><span class="line">8 0.016344      7   0.38733 0.70123 0.11415</span><br><span class="line">9 0.010000      9   0.35464 0.71140 0.11389</span><br></pre></td></tr></table></figure></li>
<li><p>由rpart()函数建立的回归树是上面列表中的最后一个树（树9）。这个树的cp值为0.01（参数cp的默认值），该树包括九个测试和一个相对误差值（与根结点相比）0.354。然而，R应用10折交叉验证的内部过程，评估该树的平均相对误差为0.70241 ± 0.11523。根据这些更稳健的性能估计信息，可以避免过度拟合问题。可以看到，8号树的预测相对误差（0.67733）最小。另一个选择标准时根据1-SE规则来选择最好的回归树，这包括检查交叉验证的估计误差（“xerror”列），以及标准误差（“xstd”列）。在这个案例中，1-SE规则树是最小的树，误差小于0.67733 + 0.10892 &#x3D; 0.78625，而由1检验的2号树的估计误差为0.73358。如果我们选择这个树而不是R建议的树，我们就可以通过使用不同的cp值来建立这棵树。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rt2.a1 &lt;- prune(rt.a1, <span class="built_in">cp</span> = 0.08)</span><br><span class="line">rt2.a1</span><br><span class="line"></span><br><span class="line">n= 198 </span><br><span class="line"></span><br><span class="line">node), <span class="built_in">split</span>, n, deviance, yval</span><br><span class="line">      * denotes terminal node</span><br><span class="line"></span><br><span class="line">1) root 198 90401.29 16.996460  </span><br><span class="line">  2) PO4&gt;=43.818 147 31279.12  8.979592 *</span><br><span class="line">  3) PO4&lt; 43.818 51 22442.76 40.103920 *</span><br></pre></td></tr></table></figure></li>
<li><p>本书添加包中的rpartXse()函数可以自动运行这个过程，它的参数se的默认值为1.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(rt.a1 &lt;- rpartXse(a1~., data=algae[,1:12]))</span><br><span class="line"></span><br><span class="line">n= 198 </span><br><span class="line"></span><br><span class="line">node), <span class="built_in">split</span>, n, deviance, yval</span><br><span class="line">      * denotes terminal node</span><br><span class="line"></span><br><span class="line">1) root 198 90401.290 16.996460  </span><br><span class="line">  2) PO4&gt;=43.818 147 31279.120  8.979592  </span><br><span class="line">    4) Cl&gt;=7.1665 142 21763.160  7.530282 *</span><br><span class="line">    5) Cl&lt; 7.1665 5   746.792 50.140000 *</span><br><span class="line">  3) PO4&lt; 43.818 51 22442.760 40.103920 *</span><br></pre></td></tr></table></figure></li>
<li><p>可以应用R的函数snip.rpart()来交互地对树进行修剪。这个函数可以通过两种方式生成一个修剪过的回归树。第一种方法是指出需要修剪那个地方的结点号（可以通过输出树对象来得到树的结点号）：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">first.tree &lt;- rpart(a1~., data =algae[,1:12])</span><br><span class="line">snip.rpart(first.tree, c(4,7))</span><br><span class="line"></span><br><span class="line">n= 198 </span><br><span class="line"></span><br><span class="line">node), <span class="built_in">split</span>, n, deviance, yval</span><br><span class="line">      * denotes terminal node</span><br><span class="line"></span><br><span class="line"> 1) root 198 90401.290 16.996460  </span><br><span class="line">   2) PO4&gt;=43.818 147 31279.120  8.979592  </span><br><span class="line">     4) Cl&gt;=7.8065 140 21622.830  7.492857 *</span><br><span class="line">     5) Cl&lt; 7.8065 7  3157.769 38.714290 *</span><br><span class="line">   3) PO4&lt; 43.818 51 22442.760 40.103920  </span><br><span class="line">     6) mxPH&lt; 7.87 28 11452.770 33.450000  </span><br><span class="line">      12) mxPH&gt;=7.045 18  5146.169 26.394440 *</span><br><span class="line">      13) mxPH&lt; 7.045 10  3797.645 46.150000 *</span><br><span class="line">     7) mxPH&gt;=7.87 23  8241.110 48.204350 *</span><br></pre></td></tr></table></figure></li>
<li><p>这个函数与rpart()函数一样返回一个数对象，所以可以用形如my.tree &lt;- snip.rpart(first.tree, c(4,7))这样的代码来保存这个修剪过的树。</p>
</li>
<li><p>另外，也可以再图形窗口下使用snip.rpart()函数。首先，画出回归树，然后调用没有第二个参数的函数。如果点击回归树的某些结点，R会在控制台输出这些结点的信息。如果继续点击这个结点，R就在这个结点对树进行修剪。可以在图形窗口继续修剪回归树，直到右击结束这一交互式的修剪过程。调用该函数的结果仍然是一个数对象：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">prettyTree(first.tree)</span><br><span class="line">snip.rpart(first.tree)</span><br><span class="line"></span><br><span class="line">node number: 2  n= 147 </span><br><span class="line">    response= 8.979592</span><br><span class="line">    Error (dev) =  31279.12 </span><br><span class="line">node number: 6  n= 28 </span><br><span class="line">    response= 33.45</span><br><span class="line">    Error (dev) =  11452.77 </span><br><span class="line">n= 198 </span><br><span class="line"></span><br><span class="line">node), <span class="built_in">split</span>, n, deviance, yval</span><br><span class="line">      * denotes terminal node</span><br><span class="line"></span><br><span class="line"> 1) root 198 90401.290 16.996460  </span><br><span class="line">   2) PO4&gt;=43.818 147 31279.120  8.979592  </span><br><span class="line">     4) Cl&gt;=7.8065 140 21622.830  7.492857  </span><br><span class="line">       8) oPO4&gt;=51.118 84  3441.149  3.846429 *</span><br><span class="line">       9) oPO4&lt; 51.118 56 15389.430 12.962500  </span><br><span class="line">        18) mnO2&gt;=10.05 24  1248.673  6.716667 *</span><br><span class="line">        19) mnO2&lt; 10.05 32 12502.320 17.646880  </span><br><span class="line">          38) NO3&gt;=3.1875 9   257.080  7.866667 *</span><br><span class="line">          39) NO3&lt; 3.1875 23 11047.500 21.473910  </span><br><span class="line">            78) mnO2&lt; 8 13  2919.549 13.807690 *</span><br><span class="line">            79) mnO2&gt;=8 10  6370.704 31.440000 *</span><br><span class="line">     5) Cl&lt; 7.8065 7  3157.769 38.714290 *</span><br><span class="line">   3) PO4&lt; 43.818 51 22442.760 40.103920  </span><br><span class="line">     6) mxPH&lt; 7.87 28 11452.770 33.450000  </span><br><span class="line">      12) mxPH&gt;=7.045 18  5146.169 26.394440 *</span><br><span class="line">      13) mxPH&lt; 7.045 10  3797.645 46.150000 *</span><br><span class="line">     7) mxPH&gt;=7.87 23  8241.110 48.204350  </span><br><span class="line">      14) PO4&gt;=15.177 12  3047.517 38.183330 *</span><br><span class="line">      15) PO4&lt; 15.177 11  2673.945 59.136360 *</span><br></pre></td></tr></table></figure></li>
<li><p>在上例中，点击并修剪了节点2和结点6.</p>
</li>
</ul>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><ul>
<li>这一节我们建立了模型，用了2种方法，分别是多元回归和回归树。那么下一节就要对我们建立的模型进行评价了。</li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步-R语言</category>
      </categories>
      <tags>
        <tag>数据挖掘与R语言-案例学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Django-1-7-3-Tutorial-Part-2-管理站点</title>
    <url>/2015/01/19/%E6%8A%80%E8%83%BD-%E4%BF%AE%E8%A1%8C-%E8%BF%9B%E6%AD%A5-Django/Django-1-7-3-Tutorial-Part-2-%E7%AE%A1%E7%90%86%E7%AB%99%E7%82%B9/</url>
    <content><![CDATA[<ul>
<li>本节教程接着<a href="">Part-1-模型</a>继续，我们继续网络民意调查(Web-poll)应用，然后把焦点放在Django的自生成的管理员站点。<blockquote>
<p><strong>哲学</strong><br>为你的员工或客户自动生成管理员站点，让它可以很方便的对内容进行增删改是一件不需要太多创新的比较乏味的事情。<br>Django是在一个新闻工作室的环境下编写的，“内容出版商”站点和“公共”站点之间有比较清晰的界限。站点管理员利用系统添加新闻故事，事件，体育等等，然后内容会显示在公共站点。Django为站点管理员编辑内容创建了统一的接口。</p>
</blockquote>
</li>
</ul>
<h2 id="新建一个管理用户"><a href="#新建一个管理用户" class="headerlink" title="新建一个管理用户"></a>新建一个管理用户</h2><ul>
<li>首先我们需要创建一个能够登入管理站点的用户。运行以下命令：<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$ python manage.py createsuperuser</span><br></pre></td></tr></table></figure></li>
<li>然后输入你想要的用户名：<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Username: admin</span><br></pre></td></tr></table></figure></li>
<li>然后继续输入你的邮箱地址：<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Email address: admin@example.com</span><br></pre></td></tr></table></figure></li>
<li>最后一步就是输入你的密码。你需要输入2次来确认你的密码：<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Password: **********</span><br><span class="line">Password (again): *********</span><br><span class="line">Superuser created successfully.</span><br></pre></td></tr></table></figure></li>
<li>我的截图：<br><img src="/img/Django-1-7-3-tutorial/createUser.png"></li>
</ul>
<h2 id="打开开发者服务器"><a href="#打开开发者服务器" class="headerlink" title="打开开发者服务器"></a>打开开发者服务器</h2><ul>
<li>Django管理站点默认是激活的。让我们开启开发者服务器对它一探究竟吧。</li>
<li>回想一下<a href="">Part-1-模型</a>，你是怎么开始服务器的：<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$ python manage.py runserver</span><br></pre></td></tr></table></figure></li>
<li>现在，打开浏览器，然后再输入以下地址<a class="link"   href="http://127.0.0.1:8000/admin/" >http://127.0.0.1:8000/admin/<i class="fas fa-external-link-alt"></i></a>。你就可以看到管理员登陆界面了：<br><img src="/img/Django-1-7-3-tutorial/admin-login.png"></li>
<li>由于页面是自动<a class="link"   href="https://docs.djangoproject.com/en/1.7/topics/i18n/translation/" >翻译<i class="fas fa-external-link-alt"></i></a>的，所以可能登陆页面是以你的语言显示的，取决于你的浏览器的设置了。<blockquote>
<p><strong>和你的不同吗？</strong><br>如果你的登陆界面打不开，而是出现了这样的错误：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ImportError at/admin/</span><br><span class="line">cannot <span class="keyword">import</span> name patterns</span><br><span class="line">...</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="进入管理站点"><a href="#进入管理站点" class="headerlink" title="进入管理站点"></a>进入管理站点</h2><ul>
<li>现在，利用你刚才设置的账户和密码登录管理员站点，你应该看到这样的页面：<br><img src="/img/Django-1-7-3-tutorial/welcome-page.png"></li>
<li>你应该会看到两种可编辑的内容：<strong>Groups</strong>和<strong>Users</strong>。它们是由<strong>django.contrib.auth</strong>提供的，这个认证框架是由Django支持的。</li>
</ul>
<h2 id="使投票-poll-应用在管理站点中被修改"><a href="#使投票-poll-应用在管理站点中被修改" class="headerlink" title="使投票(poll)应用在管理站点中被修改"></a>使投票(poll)应用在管理站点中被修改</h2><ul>
<li>但是我们的投票(poll)应用在哪里？它并不再管理首页上展示。</li>
<li>只需要做一件事情：我们需要告知管理站点<strong>Question</strong>对象有一个管理接口。打开<strong>polls&#x2F;admin.py</strong>文件，然后对它们进行以以下编辑：</li>
<li><font color = "green"><strong>polls&#x2F;admin.py</strong></font><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> django.contrib <span class="keyword">import</span> admin</span><br><span class="line"><span class="keyword">from</span> polls.models <span class="keyword">import</span> Question</span><br><span class="line"></span><br><span class="line">admin.site.register(Question)</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="探索免费的管理功能"><a href="#探索免费的管理功能" class="headerlink" title="探索免费的管理功能"></a>探索免费的管理功能</h2><ul>
<li>既然我们注册了<strong>Question</strong>，那么Django就会在管理首页进行显示了。<br><img src="/img/Django-1-7-3-tutorial/poll-resigster.png"></li>
<li>点击<strong>Question</strong>。你就进入了question的修改列表。这个页面显示了数据库中的所有的问题，然后让你选择哪个进行修改。这里显示了问题“What’s up?”在上一部分教程中：<br><img src="/img/Django-1-7-3-tutorial/question-01.png"></li>
<li>点击“What’s up?”，然后编辑它：<br><img src="/img/Django-1-7-3-tutorial/question-02.png"></li>
<li>这里要注意的是：<ul>
<li>这个表格是根据<strong>Question</strong>模型自动生成的。</li>
<li>这个不同的模型的域类型(<strong>DateTimeField,CharField</strong>)对应到合适的HTML输入小部件。每一个字段类型明白自己在Django的管理站点中如何展示。</li>
<li>每一个<strong>DateTimeField</strong>都有一个免费的Javascript快捷方式。日期(Date)会有一个“今天(today)”的快捷方式和日历弹框选择，然后时间(Time)会有一个“现在(now)”的快捷方式和一个便利的弹框，它有常用时间的输入。</li>
</ul>
</li>
<li>页面的底部给你一些选项：<ul>
<li>保存(save)—保存修改和返回当前对象类型的修改列表页面。</li>
<li>保存并且继续编辑(Save and continue editing)—保存修改并且重载当前对象的管理页面。</li>
<li>保存并且继续添加(Save and add another)—保存修改并且为当前对象加载一个新的空白的表格。</li>
<li>删除(Detele)—显示一个删除确认页面。</li>
</ul>
</li>
<li>如果发布日期(“Date published”)的值和你在第一部分创建的时间不相同，那很有可能你没有设置正确的时区。修改时区，然后重载当前页面看看是否准确。</li>
<li>通过点击“今天”和“现在”快捷键来修改“发布日期”，然后点击“保存并且继续编辑”。点击上方的“历史记录”，你会看到一个通过Django管理对当前对象做的所有修改的列表页面，有时间戳和修改者的用户名：<br><img src="/img/Django-1-7-3-tutorial/history.png"></li>
</ul>
<h2 id="添加相关的对象"><a href="#添加相关的对象" class="headerlink" title="添加相关的对象"></a>添加相关的对象</h2><ul>
<li>OK，我们有了<strong>Question</strong>管理页面。但是一个<strong>Question</strong>有多个<strong>Choices</strong>，而管理页面不显示choices.</li>
<li>但是。</li>
<li>有两种方法可以解决这个问题。第一个通过用户admin注册<strong>Choice</strong>就像我们注册<strong>Question</strong>一样。非常简单：</li>
<li><font color="green"><strong>polls&#x2F;admin.py</strong></font><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> django.contrib <span class="keyword">import</span> admin</span><br><span class="line"><span class="keyword">from</span> polls.models <span class="keyword">import</span> Choice, Question</span><br><span class="line"><span class="comment">#...</span></span><br><span class="line">admin.site.register(Choice)</span><br></pre></td></tr></table></figure></li>
<li>现在，<strong>Choices</strong>在Django中是一个可用的选项。<strong>添加choice（Add choice）</strong>的页面应该像这样：<br><img src="/img/Django-1-7-3-tutorial/choice-01.png"></li>
<li>在这个表格当中，<strong>Question</strong>属性是一个选择框(select box)，它包含了数据库当中的每一个问题(question)。Django知道**外键(ForeignKey)<strong>在管理页面中应该是一个</strong><select>**框。在我们的例子中，只有一个问题。</li>
<li>注意到”Add Another”这个链接到下一个“Question”。每一个带<strong>外键</strong>的对象都会自动生成这个链接。当你点击”Add Another”这个链接时，你可以得到一个带有“Add question”表格的弹出窗口。如果你在那个窗口中添加一个问题，然后点击“保存”按钮，Django会把问题保存到数据库，并且动态把它添加为一个你所见到的在“Add choice”表格中可选的选项。</li>
<li>但实际上，这并不是一个有效的添加<strong>Choice</strong>对象到系统的方法。如果能在创建<strong>Question</strong>的同时直接添加多个<strong>Choice</strong>，那样更好。让我们来试试吧。</li>
<li>为<strong>Choice</strong>模型删除<strong>register()<strong>方法。然后，编辑</strong>Question</strong>注册代码如下：</li>
<li><font color="green"><strong>polls&#x2F;admin.py</strong></font><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> django.contrib <span class="keyword">import</span> admin</span><br><span class="line"></span><br><span class="line"><span class="comment"># Register your models here.</span></span><br><span class="line"><span class="keyword">from</span> polls.models <span class="keyword">import</span> Question, Choice</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChoiceInline</span>(admin.StackedInline):</span><br><span class="line">	<span class="string">&quot;&quot;&quot;docstring for ChoiceInline&quot;&quot;&quot;</span></span><br><span class="line">	model = Choice</span><br><span class="line">	extra = <span class="number">3</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">QuestionAdmin</span>(admin.ModelAdmin):</span><br><span class="line">	fieldsets = [</span><br><span class="line">		(<span class="literal">None</span>, &#123;<span class="string">&#x27;fields&#x27;</span>:[<span class="string">&#x27;question_text&#x27;</span>]&#125;),</span><br><span class="line">		(<span class="string">&#x27;Date information&#x27;</span>, &#123;<span class="string">&#x27;fields&#x27;</span>:[<span class="string">&#x27;pub_date&#x27;</span>], <span class="string">&#x27;classes&#x27;</span>:[<span class="string">&#x27;collapse&#x27;</span>]&#125;),</span><br><span class="line">	]</span><br><span class="line">	inlines = [ChoiceInline]</span><br><span class="line"></span><br><span class="line">admin.site.register(Question,QuestionAdmin)</span><br></pre></td></tr></table></figure></li>
<li>它告诉Django：<strong>Choice</strong>对象在<strong>Question</strong>管理页面上边界。默认情况下，提供3个choice填写属性。</li>
<li>加载“Add question”页面来看一下：<br><img src="/img/Django-1-7-3-tutorial/choice-02.png"></li>
<li>它是这样子工作的：相关的Choice有三个可填—由<strong>Extra</strong>指定的，每一次你返回一个已经创建好的对象的<strong>Change</strong>页面，你又可以得到3个额外的choice可填。</li>
<li>在3个choice的底部，你可以找到一个“Add another Choice”链接。如果你点击它，一个新增的choice就可诞生。如果你像删除新增的choice，那么你可以点击这个choice的右上角的X。注意原来的3个choice是不可删除的。<br><img src="/img/Django-1-7-3-tutorial/choice-03.png"></li>
<li>但是有一个小问题，它占用了太多的屏幕空间。所以，Django提供了一个列表的形式显示相关的行内对象，你只需要修改<strong>ChoiceInline</strong>代码：</li>
<li><font color="green"><strong>polls&#x2F;admin.py</strong></font><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ChoiceInline</span>(admin.TabularInline):</span><br><span class="line">	<span class="comment">#....</span></span><br></pre></td></tr></table></figure></li>
<li>用<strong>TabularInline</strong>而非<strong>StackedInline</strong>，相关的对象就会以表格的形式显示得更简洁。<br><img src="/img/Django-1-7-3-tutorial/choice-04.png"></li>
<li>注意到以上还有一个删除的按钮，它可以删除新增的行。</li>
</ul>
<h2 id="自定义管理表格"><a href="#自定义管理表格" class="headerlink" title="自定义管理表格"></a>自定义管理表格</h2><ul>
<li>对你还没写的代码感到惊叹吧。通过<strong>admin.site.register(Question)<strong>来注册</strong>Question</strong>模型，Django能够构建一个默认的表格表现形式。通常，你会想自定义自己的管理表单，你只要通过注册告知Django你想怎么注册这个对象就OK了。</li>
<li>通过重新排序表格中字段，我们来看看效果。修改**admin.site.register(Question)**这一行：</li>
<li><font color="green"><strong>polls&#x2F;admin.py</strong></font><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> django.contrib <span class="keyword">import</span> admin</span><br><span class="line"><span class="keyword">from</span> polls.models <span class="keyword">import</span> Question</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">QuestionAdmin</span>(admin.ModelAdmin):</span><br><span class="line">    fields = [<span class="string">&#x27;pub_date&#x27;</span>, <span class="string">&#x27;question_text&#x27;</span>]</span><br><span class="line"></span><br><span class="line">admin.site.register(Question, QuestionAdmin)</span><br></pre></td></tr></table></figure></li>
<li>你遵循这种模式—创建一个模型管理对象，然后把它当成第二参数传给<strong>admin.site.register()</strong>—任何时候都可以修改。</li>
<li>以上的修改是把“发布日期”(Date published)放在了“问题”(Question)这个字段的前面：<br><img src="/img/Django-1-7-3-tutorial/question-03.png"></li>
<li>虽然两个字段看起来不够酷，但是对于数十个字段的表格来说，选择一个符合直觉的排序是一个非常重要的实用细节。</li>
<li>说到数十个字段的表格，你可能想到把一个表格分离成多个属性(字段).</li>
<li><font color="green"><strong>polls&#x2F;admin.py</strong></font><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> django.contrib <span class="keyword">import</span> admin</span><br><span class="line"><span class="keyword">from</span> polls.models <span class="keyword">import</span> Question</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">QuestionAdmin</span>(admiin.ModelAdmin):</span><br><span class="line">	fieldsets = [</span><br><span class="line">		(Node, &#123;<span class="string">&#x27;fields&#x27;</span>:[<span class="string">&#x27;Question_text&#x27;</span>]&#125;),</span><br><span class="line">		(<span class="string">&#x27;Date information&#x27;</span>, &#123;<span class="string">&#x27;fields&#x27;</span>:[<span class="string">&#x27;pub_date&#x27;</span>]&#125;),</span><br><span class="line">	]</span><br><span class="line">admin.site.register(Question, QuestionAdmin)</span><br></pre></td></tr></table></figure></li>
<li>在**属性(fieldsets)**中的每一个元组的第一个元素是这个属性的标题。以上的表格就是这样：<br><img src="/img/Django-1-7-3-tutorial/question-04.png"></li>
<li>你可以为属性(fieldsets)注入任意的HTML类。Django提供了一个**折叠(collapse)**类用于展示默认是折叠的特定的属性。如果你有一个包含了许多个不常用的属性的很长的表格，那么这个类是非常有用的：</li>
<li><font color="green"><strong>polls&#x2F;admin.py</strong></font><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> django.contrib <span class="keyword">import</span> admin</span><br><span class="line"><span class="keyword">from</span> polls.models <span class="keyword">import</span> Question</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">QuestionAdmin</span>(admin.ModelAdmin):</span><br><span class="line">	fieldsets = [</span><br><span class="line">		(<span class="literal">None</span>, &#123;<span class="string">&#x27;fields&#x27;</span>:[<span class="string">&#x27;question_text&#x27;</span>]&#125;),</span><br><span class="line">		(<span class="string">&#x27;Date information&#x27;</span>, &#123;<span class="string">&#x27;fields&#x27;</span>:[<span class="string">&#x27;pub_date&#x27;</span>], <span class="string">&#x27;classes&#x27;</span>:[<span class="string">&#x27;collapse&#x27;</span>]&#125;),</span><br><span class="line">	]</span><br><span class="line">admin.site.register(Question, QuestionAdmin)</span><br></pre></td></tr></table></figure>
<br><img src="/img/Django-1-7-3-tutorial/question-05.png"></li>
</ul>
<h2 id="添加相关的对象-1"><a href="#添加相关的对象-1" class="headerlink" title="添加相关的对象"></a>添加相关的对象</h2><ul>
<li>OK，我们有了<strong>Question</strong>管理页面。但是一个<strong>Question</strong>有多个<strong>Choices</strong>，而管理页面不显示choices.</li>
<li>但是。</li>
<li>有两种方法可以解决这个问题。第一个通过用户admin注册<strong>Choice</strong>就像我们注册<strong>Question</strong>一样。非常简单：</li>
<li><font color="green"><strong>polls&#x2F;admin.py</strong></font><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> django.contrib <span class="keyword">import</span> admin</span><br><span class="line"><span class="keyword">from</span> polls.models <span class="keyword">import</span> Choice, Question</span><br><span class="line"><span class="comment">#...</span></span><br><span class="line">admin.site.register(Choice)</span><br></pre></td></tr></table></figure></li>
<li>现在，<strong>Choices</strong>在Django中是一个可用的选项。<strong>添加choice（Add choice）</strong>的页面应该像这样：<br><img src="/img/Django-1-7-3-tutorial/choice-01.png"></li>
<li>在这个表格当中，<strong>Question</strong>属性是一个选择框(select box)，它包含了数据库当中的每一个问题(question)。Django知道**外键(ForeignKey)<strong>在管理页面中应该是一个</strong><select>**框。在我们的例子中，只有一个问题。</li>
<li>注意到”Add Another”这个链接到下一个“Question”。每一个带<strong>外键</strong>的对象都会自动生成这个链接。当你点击”Add Another”这个链接时，你可以得到一个带有“Add question”表格的弹出窗口。如果你在那个窗口中添加一个问题，然后点击“保存”按钮，Django会把问题保存到数据库，并且动态把它添加为一个你所见到的在“Add choice”表格中可选的选项。</li>
<li>但实际上，这并不是一个有效的添加<strong>Choice</strong>对象到系统的方法。如果能在创建<strong>Question</strong>的同时直接添加多个<strong>Choice</strong>，那样更好。让我们来试试吧。</li>
<li>为<strong>Choice</strong>模型删除<strong>register()<strong>方法。然后，编辑</strong>Question</strong>注册代码如下：</li>
<li><font color="green"><strong>polls&#x2F;admin.py</strong></font><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> django.contrib <span class="keyword">import</span> admin</span><br><span class="line"></span><br><span class="line"><span class="comment"># Register your models here.</span></span><br><span class="line"><span class="keyword">from</span> polls.models <span class="keyword">import</span> Question, Choice</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChoiceInline</span>(admin.StackedInline):</span><br><span class="line">	<span class="string">&quot;&quot;&quot;docstring for ChoiceInline&quot;&quot;&quot;</span></span><br><span class="line">	model = Choice</span><br><span class="line">	extra = <span class="number">3</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">QuestionAdmin</span>(admin.ModelAdmin):</span><br><span class="line">	fieldsets = [</span><br><span class="line">		(<span class="literal">None</span>, &#123;<span class="string">&#x27;fields&#x27;</span>:[<span class="string">&#x27;question_text&#x27;</span>]&#125;),</span><br><span class="line">		(<span class="string">&#x27;Date information&#x27;</span>, &#123;<span class="string">&#x27;fields&#x27;</span>:[<span class="string">&#x27;pub_date&#x27;</span>], <span class="string">&#x27;classes&#x27;</span>:[<span class="string">&#x27;collapse&#x27;</span>]&#125;),</span><br><span class="line">	]</span><br><span class="line">	inlines = [ChoiceInline]</span><br><span class="line"></span><br><span class="line">admin.site.register(Question,QuestionAdmin)</span><br></pre></td></tr></table></figure></li>
<li>它告诉Django：<strong>Choice</strong>对象在<strong>Question</strong>管理页面上边界。默认情况下，提供3个choice填写属性。</li>
<li>加载“Add question”页面来看一下：<br><img src="/img/Django-1-7-3-tutorial/choice-02.png"></li>
<li>它是这样子工作的：相关的Choice有三个可填—由<strong>Extra</strong>指定的，每一次你返回一个已经创建好的对象的<strong>Change</strong>页面，你又可以得到3个额外的choice可填。</li>
<li>在3个choice的底部，你可以找到一个“Add another Choice”链接。如果你点击它，一个新增的choice就可诞生。如果你像删除新增的choice，那么你可以点击这个choice的右上角的X。注意原来的3个choice是不可删除的。<br><img src="/img/Django-1-7-3-tutorial/choice-03.png"></li>
<li>但是有一个小问题，它占用了太多的屏幕空间。所以，Django提供了一个列表的形式显示相关的行内对象，你只需要修改<strong>ChoiceInline</strong>代码：</li>
<li><font color="green"><strong>polls&#x2F;admin.py</strong></font><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ChoiceInline</span>(admin.TabularInline):</span><br><span class="line">	<span class="comment">#....</span></span><br></pre></td></tr></table></figure></li>
<li>用<strong>TabularInline</strong>而非<strong>StackedInline</strong>，相关的对象就会以表格的形式显示得更简洁。<br><img src="/img/Django-1-7-3-tutorial/choice-04.png"></li>
<li>注意到以上还有一个删除的按钮，它可以删除新增的行。</li>
</ul>
<h2 id="自定义管理修改列表"><a href="#自定义管理修改列表" class="headerlink" title="自定义管理修改列表"></a>自定义管理修改列表</h2><ul>
<li>既然Question管理页面开启来不错，让我们对“修改列表”页面做一些更改–让一页显示系统中的所有问题。</li>
<li>现在的页面是：<br><img src="/img/Django-1-7-3-tutorial/choice-05.png"></li>
<li>默认情况下，Django显示每个对象的<strong>str()<strong>内容。但是有时候我们想显示单独的每个属性。这样做的话，就要用到</strong>list_display</strong>管理选项，它是一个可显示为列的属性的元组：</li>
<li><font color="green"><strong>polls&#x2F;admin.py</strong></font><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">QuestionAdmin</span>(admin.ModelAdmin):</span><br><span class="line">	<span class="comment">#...</span></span><br><span class="line">	list_display = (<span class="string">&#x27;question_text&#x27;</span>,<span class="string">&#x27;pub_date&#x27;</span>)</span><br></pre></td></tr></table></figure></li>
<li>为了更好的展示，让我们在自定义的方法表格中添加<strong>was_published_recently</strong>:</li>
<li><font color="green"><strong>polls&#x2F;admin.py</strong></font><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">QuestionAdmin</span>(admin.ModelAdmin):</span><br><span class="line">	<span class="comment">#...</span></span><br><span class="line">	list_display = (<span class="string">&#x27;question_text&#x27;</span>, <span class="string">&#x27;pub_date&#x27;</span>, <span class="string">&#x27;was_published_recently&#x27;</span>)</span><br></pre></td></tr></table></figure></li>
<li>现在问题修改页面变成这样子了：<br><img src="/img/Django-1-7-3-tutorial/choice-06.png"></li>
<li>你可以点击列头来对这些值进行排序–出了<strong>was_published_recently</strong>列头，因为通过武断的方法输出来进行排序是不支持的。还有注意到<strong>was_published_recently</strong>列头，默认的，是方法的名字(通过空格来强调)，每一行都包含输出的字符串的表示。</li>
<li>你可以通过给这个方法加一些属性来改善它(在<strong>polls&#x2F;models.py</strong>文件中)，如下：</li>
<li><font color="green"><strong>polls&#x2F;models.py</strong></font><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Question</span>(models.Model):</span><br><span class="line">	<span class="comment">#...</span></span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">was_publised_recently</span>(<span class="params">self</span>):</span><br><span class="line">		<span class="keyword">return</span> self.pub_date &gt;= timezone.now() - datetime.timedelta(days=<span class="number">1</span>)</span><br><span class="line">	was_published_recently.admin_order_field = <span class="string">&#x27;pub_date&#x27;</span></span><br><span class="line">	was_published_recently.boolean = <span class="literal">True</span></span><br><span class="line">	was_published_recently.short_description = <span class="string">&#x27;Published recently ?&#x27;</span></span><br></pre></td></tr></table></figure></li>
<li>参考更多消息，请看<a class="link"   href="https://docs.djangoproject.com/en/1.7/ref/contrib/admin/#django.contrib.admin.ModelAdmin.list_display" >list_display<i class="fas fa-external-link-alt"></i></a></li>
<li>再次编辑你的<strong>polls&#x2F;admin.py</strong>文件，为<strong>Question</strong>修改列表页面添加一个改进：用<strong>list_filter</strong>过滤，添加以下行道<strong>QuestioAdmin</strong>文件中：<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">list_filter = [<span class="string">&#x27;pub_date&#x27;</span>]</span><br></pre></td></tr></table></figure></li>
<li>过滤显示的类型取决于你在过滤的属性的类型。因为<strong>pub_date</strong>是一个<strong>DateTimeField</strong>类型，Django自动给出合适的过滤选项：“Any date”,”Today”,”Past 7 days”,”This month”,”This year”.</li>
<li>这些看起来不错，让我们添加一些查找功能：<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">search_field = [<span class="string">&#x27;question_text&#x27;</span>]</span><br></pre></td></tr></table></figure></li>
<li>这个会在修改页面的上方添加一个查询框。当输入一些关键字时，Django会查询<strong>question_text</strong>域。你还可以添加其他的任意域–因为在数据库中用到了<strong>LIKE</strong>查询，将查询的数量减少了，这样查询的速度更快。</li>
<li>现在是时候给你的修改列表来个分页显示的功能。默认是每一页显示100条。<strong>Change list pagination, search boxes, filters, date-hierarchies</strong>和<strong>column-header-ordering</strong>都可以工作。</li>
</ul>
<h2 id="自定义管理look和feel"><a href="#自定义管理look和feel" class="headerlink" title="自定义管理look和feel"></a>自定义管理look和feel</h2><ul>
<li>明显的，把“Django administration”放在每一个管理页面的头部是不合理的。它只是文本占位而已。</li>
<li>用Django的模板核能修改，但是，Django管理只是供Django自身支持，而且它的接口也是使用Django自身你的模板系统。</li>
</ul>
<h3 id="自定义你的项目模板"><a href="#自定义你的项目模板" class="headerlink" title="自定义你的项目模板"></a>自定义你的项目模板</h3><ul>
<li><p>在你的项目目录中创建一个模板(<strong>templates</strong>)目录。模板能够在Django可使用的任何的文件系统中。(你的服务器运行什么，Django就运行什么）。但是，把你的模板文件夹放在项目目录下是一个很方便的选择。</p>
</li>
<li><p>打开你的设置文件(<strong>mysite&#x2F;settings.py</strong>文件，记住)，然后添加一个TEMPLATE_DIRS设置。</p>
</li>
<li><p><font color="green"><strong>mysite&#x2F;settings.py</strong></font><br><br><img src="/img/Django-1-7-3-tutorial/1.png"></p>
<blockquote>
<p><strong>Django的源代码在哪？</strong><br>如果你在你的硬盘上找不到你的Django的源代码，运行一下口令：<br><img src="/img/Django-1-7-3-tutorial/django-source.png"></p>
</blockquote>
</li>
<li><p>然后，编辑文件，换掉，包括花括号，换成自己应用的名字。如下：<br><br><img src="/img/Django-1-7-3-tutorial/poll-admin.png"></p>
</li>
<li><p>我们用这种方法向你们传授了怎么覆盖模板。在实际的项目中，你可能更喜欢用<strong>django.contrib.admin.AdminSite.site_header</strong>的属性来进行定制，因为它更容易。</p>
</li>
<li><p><img src="http://res.cloudinary.com/djqbxphzo/image/upload/v1445845066/django-part2_zbt9g1.png"></p>
</li>
</ul>
<h3 id="自定义你的应用模板"><a href="#自定义你的应用模板" class="headerlink" title="自定义你的应用模板"></a>自定义你的应用模板</h3><ul>
<li>聪明的读者可能会问：如果<strong>TEMPLATE_DIRS</strong>默认是空的，Django是怎么找到默认的管理模板的？答案是：默认情况下，作为后备，Django自动在每个应用程序包中查找<strong>templates&#x2F;<strong>子目录。(不要忘记</strong>django.contrib.admin</strong>也是一个应用程序)。</li>
<li>我们的投票(poll)应用并不复杂，而且不需要自定义的管理模板。但是当它变得复杂而且需要对Django的标准管理模板做一些修改以适应新的功能时，修改应用程序模板就会比修改项目中的其他文件要更加小心了。这样，你可以把Poll应用程序添加到任何新的项目中，并且假设它会找到需要的自定义模板。</li>
<li>关于Django怎么找到它的模板文件的更多信息，请参考<a class="link"   href="https://docs.djangoproject.com/en/1.7/ref/templates/api/#template-loaders" >template loader documentation<i class="fas fa-external-link-alt"></i></a>。</li>
</ul>
<h2 id="自定管理首页"><a href="#自定管理首页" class="headerlink" title="自定管理首页"></a>自定管理首页</h2><ul>
<li>在一个类似的笔记中，你可能想要自定义Django首页的外观和感觉。</li>
<li>默认情况下，它会根据<strong>INSTALLED_APPS</strong>文件中所注册的程序进行展示，以字母的排序。你可能想要对布局进行重要的修改。毕竟，首页可能是最重要的管理页面，而且它应该很容易被使用的。</li>
<li>要修改的模板是<strong>admin&#x2F;index.html</strong>文件。(和上面对<strong>admin&#x2F;base_site.html</strong>文件做的一样—把它从默认路径复制到你所在的路径。)编辑文件，你可以看到一个额模板变量<strong>app_list</strong>。这个变量包含了所有安装在Django中的app。你可以不用它，但你可以对它进行重新编码，把链接指向你最想要的特定对象的管理页面。还有，如果你现在看不懂模板语言，不要担心，我们将在下一节中讨论模板语言。</li>
<li>当你熟悉了管理站点，请读下一小节，在投票程序的页面设计上下功夫。</li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步-Django</category>
      </categories>
      <tags>
        <tag>Django-Models</tag>
      </tags>
  </entry>
  <entry>
    <title>chap1-Intro to basics</title>
    <url>/2014/11/18/%E6%8A%80%E8%83%BD-%E4%BF%AE%E8%A1%8C-%E8%BF%9B%E6%AD%A5-R%E8%AF%AD%E8%A8%80/chap1-Intro-to-basics/</url>
    <content><![CDATA[<h2 id="How-it-works"><a href="#How-it-works" class="headerlink" title="How it works"></a>How it works</h2><ul>
<li>In the editor on the right you should type R code to solve the exercises.</li>
<li>R makes use of the <font color="red">#</font> sign to add comments, so that you and others can understand what the R code is about. Just like Twitter! Comments are not run as R-code,so they will not influence your result.</li>
<li>The ouput of your R code is shown in the <strong>console</strong> int the lower right corner, while <strong>graphs</strong> are shown in the upper right corner.</li>
</ul>
<h2 id="Instructions"><a href="#Instructions" class="headerlink" title="Instructions"></a>Instructions</h2><ul>
<li>In its most basic form, R can thus be used as a calculator or as a means to generate plots, but there is much more;-)!</li>
<li>You can see that R has generated some cool visualizations in the upper right corner. Use the arrows above the graphs to browse through these.</li>
</ul>
<h2 id="Exercises"><a href="#Exercises" class="headerlink" title="Exercises"></a>Exercises</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># show some demo graphs generated with R</span></span><br><span class="line">demo(<span class="string">&quot;graphics&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&gt; require(datasets)</span><br><span class="line"></span><br><span class="line">&gt; require(grDevices); require(graphics)</span><br><span class="line"></span><br><span class="line">&gt; <span class="comment">## Here is some code which illustrates some of the differences between</span></span><br><span class="line">&gt; <span class="comment">## R and S graphics capabilities.  Note that colors are generally specified</span></span><br><span class="line">&gt; <span class="comment">## by a character string name (taken from the X11 rgb.txt file) and that line</span></span><br><span class="line">&gt; <span class="comment">## textures are given similarly.  The parameter &quot;bg&quot; sets the background</span></span><br><span class="line">&gt; <span class="comment">## parameter for the plot and there is also an &quot;fg&quot; parameter which sets</span></span><br><span class="line">&gt; <span class="comment">## the foreground color.</span></span><br><span class="line">&gt; </span><br><span class="line">&gt; </span><br><span class="line">&gt; x &lt;- stats::rnorm(50)</span><br><span class="line"></span><br><span class="line">&gt; opar &lt;- par(<span class="built_in">bg</span> = <span class="string">&quot;white&quot;</span>)</span><br><span class="line"></span><br><span class="line">&gt; plot(x, ann = FALSE, <span class="built_in">type</span> = <span class="string">&quot;n&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&gt; abline(h = 0, col = gray(.90))</span><br><span class="line"></span><br><span class="line">&gt; lines(x, col = <span class="string">&quot;green4&quot;</span>, lty = <span class="string">&quot;dotted&quot;</span>)</span><br><span class="line"></span><br><span class="line">&gt; points(x, <span class="built_in">bg</span> = <span class="string">&quot;limegreen&quot;</span>, pch = 21)</span><br><span class="line"></span><br><span class="line">&gt; title(main = <span class="string">&quot;Simple Use of Color In a Plot&quot;</span>,</span><br><span class="line">+       xlab = <span class="string">&quot;Just a Whisper of a Label&quot;</span>,</span><br><span class="line">+       col.main = <span class="string">&quot;blue&quot;</span>, col.lab = gray(.8),</span><br><span class="line">+       cex.main = 1.2, cex.lab = 1.0, font.main = 4, font.lab = 3)</span><br><span class="line"></span><br><span class="line">&gt; <span class="comment">## A little color wheel.	 This code just plots equally spaced hues in</span></span><br><span class="line">&gt; <span class="comment">## a pie chart.	If you have a cheap SVGA monitor (like me) you will</span></span><br><span class="line">&gt; <span class="comment">## probably find that numerically equispaced does not mean visually</span></span><br><span class="line">&gt; <span class="comment">## equispaced.  On my display at home, these colors tend to cluster at</span></span><br><span class="line">&gt; <span class="comment">## the RGB primaries.  On the other hand on the SGI Indy at work the</span></span><br><span class="line">&gt; <span class="comment">## effect is near perfect.</span></span><br><span class="line">&gt; </span><br><span class="line">&gt; par(<span class="built_in">bg</span> = <span class="string">&quot;gray&quot;</span>)</span><br><span class="line"></span><br><span class="line">&gt; pie(rep(1,24), col = rainbow(24), radius = 0.9)</span><br></pre></td></tr></table></figure>
<center>![](/img/r-tutorial-datacamp/01-basics/01-plot.PNG)</center>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&gt; title(main = <span class="string">&quot;A Sample Color Wheel&quot;</span>, cex.main = 1.4, font.main = 3)</span><br><span class="line"></span><br><span class="line">&gt; title(xlab = <span class="string">&quot;(Use this as a test of monitor linearity)&quot;</span>,</span><br><span class="line">+       cex.lab = 0.8, font.lab = 3)</span><br><span class="line"></span><br><span class="line">&gt; <span class="comment">## We have already confessed to having these.  This is just showing off X11</span></span><br><span class="line">&gt; <span class="comment">## color names (and the example (from the postscript manual) is pretty &quot;cute&quot;.</span></span><br><span class="line">&gt; </span><br><span class="line">&gt; pie.sales &lt;- c(0.12, 0.3, 0.26, 0.16, 0.04, 0.12)</span><br><span class="line"></span><br><span class="line">&gt; names(pie.sales) &lt;- c(<span class="string">&quot;Blueberry&quot;</span>, <span class="string">&quot;Cherry&quot;</span>,</span><br><span class="line">+ 		      <span class="string">&quot;Apple&quot;</span>, <span class="string">&quot;Boston Cream&quot;</span>, <span class="string">&quot;Other&quot;</span>, <span class="string">&quot;Vanilla Cream&quot;</span>)</span><br><span class="line"></span><br><span class="line">&gt; pie(pie.sales,</span><br><span class="line">+     col = c(<span class="string">&quot;purple&quot;</span>,<span class="string">&quot;violetred1&quot;</span>,<span class="string">&quot;green3&quot;</span>,<span class="string">&quot;cornsilk&quot;</span>,<span class="string">&quot;cyan&quot;</span>,<span class="string">&quot;white&quot;</span>))</span><br></pre></td></tr></table></figure>
<center>![](/img/r-tutorial-datacamp/01-basics/02-plot.PNG)</center>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">&gt; title(main = <span class="string">&quot;January Pie Sales&quot;</span>, cex.main = 1.8, font.main = 1)</span><br><span class="line"></span><br><span class="line">&gt; title(xlab = <span class="string">&quot;(Don&#x27;t try this at home kids)&quot;</span>, cex.lab = 0.8, font.lab = 3)</span><br><span class="line"></span><br><span class="line">&gt; <span class="comment">## Boxplots:  I couldn&#x27;t resist the capability for filling the &quot;box&quot;.</span></span><br><span class="line">&gt; <span class="comment">## The use of color seems like a useful addition, it focuses attention</span></span><br><span class="line">&gt; <span class="comment">## on the central bulk of the data.</span></span><br><span class="line">&gt; </span><br><span class="line">&gt; par(<span class="built_in">bg</span>=<span class="string">&quot;cornsilk&quot;</span>)</span><br><span class="line"></span><br><span class="line">&gt; n &lt;- 10</span><br><span class="line"></span><br><span class="line">&gt; g &lt;- gl(n, 100, n*100)</span><br><span class="line"></span><br><span class="line">&gt; x &lt;- rnorm(n*100) + sqrt(as.numeric(g))</span><br><span class="line"></span><br><span class="line">&gt; boxplot(<span class="built_in">split</span>(x,g), col=<span class="string">&quot;lavender&quot;</span>, notch=TRUE)</span><br></pre></td></tr></table></figure>
<center>![](/img/r-tutorial-datacamp/01-basics/03-plot.PNG)</center>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">&gt; title(main=<span class="string">&quot;Notched Boxplots&quot;</span>, xlab=<span class="string">&quot;Group&quot;</span>, font.main=4, font.lab=1)</span><br><span class="line"></span><br><span class="line">&gt; <span class="comment">## An example showing how to fill between curves.</span></span><br><span class="line">&gt; </span><br><span class="line">&gt; par(<span class="built_in">bg</span>=<span class="string">&quot;white&quot;</span>)</span><br><span class="line"></span><br><span class="line">&gt; n &lt;- 100</span><br><span class="line"></span><br><span class="line">&gt; x &lt;- c(0,cumsum(rnorm(n)))</span><br><span class="line"></span><br><span class="line">&gt; y &lt;- c(0,cumsum(rnorm(n)))</span><br><span class="line"></span><br><span class="line">&gt; xx &lt;- c(0:n, n:0)</span><br><span class="line"></span><br><span class="line">&gt; yy &lt;- c(x, rev(y))</span><br><span class="line"></span><br><span class="line">&gt; plot(xx, yy, <span class="built_in">type</span>=<span class="string">&quot;n&quot;</span>, xlab=<span class="string">&quot;Time&quot;</span>, ylab=<span class="string">&quot;Distance&quot;</span>)</span><br></pre></td></tr></table></figure>
<center>![](/img/r-tutorial-datacamp/01-basics/04-plot.PNG)</center>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">&gt; polygon(xx, yy, col=<span class="string">&quot;gray&quot;</span>)</span><br><span class="line"></span><br><span class="line">&gt; title(<span class="string">&quot;Distance Between Brownian Motions&quot;</span>)</span><br><span class="line"></span><br><span class="line">&gt; <span class="comment">## Colored plot margins, axis labels and titles.	 You do need to be</span></span><br><span class="line">&gt; <span class="comment">## careful with these kinds of effects.	It&#x27;s easy to go completely</span></span><br><span class="line">&gt; <span class="comment">## over the top and you can end up with your lunch all over the keyboard.</span></span><br><span class="line">&gt; <span class="comment">## On the other hand, my market research clients love it.</span></span><br><span class="line">&gt; </span><br><span class="line">&gt; x &lt;- c(0.00, 0.40, 0.86, 0.85, 0.69, 0.48, 0.54, 1.09, 1.11, 1.73, 2.05, 2.02)</span><br><span class="line"></span><br><span class="line">&gt; par(<span class="built_in">bg</span>=<span class="string">&quot;lightgray&quot;</span>)</span><br><span class="line"></span><br><span class="line">&gt; plot(x, <span class="built_in">type</span>=<span class="string">&quot;n&quot;</span>, axes=FALSE, ann=FALSE)</span><br></pre></td></tr></table></figure>
<center>![](/img/r-tutorial-datacamp/01-basics/05-plot.PNG)</center>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">&gt; usr &lt;- par(<span class="string">&quot;usr&quot;</span>)</span><br><span class="line"></span><br><span class="line">&gt; rect(usr[1], usr[3], usr[2], usr[4], col=<span class="string">&quot;cornsilk&quot;</span>, border=<span class="string">&quot;black&quot;</span>)</span><br><span class="line"></span><br><span class="line">&gt; lines(x, col=<span class="string">&quot;blue&quot;</span>)</span><br><span class="line"></span><br><span class="line">&gt; points(x, pch=21, <span class="built_in">bg</span>=<span class="string">&quot;lightcyan&quot;</span>, cex=1.25)</span><br><span class="line"></span><br><span class="line">&gt; axis(2, col.axis=<span class="string">&quot;blue&quot;</span>, las=1)</span><br><span class="line"></span><br><span class="line">&gt; axis(1, at=1:12, lab=month.abb, col.axis=<span class="string">&quot;blue&quot;</span>)</span><br><span class="line"></span><br><span class="line">&gt; box()</span><br><span class="line"></span><br><span class="line">&gt; title(main= <span class="string">&quot;The Level of Interest in R&quot;</span>, font.main=4, col.main=<span class="string">&quot;red&quot;</span>)</span><br><span class="line"></span><br><span class="line">&gt; title(xlab= <span class="string">&quot;1996&quot;</span>, col.lab=<span class="string">&quot;red&quot;</span>)</span><br><span class="line"></span><br><span class="line">&gt; <span class="comment">## A filled histogram, showing how to change the font used for the</span></span><br><span class="line">&gt; <span class="comment">## main title without changing the other annotation.</span></span><br><span class="line">&gt; </span><br><span class="line">&gt; par(<span class="built_in">bg</span>=<span class="string">&quot;cornsilk&quot;</span>)</span><br><span class="line"></span><br><span class="line">&gt; x &lt;- rnorm(1000)</span><br><span class="line"></span><br><span class="line">&gt; hist(x, xlim=range(-4, 4, x), col=<span class="string">&quot;lavender&quot;</span>, main=<span class="string">&quot;&quot;</span>)</span><br></pre></td></tr></table></figure>
<center>![](/img/r-tutorial-datacamp/01-basics/06-plot.PNG)</center>

<figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="operator">&gt;</span> title<span class="punctuation">(</span>main<span class="operator">=</span><span class="string">&quot;1000 Normal Random Variates&quot;</span><span class="punctuation">,</span> font.main<span class="operator">=</span><span class="number">3</span><span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line"><span class="operator">&gt;</span> <span class="comment">## A scatterplot matrix</span></span><br><span class="line"><span class="operator">&gt;</span> <span class="comment">## The good old Iris data (yet again)</span></span><br><span class="line"><span class="operator">&gt;</span> </span><br><span class="line"><span class="operator">&gt;</span> pairs<span class="punctuation">(</span>iris<span class="punctuation">[</span><span class="number">1</span><span class="operator">:</span><span class="number">4</span><span class="punctuation">]</span><span class="punctuation">,</span> main<span class="operator">=</span><span class="string">&quot;Edgar Anderson&#x27;s Iris Data&quot;</span><span class="punctuation">,</span> font.main<span class="operator">=</span><span class="number">4</span><span class="punctuation">,</span> pch<span class="operator">=</span><span class="number">19</span><span class="punctuation">)</span></span><br></pre></td></tr></table></figure>
<center>![](/img/r-tutorial-datacamp/01-basics/07-plot.PNG)</center>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pairs(iris[1:4], main=<span class="string">&quot;Edgar Anderson&#x27;s Iris Data&quot;</span>, pch=21,</span><br><span class="line">+       <span class="built_in">bg</span> = c(<span class="string">&quot;red&quot;</span>, <span class="string">&quot;green3&quot;</span>, <span class="string">&quot;blue&quot;</span>)[unclass(iris<span class="variable">$Species</span>)])</span><br></pre></td></tr></table></figure>
<center>![](/img/r-tutorial-datacamp/01-basics/08-plot.PNG)</center>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&gt; <span class="comment">## Contour plotting</span></span><br><span class="line">&gt; <span class="comment">## This produces a topographic map of one of Auckland&#x27;s many volcanic &quot;peaks&quot;.</span></span><br><span class="line">&gt; </span><br><span class="line">&gt; x &lt;- 10*1:nrow(volcano)</span><br><span class="line"></span><br><span class="line">&gt; y &lt;- 10*1:ncol(volcano)</span><br><span class="line"></span><br><span class="line">&gt; lev &lt;- pretty(range(volcano), 10)</span><br><span class="line"></span><br><span class="line">&gt; par(<span class="built_in">bg</span> = <span class="string">&quot;lightcyan&quot;</span>)</span><br><span class="line"></span><br><span class="line">&gt; pin &lt;- par(<span class="string">&quot;pin&quot;</span>)</span><br><span class="line"></span><br><span class="line">&gt; xdelta &lt;- diff(range(x))</span><br><span class="line"></span><br><span class="line">&gt; ydelta &lt;- diff(range(y))</span><br><span class="line"></span><br><span class="line">&gt; xscale &lt;- pin[1]/xdelta</span><br><span class="line"></span><br><span class="line">&gt; yscale &lt;- pin[2]/ydelta</span><br><span class="line"></span><br><span class="line">&gt; scale &lt;- min(xscale, yscale)</span><br><span class="line"></span><br><span class="line">&gt; xadd &lt;- 0.5*(pin[1]/scale - xdelta)</span><br><span class="line"></span><br><span class="line">&gt; yadd &lt;- 0.5*(pin[2]/scale - ydelta)</span><br><span class="line"></span><br><span class="line">&gt; plot(numeric(0), numeric(0),</span><br><span class="line">+      xlim = range(x)+c(-1,1)*xadd, ylim = range(y)+c(-1,1)*yadd,</span><br><span class="line">+      <span class="built_in">type</span> = <span class="string">&quot;n&quot;</span>, ann = FALSE)</span><br></pre></td></tr></table></figure>
<center>![](/img/r-tutorial-datacamp/01-basics/09-plot.PNG)</center>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&gt; usr &lt;- par(<span class="string">&quot;usr&quot;</span>)</span><br><span class="line"></span><br><span class="line">&gt; rect(usr[1], usr[3], usr[2], usr[4], col=<span class="string">&quot;green3&quot;</span>)</span><br><span class="line"></span><br><span class="line">&gt; contour(x, y, volcano, levels = lev, col=<span class="string">&quot;yellow&quot;</span>, lty=<span class="string">&quot;solid&quot;</span>, add=TRUE)</span><br><span class="line"></span><br><span class="line">&gt; box()</span><br><span class="line"></span><br><span class="line">&gt; title(<span class="string">&quot;A Topographic Map of Maunga Whau&quot;</span>, font= 4)</span><br><span class="line"></span><br><span class="line">&gt; title(xlab = <span class="string">&quot;Meters North&quot;</span>, ylab = <span class="string">&quot;Meters West&quot;</span>, font= 3)</span><br><span class="line"></span><br><span class="line">&gt; mtext(<span class="string">&quot;10 Meter Contour Spacing&quot;</span>, side=3, line=0.35, outer=FALSE,</span><br><span class="line">+       at = mean(par(<span class="string">&quot;usr&quot;</span>)[1:2]), cex=0.7, font=3)</span><br><span class="line"></span><br><span class="line">&gt; <span class="comment">## Conditioning plots</span></span><br><span class="line">&gt; </span><br><span class="line">&gt; par(<span class="built_in">bg</span>=<span class="string">&quot;cornsilk&quot;</span>)</span><br><span class="line"></span><br><span class="line">&gt; coplot(lat ~ long | depth, data = quakes, pch = 21, <span class="built_in">bg</span> = <span class="string">&quot;green3&quot;</span>)</span><br></pre></td></tr></table></figure>
<center>![](/img/r-tutorial-datacamp/01-basics/10-plot.PNG)</center>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&gt; par(opar)</span><br></pre></td></tr></table></figure>
<center>![](/img/r-tutorial-datacamp/01-basics/11-plot.PNG)</center>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Calculate 3+4</span></span><br><span class="line">3 + 4</span><br><span class="line">[1] 7</span><br></pre></td></tr></table></figure>
<h2 id="Next-Tutorial"><a href="#Next-Tutorial" class="headerlink" title="Next Tutorial"></a><a class="link"   href="http://chenyuqing.github.io/2014/11/18/chap1-little-arithmeics-with-R/" >Next Tutorial<i class="fas fa-external-link-alt"></i></a></h2>]]></content>
      <categories>
        <category>技能-修行-进步-R语言</category>
      </categories>
      <tags>
        <tag>R Tutorial</tag>
      </tags>
  </entry>
  <entry>
    <title>chap1-variable-assignment</title>
    <url>/2014/11/18/%E6%8A%80%E8%83%BD-%E4%BF%AE%E8%A1%8C-%E8%BF%9B%E6%AD%A5-R%E8%AF%AD%E8%A8%80/chap1-variable-assignment/</url>
    <content><![CDATA[<h2 id="Last-Tutorial"><a href="#Last-Tutorial" class="headerlink" title="Last Tutorial"></a><a class="link"   href="http://chenyuqing.github.io/2014/11/18/chap1-little-arithmeics-with-R/" >Last Tutorial<i class="fas fa-external-link-alt"></i></a></h2><h2 id="Variable-assignment-1"><a href="#Variable-assignment-1" class="headerlink" title="Variable assignment(1)"></a>Variable assignment(1)</h2><ul>
<li>A basic concept in (statistical) programming is called a <strong>varibale.</strong></li>
<li>A variable allows you to store a value (e.g.4) or an object (e.g. a function description) in R. You can then later use this variable’s name to easily access the value or the object that is stored within this variable.</li>
<li>You can assign a value 4 to a variable <font color="red">my_variable</font> with the command: <font color="red">my_variable &#x3D; 4.</font></li>
</ul>
<h2 id="Exercises1"><a href="#Exercises1" class="headerlink" title="Exercises1"></a>Exercises1</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&gt; <span class="comment"># Assign the value 42 to x</span></span><br><span class="line">&gt; x = 42</span><br><span class="line">&gt; <span class="comment"># Print out the value of the variable x</span></span><br><span class="line">&gt; x</span><br><span class="line">[1] 42</span><br></pre></td></tr></table></figure>

<h2 id="Variable-assignment-2"><a href="#Variable-assignment-2" class="headerlink" title="Variable assignment(2)"></a>Variable assignment(2)</h2><ul>
<li>Suppose you have a fruit basket with five apples. As a data ananlyst in training, you want to store the number of apples in a variable with the name <font color="red">my_apples.</font></li>
</ul>
<h2 id="Exercises2"><a href="#Exercises2" class="headerlink" title="Exercises2"></a>Exercises2</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&gt; <span class="comment"># Assign the value 5 to the variable called my_apples</span></span><br><span class="line">&gt; my_apples &lt;- 5</span><br><span class="line">&gt; <span class="comment"># Print out the value of the variable my_apples</span></span><br><span class="line">&gt; my_apples</span><br><span class="line">[1] 5</span><br></pre></td></tr></table></figure>

<h2 id="Variable-assignment-3"><a href="#Variable-assignment-3" class="headerlink" title="Variable assignment(3)"></a>Variable assignment(3)</h2><ul>
<li>Every tasty fruit basket needs oranges, so you decide to add six oranges. As a data ananlyst, your reflex is to immediately create the variable <font color="red">my_orange</font> and assign the value 6 to it. Next, you want to calculate how many pieces of fruit you have in total. Since you have given meaningful names to these values, you can now code this in a clear way:<font color="red">my_apples + my_oranges.</font></li>
</ul>
<h2 id="Exercise3"><a href="#Exercise3" class="headerlink" title="Exercise3"></a>Exercise3</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&gt; <span class="comment"># Assign a value to the variables called my_apples and my_oranges</span></span><br><span class="line">&gt; my_apples = 5</span><br><span class="line">&gt; my_oranges = 6</span><br><span class="line">&gt; <span class="comment"># Add these two variables together and print the result</span></span><br><span class="line">&gt; <span class="built_in">print</span>(my_apples + my_oranges)</span><br><span class="line">[1] 11</span><br><span class="line">&gt; <span class="comment"># Create the variable my_fruit</span></span><br><span class="line">&gt; my_fruit = my_apples + my_oranges</span><br></pre></td></tr></table></figure>

<h2 id="Apples-and-oranges"><a href="#Apples-and-oranges" class="headerlink" title="Apples and oranges"></a>Apples and oranges</h2><ul>
<li>Common knowledge tells you not to add apples and oranges. But hey, that is what you just did, no:-)? The <font color="red">my_apples</font> and <font color="red">my_oranges</font> variables both contained a number in the previous exercise. The <font color="red"> + </font> operator works with numeric variables in R. If you really tried to add “apples” and “oranges”, and assigned a text value to the variable <font color="red"> my_oranges </font>(see the editor), you would be trying to assign the addition of a numeric a character variable to the variable <font color="red"> my_fruit. </font> This is not possible.</li>
</ul>
<h2 id="Exercise4"><a href="#Exercise4" class="headerlink" title="Exercise4"></a>Exercise4</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&gt; <span class="comment"># Assign a value to the variable called my_apples</span></span><br><span class="line">&gt; my_apples = 5</span><br><span class="line">&gt; <span class="comment"># Print out the value of my_apples</span></span><br><span class="line">&gt; my_apples</span><br><span class="line">[1] 5</span><br><span class="line">&gt; </span><br><span class="line">&gt; <span class="comment"># Add a character</span></span><br><span class="line">&gt; my_oranges = 6</span><br><span class="line">&gt; my_oranges</span><br><span class="line">[1] 6</span><br><span class="line">&gt; </span><br><span class="line">&gt; <span class="comment"># New variable that contains total amount of fruit</span></span><br><span class="line">&gt; my_fruit = my_apples + my_oranges</span><br><span class="line">&gt; my_fruit</span><br><span class="line">[1] 11</span><br></pre></td></tr></table></figure>

<h2 id="Next-Tutorial"><a href="#Next-Tutorial" class="headerlink" title="Next Tutorial"></a><a class="link"   href="http://chenyuqing.github.io/" >Next Tutorial<i class="fas fa-external-link-alt"></i></a></h2>]]></content>
      <categories>
        <category>技能-修行-进步-R语言</category>
      </categories>
      <tags>
        <tag>R Tutorial</tag>
      </tags>
  </entry>
  <entry>
    <title>chp2_JSP</title>
    <url>/2014/07/06/%E6%8A%80%E8%83%BD-%E4%BF%AE%E8%A1%8C-%E8%BF%9B%E6%AD%A5-JSP/chp2-JSP/</url>
    <content><![CDATA[<h1 id="第二章"><a href="#第二章" class="headerlink" title="第二章"></a>第二章</h1><hr>
<h3 id="2-3-安装和配置Tomcat-page15"><a href="#2-3-安装和配置Tomcat-page15" class="headerlink" title="2.3 安装和配置Tomcat(page15)"></a>2.3 安装和配置Tomcat(page15)</h3><ul>
<li>Tomcat 服务器的默认端口是 <strong>8080</strong></li>
<li>访问Tomcat的默认路径是：<strong><a class="link"   href="http://localhost:8080/" >http://localhost:8080<i class="fas fa-external-link-alt"></i></a></strong></li>
</ul>
<hr>
<h3 id="2-3-1-配置Tomcat-page18"><a href="#2-3-1-配置Tomcat-page18" class="headerlink" title="2.3.1 配置Tomcat(page18)"></a>2.3.1 配置Tomcat(page18)</h3><ul>
<li>更改服务端口：在Tomcat下打开conf文件夹找到<strong>server.xml</strong>文件用记事本打开在**&lt; connector port &#x3D;”8080” &gt;**中把8080更改即可</li>
</ul>
<hr>
<h3 id="2-3-2-测试第一个JSP页面-page20"><a href="#2-3-2-测试第一个JSP页面-page20" class="headerlink" title="2.3.2 测试第一个JSP页面(page20)"></a>2.3.2 测试第一个JSP页面(page20)</h3><ul>
<li><p>第一段JSP程序（Hello World）</p>
<blockquote>
<p><strong>&lt;%**<br>**out.print(“Hello World”);**<br>**%&gt;</strong></p>
</blockquote>
</li>
<li><p>对这个程序做简单的说明：</p>
<ul>
<li>所有的JSP脚本程序都必须用<strong>“&lt;%”和“%&gt;”</strong>括起来；</li>
<li>可以用<strong>out</strong>对象的<strong>print</strong>方法输出信息，输出的字符需要用<strong>双引号</strong>括起来；</li>
<li>每一条JSP语句的<strong>末尾</strong>用<strong>分号</strong>结束。</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步-JSP</category>
      </categories>
      <tags>
        <tag>JSP网页开发</tag>
      </tags>
  </entry>
  <entry>
    <title>chp1_JSP</title>
    <url>/2014/07/06/%E6%8A%80%E8%83%BD-%E4%BF%AE%E8%A1%8C-%E8%BF%9B%E6%AD%A5-JSP/chp1-JSP/</url>
    <content><![CDATA[<h1 id="第一章"><a href="#第一章" class="headerlink" title="第一章"></a>第一章</h1><hr>
<h3 id="1-3-3-JSP-概述-page5"><a href="#1-3-3-JSP-概述-page5" class="headerlink" title="1.3.3 JSP 概述(page5)"></a>1.3.3 JSP 概述(page5)</h3><ul>
<li><p>jsp的最大优点是：<strong>开放的，跨平台</strong>的结构，它可以<strong>运行在所有的服务器系统上</strong>。</p>
</li>
<li><p>JSP与ASP的区别：</p>
<ul>
<li><p>每次访问asp文件，服务器都要将该文件解释一遍，然后将标准的HTML代码发送到客户端；</p>
</li>
<li><p>而JSP有所不同，当第一次访问JSP文件时，服务器先将JSP编译成二进制码，以后再访问的时候，就直接访问二进制码，这样大大提高了执行的效率。</p>
<p>  <strong>总结：JSP一次编译，多次运行；而ASP每次运行需要每次编译。</strong></p>
</li>
</ul>
</li>
<li><p>JSP的优点如下：</p>
<ol>
<li>多平台的支持，可以再所有的服务器操作系统上运行。</li>
<li>编译后执行，能够大大提高执行效率。</li>
<li>JSP采用Java技术，Java应用比较普遍，因此学习起来比较容易。</li>
<li>JSP是J2EE十三种核心技术中的一种，可以和其他核心技术共同建立企业应用。</li>
</ol>
</li>
<li><p>JSP的缺点如下：</p>
<ol>
<li>开发环境相对ASP来说，比较复杂。需要先安装JDK，然后安装Web服务器。</li>
<li>相对ASP的VBsript脚本语言，Java语言学起来稍微复杂。</li>
</ol>
</li>
</ul>
<hr>
<h3 id="1-4-3-J2EE体系概述-page6"><a href="#1-4-3-J2EE体系概述-page6" class="headerlink" title="1.4.3 J2EE体系概述(page6)"></a>1.4.3 J2EE体系概述(page6)</h3><ul>
<li>J2EE的任务是提供一个<strong>平台独立的，便携式，多用户，安全及标准</strong>的企业级平台。</li>
<li>J2EE的13种核心技术包括（<strong>不全，常见的</strong>）：<ol>
<li><strong>JDBC</strong> (Java Database Connectivity, Java数据库连接)</li>
<li><strong>EJB</strong> （Enterprise Java Bean，企业JavaBean）</li>
<li><strong>JSP</strong> （Java Server Pages, Java服务器端网页）</li>
<li><strong>Servlet</strong> （服务器端小程序）</li>
<li><strong>XML</strong> （eXtensible Markup Language）</li>
<li><strong>JavaMail</strong> (Java邮件)</li>
<li><strong>JTS</strong> （Java Transaction Service, Java事务服务）</li>
<li>。。。</li>
</ol>
</li>
</ul>
<hr>
<h3 id="1-5-1-N层开发框架（page8）"><a href="#1-5-1-N层开发框架（page8）" class="headerlink" title="1.5.1 N层开发框架（page8）"></a>1.5.1 N层开发框架（page8）</h3><ul>
<li>理想的J2EE体系包括<strong>6个层</strong>：<strong>表示，应用，服务，域，连通性</strong>和<strong>持续化</strong>。</li>
<li>这些层横跨<strong>客户机</strong>和<strong>服务器</strong>，而它们逻辑上划分为<strong>Web容器，EJB容器</strong>和<strong>数据库</strong>，如图1-7所示：<br/><br/><center>![](/img/jsp_review/1-7.jpg)</center></li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步-JSP</category>
      </categories>
      <tags>
        <tag>JSP网页开发</tag>
      </tags>
  </entry>
  <entry>
    <title>chp3_JSP</title>
    <url>/2014/07/06/%E6%8A%80%E8%83%BD-%E4%BF%AE%E8%A1%8C-%E8%BF%9B%E6%AD%A5-JSP/chp3-JSP/</url>
    <content><![CDATA[<h1 id="第三章-Servlet编程技术"><a href="#第三章-Servlet编程技术" class="headerlink" title="第三章 Servlet编程技术"></a>第三章 Servlet编程技术</h1><hr>
<h3 id="3-1-1-Servlet概念-page45"><a href="#3-1-1-Servlet概念-page45" class="headerlink" title="3.1.1 Servlet概念(page45)"></a>3.1.1 Servlet概念(page45)</h3><ul>
<li><p>Servlet</p>
<blockquote>
<p><strong>Servlet是一个标准的Java类，它的特殊之处是可以处理HTTP请求。</strong></p>
</blockquote>
</li>
<li><p>JSP与Servlet有什么关系？  </p>
<blockquote>
<p><strong>JSP是以另一种方式实现的Servlet，Servlet是JSP的早期版本，在JSP中，更加注重页面的表现，而在Servlet中则更注重业务逻辑的实现。</strong></p>
</blockquote>
</li>
</ul>
<br/>

<hr>
<h3 id="3-1-2-Servlet的生命周期-page45"><a href="#3-1-2-Servlet的生命周期-page45" class="headerlink" title="3.1.2 Servlet的生命周期(page45)"></a>3.1.2 Servlet的生命周期(page45)</h3><p><img src="/img/jsp_review/Servlet_LifeCycle.png"></p>
<ul>
<li><p><strong>init()方法：服务器初始化Servlet</strong></p>
<blockquote>
<p><strong>该方法描述为：</strong><br><strong>public void init(ServletConfig config)throws ServletException</strong>  </p>
<p><strong>当Servlet第一次被加载时，服务器调用init()方法初始化一个Servlet对象</strong> </p>
</blockquote>
</li>
<li><p><strong>service()方法:初始化完毕，Servlet对象调用该方法响应客户端请求</strong></p>
<blockquote>
<p><strong>该方法描述为：</strong><br><strong>public void service(HttpServletRequest request, HttpServletResponse response)throws ServletException, IOException</strong>  </p>
<p><strong>service()方法可以被多次调用，每次用户请求都导致service()方法被调用，调用过程运行在不同的进程中，互不干扰</strong> </p>
</blockquote>
</li>
<li><p><strong>destroy()方法：调用该方法消灭Servlet对象</strong></p>
<blockquote>
<p><strong>该方法描述为：</strong><br><strong>public void destroy()</strong><br><strong>当Servlet引擎终止服务时，比如关闭服务器等，destroy()方法会被执行，销毁Servlet对象。</strong> </p>
</blockquote>
<pre><code>  总结：在整个Servlet的生命周期中，init()方法和destroy()方法都只被调用一次，
  而service()方法被调用多次。
</code></pre>
</li>
</ul>
<h3 id="3-3-2-GenericServlet类和HttpServlet类-page51"><a href="#3-3-2-GenericServlet类和HttpServlet类-page51" class="headerlink" title="3.3.2 GenericServlet类和HttpServlet类 (page51)"></a>3.3.2 GenericServlet类和HttpServlet类 (page51)</h3><p><img src="/img/jsp_review/HttpServlet.JPG"></p>
<blockquote>
<p><strong>有上述继承树可知：GenericServlet是父类，它实现了Servlet接口中的service()方法，但它还是一个抽象方法，所有子类都应该实现这个方法。HttpServlet继承了GenericServlet类，自然也要实现service()方法。</strong></p>
</blockquote>
<ul>
<li><p>service()方法</p>
<ul>
<li><p>HttpServlet类有两种形式的service()方法：public 和 protected，描述如下：</p>
<blockquote>
<p><strong>public void service(ServletRequest request, ServletResponse response) throws ServletException, IOException</strong>  </p>
</blockquote>
<blockquote>
<p><strong>protected void service(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException</strong> </p>
</blockquote>
</li>
<li><p>当包容器为一个Servlet收到一个请求时，这个方法的调用顺序是：</p>
<blockquote>
<ol>
<li><strong>包容器调用public的service()方法；</strong></li>
<li><strong>在把参数分布转换为HttpServletRequest和HttpServletResponse后，public的service()方法调用protected的service()方法；</strong></li>
<li><strong>根据HTTP请求方法的类型，protected的service()调用doXXX()方法之一。</strong></li>
</ol>
</blockquote>
</li>
</ul>
<p>  #####注意：常用的doXXX()方法有doGet()和doPost()，我们编写的Servlet类继承HttpServlet之后，只需要覆盖doGet()或doPost()方法即可，不需要覆盖service()方法。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步-JSP</category>
      </categories>
      <tags>
        <tag>JSP网页开发</tag>
      </tags>
  </entry>
  <entry>
    <title>chp4_JSP</title>
    <url>/2014/07/06/%E6%8A%80%E8%83%BD-%E4%BF%AE%E8%A1%8C-%E8%BF%9B%E6%AD%A5-JSP/chp4-JSP/</url>
    <content><![CDATA[<h1 id="第四章-JSP编程技术-重点"><a href="#第四章-JSP编程技术-重点" class="headerlink" title="第四章 JSP编程技术(重点)"></a>第四章 JSP编程技术(重点)</h1><hr>
<ul>
<li>JSP的主要内容包括：<strong>3大编译指令</strong>，<strong>7大操作指令</strong>(课本6个)和<strong>9大隐含对象</strong>(课本7个)。</li>
</ul>
<h3 id="4-2-JSP页面结构-page68"><a href="#4-2-JSP页面结构-page68" class="headerlink" title="4.2 JSP页面结构(page68)"></a>4.2 JSP页面结构(page68)</h3><ul>
<li><p>JSP的页面主要包含3种元素：<strong>编译指令</strong>，<strong>操作指令</strong>和<strong>JSP代码</strong>。</p>
<ul>
<li>编译指令<blockquote>
<p><strong>编译指令告诉JSP解释引擎，需要在编译时做什么动作，例如引入其他类，设置JSP页面使用什么语言编码等。</strong></p>
</blockquote>
</li>
<li>操作指令<blockquote>
<p><strong>操作指令则是在JSP页面被请求时动态执行的，比如可以根据某个条件动态跳转到另一个页面。</strong></p>
</blockquote>
</li>
<li>JSP代码<blockquote>
<p><strong>JSP代码指我们嵌入JSP页面中的Java代码，分两种：变量和方法的声明，使用“&lt;%!”和“%&gt;”标记，另一种是常用到的用“&lt;%”和“%&gt;”包含的JSP代码块。</strong></p>
</blockquote>
</li>
</ul>
</li>
</ul>
<br/>

<hr>
<h3 id="4-3-编译指令-page68"><a href="#4-3-编译指令-page68" class="headerlink" title="4.3 编译指令(page68)"></a>4.3 编译指令(page68)</h3><ul>
<li><p>JSP指令的<strong>一般形式</strong>：**&lt;%@ 指令名 属性1 &#x3D; “value1” %&gt;<strong>，</strong>&lt;%@ 指令名 属性2 &#x3D; “value2” %&gt;<strong>，多个指令也可以合并写为：</strong>&lt;%@ 指令名 属性1 &#x3D; “value1” 属性2 &#x3D; “value2” %&gt;**</p>
</li>
<li><p>JSP的3大编译指令：<strong>page指令</strong>，<strong>include指令</strong>，taglib指令(不考)。</p>
<ul>
<li>page指令：page 指令是最复杂的JSP指令，它的主要功能为设定整个JSP 网页的属性和相关功能。  <table>
          <tr>
              <th>属性</th>
              <th>定义</th>
          </tr>
         <tr>
            <td width="170">language=“语言"</td>
            <td width="500">主要指定JSP 容器 要用什么语言来编译JSP 网页。JSP 1.2 规范中指出，目前只可以使用Java 语言，不过未来不排除增加其他语言，如C、C++、Perl 等等。默认值为Java语言 </td>      
         </tr>
         <tr>
            <td>extends=“基类名"</td>
            <td>主要定义此JSP 网页产生的Servlet 是继承哪个父类</td>     
         </tr>
          <tr>
            <td>import= "importList"</td>
            <td>定义此JSP 网页可以使用哪些Java类库</td>     
         </tr>
         <tr>
            <td>errorPage="error_url" </td>
            <td>表示如果发生异常错误时，网页会被重新指向指定的URL</td>     
         </tr>
          <tr>
            <td>isErrorPage="true | false" </td>
            <td>表示此JSP Page 是否为专门处理错误和异常的网页</td>     
         </tr>
          <tr>
            <td>contentType = "ctinfo"</td>
            <td>表示MIME 类型和JSP 网页的编码方式，其作用相当于HttpServletResponse接口的setContentType()方法</td>     
         </tr>
          <tr>
            <td>isThreadSafe="true | false"</td>
            <td>告诉JSP 容器，此JSP 网页是否能同时处理多个请求。默认值为true，如果此值设为false， 转义生成的Servlet会实现SingleThreadModel接口。</td>     
         </tr>
          
<pre><code>      &lt;tr&gt;
        &lt;td&gt;session=&quot;true | false&quot;&lt;/td&gt;
        &lt;td&gt;决定此JSP 网页是否可以使用session 对象。默认值为true&lt;/td&gt;     
     &lt;/tr&gt;
  &lt;/table&gt;	
</code></pre>
</li>
<li>include指令(page70):用来指定怎样把另一个文件包含到当前的JSP页面中，这个文件可以是普通的文本文件，也可以是JSP页面。例如：**&lt;%@include file&#x3D;”login.htm”%&gt;**。<blockquote>
<p>使用include指令，<strong>可以实现JSP页面的模块化，使JSP的开发和维护变得非常简单</strong>。</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<br/>

<hr>
<h3 id="4-4-操作指令-page71"><a href="#4-4-操作指令-page71" class="headerlink" title="4.4 操作指令(page71)"></a>4.4 操作指令(page71)</h3><ul>
<li><p>操作指令和编译指令不同，编译指令是通知Servlet引擎的处理消息，而<strong>操作指令只是运行时的动作。</strong>编译指令在将JSP编译成Servlet时起作用；而<strong>操作指令通常可替换成JSP脚本，它只是JSP脚本的标准化写法</strong>。</p>
</li>
<li><p>JSP操作指令主要有如下的6个：</p>
<ol>
<li>jsp:include：用于引入静态和动态的资源，功能和include指令相同。格式：&lt;jsp:include page&#x3D;”test.htm”&#x2F;&gt; </li>
<li>jsp:forward：执行页面转向，将请求的处理转发到下一个页面。格式：&lt;jsp:forward page&#x3D;”test.htm”&#x2F;&gt;   </li>
<li>jsp:param：用于传递参数，必须与其他支持参数的标签一起使用。   <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;jsp:forward page=<span class="string">&quot;mypage.jsp&quot;</span>&gt;  </span><br><span class="line">&lt;jsp:param name=<span class="string">&quot;param1&quot;</span> value=<span class="string">&quot;value1&quot;</span>/&gt;  </span><br><span class="line">&lt;jsp:param name=<span class="string">&quot;param2&quot;</span> value=<span class="string">&quot;value2&quot;</span>/&gt;  </span><br><span class="line">&lt;/jsp:forward&gt; </span><br></pre></td></tr></table></figure></li>
<li>jsp:useBean：创建一个JavaBean的实例。  </li>
<li>jsp:setProperty：设置JavaBean实例的属性值。  </li>
<li>jsp:getProperty：输出JavaBean实例的属性值</li>
<li></li>
</ol>
<p>   	</p>
</li>
<li><p>JSP的操作指令均以<strong>“&#x2F;&gt;”</strong>结束。</p>
</li>
</ul>
<hr>
<h3 id="4-5-JSP代码-page72"><a href="#4-5-JSP代码-page72" class="headerlink" title="4.5 JSP代码(page72)"></a>4.5 JSP代码(page72)</h3><ul>
<li>变量和方法(略)</li>
<li>代码块(略)</li>
</ul>
<hr>
<h3 id="4-6-7大隐含对象-page75"><a href="#4-6-7大隐含对象-page75" class="headerlink" title="4.6 7大隐含对象(page75)"></a>4.6 7大隐含对象(page75)</h3><ul>
<li>隐含对象：有些对象不用声明就可以在JSP页面的脚本代码和表达式中随意使用，这些缺省对象统称为隐含对象。</li>
<li>7大隐含对象：<ul>
<li><strong>out</strong>		页面输出对象；</li>
<li><strong>request</strong>	请求对象；</li>
<li><strong>response</strong>	响应对象；</li>
<li><strong>application</strong>	应用对象； </li>
<li><strong>session</strong>	会话对象；</li>
<li><strong>cookie</strong>		对象；</li>
<li><strong>pageContext</strong>	对象；  <table>
      <tr>
          <th>对象名</th>
          <th>对象类型</th>
          <th>作用域</th>
          <th>定义</th>
      </tr>
     <tr>
        <td>out</td>
        <td>JspWriter</td> 
        <td>page</td>
        <td>一个输出的缓冲流，给浏览器的客户返回内容</td>      
     </tr>
      <tr>
        <td>request</td>
        <td>HttpServletRequest</td> 
        <td>request</td>
        <td>用来得到客户端的信息</td>      
     </tr>
     <tr>
        <td>response</td>
        <td>HttpServletResponse</td> 
        <td>page</td>
        <td>处理服务器端对客户端的一些响应</td>      
     </tr>
      <tr>
        <td>application</td>
        <td>ServletContext</td> 
        <td>application</td>
        <td>用来保存网站的一些全局变量</td>      
     </tr>
     <tr>
        <td>session</td>
        <td>HttpSession</td> 
        <td>session</td>
        <td>用来保存单个用户访问时的一些信息</td>      
     </tr> 
      <tr>
        <td>cookie</td>
        <td>Cookie</td> 
        <td>不清楚呢</td>
        <td>将服务器端的一些信息写到客户端的浏览器中</td>      
     </tr> 
      <tr>
        <td>pageContext</td>
        <td>PageContext</td> 
        <td>page</td>
        <td>提供了访问和放置页面中共享数据的方式</td>      
     </tr>   
  </table></li>
</ul>
</li>
</ul>
<hr>
<h3 id="4-7-response对象-page76"><a href="#4-7-response对象-page76" class="headerlink" title="4.7 response对象(page76)"></a>4.7 response对象(page76)</h3><ul>
<li><p>网页转向：sendRedirect()方法，跳转到其他页面</p>
<blockquote>
<p>格式：response.sendRedirect(“URL 地址”);</p>
</blockquote>
</li>
<li><p>与<a class="link"   href="jsp:forward" >jsp:forward<i class="fas fa-external-link-alt"></i></a>的最大区别</p>
<blockquote>
<p>使用<a class="link"   href="jsp:forward" >jsp:forward<i class="fas fa-external-link-alt"></i></a>只能在本站内跳转，但用response.sendRedirect(“URL 地址”)可以跳转到任何一个地址的页面。</p>
</blockquote>
</li>
<li><p>其他(略，自己看书)</p>
</li>
</ul>
<hr>
<h3 id="4-8-request对象-page78"><a href="#4-8-request对象-page78" class="headerlink" title="4.8 request对象(page78)"></a>4.8 request对象(page78)</h3><ul>
<li>自己看书</li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步-JSP</category>
      </categories>
      <tags>
        <tag>JSP网页开发</tag>
      </tags>
  </entry>
  <entry>
    <title>chp5_JSP</title>
    <url>/2014/07/06/%E6%8A%80%E8%83%BD-%E4%BF%AE%E8%A1%8C-%E8%BF%9B%E6%AD%A5-JSP/chp5-JSP/</url>
    <content><![CDATA[<h1 id="第五章-JavaBean编程技术"><a href="#第五章-JavaBean编程技术" class="headerlink" title="第五章 JavaBean编程技术"></a>第五章 JavaBean编程技术</h1><hr>
<h3 id="5-1-3-JavaBean简介-page98"><a href="#5-1-3-JavaBean简介-page98" class="headerlink" title="5.1.3 JavaBean简介(page98)"></a>5.1.3 JavaBean简介(page98)</h3><ul>
<li>JavaBean的4个特性：<strong>独立性</strong>，<strong>可重用性</strong>，<strong>在可视化开发工具中使用</strong>，<strong>状态可以保存</strong>。</li>
</ul>
<h3 id="5-2-1-JavaBean的特点-page98"><a href="#5-2-1-JavaBean的特点-page98" class="headerlink" title="5.2.1 JavaBean的特点(page98)"></a>5.2.1 JavaBean的特点(page98)</h3><ul>
<li><p>编写JavaBean就是编写一个Java类，一个完整JavaBean在类的命名上需要遵守以下4点：</p>
<ol>
<li>如果类的成员变量的名字是XXX，那么未来更改或获取成员变量的值，在类中使用以下两个方法。<ul>
<li>getXXX()：用来获取属性XXX</li>
<li>setXXX()：用来修改属性XXX</li>
</ul>
</li>
<li>对于boolean类型的成员变量，允许使用is代替get和set。</li>
<li>类中方法的访问属性必须是public。</li>
<li>类中如果有构造方法，那么这个构造方法也是public的，并且是无参数的。</li>
</ol>
</li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步-JSP</category>
      </categories>
      <tags>
        <tag>JSP网页开发</tag>
      </tags>
  </entry>
  <entry>
    <title>KNN Example 01 To predict the cancer of breast cancer</title>
    <url>/2017/02/15/%E6%8A%80%E8%83%BD-%E4%BF%AE%E8%A1%8C-%E8%BF%9B%E6%AD%A5-R%E8%AF%AD%E8%A8%80/KNN-example01-breast-cancer-predict/</url>
    <content><![CDATA[<h2 id="Set-the-path"><a href="#Set-the-path" class="headerlink" title="Set the path"></a>Set the path</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">setwd(&quot;D:/git-ware/machine-learning-R-examples/01_KNN&quot;)</span><br><span class="line">getwd()</span><br></pre></td></tr></table></figure>

<h1 id="Get-the-data-from-the-Internet-and-do-the-exploration"><a href="#Get-the-data-from-the-Internet-and-do-the-exploration" class="headerlink" title="Get the data from the Internet and do the exploration"></a>Get the data from the Internet and do the exploration</h1><h2 id="Download-the-data-from-Internet"><a href="#Download-the-data-from-Internet" class="headerlink" title="Download the data from Internet"></a>Download the data from Internet</h2><ul>
<li><p>Data: <a class="link"   href="https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data" >https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data<i class="fas fa-external-link-alt"></i></a></p>
</li>
<li><p>Description: <a class="link"   href="https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.names" >https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.names<i class="fas fa-external-link-alt"></i></a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># download the data from the Internet</span><br><span class="line">library(RCurl)</span><br><span class="line">data_url = &quot;https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data&quot;</span><br><span class="line">name_url = &quot;https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.names&quot;</span><br><span class="line">download.file(data_url, &quot;wdbc.data&quot;, method=&quot;libcurl&quot;)</span><br><span class="line">download.file(name_url, &quot;wdbc.names&quot;, method = &quot;libcurl&quot;)</span><br><span class="line"></span><br><span class="line"># loading dataset</span><br><span class="line">wdbc = read.csv(&quot;wdbc.data&quot;, header = FALSE)</span><br><span class="line"></span><br><span class="line"># set the column names  </span><br><span class="line">wdbc.names=c(&quot;Radius&quot;,&quot;Texture&quot;,&quot;Perimeter&quot;,&quot;Area&quot;,&quot;Smoothness&quot;,&quot;Compactness&quot;,&quot;Concavity&quot;,&quot;Concave points&quot;,&quot;Symmetry&quot;,&quot;Fractal dimension&quot;)</span><br><span class="line">wdbc.names=c(wdbc.names,paste(wdbc.names,&quot;_mean&quot;,sep=&quot;&quot;),paste(wdbc.names,&quot;_worst&quot;,sep=&quot;&quot;))</span><br><span class="line"></span><br><span class="line">names(wdbc)=c(&quot;id&quot;,&quot;diagnosis&quot;,wdbc.names)</span><br><span class="line">str(wdbc)</span><br><span class="line">dim(wdbc)</span><br></pre></td></tr></table></figure>
</li>
<li><p>So from the output above, we can see that the dataset includes 569 samples and 32 features.</p>
</li>
<li><p>From the description file, we know that the first feature(column) is id, and the second feature(column) is the diagnosis, it has two labels: “B” is benign cancer, and the “M” means malignant cancer. And the rest are the features which include the means, standard error and maximum, etc.</p>
</li>
<li><p>We explore the ratio of two labels</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">table(wdbc$diagnosis)</span><br></pre></td></tr></table></figure></li>
<li><p>We see that the dataset has 357 benign cancer and 212 malignant cancer.</p>
</li>
<li><p>Since the id column has no significance to the model, so we delete the it</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wdbc$diagnosis=factor(wdbc$diagnosis,levels=c(&quot;B&quot;,&quot;M&quot;),labels=c(&quot;Benign&quot;,&quot;Malignant&quot;))</span><br><span class="line">round(prop.table(table(wdbc$diagnosis)) * 100, digits = 1)</span><br><span class="line">wdbc=wdbc[-1]</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">summary(wdbc[c(&quot;Radius_mean&quot;, &quot;Area_mean&quot;, &quot;Smoothness_mean&quot;)])</span><br></pre></td></tr></table></figure>
</li>
<li><p>We can see that the scale between features are far too much, so we have to do the normalization.</p>
</li>
<li><p>Here is the function of what define.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">normalize &lt;- function(x) &#123;</span><br><span class="line">  return ((x - min(x)) / (max(x) - min(x)))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wdbc_n &lt;- as.data.frame(lapply(wdbc[2:31], normalize))</span><br><span class="line">summary(wdbc_n[c(&quot;Radius_mean&quot;, &quot;Area_mean&quot;, &quot;Smoothness_mean&quot;)])</span><br></pre></td></tr></table></figure>
<ul>
<li>After the normalization, we can see the scale of the features are on the same level.</li>
</ul>
<h1 id="Split-the-data-and-build-the-model"><a href="#Split-the-data-and-build-the-model" class="headerlink" title="Split the data and build the model"></a>Split the data and build the model</h1><h2 id="Split-the-data-into-two-parts-training-data-and-testing-data"><a href="#Split-the-data-into-two-parts-training-data-and-testing-data" class="headerlink" title="Split the data into two parts: training data and testing data"></a>Split the data into two parts: training data and testing data</h2><ul>
<li>divide the data into two parts with the interval directly<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wdbc_train = wdbc_n[1:469, ]</span><br><span class="line">wdbc_test = wdbc_n[470:569, ]</span><br><span class="line">wdbc_train_label = wdbc[1:469, 1]</span><br><span class="line">wdbc_test_label = wdbc[470:569, 1]</span><br><span class="line">mal_rate=table(wdbc_train_label)</span><br><span class="line">round(mal_rate[2]/sum(mal_rate), digits = 2)</span><br></pre></td></tr></table></figure></li>
<li>There is a problem that if the first 469 cloumn includes most of the benign cancer data, that is not good for the partition. So we have to sample the data.</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">set.seed(2017)</span><br><span class="line">inTrain = sample(1:dim(wdbc_n)[1],469,replace=F)</span><br><span class="line">wdbc_train=wdbc_n[inTrain,]</span><br><span class="line">wdbc_test=wdbc_n[-inTrain,]</span><br><span class="line">wdbc_train_label=wdbc[inTrain,1]</span><br><span class="line">wdbc_test_label=wdbc[-inTrain,1]</span><br><span class="line">mal_rate=table(wdbc_train_label)</span><br><span class="line">round(mal_rate[2]/sum(mal_rate), digits = 2)</span><br></pre></td></tr></table></figure>
<ul>
<li>otherwise, we can use the createDataPartition function of the caret package to do the job.<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">require(caret)</span><br><span class="line">set.seed(2017)</span><br><span class="line">inTrain=createDataPartition(y=wdbc$diagnosis,p=0.8,list=FALSE)</span><br><span class="line">wdbc_train=wdbc_n[inTrain,]</span><br><span class="line">wdbc_test=wdbc_n[-inTrain,]</span><br><span class="line">wdbc_train_label=wdbc[inTrain,1]</span><br><span class="line">wdbc_test_label=wdbc[-inTrain,1]</span><br><span class="line">mal_rate=table(wdbc_train_label)</span><br><span class="line">round(mal_rate[2]/sum(mal_rate), digits = 2)</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="Build-the-KNN-model"><a href="#Build-the-KNN-model" class="headerlink" title="Build the KNN model"></a>Build the KNN model</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">require(class)</span><br><span class="line">wdbc_test_pred &lt;- knn(train = wdbc_train, test = wdbc_test,cl = wdbc_train_label, k=21)</span><br></pre></td></tr></table></figure>
<ul>
<li>K&#x3D;21 here is based on the sqrt of the length(wdbc_train_label).</li>
<li>the parameters of the knn funciton<ul>
<li>train: training data</li>
<li>test: testing data</li>
<li>cl: the labels of training data</li>
</ul>
</li>
</ul>
<h1 id="Model-validation-and-improvement"><a href="#Model-validation-and-improvement" class="headerlink" title="Model validation and improvement"></a>Model validation and improvement</h1><h2 id="Model-validation"><a href="#Model-validation" class="headerlink" title="Model validation"></a>Model validation</h2><ul>
<li>This is a classification problem, so we use the crossTable to validate the model<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">require(gmodels)</span><br><span class="line">CrossTable(x = wdbc_test_label, y = wdbc_test_pred,prop.chisq=FALSE)</span><br></pre></td></tr></table></figure></li>
<li>From the cross table, we can get that: TN &#x3D; 69,TP &#x3D; 39, FN&#x3D;3,FP&#x3D;2</li>
<li>So <ul>
<li>accuracy &#x3D; (TN+TP)&#x2F;113&#x3D;97.345%  </li>
<li>sensitivity&#x3D;TP&#x2F;(TP+FN)&#x3D; 92.86%  </li>
<li>Specificity&#x3D;TN&#x2F;(TN+FP)&#x3D; 100%</li>
</ul>
</li>
<li>And the sensitivity is how much we predict the benign breast cancer correctly, and the specificity is how much we predict the malignant breast cancer correctly.</li>
</ul>
<h2 id="Model-improvement"><a href="#Model-improvement" class="headerlink" title="Model improvement"></a>Model improvement</h2><ul>
<li>Since before we have used the max-min normalization, it maybe reduce the influence of the minimum. So we now try to use the z-score normalization<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wdbc_z=as.data.frame(scale(wdbc[-1]))</span><br><span class="line">summary(wdbc_z$Area_mean)</span><br><span class="line">set.seed(2017)</span><br><span class="line">inTrain=createDataPartition(y=wdbc$diagnosis,p=0.8,list=FALSE)</span><br><span class="line">wdbc_train=wdbc_z[inTrain,]</span><br><span class="line">wdbc_test=wdbc_z[-inTrain,]</span><br><span class="line">wdbc_train_label=wdbc[inTrain,1]</span><br><span class="line">wdbc_test_label=wdbc[-inTrain,1]</span><br><span class="line">wdbc_test_pred = knn(train = wdbc_train, test = wdbc_test,cl = wdbc_train_label, k=21)</span><br><span class="line">CrossTable(x = wdbc_test_label, y = wdbc_test_pred,prop.chisq=FALSE)</span><br></pre></td></tr></table></figure></li>
<li>From the cross table, we can get: TN &#x3D; 71,TP &#x3D; 37, FN&#x3D;5,FP&#x3D;0</li>
<li>so we can calculate:<ul>
<li>accuracy &#x3D; (TN+TP)&#x2F;113&#x3D;96.46%  </li>
<li>sensitivity&#x3D;TP&#x2F;(TP+FN)&#x3D; 90.47%  </li>
<li>Specificity&#x3D;TN&#x2F;(TN+FP)&#x3D; 100%</li>
</ul>
</li>
<li>But it’s out of our expect, it gets worse now.</li>
<li>So we can try to tune the k value too.</li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步-R语言</category>
      </categories>
      <tags>
        <tag>ML</tag>
        <tag>KNN</tag>
        <tag>Classification</tag>
      </tags>
  </entry>
  <entry>
    <title>chp0_JSP</title>
    <url>/2014/07/06/%E6%8A%80%E8%83%BD-%E4%BF%AE%E8%A1%8C-%E8%BF%9B%E6%AD%A5-JSP/chp0-JSP/</url>
    <content><![CDATA[<h1 id="JSP-Review-201407"><a href="#JSP-Review-201407" class="headerlink" title="JSP-Review-201407"></a>JSP-Review-201407</h1><p>JSP的课本重点整理—《JSP应用教程（修订本）》石志国</p>
<p>11医用（1）班 整理者：陈玉庆 教授：陈国华</p>
<h1 id="2014今年大题考背代码"><a href="#2014今年大题考背代码" class="headerlink" title="2014今年大题考背代码"></a>2014今年大题考背代码</h1><ul>
<li>page175 必背</li>
<li>page223 必背</li>
<li>page256 必背 9-25.jsp</li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步-JSP</category>
      </categories>
      <tags>
        <tag>JSP网页开发</tag>
      </tags>
  </entry>
  <entry>
    <title>chp6_JSP</title>
    <url>/2014/07/06/%E6%8A%80%E8%83%BD-%E4%BF%AE%E8%A1%8C-%E8%BF%9B%E6%AD%A5-JSP/chp6-JSP/</url>
    <content><![CDATA[<h1 id="第六章-JSP经典开发技巧"><a href="#第六章-JSP经典开发技巧" class="headerlink" title="第六章 JSP经典开发技巧"></a>第六章 JSP经典开发技巧</h1><hr>
<h3 id="6-1-2-三种网页对话框-page115"><a href="#6-1-2-三种网页对话框-page115" class="headerlink" title="6.1.2 三种网页对话框(page115)"></a>6.1.2 三种网页对话框(page115)</h3><ul>
<li>使用window.open打开的网页</li>
<li>使用Web模式对话框</li>
<li>使用Web非模式对话框<br><img src="/img/jsp_review/dialogs.JPG"></li>
</ul>
<blockquote>
<p><strong>三种对话框的区别是：利用window.open打开的页面和其他的窗口一样，可以在几个窗口之间切换；模式对话框不可以和其他窗口切换焦点，只能是当前窗口。非模式对话框可以和其他对话框切换焦点，但是永远在屏幕的最前面。</strong></p>
</blockquote>
<hr>
<h3 id="6-7-面向对象设计模式-page150"><a href="#6-7-面向对象设计模式-page150" class="headerlink" title="6.7 面向对象设计模式(page150)"></a>6.7 面向对象设计模式(page150)</h3><blockquote>
<p><strong>注：本节老师没划重点，但在课上有讲到，高分者可详看。</strong></p>
</blockquote>
<ul>
<li>Factory模式</li>
<li>Singleton模式</li>
<li>mvc架构模式</li>
</ul>
<p><img src="/img/jsp_review/mvc.jpg"></p>
]]></content>
      <categories>
        <category>技能-修行-进步-JSP</category>
      </categories>
      <tags>
        <tag>JSP网页开发</tag>
      </tags>
  </entry>
  <entry>
    <title>chp7_JSP</title>
    <url>/2014/07/06/%E6%8A%80%E8%83%BD-%E4%BF%AE%E8%A1%8C-%E8%BF%9B%E6%AD%A5-JSP/chp7-JSP/</url>
    <content><![CDATA[<h1 id="第七章-JDBC数据库开发接口"><a href="#第七章-JDBC数据库开发接口" class="headerlink" title="第七章 JDBC数据库开发接口"></a>第七章 JDBC数据库开发接口</h1><hr>
<h3 id="7-3-1-JDBC的四种类型-page171"><a href="#7-3-1-JDBC的四种类型-page171" class="headerlink" title="7.3.1 JDBC的四种类型(page171)"></a>7.3.1 JDBC的四种类型(page171)</h3><ul>
<li>JDBC-ODBC桥加ODBC驱动程序</li>
<li>本地API</li>
<li>JDBC网络纯Java驱动程序</li>
<li>本地协议纯Java驱动程序</li>
</ul>
<hr>
<h3 id="7-3-2-数据驱动程序-page172"><a href="#7-3-2-数据驱动程序-page172" class="headerlink" title="7.3.2 数据驱动程序(page172)"></a>7.3.2 数据驱动程序(page172)</h3><ul>
<li><p>加载Oracle的JDBC驱动程序的语句为：</p>
<blockquote>
<p><strong>Class.forName(“oracle.jdbc.driver.OracleDriver”);</strong></p>
</blockquote>
</li>
<li><p>使用JDBC-ODBC桥驱动程序的语句为：</p>
<blockquote>
<p><strong>Class.forName(“sun.jdbc.odbc.JdbcOdbcDriver”);</strong></p>
</blockquote>
</li>
<li><p>加载Sql2005驱动程序的语句为：</p>
<blockquote>
<p><strong>Class.forName(“com.microsoft.jdbc.sqlserver.SQLServerDriver”);</strong></p>
</blockquote>
</li>
<li><p>加载MySQL驱动下次语句为：</p>
<blockquote>
<p><strong>Class.forName(“com.mysql.jdbc.Driver”);</strong></p>
</blockquote>
</li>
</ul>
<hr>
<h3 id="7-3-3-Connection对象-page172"><a href="#7-3-3-Connection对象-page172" class="headerlink" title="7.3.3 Connection对象(page172)"></a>7.3.3 Connection对象(page172)</h3><pre>
<code>
import java.sql.*;

public class DB &#123;
    public static Connection getConn() &#123;
        Connection conn = null;
        try &#123;
            Class.forName("com.mysql.jdbc.Driver");
            conn = DriverManager.getConnection("jdbc:mysql://localhost/shopping?user=root&password=123456");
        &#125; catch (ClassNotFoundException e) &#123;
            e.printStackTrace();
        &#125; catch (SQLException e) &#123;
            e.printStackTrace();
        &#125;
        
        return conn;
    &#125;
    
    public static PreparedStatement prepare(Connection conn,  String sql) &#123;
        PreparedStatement pstmt = null; 
        try &#123;
            if(conn != null) &#123;
                pstmt = conn.prepareStatement(sql);
            &#125;
        &#125; catch (SQLException e) &#123;
            e.printStackTrace();
        &#125;
        return pstmt;
    &#125;
    
    public static PreparedStatement prepare(Connection conn,  String sql, int autoGenereatedKeys) &#123;
        PreparedStatement pstmt = null; 
        try &#123;
            if(conn != null) &#123;
                pstmt = conn.prepareStatement(sql, autoGenereatedKeys);
            &#125;
        &#125; catch (SQLException e) &#123;
            e.printStackTrace();
        &#125;
        return pstmt;
    &#125;
    
    public static Statement getStatement(Connection conn) &#123;
        Statement stmt = null; 
        try &#123;
            if(conn != null) &#123;
                stmt = conn.createStatement();
            &#125;
        &#125; catch (SQLException e) &#123;
            e.printStackTrace();
        &#125;
        return stmt;
    &#125;
    
    /*
    public static ResultSet getResultSet(Connection conn, String sql) &#123;
        Statement stmt = getStatement(conn);
        ResultSet rs = getResultSet(stmt, sql);
        close(stmt);
        return rs;
    &#125;
    */
    
    public static ResultSet getResultSet(Statement stmt, String sql) &#123;
        ResultSet rs = null;
        try &#123;
            if(stmt != null) &#123;
                rs = stmt.executeQuery(sql);
            &#125;
        &#125; catch (SQLException e) &#123;
            e.printStackTrace();
        &#125;
        return rs;
    &#125;
    
    public static void executeUpdate(Statement stmt, String sql) &#123;
        try &#123;
            if(stmt != null) &#123;
                stmt.executeUpdate(sql);
            &#125;
        &#125; catch (SQLException e) &#123;
            e.printStackTrace();
        &#125;
    &#125;
    
    public static void close(Connection conn) &#123;
        try &#123;
            if(conn != null) &#123;
                conn.close();
                conn = null;
            &#125;
        &#125; catch (SQLException e) &#123;
            e.printStackTrace();
        &#125;
    &#125;
    
    public static void close(Statement stmt) &#123;
        try &#123;
            if(stmt != null) &#123;
                stmt.close();
                stmt = null;
            &#125;
        &#125; catch (SQLException e) &#123;
            e.printStackTrace();
        &#125;
    &#125;
</code>
</pre>]]></content>
      <categories>
        <category>技能-修行-进步-JSP</category>
      </categories>
      <tags>
        <tag>JSP网页开发</tag>
      </tags>
  </entry>
  <entry>
    <title>chp8_JSP</title>
    <url>/2014/07/06/%E6%8A%80%E8%83%BD-%E4%BF%AE%E8%A1%8C-%E8%BF%9B%E6%AD%A5-JSP/chp8-JSP/</url>
    <content><![CDATA[<h1 id="第八章-Hibernate数据持久化技术"><a href="#第八章-Hibernate数据持久化技术" class="headerlink" title="第八章 Hibernate数据持久化技术"></a>第八章 Hibernate数据持久化技术</h1><hr>
<h3 id="8-1-1-ORM的基本概念-page211"><a href="#8-1-1-ORM的基本概念-page211" class="headerlink" title="8.1.1 ORM的基本概念(page211)"></a>8.1.1 ORM的基本概念(page211)</h3><ul>
<li>ORM<blockquote>
<p><strong>（Object&#x2F;Relation Mapping）对象关系映射</strong></p>
</blockquote>
</li>
<li>作用<blockquote>
<p><strong>实现了Java应用中的对象到关系数据库中的表的自动的（和透明的）持久化，使用元数据描述对象鱼数据库间的映射。</strong></p>
</blockquote>
</li>
<li>ORM的优点<blockquote>
<p><strong>可以提高生产率，增加程序的可维护性，提供更好的性能。</strong></p>
</blockquote>
</li>
</ul>
<hr>
<h3 id="8-1-2-POJO与PO的概念-page211"><a href="#8-1-2-POJO与PO的概念-page211" class="headerlink" title="8.1.2 POJO与PO的概念(page211)"></a>8.1.2 POJO与PO的概念(page211)</h3><ul>
<li><p>POJO</p>
<blockquote>
<p><strong>(Pure Old Java Object或者Plain Ordinary Java Object，纯Java对象)，用来与数据库表建立映射的Java文件。</strong></p>
</blockquote>
</li>
<li><p>PO</p>
<blockquote>
<p><strong>（Persistent Object，持久化对象），是在操作数据库时创建的对象。</strong></p>
</blockquote>
</li>
<li><p>有一下的数据库表</p>
  <pre>
  <code>
  CREATE TABLE User
  (
      id int,
      name varchar(20)
  )
  </code>
  </pre></li>
<li><p>编写一个与之对应的持久化对象的类</p>
  <pre>
  <code>
  public class User &#123;
      private long id;
      private String name;
      public void setId(long id)&#123;
          this.id = id;
      &#125;
      public void setName(String name) &#123;
          this.name = name;
      &#125;
      public long getId() &#123;
          return id;
      &#125;
      public String getName() &#123;
          return name;
      &#125;
  &#125;
  </code>
  </pre></li>
</ul>
<hr>
<h3 id="加强训练"><a href="#加强训练" class="headerlink" title="加强训练"></a>加强训练</h3><ul>
<li><p>给出以下数据库表（page217）</p>
  <pre>
  <code>
  use pubs;
  go
  CREATE TABLE Usertab
  (
      userid int Identity primary key,
      username varchar(20),
      userpwd varchar(20)
  )
  INSERT INTO usertab values('tom','tom');
  </code>
  </pre></li>
<li><p>编写一个与之对应的持久化对象的类(page223)</p>
  <pre>
  <code>
  import java.io.Serializable;
  public class Usertab implements Serializable &#123;
      private Integer userid;
      private String username;
      private String userpwd;
      public Usertab()&#123;&#125;
      public Usertab(String username, String userpwd) &#123;
          this.username = username;
          this.userpwd = userpwd;
      &#125;
      public Integer getUserid() &#123;
          return userid;
      &#125;
      public void setUserid(Integer userid) &#123;
          this.userid = userid;
      &#125;
      public String getUsername() &#123;
          return username;
      &#125;
      public void setUsername(String username) &#123;
          this.username = username;
      &#125;
      public String getUserpwd() &#123;
          return userpwd;
      &#125;
      public void setUserpwd(String userpwd) &#123;
          this.userpwd = userpwd;
      &#125;
  &#125;
  </code>
  </pre></li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步-JSP</category>
      </categories>
      <tags>
        <tag>JSP网页开发</tag>
      </tags>
  </entry>
  <entry>
    <title>chp9_JSP</title>
    <url>/2014/07/06/%E6%8A%80%E8%83%BD-%E4%BF%AE%E8%A1%8C-%E8%BF%9B%E6%AD%A5-JSP/chp9-JSP/</url>
    <content><![CDATA[<h1 id="第九章-XML数据操作接口"><a href="#第九章-XML数据操作接口" class="headerlink" title="第九章 XML数据操作接口"></a>第九章 XML数据操作接口</h1><hr>
<h3 id="9-1-XML-page233"><a href="#9-1-XML-page233" class="headerlink" title="9.1 XML(page233)"></a>9.1 XML(page233)</h3><ul>
<li><p>XML：（eXtensible Markup Language）即可扩展的标记语言，可以定义语义标记，是元标记语言。</p>
</li>
<li><p>XML的结构：序言和文档元素</p>
<ul>
<li>序言<blockquote>
<p><strong>XML声明、处理指令、注释</strong></p>
</blockquote>
</li>
<li>文档元素<blockquote>
<p><strong>元素、属性、文本内容、字符、实体引用、CDATA区</strong></p>
</blockquote>
</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步-JSP</category>
      </categories>
      <tags>
        <tag>JSP网页开发</tag>
      </tags>
  </entry>
  <entry>
    <title>SVM入门系列博文-转自Jasper&#39;s Java Jacal-备份-毕设系列</title>
    <url>/2015/01/08/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%E7%B3%BB%E5%88%97/SVM%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%97%E5%8D%9A%E6%96%87-%E8%BD%AC%E8%87%AAJasper-s-Java-Jacal-%E5%A4%87%E4%BB%BD-%E6%AF%95%E8%AE%BE%E7%B3%BB%E5%88%97/</url>
    <content><![CDATA[<h2 id="写在前面的话"><a href="#写在前面的话" class="headerlink" title="写在前面的话"></a>写在前面的话</h2><ul>
<li>本文是一个备份，转自：<a class="link"   href="http://www.blogjava.net/zhenandaci/" >Jasper’s Java Jacal<i class="fas fa-external-link-alt"></i></a></li>
<li>以下是原文。请细赏！</li>
</ul>
<h2 id="SVM入门（一）之SVM的八股简介"><a href="#SVM入门（一）之SVM的八股简介" class="headerlink" title="SVM入门（一）之SVM的八股简介"></a>SVM入门（一）之SVM的八股简介</h2><ul>
<li>支持向量机(Support Vector Machine)是Cortes和Vapnik于1995年首先提出的，它在解决<font color="red"><strong>小样本、非线性及高维模式识别</strong></font>中表现出许多特有的优势，并能够推广应用到函数拟合等其他机器学习问题中[10]。</li>
<li>支持向量机方法是建立在<font color="red"><strong>统计学习理论的VC维理论和结构风险最小原理</strong></font>基础上的，根据有限的样本信息在模型的复杂性（即对特定训练样本的学习精度，Accuracy）和学习能力（即无错误地识别任意样本的能力）之间寻求最佳折衷，以期获得最好的推广能力[14]（或称泛化能力）。</li>
<li>以上是经常被有关SVM 的学术文献引用的介绍，有点八股，我来逐一分解并解释一下。</li>
</ul>
<h3 id="传统机器学习与统计机器学习"><a href="#传统机器学习与统计机器学习" class="headerlink" title="@传统机器学习与统计机器学习"></a>@传统机器学习与统计机器学习</h3><ul>
<li>Vapnik是统计机器学习的大牛，这想必都不用说，他出版的《Statistical Learning Theory》是一本完整阐述统计机器学习思想的名著。在该书中详细的论证了统计机器学习之所以区别于传统机器学习的本质，就在于统计机器学习能够精确的给出学习效果，能够解答需要的样本数等等一系列问题。与统计机器学习的精密思维相比，传统的机器学习基本上属于摸着石头过河，用传统的机器学习方法构造分类系统完全成了一种技巧，一个人做的结果可能很好，另一个人差不多的方法做出来却很差，缺乏指导和原则。</li>
</ul>
<h3 id="VC维"><a href="#VC维" class="headerlink" title="@VC维"></a>@VC维</h3><ul>
<li>所谓<font color="red"><strong>VC维是对函数类的一种度量，可以简单的理解为问题的复杂程度，VC维越高，一个问题就越复杂</strong></font>。正是因为SVM关注的是VC维，后面我们可以看到，SVM解决问题的时候，和样本的维数是无关的（甚至样本是上万维的都可以，这使得SVM很适合用来解决文本分类的问题，当然，有这样的能力也因为引入了核函数）。</li>
</ul>
<h3 id="结构风险最小"><a href="#结构风险最小" class="headerlink" title="@结构风险最小"></a>@结构风险最小</h3><ul>
<li><font color="red"><strong>结构风险最小</strong></font>听上去文绉绉，其实说的也无非是下面这回事。</li>
<li>机器学习本质上就是<font color="red"><strong>一种对问题真实模型的逼近（我们选择一个我们认为比较好的近似模型，这个近似模型就叫做一个假设）</strong></font>，但毫无疑问，真实模型一定是不知道的（如果知道了，我们干吗还要机器学习？直接用真实模型解决问题不就可以了？对吧，哈哈）既然真实模型不知道，那么我们选择的假设与问题真实解之间究竟有多大差距，我们就没法得知。比如说我们认为宇宙诞生于150亿年前的一场大爆炸，这个假设能够描述很多我们观察到的现象，但它与真实的宇宙模型之间还相差多少？谁也说不清，因为我们压根就不知道真实的宇宙模型到底是什么。</li>
<li>这个与问题真实解之间的误差，就叫做<font color="red"><strong>风险（更严格的说，误差的累积叫做风险）</strong></font>。我们选择了一个假设之后（更直观点说，我们得到了一个分类器以后），真实误差无从得知，但我们可以用某些可以掌握的量来逼近它。最直观的想法就是使用分类器在样本数据上的分类的结果与真实结果（因为样本是已经标注过的数据，是准确的数据）之间的差值来表示。这个差值叫做<font color="red"><strong>经验风险Remp(w)</strong></font>。以前的机器学习方法都把经验风险最小化作为努力的目标，但后来发现很多分类函数能够在样本集上轻易达到100%的正确率，在真实分类时却一塌糊涂（即所谓的推广能力差，或泛化能力差）。此时的情况便是选择了一个足够复杂的分类函数（它的VC维很高），能够精确的记住每一个样本，但对样本之外的数据一律分类错误。回头看看经验风险最小化原则我们就会发现，此原则适用的大前提是经验风险要确实能够逼近真实风险才行（行话叫一致），但实际上能逼近么？答案是不能，因为样本数相对于现实世界要分类的文本数来说简直九牛一毛，<font color="red"><strong>经验风险最小化原则只在这占很小比例的样本上做到没有误差，当然不能保证在更大比例的真实文本上也没有误差。</strong></font></li>
</ul>
<h3 id="泛化误差界"><a href="#泛化误差界" class="headerlink" title="@泛化误差界"></a>@泛化误差界</h3><ul>
<li>统计学习因此而引入了泛化误差界的概念，就是指<font color="red"><strong>真实风险应该由两部分内容刻画，一是经验风险，代表了分类器在给定样本上的误差；二是置信风险，代表了我们在多大程度上可以信任分类器在未知文本上分类的结果。</strong></font>很显然，第二部分是没有办法精确计算的，因此只能给出一个估计的区间，也使得整个误差只能计算上界，而无法计算准确的值（所以叫做泛化误差界，而不叫泛化误差）。 </li>
<li>置信风险与两个量有关，一是样本数量，显然给定的样本数量越大，我们的学习结果越有可能正确，此时置信风险越小；二是分类函数的VC维，显然VC维越大，推广能力越差，置信风险会变大。</li>
<li>泛化误差界的公式为：R(w)≤Remp(w)+Ф(n&#x2F;h) </li>
<li>公式中R(w)就是真实风险，Remp(w)就是经验风险，Ф(n&#x2F;h)就是置信风险。统计学习的目标从经验风险最小化变为了寻求经验风险与置信风险的和最小，即结构风险最小。</li>
<li>SVM正是这样一种努力最小化结构风险的算法。</li>
</ul>
<h3 id="小样本，非线性，高维度识别"><a href="#小样本，非线性，高维度识别" class="headerlink" title="@小样本，非线性，高维度识别"></a>@小样本，非线性，高维度识别</h3><ul>
<li>SVM其他的特点就比较容易理解了。</li>
<li><font color="red"><strong>小样本</strong></font>，并不是说样本的绝对数量少（实际上，对任何算法来说，更多的样本几乎总是能带来更好的效果），而是说与问题的复杂度比起来，SVM算法要求的样本数是相对比较少的。</li>
<li><font color="red"><strong>非线性</strong></font>，是指SVM擅长应付样本数据线性不可分的情况，主要通过松弛变量（也有人叫惩罚变量）和核函数技术来实现，这一部分是SVM的精髓，以后会详细讨论。多说一句，关于文本分类这个问题究竟是不是线性可分的，尚没有定论，因此不能简单的认为它是线性可分的而作简化处理，在水落石出之前，只好先当它是线性不可分的（反正线性可分也不过是线性不可分的一种特例而已，我们向来不怕方法过于通用）。</li>
<li><font color="red"><strong>高维模式识别</strong></font>是指样本维数很高，例如文本的向量表示，如果没有经过另一系列文章（《文本分类入门》）中提到过的降维处理，出现几万维的情况很正常，其他算法基本就没有能力应付了，SVM却可以，主要是因为SVM 产生的分类器很简洁，用到的样本信息很少（仅仅用到那些称之为“支持向量”的样本，此为后话），使得即使样本维数很高，也不会给存储和计算带来大麻烦（相对照而言，kNN算法在分类时就要用到所有样本，样本数巨大，每个样本维数再一高，这日子就没法过了……）。</li>
</ul>
<h3 id="下节预告"><a href="#下节预告" class="headerlink" title="@下节预告"></a>@下节预告</h3><ul>
<li>下一节开始正式讨论SVM。别嫌我说得太详细哦。</li>
</ul>
<h2 id="SVM入门（二）线性分类器Part-1"><a href="#SVM入门（二）线性分类器Part-1" class="headerlink" title="SVM入门（二）线性分类器Part 1"></a>SVM入门（二）线性分类器Part 1</h2><h3 id="线性分类器"><a href="#线性分类器" class="headerlink" title="@线性分类器"></a>@线性分类器</h3><ul>
<li>线性分类器(一定意义上,也可以叫做<font color="red"><strong>感知机</strong></font>) 是最简单也很有效的分类器形式.在一个线性分类器中,可以看到SVM形成的思路,并接触很多SVM的核心概念。 </li>
<li>用一个二维空间里仅有两类样本的分类问题来举个小例子。如图所示：<br><img src="/img/paperBlog/intro-SVM-serial/serial02/clip_image002_thumb.gif"></li>
<li>C1和C2是要区分的两个类别，在二维平面中它们的样本如上图所示。<font color="red"><strong>中间的直线就是一个分类函数</strong></font>，它可以将两类样本完全分开。一般的，如果一个线性函数能够将样本完全正确的分开，就称这些数据是线性可分的，否则称为非线性可分的。</li>
</ul>
<h3 id="线性函数"><a href="#线性函数" class="headerlink" title="@线性函数"></a>@线性函数</h3><ul>
<li><p>什么叫线性函数呢？在一维空间里就是一个点，在二维空间里就是一条直线，三维空间里就是一个平面，可以如此想象下去，如果不关注空间的维数，这种线性函数还有一个统一的名称——<font color="red"><strong>超平面（Hyper Plane）</strong></font>！</p>
</li>
<li><p>实际上，一个线性函数是一个实值函数（即函数的值是连续的实数），而我们的分类问题（例如这里的二元分类问题——回答一个样本属于还是不属于一个类别的问题）需要离散的输出值，例如用1表示某个样本属于类别C1，而用0表示不属于（不属于C1也就意味着属于C2），这时候只需要简单的在实值函数的基础上附加一个阈值即可，通过分类函数执行时得到的值大于还是小于这个阈值来确定类别归属。 例如我们有一个线性函数</p>
<p>  g(x)&#x3D;wx+b</p>
</li>
<li><p>我们可以取阈值为0，这样当有一个样本xi需要判别的时候，我们就看g(xi)的值。若g(xi)&gt;0，就判别为类别C1，若g(xi)&lt;0，则判别为类别C2（等于的时候我们就拒绝判断，呵呵）。此时也等价于给函数g(x)附加一个<strong>符号函数</strong>sgn()，即f(x)&#x3D;sgn[g(x)]是我们真正的<strong>判别函数</strong>。</p>
</li>
<li><p>关于g(x)&#x3D;wx+b这个表达式要注意三点：</p>
<ul>
<li>一，式中的x不是二维坐标系中的横轴，而是样本的向量表示，例如一个样本点的坐标是(3,8)，则xT&#x3D;(3,8) ，而不是x&#x3D;3（一般说向量都是说列向量，因此以行向量形式来表示时，就加上转置）。</li>
<li>二，这个形式并不局限于二维的情况，在n维空间中仍然可以使用这个表达式，只是式中的w成为了n维向量（在二维的这个例子中，w是二维向量，为了表示起来方便简洁，以下均不区别列向量和它的转置，聪明的读者一看便知）；</li>
<li>三，g(x)不是中间那条直线的表达式，中间那条直线的表达式是g(x)&#x3D;0，即wx+b&#x3D;0，我们也把这个函数叫做分类面。</li>
</ul>
</li>
<li><p>实际上很容易看出来，中间那条分界线并不是唯一的，我们把它稍微旋转一下，只要不把两类数据分错，仍然可以达到上面说的效果，稍微平移一下，也可以。此时就牵涉到一个问题，对同一个问题存在多个分类函数的时候，哪一个函数更好呢？显然必须要先找一个指标来量化“好”的程度，通常使用的都是叫做<font color="red"><strong>“分类间隔”</strong></font>的指标。</p>
</li>
</ul>
<h3 id="下节预告-1"><a href="#下节预告-1" class="headerlink" title="@下节预告"></a>@下节预告</h3><ul>
<li>下一节我们就仔细说说<font color="red"><strong>分类间隔</strong></font>，也补一补相关的数学知识。</li>
</ul>
<h2 id="SVM入门（三）线性分类器Part-2"><a href="#SVM入门（三）线性分类器Part-2" class="headerlink" title="SVM入门（三）线性分类器Part 2"></a>SVM入门（三）线性分类器Part 2</h2><ul>
<li>上回说到对于文本分类这样的<strong>不适定问题</strong>（<em>有一个以上解的问题称为不适定问题</em>），需要有一个指标来衡量解决方案（即我们通过训练建立的分类模型）的好坏，而<font color="red"><strong>分类间隔</strong></font>是一个比较好的指标。</li>
</ul>
<h3 id="文本分类在计算机中的表示"><a href="#文本分类在计算机中的表示" class="headerlink" title="@文本分类在计算机中的表示"></a>@文本分类在计算机中的表示</h3><ul>
<li>在进行文本分类的时候，我们可以让计算机这样来看待我们提供给它的训练样本，每一个样本由一个向量（就是那些文本特征所组成的向量）和一个标记（标示出这个样本属于哪个类别）组成。如下：<br>  Di&#x3D;(xi,yi)</li>
<li>xi就是文本向量（维数很高），yi就是分类标记。</li>
<li>在二元的线性分类中，这个表示分类的标记只有两个值，1和-1（用来表示属于还是不属于这个类）。有了这种表示法，我们就可以定义一个样本点到某个超平面的间隔：<br>  δi&#x3D;yi(wxi+b)</li>
<li>这个公式乍一看没什么神秘的，也说不出什么道理，只是个定义而已，但我们做做变换，就能看出一些有意思的东西。</li>
</ul>
<h3 id="由分类间隔到几何间隔"><a href="#由分类间隔到几何间隔" class="headerlink" title="@由分类间隔到几何间隔"></a>@由分类间隔到几何间隔</h3><ul>
<li>首先注意到如果某个样本属于该类别的话，那么wxi+b&gt;0（记得么？这是因为我们所选的g(x)&#x3D;wx+b就通过大于0还是小于0来判断分类），而yi也大于0；若不属于该类别的话，那么wxi+b&lt;0，而yi也小于0，这意味着yi(wxi+b)总是大于0的，而且它的值就等于|wxi+b|！（也就是|g(xi)|） </li>
<li>现在把w和b进行一下归一化，即用w&#x2F;||w||和b&#x2F;||w||分别代替原来的w和b，那么间隔就可以写成<br><img src="/img/paperBlog/intro-SVM-serial/serial03/formula1.gif"></li>
<li>这个公式是不是看上去有点眼熟？没错，这不就是解析几何中点xi到直线g(x)&#x3D;0的距离公式嘛！（推广一下，是到超平面g(x)&#x3D;0的距离， g(x)&#x3D;0就是上节中提到的分类超平面） <blockquote>
<p>小Tips：||w||是什么符号？||w||叫做向量w的范数，范数是对向量长度的一种度量。我们常说的向量长度其实指的是它的2-范数，范数最一般的表示形式为p-范数，可以写成如下表达式<br>      向量w&#x3D;(w1, w2, w3,…… wn)<br>它的p-范数为 <br><img src="/img/paperBlog/intro-SVM-serial/serial03/formula2.gif"></p>
</blockquote>
</li>
<li>看看把p换成2的时候，不就是传统的向量长度么？当我们不指明p的时候，就像||w||这样使用时，就意味着我们不关心p的值，用几范数都可以；或者上文已经提到了p的值，为了叙述方便不再重复指明。 </li>
<li>当用归一化的w和b代替原值之后的间隔有一个专门的名称，叫做<font color="red"><strong>几何间隔</strong></font>，几何间隔所表示的正是点到超平面的欧氏距离，我们下面就简称几何间隔为“距离”。以上是单个点到某个超平面的距离（就是间隔，后面不再区别这两个词）定义，同样可以定义一个点的集合（就是一组样本）到某个超平面的距离为此集合中离超平面最近的点的距离。下面这张图更加直观的展示出了几何间隔的现实含义： <br><img src="/img/paperBlog/intro-SVM-serial/serial03/p1.png"></li>
<li>H是分类面，而H1和H2是平行于H，且过离H最近的两类样本的直线，H1与H，H2与H之间的距离就是<font color="red"><strong>几何间隔</strong></font>。 </li>
<li>之所以如此关心几何间隔这个东西，是因为几何间隔与样本的误分次数间存在关系：<br><img src="/img/paperBlog/intro-SVM-serial/serial03/formula3.gif"></li>
<li>其中的δ是样本集合到分类面的间隔，R&#x3D;max ||xi||  i&#x3D;1,…,n，即R是所有样本中（xi是以向量表示的第i个样本）向量长度最长的值（也就是说代表样本的分布有多么广）。先不必追究误分次数的具体定义和推导过程，只要记得这个误分次数一定程度上代表分类器的误差。而从上式可以看出，误分次数的上界由几何间隔决定！（当然，是样本已知的时候）</li>
<li>至此我们就明白为何要选择几何间隔来作为评价一个解优劣的指标了，<font color="red"><strong>原来几何间隔越大的解，它的误差上界越小</strong></font>。因此最大化几何间隔成了我们训练阶段的目标，而且，与二把刀作者所写的不同，最大化分类间隔并不是SVM的专利，而是早在线性分类时期就已有的思想。</li>
</ul>
<h2 id="SVM入门（四）线性分类器的求解——问题的描述Part1"><a href="#SVM入门（四）线性分类器的求解——问题的描述Part1" class="headerlink" title="SVM入门（四）线性分类器的求解——问题的描述Part1"></a>SVM入门（四）线性分类器的求解——问题的描述Part1</h2><h3 id="上节回顾-间隔和几何间隔"><a href="#上节回顾-间隔和几何间隔" class="headerlink" title="@上节回顾-间隔和几何间隔"></a>@上节回顾-间隔和几何间隔</h3><ul>
<li>上节说到我们有了一个线性分类函数，也有了判断解优劣的标准——即有了优化的目标，<font color="red"><strong>这个目标就是最大化几何间隔</strong></font>，但是看过一些关于SVM的论文的人一定记得什么优化的目标是要最小化||w||这样的说法，这是怎么回事呢？回头再看看我们对<strong>间隔</strong>和<strong>几何间隔</strong>的定义： </li>
<li>间隔：δ&#x3D;y(wx+b)&#x3D;|g(x)| </li>
<li>几何间隔：<img src="/img/paperBlog/intro-SVM-serial/serial04/formula1.gif"></li>
<li>可以看出δ&#x3D;||w||δ几何。注意到几何间隔与||w||是成反比的，因此最大化几何间隔与最小化||w||完全是一回事。而我们常用的方法并不是固定||w||的大小而寻求最大几何间隔，而是固定间隔（例如固定为1），寻找最小的||w||。</li>
</ul>
<h3 id="寻优问题"><a href="#寻优问题" class="headerlink" title="@寻优问题"></a>@寻优问题</h3><ul>
<li>而凡是求一个函数的最小值（或最大值）的问题都可以称为寻优问题（也叫作一个<font color="red"><strong>规划问题</strong></font>），又由于找最大值的问题总可以通过加一个负号变为找最小值的问题，因此我们下面讨论的时候都针对找最小值的过程来进行。一个寻优问题最重要的部分是<font color="red"><strong>目标函数</strong></font>，顾名思义，就是指寻优的目标。例如我们想寻找最小的||w||这件事，就可以用下面的式子表示：<br><img src="/img/paperBlog/intro-SVM-serial/serial04/formula2.gif"> </li>
<li>但实际上对于这个目标，我们常常使用另一个完全等价的目标函数来代替，那就是：<br><img src="/img/paperBlog/intro-SVM-serial/serial04/formula3.gif"> </li>
<li>不难看出当||w||2达到最小时，||w||也达到最小，反之亦然（前提当然是||w||描述的是向量的长度，因而是非负的）。之所以采用这种形式，是因为后面的求解过程会对目标函数作一系列变换，而式（1）的形式会使变换后的形式更为简洁（正如聪明的读者所料，添加的系数二分之一和平方，皆是为求导数所需）。</li>
</ul>
<h3 id="加约束条件"><a href="#加约束条件" class="headerlink" title="@加约束条件"></a>@加约束条件</h3><ul>
<li>接下来我们自然会问的就是，这个式子是否就描述了我们的问题呢？（回想一下，我们的问题是有一堆点，可以被分成两类，我们要找出最好的分类面） </li>
<li>如果直接来解这个求最小值问题，很容易看出当||w||&#x3D;0的时候就得到了目标函数的最小值。但是你也会发现，无论你给什么样的数据，都是这个解！反映在图中，就是H1与H2两条直线间的距离无限大，这个时候，所有的样本点（无论正样本还是负样本）都跑到了H1和H2中间，而我们原本的意图是，H1右侧的被分为正类，H2 左侧的被分为负类，位于两类中间的样本则拒绝分类（拒绝分类的另一种理解是分给哪一类都有道理，因而分给哪一类也都没有道理）。这下可好，所有样本点都进入了无法分类的灰色地带。<br><img src="/img/paperBlog/intro-SVM-serial/serial04/p1.gif"> </li>
<li>造成这种结果的原因是在描述问题的时候只考虑了目标，而没有加入<font color="red"><strong>约束条件</strong></font>，约束条件就是在求解过程中必须满足的条件，体现在我们的问题中就是样本点必须在H1或H2的某一侧（或者至少在H1和H2上），而不能跑到两者中间。我们前文提到过把间隔固定为1，这是指把所有样本点中间隔最小的那一点的间隔定为1（这也是集合的间隔的定义，有点绕嘴），也就意味着集合中的其他点间隔都不会小于1，按照间隔的定义，满足这些条件就相当于让下面的式子总是成立： <ul>
<li>yi[(w·xi)+b]≥1 (i&#x3D;1,2,…,l) （l是总的样本数）</li>
</ul>
</li>
<li>但我们常常习惯让式子的值和0比较，因而经常用变换过的形式： <ul>
<li>yi[(w·xi)+b]-1≥0 (i&#x3D;1,2,…,l) （l是总的样本数）</li>
</ul>
</li>
<li>因此我们的两类分类问题也被我们转化成了它的数学形式，一个<font color="red"><strong>带约束的最小值的问题</strong></font>： <br><img src="/img/paperBlog/intro-SVM-serial/serial04/formula4.gif"></li>
</ul>
<h3 id="下节预告-2"><a href="#下节预告-2" class="headerlink" title="@下节预告"></a>@下节预告</h3><ul>
<li>下一节我们从最一般的意义上看看一个求最小值的问题有何特征，以及如何来解。</li>
</ul>
<h2 id="SVM入门（五）线性分类器的求解——问题的描述Part2"><a href="#SVM入门（五）线性分类器的求解——问题的描述Part2" class="headerlink" title="SVM入门（五）线性分类器的求解——问题的描述Part2"></a>SVM入门（五）线性分类器的求解——问题的描述Part2</h2><h3 id="规划-Programming"><a href="#规划-Programming" class="headerlink" title="@规划(Programming)"></a>@规划(Programming)</h3><ul>
<li>从最一般的定义上说，一个求最小值的问题就是一个优化问题（也叫寻优问题，更文绉绉的叫法是<font color="red"><strong>规划</strong></font>——Programming），它同样由两部分组成，目标函数和约束条件，可以用下面的式子表示：<br><img src="/img/paperBlog/intro-SVM-serial/serial05/formula1.gif"> （式1）</li>
<li>约束条件用函数c来表示，就是constrain的意思啦。你可以看出一共有p+q个约束条件，其中p个是<font color="red"><strong>不等式约束</strong></font>，q个<font color="red"><strong>等式约束</strong></font>。 </li>
<li>关于这个式子可以这样来理解：式中的x是自变量，但不限定它的维数必须为1（视乎你解决的问题空间维数，对我们的文本分类来说，那可是成千上万啊）。要求f(x)在哪一点上取得最小值（反倒不太关心这个最小值到底是多少，关键是哪一点），但不是在整个空间里找，而是在约束条件所划定的一个有限的空间里找，这个有限的空间就是优化理论里所说的<font color="red"><strong>可行域</strong></font>。注意可行域中的每一个点都要求满足所有p+q个条件，而不是满足其中一条或几条就可以（切记，要满足每个约束），同时可行域边界上的点有一个额外好的特性，它们可以使<font color="red"><strong>不等式约束</strong></font>取得等号！而边界内的点不行。</li>
</ul>
<h3 id="凸集"><a href="#凸集" class="headerlink" title="@凸集"></a>@凸集</h3><ul>
<li>关于可行域还有个概念不得不提，那就是<font color="red"><strong>凸集</strong></font>，凸集是指有这么一个点的集合，其中任取两个点连一条直线，这条线上的点仍然在这个集合内部，因此说“凸”是很形象的（一个反例是，二维平面上，一个月牙形的区域就不是凸集，你随便就可以找到两个点违反了刚才的规定）。</li>
</ul>
<h3 id="凸二次规划"><a href="#凸二次规划" class="headerlink" title="@凸二次规划"></a>@凸二次规划</h3><ul>
<li>回头再来看我们线性分类器问题的描述，可以看出更多的东西。<br><img src="/img/paperBlog/intro-SVM-serial/serial05/formula2.gif"> （式2）</li>
<li>在这个问题中，自变量就是w，而目标函数是w的二次函数，所有的约束条件都是w的线性函数（哎，千万不要把xi当成变量，它代表样本，是已知的），这种规划问题有个很有名气的称呼——<font color="red"><strong>二次规划</strong></font>（Quadratic Programming，QP），而且可以更进一步的说，由于它的可行域是一个凸集，因此它是一个<font color="red"><strong>凸二次规划</strong></font>。 </li>
<li>一下子提了这么多术语，实在不是为了让大家以后能向别人炫耀学识的渊博，这其实是我们继续下去的一个重要前提，因为在动手求一个问题的解之前（好吧，我承认，是动计算机求……），我们必须先问自己：<strong>这个问题是不是有解？如果有解，是否能找到？</strong></li>
</ul>
<h3 id="问题可解吗"><a href="#问题可解吗" class="headerlink" title="@问题可解吗"></a>@问题可解吗</h3><ul>
<li>对于一般意义上的规划问题，两个问题的答案都是不一定，<strong>但凸二次规划让人喜欢的地方就在于，它有解（教科书里面为了严谨，常常加限定成分，说它有全局最优解，由于我们想找的本来就是全局最优的解，所以不加也罢），而且可以找到！</strong>（当然，依据你使用的算法不同，找到这个解的速度，行话叫收敛速度，会有所不同）</li>
<li>对比（式2）和（式1）还可以发现，我们的线性分类器问题只有不等式约束，因此形式上看似乎比一般意义上的规划问题要简单，但解起来却并非如此。 </li>
<li>因为我们实际上并不知道该怎么解一个带约束的优化问题。如果你仔细回忆一下高等数学的知识，会记得我们可以轻松的解一个不带任何约束的优化问题（实际上就是当年背得烂熟的函数求极值嘛，求导再找0点呗，谁不会啊？笑），我们甚至还会解一个只带等式约束的优化问题，也是背得烂熟的，求条件极值，记得么，通过添加拉格朗日乘子，构造拉格朗日函数，来把这个问题转化为无约束的优化问题云云（如果你一时没想通，我提醒一下，构造出的拉格朗日函数就是转化之后的问题形式，它显然没有带任何条件）。</li>
</ul>
<h3 id="读者问"><a href="#读者问" class="headerlink" title="@读者问"></a>@读者问</h3><ul>
<li>读者问：如果只带等式约束的问题可以转化为无约束的问题而得以求解，那么可不可以把带不等式约束的问题向只带等式约束的问题转化一下而得以求解呢？ </li>
<li>聪明，可以，实际上我们也正是这么做的。下一节就来说说如何做这个转化，一旦转化完成，求解对任何学过高等数学的人来说，都是小菜一碟啦。</li>
</ul>
<h2 id="SVM入门（六）线性分类器的求解——问题的转化，直观角度"><a href="#SVM入门（六）线性分类器的求解——问题的转化，直观角度" class="headerlink" title="SVM入门（六）线性分类器的求解——问题的转化，直观角度"></a>SVM入门（六）线性分类器的求解——问题的转化，直观角度</h2><h3 id="回到问题"><a href="#回到问题" class="headerlink" title="@回到问题"></a>@回到问题</h3><ul>
<li>让我再一次比较完整的重复一下我们要解决的问题：我们有属于两个类别的样本点（并不限定这些点在二维空间中）若干，如图，<br><img src="/img/paperBlog/intro-SVM-serial/serial06/p1.png"> </li>
<li>圆形的样本点定为正样本（连带着，我们可以把正样本所属的类叫做正类），方形的点定为负例。我们想求得这样一个线性函数（在n维空间中的线性函数）： <ul>
<li>g(x)&#x3D;wx+b</li>
</ul>
</li>
<li>使得所有属于正类的点x+代入以后有g(x+)≥1，而所有属于负类的点x-代入后有g(x-)≤-1（之所以总跟1比较，无论正一还是负一，都是因为我们固定了间隔为1，注意间隔和几何间隔的区别）。代入g(x)后的值如果在1和-1之间，我们就拒绝判断。</li>
</ul>
<h3 id="问题实际上就是求解w和b"><a href="#问题实际上就是求解w和b" class="headerlink" title="@问题实际上就是求解w和b"></a>@问题实际上就是求解w和b</h3><ul>
<li>求这样的g(x)的过程就是求w（一个n维向量）和b（一个实数）两个参数的过程（但实际上只需要求w，求得以后找某些样本点代入就可以求得b）。因此在求g(x)的时候，w才是变量。 </li>
<li>你肯定能看出来，一旦求出了w（也就求出了b），那么中间的直线H就知道了（因为它就是wx+b&#x3D;0嘛，哈哈），那么H1和H2也就知道了（因为三者是平行的，而且相隔的距离还是||w||决定的）。那么w是谁决定的？显然是你给的样本决定的，一旦你在空间中给出了那些个样本点，三条直线的位置实际上就唯一确定了（因为我们求的是最优的那三条，当然是唯一的），我们解优化问题的过程也只不过是把这个确定了的东西算出来而已。</li>
</ul>
<h3 id="w的数学表示"><a href="#w的数学表示" class="headerlink" title="@w的数学表示"></a>@w的数学表示</h3><ul>
<li>样本确定了w，用数学的语言描述，就是w可以表示为样本的某种组合： <ul>
<li>w&#x3D;α1x1+α2x2+…+αnxn</li>
</ul>
</li>
<li>式子中的αi是一个一个的数（在严格的证明过程中，这些α被称为<font color="red"><strong>拉格朗日乘子</strong></font>），而xi是样本点，因而是向量，n就是总样本点的个数。为了方便描述，以下开始严格区别数字与向量的乘积和向量间的乘积，我会用α1x1表示数字和向量的乘积，而用&lt;x1,x2&gt;表示向量x1,x2的内积（也叫点积，注意与向量叉积的区别）。因此g(x)的表达式严格的形式应该是： <br><img src="/img/paperBlog/intro-SVM-serial/serial06/f1.png"></li>
</ul>
<h3 id="式子转换"><a href="#式子转换" class="headerlink" title="@式子转换"></a>@式子转换</h3><ul>
<li>但是上面的式子还不够好，你回头看看图中正样本和负样本的位置，想像一下，我不动所有点的位置，而只是把其中一个正样本点定为负样本点（也就是把一个点的形状从圆形变为方形），结果怎么样？三条直线都必须移动（因为对这三条直线的要求是必须把方形和圆形的点正确分开）！<strong>这说明w不仅跟样本点的位置有关，还跟样本的类别有关（也就是和样本的“标签”有关）</strong>。因此用下面这个式子表示才算完整： <ul>
<li>w&#x3D;α1y1x1+α2y2x2+…+αnynxn （式1）</li>
</ul>
</li>
<li>其中的yi就是第i个样本的标签，它等于1或者-1。其实以上式子的那一堆<font color="red"><strong>拉格朗日乘子</strong></font>中，只有很少的一部分不等于0（不等于0才对w起决定作用），这部分不等于0的拉格朗日乘子后面所乘的样本点，其实都落在H1和H2上，也正是这部分样本（而不需要全部样本）唯一的确定了分类函数，当然，更严格的说，这些样本的一部分就可以确定，因为例如确定一条直线，只需要两个点就可以，即便有三五个都落在上面，我们也不是全都需要。这部分我们真正需要的样本点，就叫做<font color="red"><strong>支持（撑）向量</strong></font>！（名字还挺形象吧，他们“撑”起了分界线） </li>
<li>式子也可以用求和符号简写一下：<br><img src="/img/paperBlog/intro-SVM-serial/serial06/formula1.gif"></li>
<li>因此原来的g(x)表达式可以写为：<br><img src="/img/paperBlog/intro-SVM-serial/serial06/formula2.gif"></li>
<li>注意式子中x才是变量，也就是你要分类哪篇文档，就把该文档的向量表示代入到 x的位置，而所有的xi统统都是已知的样本。还注意到式子中只有xi和x是向量，因此一部分可以从内积符号中拿出来，得到g(x)的式子为：<br><img src="/img/paperBlog/intro-SVM-serial/serial06/formula3.gif"></li>
<li>发现了什么？<strong>w不见啦！从求w变成了求α。</strong></li>
<li>但肯定有人会说，这并没有把原问题简化呀。嘿嘿，其实简化了，只不过在你看不见的地方，以这样的形式描述问题以后，我们的优化问题少了很大一部分不等式约束（记得这是我们解不了极值问题的万恶之源）。但是接下来先跳过线性分类器求解的部分，来看看 SVM在线性分类器上所做的重大改进——<font color="red"><strong>核函数</strong></font>。</li>
</ul>
<h2 id="SVM入门（七）为何需要核函数"><a href="#SVM入门（七）为何需要核函数" class="headerlink" title="SVM入门（七）为何需要核函数"></a>SVM入门（七）为何需要核函数</h2><ul>
<li>生存？还是毁灭？——哈姆雷特</li>
<li>可分？还是不可分？——支持向量机</li>
</ul>
<h3 id="线性不可分到线性可分，可能吗？"><a href="#线性不可分到线性可分，可能吗？" class="headerlink" title="@线性不可分到线性可分，可能吗？"></a>@线性不可分到线性可分，可能吗？</h3><ul>
<li>之前一直在讨论的线性分类器,器如其名（汗，这是什么说法啊），只能对线性可分的样本做处理。如果提供的样本线性不可分，结果很简单，线性分类器的求解程序会无限循环，永远也解不出来。这必然使得它的适用范围大大缩小，而它的很多优点我们实在不原意放弃，怎么办呢？<strong>是否有某种方法，让线性不可分的数据变得线性可分呢？</strong> </li>
<li>有！其思想说来也简单，来用一个二维平面中的分类问题作例子，你一看就会明白。事先声明，下面这个例子是网络早就有的，我一时找不到原作者的正确信息，在此借用，并加进了我自己的解说而已。 </li>
<li>例子是下面这张图： <br><img src="/img/paperBlog/intro-SVM-serial/serial07/p1.jpg"></li>
<li>我们把横轴上端点a和b之间红色部分里的所有点定为正类，两边的黑色部分里的点定为负类。试问能找到一个线性函数把两类正确分开么？不能，因为二维空间里的线性函数就是指直线，显然找不到符合条件的直线。 </li>
<li>但我们可以找到一条曲线，例如下面这一条：<br><img src="/img/paperBlog/intro-SVM-serial/serial07/p2.gif"> </li>
<li>显然通过点在这条曲线的上方还是下方就可以判断点所属的类别（你在横轴上随便找一点，算算这一点的函数值，会发现负类的点函数值一定比0大，而正类的一定比0小）。这条曲线就是我们熟知的二次曲线，它的函数表达式可以写为： <br><img src="/img/paperBlog/intro-SVM-serial/serial07/f1.gif"> </li>
<li>问题只是它不是一个线性函数，但是，下面要注意看了，新建一个向量y和a： <br><img src="/img/paperBlog/intro-SVM-serial/serial07/f2.gif"> </li>
<li>这样g(x)就可以转化为<img src="/img/paperBlog/intro-SVM-serial/serial07/f5.png"> ，你可以把y和a分别回带一下，看看等不等于原来的g(x)。用内积的形式写你可能看不太清楚，实际上f(y)的形式就是：<blockquote>
<p>g(x)&#x3D;f(y)&#x3D;ay </p>
</blockquote>
</li>
<li><strong>在任意维度的空间中，这种形式的函数都是一个线性函数（只不过其中的a和y都是多维向量罢了），因为自变量y的次数不大于1</strong>。</li>
</ul>
<h3 id="妙！高维度空间可分了！"><a href="#妙！高维度空间可分了！" class="headerlink" title="@妙！高维度空间可分了！"></a>@妙！高维度空间可分了！</h3><ul>
<li>看出妙在哪了么？原来在二维空间中一个线性不可分的问题，映射到四维空间后，变成了线性可分的！因此这也形成了我们最初想解决线性不可分问题的基本思路——<font color="red"><strong>向高维空间转化，使其变得线性可分</strong></font>。 </li>
<li>而转化最关键的部分就在于找到x到y的映射方法。遗憾的是，如何找到这个映射，没有系统性的方法（也就是说，纯靠猜和凑）。具体到我们的文本分类问题，文本被表示为上千维的向量，即使维数已经如此之高，也常常是线性不可分的，还要向更高的空间转化。其中的难度可想而知。<blockquote>
<p><strong>小Tips</strong>:为什么说f(y)&#x3D;ay是四维空间里的函数?<br>大家可能一时没看明白。回想一下我们二维空间里的函数定义<br>        g(x)&#x3D;ax+b<br>  变量x是一维的，为什么说它是二维空间里的函数呢？因为还有一个变量我们没写出来，它的完整形式其实是<br>        y&#x3D;g(x)&#x3D;ax+b<br>  即<br>        y&#x3D;ax+b<br>  看看，有几个变量？两个。那是几维空间的函数？（作者五岁的弟弟答：五维的。作者：……）<br>  再看看<br>      f(y)&#x3D;ay<br>  里面的y是三维的变量，那f(y)是几维空间里的函数？（作者五岁的弟弟答：还是五维的。作者：……）</p>
</blockquote>
</li>
</ul>
<h3 id="文本分类例子又来了"><a href="#文本分类例子又来了" class="headerlink" title="@文本分类例子又来了"></a>@文本分类例子又来了</h3><ul>
<li>用一个具体文本分类的例子来看看这种向高维空间映射从而分类的方法如何运作，想象一下，我们文本分类问题的原始空间是1000维的（即每个要被分类的文档被表示为一个1000维的向量），在这个维度上问题是线性不可分的。现在我们有一个2000维空间里的线性函数<br><img src="/img/paperBlog/intro-SVM-serial/serial07/f6.png"> </li>
<li>注意向量的右上角有个 ’哦。它能够将原问题变得可分。式中的 w’和x’都是2000维的向量，只不过w’是定值，而x’是变量（好吧,严格说来这个函数是2001维的,哈哈），现在我们的输入呢，是一个1000维的向量x，分类的过程是先把x变换为2000维的向量x’，然后求这个变换后的向量x’与向量w’的内积，再把这个内积的值和b相加，就得到了结果，看结果大于阈值还是小于阈值就得到了分类结果。 </li>
<li>你发现了什么？我们其实只关心那个高维空间里内积的值，那个值算出来了，分类结果就算出来了。而从理论上说， x’是经由x变换来的，因此广义上可以把它叫做x的函数（有一个x，就确定了一个x’，对吧，确定不出第二个），而w’是常量，它是一个低维空间里的常量w经过变换得到的，所以给了一个w 和x的值，就有一个确定的f(x’)值与其对应。<font color="red"><strong>这让我们幻想，是否能有这样一种函数K(w,x),他接受低维空间的输入值，却能算出高维空间的内积值&lt;w’,x’&gt;？</strong></font> </li>
<li>如果有这样的函数，那么当给了一个低维空间的输入x以后，<br><img src="/img/paperBlog/intro-SVM-serial/serial07/f7.png">  </li>
<li>这两个函数的计算结果就完全一样，我们也就用不着费力找那个映射关系，直接拿低维的输入往g(x)里面代就可以了（再次提醒，这回的g(x)就不是线性函数啦，因为你不能保证K(w,x)这个表达式里的x次数不高于1哦）。</li>
</ul>
<h3 id="核函数大神出来了"><a href="#核函数大神出来了" class="headerlink" title="@核函数大神出来了"></a>@核函数大神出来了</h3><ul>
<li>万幸的是，这样的K(w,x)确实存在（发现凡是我们人类能解决的问题，大都是巧得不能再巧，特殊得不能再特殊的问题，总是恰好有些能投机取巧的地方才能解决，由此感到人类的渺小），它被称作<font color="red"><strong>核函数（核，kernel）</strong></font>，而且还不止一个，事实上，只要是满足了Mercer条件的函数，都可以作为核函数。<font color="red"><strong>核函数的基本作用就是接受两个低维空间里的向量，能够计算出经过某个变换后在高维空间里的向量内积值</strong></font>。几个比较常用的核函数，线性核函数，高斯核函数，径向基核函数,教课书里都列过，我就不敲了（懒！）。</li>
</ul>
<h3 id="让核函数来拯救线性不可分吧-其实是简化了高维度中向量的内积计算"><a href="#让核函数来拯救线性不可分吧-其实是简化了高维度中向量的内积计算" class="headerlink" title="@让核函数来拯救线性不可分吧(其实是简化了高维度中向量的内积计算$_$)"></a>@让核函数来拯救线性不可分吧(其实是简化了高维度中向量的内积计算$_$)</h3><ul>
<li>回想我们上节说的求一个线性分类器，它的形式应该是： <br><img src="/img/paperBlog/intro-SVM-serial/serial07/f3.gif"></li>
<li>现在这个就是高维空间里的线性函数（为了区别低维和高维空间里的函数和向量，我改了函数的名字，并且给w和x都加上了 ’），我们就可以用一个低维空间里的函数（再一次的，这个低维空间里的函数就不再是线性的啦）来代替， <br><img src="/img/paperBlog/intro-SVM-serial/serial07/f4.gif"> </li>
<li>又发现什么了？<font color="red"><strong>f(x’) 和g(x)里的α，y，b全都是一样一样的！这就是说，尽管给的问题是线性不可分的，但是我们就硬当它是线性问题来求解，只不过求解过程中，凡是要求内积的时候就用你选定的核函数来算</strong></font>。这样求出来的α再和你选定的核函数一组合，就得到分类器啦！</li>
</ul>
<h3 id="问题来了"><a href="#问题来了" class="headerlink" title="@问题来了"></a>@问题来了</h3><ul>
<li>明白了以上这些，会自然的问接下来两个问题： <ul>
<li><strong>1． 既然有很多的核函数，针对具体问题该怎么选择？</strong> </li>
<li><strong>2． 如果使用核函数向高维空间映射后，问题仍然是线性不可分的，那怎么办？</strong></li>
</ul>
</li>
<li>第一个问题现在就可以回答你：对核函数的选择，现在还缺乏指导原则！各种实验的观察结果（不光是文本分类）的确表明，某些问题用某些核函数效果很好，用另一些就很差，但是一般来讲，<strong>径向基核函数</strong>是不会出太大偏差的一种，首选。（我做文本分类系统的时候，使用径向基核函数，没有参数调优的情况下，绝大部分类别的准确和召回都在85%以上，可见。虽然libSVM的作者林智仁认为文本分类用线性核函数效果更佳，待考证）</li>
</ul>
<h3 id="下节预告-3"><a href="#下节预告-3" class="headerlink" title="@下节预告"></a>@下节预告</h3><p>对第二个问题的解决则引出了我们下一节的主题：<strong>松弛变量</strong>。 </p>
<h2 id="SVM入门（八）松弛变量"><a href="#SVM入门（八）松弛变量" class="headerlink" title="SVM入门（八）松弛变量"></a>SVM入门（八）松弛变量</h2><h3 id="“近似线性可分”与“硬间隔”"><a href="#“近似线性可分”与“硬间隔”" class="headerlink" title="@“近似线性可分”与“硬间隔”"></a>@“近似线性可分”与“硬间隔”</h3><ul>
<li>现在我们已经把一个本来线性不可分的文本分类问题，通过映射到高维空间而变成了线性可分的。就像下图这样：<br><img src="/img/paperBlog/intro-SVM-serial/serial08/p1.png"> </li>
<li>圆形和方形的点各有成千上万个（毕竟，这就是我们训练集中文档的数量嘛，当然很大了）。现在想象我们有另一个训练集，只比原先这个训练集多了一篇文章，映射到高维空间以后（当然，也使用了相同的核函数），也就多了一个样本点，但是这个样本的位置是这样的：<br><img src="/img/paperBlog/intro-SVM-serial/serial08/p2.png"> </li>
<li>就是图中黄色那个点，它是方形的，因而它是负类的一个样本，这单独的一个样本，使得原本线性可分的问题变成了线性不可分的。这样类似的问题（仅有少数点线性不可分）叫做<font color="red"><strong>“近似线性可分”</strong></font>的问题。 </li>
<li>以我们人类的常识来判断，说有一万个点都符合某种规律（因而线性可分），有一个点不符合，那这一个点是否就代表了分类规则中我们没有考虑到的方面呢（因而规则应该为它而做出修改）？ </li>
<li>其实我们会觉得，更有可能的是，这个样本点压根就是错误，是噪声，是提供训练集的同学人工分类时一打瞌睡错放进去的。所以我们会简单的忽略这个样本点，仍然使用原来的分类器，其效果丝毫不受影响。 </li>
<li>但这种对噪声的容错性是人的思维带来的，我们的程序可没有。由于我们原本的优化问题的表达式中，确实要考虑所有的样本点（不能忽略某一个，因为程序它怎么知道该忽略哪一个呢？），在此基础上寻找正负类之间的最大几何间隔，而几何间隔本身代表的是距离，是非负的，像上面这种有噪声的情况会使得整个问题无解。这种解法其实也叫做<font color="red"><strong>“硬间隔”</strong></font>分类法，因为他硬性的要求所有样本点都满足和分类平面间的距离必须大于某个值。 </li>
<li>因此由上面的例子中也可以看出，硬间隔的分类法其结果容易受少数点的控制，这是很危险的（尽管有句话说真理总是掌握在少数人手中，但那不过是那一小撮人聊以自慰的词句罢了，咱还是得民主）。</li>
</ul>
<h3 id="要容错啊，变软间隔吧–松弛变量来帮你"><a href="#要容错啊，变软间隔吧–松弛变量来帮你" class="headerlink" title="@要容错啊，变软间隔吧–松弛变量来帮你"></a>@要容错啊，变软间隔吧–松弛变量来帮你</h3><ul>
<li>但解决方法也很明显，就是仿照人的思路，允许一些点到分类平面的距离不满足原先的要求。由于不同的训练集各点的间距尺度不太一样，因此用间隔（而不是几何间隔）来衡量有利于我们表达形式的简洁。我们原先对样本点的要求是：<br><img src="/img/paperBlog/intro-SVM-serial/serial08/f1.gif"> </li>
<li>意思是说离分类面最近的样本点函数间隔也要比1大。如果要引入容错性，就给1这个硬性的阈值加一个<font color="red"><strong>松弛变量</strong></font>，即允许<br><img src="/img/paperBlog/intro-SVM-serial/serial08/f2.gif"></li>
<li>因为<font color="red"><strong>松弛变量</strong></font>是非负的，因此最终的结果是要求间隔可以比1小。但是当某些点出现这种间隔比1小的情况时（这些点也叫<font color="red"><strong>离群点</strong></font>），意味着我们放弃了对这些点的精确分类，而这对我们的分类器来说是种损失。但是放弃这些点也带来了好处，那就是使分类面不必向这些点的方向移动，因而可以得到更大的几何间隔（在低维空间看来，分类边界也更平滑）。显然我们必须权衡这种损失和好处。好处很明显，我们得到的分类间隔越大，好处就越多。回顾我们原始的<font color="red"><strong>硬间隔分类</strong></font>对应的优化问题：<br><img src="/img/paperBlog/intro-SVM-serial/serial08/f3.gif"></li>
<li>||w||2就是我们的目标函数（当然系数可有可无），希望它越小越好，因而损失就必然是一个能使之变大的量（能使它变小就不叫损失了，我们本来就希望目标函数值越小越好）。那如何来衡量损失，有两种常用的方式，有人喜欢用<br><img src="/img/paperBlog/intro-SVM-serial/serial08/f4.gif"></li>
<li>而有人喜欢用<br><img src="/img/paperBlog/intro-SVM-serial/serial08/f5.gif"></li>
<li>其中l都是样本的数目。两种方法没有大的区别。如果选择了第一种，得到的方法的就叫做<font color="red"><strong>二阶软间隔分类器</strong></font>，第二种就叫做<font color="red"><strong>一阶软间隔分类器</strong></font>。把损失加入到<strong>目标函数</strong>里的时候，就需要一个<font color="red"><strong>惩罚因子</strong></font>（cost，也就是libSVM的诸多参数中的C），原来的优化问题就变成了下面这样：<br><img src="/img/paperBlog/intro-SVM-serial/serial08/f6.gif"></li>
<li>这个式子有这么几点要注意：<ul>
<li>一是并非所有的样本点都有一个<font color="red"><strong>松弛变量</strong></font>与其对应。实际上只有<strong>“离群点”</strong>才有，或者也可以这么看，所有没离群的点<font color="red"><strong>松弛变量</strong></font>都等于0（对负类来说，离群点就是在前面图中，跑到H2右侧的那些负样本点，对正类来说，就是跑到H1左侧的那些正样本点）。 </li>
<li>二是<font color="red"><strong>松弛变量</strong></font>的值实际上<strong>标示出了对应的点到底离群有多远，值越大，点就越远</strong>。 </li>
<li>三是<font color="red"><strong>惩罚因子C</strong></font>决定了你有多重视离群点带来的损失，显然当所有离群点的<font color="red"><strong>松弛变量</strong></font>的和一定时，你定的C越大，对目标函数的损失也越大，此时就暗示着你非常不愿意放弃这些离群点，最极端的情况是你把C定为无限大，这样只要稍有一个点离群，目标函数的值马上变成无限大，马上让问题变成无解，这就退化成了硬间隔问题。</li>
<li>四是<font color="red"><strong>惩罚因子C</strong></font>不是一个变量，整个优化问题在解的时候，C是一个你必须事先指定的值，指定这个值以后，解一下，得到一个分类器，然后用测试数据看看结果怎么样，如果不够好，换一个C的值，再解一次优化问题，得到另一个分类器，再看看效果，如此就是一个参数寻优的过程，但这和优化问题本身决不是一回事，优化问题在解的过程中，C一直是定值，要记住。</li>
<li>五是尽管加了<font color="red"><strong>松弛变量</strong></font>这么一说，但这个优化问题仍然是一个优化问题（汗，这不废话么），解它的过程比起原始的硬间隔问题来说，没有任何更加特殊的地方。</li>
</ul>
</li>
<li>从大的方面说优化问题解的过程，就是先试着确定一下w，也就是确定了前面图中的三条直线，这时看看间隔有多大，又有多少点离群，把目标函数的值算一算，再换一组三条直线（你可以看到，分类的直线位置如果移动了，有些原来离群的点会变得不再离群，而有的本来不离群的点会变成离群点），再把目标函数的值算一算，如此往复（迭代），直到最终找到目标函数最小时的w。</li>
</ul>
<h3 id="＠读者又提问了–松弛变量和核函数都是解决线性不可分问题"><a href="#＠读者又提问了–松弛变量和核函数都是解决线性不可分问题" class="headerlink" title="＠读者又提问了–松弛变量和核函数都是解决线性不可分问题"></a>＠读者又提问了–松弛变量和核函数都是解决线性不可分问题</h3><ul>
<li>啰嗦了这么多，读者一定可以马上自己总结出来，松弛变量也就是个解决线性不可分问题的方法罢了，但是回想一下，核函数的引入不也是为了解决线性不可分的问题么？为什么要为了一个问题使用两种方法呢？ </li>
<li>其实两者还有微妙的不同。一般的过程应该是这样，还以文本分类为例。在原始的低维空间中，样本相当的不可分，无论你怎么找分类平面，总会有大量的离群点，此时用核函数向高维空间映射一下，虽然结果仍然是不可分的，但比原始空间里的要更加接近线性可分的状态（就是达到了近似线性可分的状态），此时再用松弛变量处理那些少数“冥顽不化”的离群点，就简单有效得多啦。 </li>
<li>本节中的（式1）也确实是支持向量机最最常用的形式。至此一个比较完整的支持向量机框架就有了，简单说来，<font color="red"><strong>支持向量机就是使用了核函数的软间隔线性分类法</strong></font>。</li>
</ul>
<h3 id="下节预告-4"><a href="#下节预告-4" class="headerlink" title="@下节预告"></a>@下节预告</h3><ul>
<li>下一节会说说松弛变量剩下的一点点东西，顺便搞个读者调查，看看大家还想侃侃SVM的哪些方面。</li>
</ul>
<h2 id="SVM入门（九）松弛变量（续）"><a href="#SVM入门（九）松弛变量（续）" class="headerlink" title="SVM入门（九）松弛变量（续）"></a>SVM入门（九）松弛变量（续）</h2><h3 id="惩罚因子C的权值"><a href="#惩罚因子C的权值" class="headerlink" title="@惩罚因子C的权值"></a>@惩罚因子C的权值</h3><ul>
<li>接下来要说的东西其实不是松弛变量本身，但由于是为了使用松弛变量才引入的，因此放在这里也算合适，那就是<font color="red"><strong>惩罚因子C</strong></font>。回头看一眼引入了松弛变量以后的优化问题：<br><img src="/img/paperBlog/intro-SVM-serial/serial09/f1.gif"></li>
<li>注意其中C的位置，也可以回想一下C所起的作用<font color="red"><strong>（表征你有多么重视离群点，C越大越重视，越不想丢掉它们）</strong></font>。这个式子是以前做SVM的人写的，大家也就这么用，但没有任何规定说必须对所有的松弛变量都使用同一个惩罚因子，我们完全可以给每一个离群点都使用不同的C，这时就意味着你对每个样本的重视程度都不一样，有些样本丢了也就丢了，错了也就错了，这些就给一个比较小的C；而有些样本很重要，决不能分类错误（比如中央下达的文件啥的，笑），就给一个很大的C。</li>
</ul>
<h3 id="数据集偏斜问题"><a href="#数据集偏斜问题" class="headerlink" title="@数据集偏斜问题"></a>@数据集偏斜问题</h3><ul>
<li>当然实际使用的时候并没有这么极端，但一种很常用的变形可以用来解决分类问题中样本的<strong>“偏斜”</strong>问题。</li>
<li>先来说说样本的偏斜问题，也叫<font color="red"><strong>数据集偏斜（unbalanced）</strong></font>，它指的是参与分类的两个类别（也可以指多个类别）样本数量差异很大。比如说正类有10，000个样本，而负类只给了100个，这会引起的问题显而易见，可以看看下面的图：<br><img src="/img/paperBlog/intro-SVM-serial/serial09/p1.png"></li>
<li>方形的点是负类。H，H1，H2是根据给的样本算出来的分类面，由于负类的样本很少很少，所以有一些本来是负类的样本点没有提供，比如图中两个灰色的方形点，如果这两个点有提供的话，那算出来的分类面应该是H’，H2’和H1，他们显然和之前的结果有出入，实际上负类给的样本点越多，就越容易出现在灰色点附近的点，我们算出的结果也就越接近于真实的分类面。但现在由于偏斜的现象存在，使得数量多的正类可以把分类面向负类的方向“推”，因而影响了结果的准确性。</li>
</ul>
<h3 id="惩罚因子C，数量越少越重视"><a href="#惩罚因子C，数量越少越重视" class="headerlink" title="@惩罚因子C，数量越少越重视"></a>@惩罚因子C，数量越少越重视</h3><ul>
<li>对付数据集偏斜问题的方法之一就是在惩罚因子上作文章，想必大家也猜到了，那就是给样本数量少的负类更大的惩罚因子，表示我们重视这部分样本（本来数量就少，再抛弃一些，那人家负类还活不活了），因此我们的目标函数中因<font color="red"><strong>松弛变量</strong></font>而损失的部分就变成了：<br><img src="/img/paperBlog/intro-SVM-serial/serial09/f2.gif"></li>
<li>其中i&#x3D;1…p都是正样本，j&#x3D;p+1…p+q都是负样本。libSVM这个算法包在解决偏斜问题的时候用的就是这种方法。</li>
</ul>
<h3 id="怎么比较正类多，还是负类多？"><a href="#怎么比较正类多，还是负类多？" class="headerlink" title="@怎么比较正类多，还是负类多？"></a>@怎么比较正类多，还是负类多？</h3><ul>
<li>那C+和C-怎么确定呢？它们的大小是试出来的（参数调优），但是他们的比例可以有些方法来确定。咱们先假定说C+是5这么大，那确定C-的一个很直观的方法就是<font color="red"><strong>使用两类样本数的比来算</strong></font>，对应到刚才举的例子，C-就可以定为500这么大（因为10，000：100&#x3D;100：1嘛）。 </li>
<li>但是这样并不够好，回看刚才的图，你会发现正类之所以可以“欺负”负类，其实并不是因为负类样本少，真实的原因是负类的样本分布的不够广（没扩充到负类本应该有的区域）。说一个具体点的例子，现在想给政治类和体育类的文章做分类，政治类文章很多，而体育类只提供了几篇关于篮球的文章，这时分类会明显偏向于政治类，如果要给体育类文章增加样本，但增加的样本仍然全都是关于篮球的（也就是说，没有足球，排球，赛车，游泳等等），那结果会怎样呢？虽然体育类文章在数量上可以达到与政治类一样多，但过于集中了，结果仍会偏向于政治类！<font color="red"><strong>所以给C+和C-确定比例更好的方法应该是衡量他们分布的程度</strong></font>。比如可以算算他们在空间中占据了多大的体积，例如给负类找一个超球——就是高维空间里的球啦——它可以包含所有负类的样本，再给正类找一个，比比两个球的半径，就可以大致确定分布的情况。显然半径大的分布就比较广，就给小一点的惩罚因子。 </li>
<li>但是这样还不够好，<font color="red"><strong>因为有的类别样本确实很集中，这不是提供的样本数量多少的问题，这是类别本身的特征</strong></font>（就是某些话题涉及的面很窄，例如计算机类的文章就明显不如文化类的文章那么“天马行空”），这个时候即便超球的半径差异很大，也不应该赋予两个类别不同的惩罚因子。</li>
<li>看到这里读者一定疯了，因为说来说去，这岂不成了一个解决不了的问题？然而事实如此，完全的方法是没有的，根据需要，选择实现简单又合用的就好（<font color="red"><strong>例如libSVM就直接使用样本数量的比</strong></font>）。</li>
</ul>
<h2 id="SVM入门（十）将SVM用于多类分类"><a href="#SVM入门（十）将SVM用于多类分类" class="headerlink" title="SVM入门（十）将SVM用于多类分类"></a>SVM入门（十）将SVM用于多类分类</h2><h3 id="SVM只是个两类分类器"><a href="#SVM只是个两类分类器" class="headerlink" title="@SVM只是个两类分类器"></a>@SVM只是个两类分类器</h3><ul>
<li>从SVM的那几张图可以看出来，<strong>SVM是一种典型的两类分类器</strong>，即它只回答属于正类还是负类的问题。而现实中要解决的问题，往往是多类的问题（少部分例外，例如垃圾邮件过滤，就只需要确定“是”还是“不是”垃圾邮件），比如文本分类，比如数字识别。如何由两类分类器得到多类分类器，就是一个值得研究的问题。</li>
</ul>
<h3 id="穷举法？行不通！"><a href="#穷举法？行不通！" class="headerlink" title="@穷举法？行不通！"></a>@穷举法？行不通！</h3><ul>
<li>还以文本分类为例，现成的方法有很多，其中一种一劳永逸的方法，就是真的一次性考虑所有样本，并求解一个多目标函数的优化问题，一次性得到多个分类面，就像下图这样：<br><img src="/img/paperBlog/intro-SVM-serial/serial10/p1.jpg">  </li>
<li>多个超平面把空间划分为多个区域，每个区域对应一个类别，给一篇文章，看它落在哪个区域就知道了它的分类。 </li>
<li>看起来很美对不对？只可惜这种算法还基本停留在纸面上，因为一次性求解的方法计算量实在太大，大到无法实用的地步。</li>
</ul>
<h3 id="一对其余"><a href="#一对其余" class="headerlink" title="@一对其余"></a>@一对其余</h3><ul>
<li>稍稍退一步，我们就会想到所谓<font color="red"><strong>“一类对其余”</strong></font>的方法，就是每次仍然解一个两类分类的问题。比如我们有5个类别，第一次就把类别1的样本定为正样本，其余2，3，4，5的样本合起来定为负样本，这样得到一个两类分类器，它能够指出一篇文章是还是不是第1类的；第二次我们把类别2 的样本定为正样本，把1，3，4，5的样本合起来定为负样本，得到一个分类器，如此下去，我们可以得到5个这样的两类分类器（总是和类别的数目一致）。到了有文章需要分类的时候，我们就拿着这篇文章挨个分类器的问：是属于你的么？是属于你的么？哪个分类器点头说是了，文章的类别就确定了。</li>
<li>这种方法的<font color="red"><strong>好处是每个优化问题的规模比较小，而且分类的时候速度很快（只需要调用5个分类器就知道了结果）</strong></font>。但有时也会出现两种很尴尬的情况，例如拿一篇文章问了一圈，每一个分类器都说它是属于它那一类的，或者每一个分类器都说它不是它那一类的，前者叫<font color="red"><strong>分类重叠现象</strong></font>，后者叫<font color="red"><strong>不可分类现象</strong></font>。分类重叠倒还好办，随便选一个结果都不至于太离谱，或者看看这篇文章到各个超平面的距离，哪个远就判给哪个。不可分类现象就着实难办了，只能把它分给第6个类别了……更要命的是，本来各个类别的样本数目是差不多的，但“其余”的那一类样本数总是要数倍于正类（因为它是除正类以外其他类别的样本之和嘛），这就人为的造成了上一节所说的<strong>“数据集偏斜”问题</strong>。</li>
</ul>
<h3 id="一对一"><a href="#一对一" class="headerlink" title="@一对一"></a>@一对一</h3><ul>
<li>因此我们还得再退一步，还是解两类分类问题，还是每次选一个类的样本作正类样本，而负类样本则变成只选一个类（称为<font color="red"><strong>“一对一单挑”</strong></font>的方法，哦，不对，没有单挑，就是<font color="red"><strong>“一对一”</strong></font>的方法，呵呵），这就避免了偏斜。因此过程就是算出这样一些分类器，第一个只回答“是第1类还是第2类”，第二个只回答“是第1类还是第3类”，第三个只回答“是第1类还是第4类”，如此下去，你也可以马上得出，这样的分类器应该有5 X 4&#x2F;2&#x3D;10个（通式是，如果有k个类别，则总的两类分类器数目为k(k-1)&#x2F;2）。虽然分类器的数目多了，但是在训练阶段（也就是算出这些分类器的分类平面时）所用的总时间却比“一类对其余”方法少很多，在真正用来分类的时候，把一篇文章扔给所有分类器，第一个分类器会投票说它是“1”或者“2”，第二个会说它是“1”或者“3”，让每一个都投上自己的一票，最后统计票数，如果类别“1”得票最多，就判这篇文章属于第1类。这种方法显然也会有分类重叠的现象，但不会有不可分类现象，因为总不可能所有类别的票数都是0。看起来够好么？其实不然，想想分类一篇文章，我们调用了多少个分类器？10个，这还是类别数为5的时候，类别数如果是1000，要调用的分类器数目会上升至约500,000个（类别数的平方量级）。这如何是好？</li>
</ul>
<h3 id="有向无环图-DAG-SVM"><a href="#有向无环图-DAG-SVM" class="headerlink" title="@有向无环图-DAG SVM"></a>@有向无环图-DAG SVM</h3><ul>
<li>看来我们必须再退一步，在分类的时候下功夫，我们还是像一对一方法那样来训练，只是在对一篇文章进行分类之前，我们先按照下面图的样子来组织分类器（如你所见，这是一个<font color="red"><strong>有向无环图</strong></font>，因此这种方法也叫做<font color="red"><strong>DAG SVM</strong></font>）<br><img src="/img/paperBlog/intro-SVM-serial/serial10/p2.png"> </li>
<li>这样在分类时,我们就可以先问分类器“1对5”（意思是它能够回答“是第1类还是第5类”），如果它回答5，我们就往左走，再问“2对5”这个分类器，如果它还说是“5”，我们就继续往左走，这样一直问下去，就可以得到分类结果。<font color="red"><strong>好处在哪？我们其实只调用了4个分类器（如果类别数是k，则只调用k-1个），分类速度飞快，且没有分类重叠和不可分类现象！</strong></font><font color="green"><strong>缺点在哪？假如最一开始的分类器回答错误（明明是类别1的文章，它说成了5），那么后面的分类器是无论如何也无法纠正它的错误的（因为后面的分类器压根没有出现“1”这个类别标签），其实对下面每一层的分类器都存在这种错误向下累积的现象</strong></font>。</li>
<li>不过不要被DAG方法的错误累积吓倒，错误累积在一对其余和一对一方法中也都存在，DAG方法好于它们的地方就在于，累积的上限，不管是大是小，总是有定论的，有理论证明。而一对其余和一对一方法中，尽管每一个两类分类器的泛化误差限是知道的，但是合起来做多类分类的时候，误差上界是多少，没人知道，这意味着准确率低到0也是有可能的，这多让人郁闷。</li>
<li>而且现在DAG方法根节点的选取（也就是如何选第一个参与分类的分类器），也有一些方法可以改善整体效果，我们总希望根节点少犯错误为好，因此参与第一次分类的两个类别，最好是差别特别特别大，大到以至于不太可能把他们分错；或者我们就总取在两类分类中正确率最高的那个分类器作根节点，或者我们让两类分类器在分类的时候，不光输出类别的标签，还输出一个类似“置信度”的东东，当它对自己的结果不太自信的时候，我们就不光按照它的输出走，把它旁边的那条路也走一走，等等。</li>
</ul>
<h3 id="大Tips：SVM的计算复杂度"><a href="#大Tips：SVM的计算复杂度" class="headerlink" title="@大Tips：SVM的计算复杂度"></a>@大Tips：SVM的计算复杂度</h3><ul>
<li>使用SVM进行分类的时候，实际上是<font color="red"><strong>训练和分类</strong></font>两个完全不同的过程，因而讨论复杂度就不能一概而论，我们这里所说的主要是训练阶段的复杂度，即解那个二次规划问题的复杂度。对这个问题的解，基本上要划分为两大块，<font color="red"><strong>解析解和数值解</strong></font>。</li>
<li><font color="red"><strong>解析解就是理论上的解</strong></font>，它的形式是表达式，因此它是精确的，一个问题只要有解（无解的问题还跟着掺和什么呀，哈哈），那它的解析解是一定存在的。当然存在是一回事，能够解出来，或者可以在可以承受的时间范围内解出来，就是另一回事了。对SVM来说，求得解析解的时间复杂度最坏可以达到O(Nsv3)，其中Nsv是支持向量的个数，而虽然没有固定的比例，但支持向量的个数多少也和训练集的大小有关。</li>
<li><font color="red"><strong>数值解就是可以使用的解</strong></font>，是一个一个的数，往往都是近似解。求数值解的过程非常像穷举法，从一个数开始，试一试它当解效果怎样，不满足一定条件（叫做停机条件，就是满足这个以后就认为解足够精确了，不需要继续算下去了）就试下一个，当然下一个数不是乱选的，也有一定章法可循。有的算法，每次只尝试一个数，有的就尝试多个，而且找下一个数字（或下一组数）的方法也各不相同，停机条件也各不相同，最终得到的解精度也各不相同，可见对求数值解的复杂度的讨论不能脱开具体的算法。</li>
<li>一个具体的算法，<font color="red"><strong>Bunch-Kaufman训练算法</strong></font>，典型的时间复杂度在O(Nsv3+LNsv2+dLNsv)和O(dL2)之间，其中Nsv是支持向量的个数，L是训练集样本的个数，d是每个样本的维数（原始的维数，没有经过向高维空间映射之前的维数）。复杂度会有变化，是因为它不光跟输入问题的规模有关（不光和样本的数量，维数有关），也和问题最终的解有关（即支持向量有关），如果支持向量比较少，过程会快很多，如果支持向量很多，接近于样本的数量，就会产生O(dL2)这个十分糟糕的结果（给10，000个样本，每个样本1000维，基本就不用算了，算不出来，呵呵，而这种输入规模对文本分类来说太正常了）。 </li>
<li>这样再回头看就会明白为什么一对一方法尽管要训练的两类分类器数量多，但总时间实际上比一对其余方法要少了，因为一对其余方法每次训练都考虑了所有样本（只是每次把不同的部分划分为正类或者负类而已），自然慢上很多。</li>
</ul>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><ul>
<li>这篇文章真的写的不错，不要漏了。</li>
</ul>
]]></content>
      <categories>
        <category>毕业设计系列</category>
      </categories>
      <tags>
        <tag>SVM入门</tag>
      </tags>
  </entry>
  <entry>
    <title>Support Vector Machines-scikielearn-翻译-毕设系列</title>
    <url>/2015/01/12/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%E7%B3%BB%E5%88%97/Support-Vector-Machines-scikielearn/</url>
    <content><![CDATA[<h2 id="写在前面的话"><a href="#写在前面的话" class="headerlink" title="写在前面的话"></a>写在前面的话</h2><ul>
<li>本文是一篇译文，来自<a class="link"   href="http://scikit-learn.org/stable" >scikit-learn<i class="fas fa-external-link-alt"></i></a>上的一篇关于SVM的简介。翻译本文的目的是在于更好的理解SVM，另一方面也可锻炼我的英语阅读能力和翻译水平。</li>
<li>原文链接<a class="link"   href="http://scikit-learn.org/stable/modules/svm.html" >Support Vector Machines<i class="fas fa-external-link-alt"></i></a></li>
</ul>
<h2 id="支持向量机-SVM"><a href="#支持向量机-SVM" class="headerlink" title="支持向量机(SVM)"></a>支持向量机(SVM)</h2><ul>
<li>支持向量机是监督学习的一种，它的功能很强大，即可以应用于<a class="link"   href="http://scikit-learn.org/stable/modules/svm.html#svm-classification" >分类<i class="fas fa-external-link-alt"></i></a>，又可以应用于<a class="link"   href="http://scikit-learn.org/stable/modules/svm.html#svm-regression" >回归<i class="fas fa-external-link-alt"></i></a>和<a class="link"   href="http://scikit-learn.org/stable/modules/svm.html#svm-outlier-detection" >离群点的检测<i class="fas fa-external-link-alt"></i></a>。</li>
<li>支持向量机的优点：<ul>
<li>在高维空间中有效</li>
<li>可以处理由低维空间转换到高维空间中的样本</li>
<li>决策函数中只用到训练集中的一个子集(通常被称为支持向量)，所以所占内存较小</li>
<li>通用性：决策函数中可以指定不同的<a class="link"   href="http://scikit-learn.org/stable/modules/svm.html#svm-kernels" >核函数<i class="fas fa-external-link-alt"></i></a>.支持常用的核函数，但也可以自定义自己的核函数</li>
</ul>
</li>
<li>支持向量机的缺点：<ul>
<li>如果特征维数比样本数要大，那么效果较差</li>
<li>支持向量机不直接提供概率估计，它是通过一个较为复杂的5倍交叉验证来完成(看下面的<a class="link"   href="http://scikit-learn.org/stable/modules/svm.html#scores-probabilities" >分数和概率<i class="fas fa-external-link-alt"></i></a></li>
</ul>
</li>
<li>scikit-learn中实现的支持向量机既接受密集的样本(numpy.ndarray and convertible to that by numpy.asarray)又接受稀少(any scipy.sparse)的样本向量作为输入.但是，如果用支持向量机为稀少的样本向量做预测，它必须先拟合好这样的数据。要得到最佳化的表现，密集的用C-ordered numpy.ndarray，稀少的用scipy.spare.csr_matrix，而且dtype&#x3D;float64。</li>
</ul>
<h3 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h3><ul>
<li>SVC，NuSVC和LinearSVC可以对数据集进行多类分类。<br><img src="/img/paperBlog/scikit-learn-SVM/svm-fun.png"></li>
<li>SVC和NuSVC是相似的方法，但是接收的参数和数学公式有少少不同(详见<a class="link"   href="http://scikit-learn.org/stable/modules/svm.html#svm-mathematical-formulation" >数学公式<i class="fas fa-external-link-alt"></i></a>)。另一方面，LinearSVC则是通过线性核函数来实现支持向量机的另一种方式。既然LinearSVC不接受kernel作为关键字，那么我们就默认它是线性的。它还可能缺少SVC和NuSVC中的某些字段，例如support_。</li>
<li>SVC，NuSVC和LinearSVC中的输入为两个数组，X数组为训练集，它的大小是[n_samples, n_features],Y数组是一个标签类，字符串或者整数，大小为[n_samples]。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X = [[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>]]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = [<span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>clf = svm.SVC()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>clf.fit(X, y)  </span><br><span class="line">SVC(C=<span class="number">1.0</span>, cache_size=<span class="number">200</span>, class_weight=<span class="literal">None</span>, coef0=<span class="number">0.0</span>, degree=<span class="number">3</span>,</span><br><span class="line">gamma=<span class="number">0.0</span>, kernel=<span class="string">&#x27;rbf&#x27;</span>, max_iter=-<span class="number">1</span>, probability=<span class="literal">False</span>, random_state=<span class="literal">None</span>,</span><br><span class="line">shrinking=<span class="literal">True</span>, tol=<span class="number">0.001</span>, verbose=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>拟合之后，模型就可以用来预测新变量：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>clf.predict([[<span class="number">2.</span>, <span class="number">2.</span>]])</span><br><span class="line">array([<span class="number">1</span>])</span><br></pre></td></tr></table></figure>

<ul>
<li>支持向量机决策函数依赖训练集的某个子集，被称作支持向量。这些支持向量的某些属性可以在成员support_vectors,support_和n_support中找到。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># get support vectors</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>clf.support_vectors_</span><br><span class="line">array([[ <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">       [ <span class="number">1.</span>,  <span class="number">1.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># get indices of support vectors</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>clf.support_ </span><br><span class="line">array([<span class="number">0</span>, <span class="number">1</span>]...)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># get number of support vectors for each class</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>clf.n_support_ </span><br><span class="line">array([<span class="number">1</span>, <span class="number">1</span>]...)</span><br></pre></td></tr></table></figure>

<h4 id="多类分类器"><a href="#多类分类器" class="headerlink" title="多类分类器"></a>多类分类器</h4><ul>
<li>SVC和NuSVC为多分类分类器实现了“一对一”的方法(Kerr et al., 1991)。如果n_class代表类的个数，那么就要构造n_class * (n_class - 1) &#x2F; 2个分类器，而且每一个数据训练成两个类：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>X = [[<span class="number">0</span>], [<span class="number">1</span>], [<span class="number">2</span>], [<span class="number">3</span>]]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Y = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>clf = svm.SVC()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>clf.fit(X, Y) </span><br><span class="line">SVC(C=<span class="number">1.0</span>, cache_size=<span class="number">200</span>, class_weight=<span class="literal">None</span>, coef0=<span class="number">0.0</span>, degree=<span class="number">3</span>,</span><br><span class="line">gamma=<span class="number">0.0</span>, kernel=<span class="string">&#x27;rbf&#x27;</span>, max_iter=-<span class="number">1</span>, probability=<span class="literal">False</span>, random_state=<span class="literal">None</span>,</span><br><span class="line">shrinking=<span class="literal">True</span>, tol=<span class="number">0.001</span>, verbose=<span class="literal">False</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dec = clf.decision_function([[<span class="number">1</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dec.shape[<span class="number">1</span>] <span class="comment"># 4 classes: 4*3/2 = 6</span></span><br><span class="line"><span class="number">6</span></span><br></pre></td></tr></table></figure>

<ul>
<li>另一个方面，LinearSVC则为多分类分类器实现了“一对其他”的方法，所以只需要训练n_class个模型，如果是分两类，那么只需要训练一个模型。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>lin_clf = svm.LinearSVC()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lin_clf.fit(X, Y) </span><br><span class="line">LinearSVC(C=<span class="number">1.0</span>, class_weight=<span class="literal">None</span>, dual=<span class="literal">True</span>, fit_intercept=<span class="literal">True</span>,</span><br><span class="line">intercept_scaling=<span class="number">1</span>, loss=<span class="string">&#x27;l2&#x27;</span>, multi_class=<span class="string">&#x27;ovr&#x27;</span>, penalty=<span class="string">&#x27;l2&#x27;</span>,</span><br><span class="line">random_state=<span class="literal">None</span>, tol=<span class="number">0.0001</span>, verbose=<span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dec = lin_clf.decision_function([[<span class="number">1</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dec.shape[<span class="number">1</span>]</span><br><span class="line"><span class="number">4</span></span><br></pre></td></tr></table></figure>
<ul>
<li>关于决策函数，详见<a class="link"   href="http://scikit-learn.org/stable/modules/svm.html#svm-mathematical-formulation" >数学公式<i class="fas fa-external-link-alt"></i></a></li>
<li>既然LinearSVC也实现了另一个候补的多分类策略，由Crammer和Singer构造的所谓的多分类SVM，记作multi_class&#x3D;’crammer_singer’。这个方法是很稳定的，但是对于“一对其他”的分类器并非如此。实际上，“一对其他”分类器通常是首选的，因为结果大多数比较相似的，但是运行时间就没有什么比较的意义了。</li>
<li>对于“一对其他”的LinearSVC中的coef_和intercept_属性，他们分别表示为[n_class,n_features]和[n_class]。</li>
</ul>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2>]]></content>
      <categories>
        <category>毕业设计系列</category>
      </categories>
      <tags>
        <tag>SVM</tag>
      </tags>
  </entry>
  <entry>
    <title>手写数字识别-Kernel Support Vector Machine-论文翻译-毕设系列</title>
    <url>/2015/01/03/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%E7%B3%BB%E5%88%97/%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB-Kernel-Support-Vector-Machine-%E5%8D%9A%E5%AE%A2%E7%BF%BB%E8%AF%91-%E6%AF%95%E8%AE%BE%E7%B3%BB%E5%88%97/</url>
    <content><![CDATA[<h1 id="写在前面的话"><a href="#写在前面的话" class="headerlink" title="写在前面的话"></a>写在前面的话</h1><ul>
<li>本篇博文是翻译自Code Project上的<a class="link"   href="http://www.codeproject.com/script/Membership/View.aspx?mid=1841592" >César de Souza<i class="fas fa-external-link-alt"></i></a>教授的关于用Kernel Support Vector Machine手写数字识别的博客。认真学习借鉴一下。</li>
<li>出处：<a class="link"   href="http://www.codeproject.com/Articles/106583/Handwriting-Recognition-Revisited-Kernel-Support-V" >Handwriting Recognition Revisited: Kernel Support Vector Machines<i class="fas fa-external-link-alt"></i></a></li>
</ul>
<h1 id="博文正文"><a href="#博文正文" class="headerlink" title="博文正文"></a>博文正文</h1><ul>
<li>在上一篇文章中，我们讨论了怎么利用基于核函数的辨别分析(Kernel Discriminant Analysis)的方法来解决手写数字识别的问题。在这里，我们将要讨论如何利用基于核函数的支持向量机(Kernel Support Vector Machine)的一些技巧来解决手写数字的识别问题。</li>
<li><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/download.png"><a class="link"   href="http://www.codeproject.com/KB/recipes/handwriting-svm/accord-handwritting-svm-src.zip" >Download source code - 584 KB <i class="fas fa-external-link-alt"></i></a></li>
<li><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/download.png"><a class="link"   href="http://www.codeproject.com/KB/recipes/handwriting-svm/accord-handwritting-svm-bin.zip" >Download sample application - 522 KB<i class="fas fa-external-link-alt"></i></a></li>
<li><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/download.png">Download the <a class="link"   href="http://accord-framework.net/" >Accord.NET Machine Learning Framework.<i class="fas fa-external-link-alt"></i></a></li>
<li>由于在最新的代码库中，它通常包含了最新的功能增强和修正，所以请下载  最新的<a class="link"   href="http://accord-framework.net/" >Accord.NET Framework<i class="fas fa-external-link-alt"></i></a>.</li>
<li><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/font.png"></li>
</ul>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><ul>
<li>在上一篇文章中，我想向大家展示怎么用<a class="link"   href="http://crsouza.blogspot.com/2010/01/kernel-discriminant-analysis-in-c.html" >核判别分析法<i class="fas fa-external-link-alt"></i></a>来解决手写数字识别的问题。但是，我发现自己并没有更多的关注手写数字识别的问题，因为我把焦点都放在了KDA方法上了，而不是识别问题本身。在本篇文章中，我会给大家展示一个更好的方法来解决数字识别的问题。</li>
<li>核判别分析方法有自己的问题集。尽管它在处理高维度的数据是没有任何问题，但当样本的数量达到O(n³)，它就显得有些无能为力了。另外一个更严重的问题是在模型评估过程中核判别分析方法需要载入全部数据集，这样令它很难推广(例如嵌入式系统)。</li>
<li>在上一篇文章的最后，我提到了SVM其实是一种解决数字识别的更好的方法。SVM的一个优点是它们的解决问题的方法比较单一，不像KDA,它们在数据评估的过程中不需要载入全部数据集，而只是需要非常小部分的数据。这部分数据就是我们所通常称的”支持向量”。</li>
</ul>
<h3 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h3><ul>
<li><a class="link"   href="http://en.wikipedia.org/wiki/Support_vector_machine" >支持向量机<i class="fas fa-external-link-alt"></i></a>是属于<a class="link"   href="http://en.wikipedia.org/wiki/Supervised_learning" >监督学习<i class="fas fa-external-link-alt"></i></a>方法中的一种，它既可以用作<a class="link"   href="http://en.wikipedia.org/wiki/Statistical_classification" >分类<i class="fas fa-external-link-alt"></i></a>，也可以用做<a class="link"   href="http://en.wikipedia.org/wiki/Regression_analysis" >回归<i class="fas fa-external-link-alt"></i></a>。简单的说，给定一个训练数据样本，其中的每条记录都有一个标记变量，它标记着本条记录是属于哪一个分类的(现在讨论的是二类分类器)，然后数据集通过SVM分类器进行训练得到一个<a class="link"   href="http://en.wikipedia.org/wiki/Classifier_(mathematics)" >决策模型<i class="fas fa-external-link-alt"></i></a>，这个模型可以预测新进来的一条记录是属于两个分类中的哪一种。如果样本中的每条记录是落在空间上的某个点，那么一个SVM的线性分类器可以看做是空间中的一个分界，把空间分成两类，这样我们希望把样本分成两类的清晰的间隔，它越宽越好。新的样本点看它落在间隔的那一边上就可以预测它属于那一类的了。<br><br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/SVM-1.png"></li>
<li>一个线性SVM是由给定的支持向量<strong>z</strong>集合和权重<strong>w</strong>集合组成。由N个支持向量z1,z2…zN和w1,w2…wN构成的支持向量机输出的计算公式是：<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/SVM-fornular-1.png"></li>
<li>一个决策函数通常把这个作为输入变量，然后转化为一个二类分类器。通常地，我们用sign(.)函数，就是符号函数，输入变量大于0的作为一类，输入变量小于0的作为另外一类。</li>
</ul>
<h3 id="基于核函数的支持向量机"><a href="#基于核函数的支持向量机" class="headerlink" title="基于核函数的支持向量机"></a>基于核函数的支持向量机</h3><ul>
<li>如上所述，原始的SVM的最优化平面是一个<a class="link"   href="http://en.wikipedia.org/wiki/Linear_classifier" >线性分类器<i class="fas fa-external-link-alt"></i></a>。然而，从它在1963年提出的30年后，一些研究者(包括原提出者自己)建议把<a class="link"   href="http://en.wikipedia.org/wiki/Kernel_trick" >核技巧<i class="fas fa-external-link-alt"></i></a>应用到那些最大边界超平面来创建一个非线性分类器。结果引起了研究<a class="link"   href="http://www.kernel-machines.org/" >“核方法”<i class="fas fa-external-link-alt"></i></a>的一片浪潮，而核方法开始成为一个最有力的而且最受欢迎的分类方法。</li>
<li>不容置疑的是，核技巧是一种非常有力的工具，它提供了一种仅仅依赖于求两个向量的点积的算法来打通了线性和非线性的之间的桥梁。事实上，我们首先把输入数据映射到一个高维空间，然后一个线性的算法就可以在这个空间上操作在原始空间中的非线性的输入数据。</li>
<li>这个“技巧”的厉害之处在于它根本就不用计算映射后的点积；我们所需要做的是找到一个适合的核函数来代替所有的点积(这样便可以简化了计算)。核函数标记特征空间中的一个内积，它通常记为：<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/kernel-function-form.png"><br>(其中Ψ()代表映射函数)。</li>
<li>利用核函数，算法能被带入到高维空间而不需要明确的把输入点映射到这个空间上。这是非常取巧的，特别是当高维的特征空间是无穷多维的，它是不可以计算的时候。正是由于原始的SVM的公式中包含点积运算，它是可以直接应用核技巧的。即使结果分类器在高维特征空间中是个超平面，但在原始空间中它还是非线性的。核技巧的应用同样为不同的视野去进行比较的分类器提供了非常有力的理论支持，例如，生物。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/kernel-transform.png"></li>
<li>可以很明显的看出，通过核函数(of the form K(z,x) &#x3D; &lt;z,x&gt; &#x3D; zTx)，我们又得到了原始线性SVM的相似公式。想了解更详细的关于核技巧的资料和核函数应用的例子，可以参考<a class="link"   href="http://www.codeproject.com/KB/recipes/handwriting-kda.aspx" >previous article about Kernel Discriminant Analysis<i class="fas fa-external-link-alt"></i></a>，或者<a class="link"   href="http://crsouza.blogspot.com/2010/03/kernel-functions-for-machine-learning.html" >Kernel Functions for Machine Learning Applications<i class="fas fa-external-link-alt"></i></a>。</li>
</ul>
<h3 id="多分类的支持向量机"><a href="#多分类的支持向量机" class="headerlink" title="多分类的支持向量机"></a>多分类的支持向量机</h3><ul>
<li>很不幸的，不像<a class="link"   href="http://www.codeproject.com/KB/recipes/handwriting-kda.aspx" >KDA<i class="fas fa-external-link-alt"></i></a>，支持向量机并没有很自然的推广到多分类的问题。原始的SVM是一个<a class="link"   href="http://en.wikipedia.org/wiki/Binary_classification" >二类分类器<i class="fas fa-external-link-alt"></i></a>，它一次只可以在两个分类中进行预测。然而，<a class="link"   href="http://en.wikipedia.org/wiki/Support_vector_machines#Multiclass_SVM" >现实问题需要更多的是可以用SVM解决多分类问题<i class="fas fa-external-link-alt"></i></a>，下面我们就来举一个例子。</li>
<li>假设我们有三个分类A,B,C。现在，假设我们只有二类分类器，那么我们怎么把二类分类器去解决一个多分类器的问题呢？其中一个可行的方法就是把我们的多分类问问题拆成多个二类分类器的集合。下面左边的矩阵是泳衣解决三个分类的分类器的二类分类器的所有组合：<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/binary-conbination.png"></li>
<li>然而，注意到上面左边的矩阵中有一些多余的情况。譬如，计算AxA是没有意义的。还有，计算AxB之后再计算BxA是很低效率的，我们计算了AxB后，可以通过取反就得到了BxA。丢弃了多余的选项后，我们只剩下右边的(半透明的，除了AxA,BxB,CxC)矩阵。观察可知，一个n类的分类问题可以拆分成n(n-1)&#x2F;2个二类分类器的组合组成的小的子集合。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/n-binary.png"></li>
<li>现在我们得到了3个二类分类的问题，所以，我们需要创建3个SVM来解决每一个子问题。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/3-SVM.png"></li>
<li>要确定一个分类，我们就看3个SVM当中谁的投票最多。譬如，A在第一个SVM中胜出，而C在其他的两个SVM中都胜出。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/3-SVM-2.png"></li>
<li>如果我们把胜出次数最多的作为赢家，那么我们应该把它归为C类。这种方法通常称作多分类器中的”一对一”策略。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/table-one-against-one.png"></li>
<li>另外一种方法是利用“一对多”的策略，把输入放到所有的SVM中，然后选择最高的输出的那个SVM。很不幸的，我们不能保证有最高的输出就是最好的SVM。这个不作本文讨论的范畴。</li>
</ul>
<h2 id="源代码"><a href="#源代码" class="headerlink" title="源代码"></a>源代码</h2><ul>
<li>基于核方法的支持向量机的代码也是属于<a class="link"   href="http://accord-framework.net/" >Accord.NET<i class="fas fa-external-link-alt"></i></a>的一部分，这个框架我做了数年。它是在<a class="link"   href="http://code.google.com/p/aforge/" >AForge.NET<i class="fas fa-external-link-alt"></i></a>的顶层建立的,<a class="link"   href="http://code.google.com/p/aforge/" >AForge.NET<i class="fas fa-external-link-alt"></i></a>是计算机视觉，机器学习中非常受欢迎的框架，它集合了我过去的研究中的多个主题。目前，它有了<a class="link"   href="http://crsouza.blogspot.com/2009/09/principal-component-analysis-in-c.html" >PCA<i class="fas fa-external-link-alt"></i></a>, <a class="link"   href="http://crsouza.blogspot.com/2010/01/kernel-principal-component-analysis-in.html" >KPCA<i class="fas fa-external-link-alt"></i></a>, <a class="link"   href="http://crsouza.blogspot.com/2010/01/linear-discriminant-analysis-in-c.html" >LDA<i class="fas fa-external-link-alt"></i></a>, <a class="link"   href="http://crsouza.blogspot.com/2010/01/kernel-discriminant-analysis-in-c.html" >KDA<i class="fas fa-external-link-alt"></i></a>, <a class="link"   href="http://crsouza.blogspot.com/2010/02/logistic-regression-in-c.html" >LR<i class="fas fa-external-link-alt"></i></a>, <a class="link"   href="http://crsouza.blogspot.com/2010/04/partial-least-squares-analysis-and.html" >PLS<i class="fas fa-external-link-alt"></i></a>, <a class="link"   href="http://crsouza.blogspot.com/2010/04/kernel-support-vector-machines-for.html" >SVMs<i class="fas fa-external-link-alt"></i></a>, <a class="link"   href="http://www.codeproject.com/Articles/69647/Hidden-Markov-Models-in-Csharp.aspx" >HMMs<i class="fas fa-external-link-alt"></i></a>, <a class="link"   href="http://www.codeproject.com/Articles/55691/Neural-Network-Learning-by-the-Levenberg-Marquardt.aspx" >LM-ANN<i class="fas fa-external-link-alt"></i></a>和其他的缩写。这个项目在Github上举办，地址是：<a class="link"   href="https://github.com/accord-net/framework/" >https://github.com/accord-net/framework/<i class="fas fa-external-link-alt"></i></a>。最小的版本中包含了最小的bug修正，完善和功能加强，新特征等，我强烈推荐大家直接从Github上下载最新的版本库。</li>
</ul>
<h3 id="支持向量机-1"><a href="#支持向量机-1" class="headerlink" title="支持向量机"></a>支持向量机</h3><ul>
<li>支持向量机类结构如下：(C#和VB实现)<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/svm-class-structure.png"></li>
<li><a class="link"   href="http://accord-framework.net/docs/html/T_Accord_MachineLearning_VectorMachines_KernelSupportVectorMachine.htm" >KernelSupportVectorMachine<i class="fas fa-external-link-alt"></i></a>类继承SupportVectorMachine类，加了kernel方法。MulticlassSupportVectorMachine类集合了一堆实现了“一对一”策略的KernelSupportVectorMachines类来实现多分类器。框架的API在此：<a class="link"   href="http://accord-framework.net/docs/html/N_Accord_Statistics_Kernels.htm" >extensive list of machine learning kernel functions to chose from<i class="fas fa-external-link-alt"></i></a>.</li>
</ul>
<h3 id="训练算法"><a href="#训练算法" class="headerlink" title="训练算法"></a>训练算法</h3><ul>
<li>训练算法既可以实现分类也可以实现回归。它们是<a class="link"   href="http://research.microsoft.com/apps/pubs/default.aspx?id=69644" >Platt的序列最优化(SMO)算法<i class="fas fa-external-link-alt"></i></a>的直接实现。MulticlassSupportVectorLearning类提供了一个回调函数，名字是Configure，它可以被任何的算法选择并进行配置。这个方法并没有强加需要利用哪一种算法，而且还允许用户利用自定义的算法来进行训练。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/svm-class-structure-2.png"></li>
<li>因为MulticlassSupportVectorLearning算法一次可以训练一堆独立的机器，所以它容易实现并行运算。事实上，这些实现方法在单台机器中可以充分利用剩下的核。<figure class="highlight c#"><table><tr><td class="code"><pre><span class="line"><span class="comment"><span class="doctag">///</span> <span class="doctag">&lt;summary&gt;</span></span></span><br><span class="line"><span class="comment"><span class="doctag">///</span>   Runs the one-against-one learning algorithm.</span></span><br><span class="line"><span class="comment"><span class="doctag">///</span> <span class="doctag">&lt;/summary&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="built_in">double</span> <span class="title">Run</span>(<span class="params"><span class="built_in">bool</span> computeError</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">// For each class i</span></span><br><span class="line">    AForge.Parallel.For(<span class="number">0</span>, msvm.Classes, <span class="built_in">delegate</span>(<span class="built_in">int</span> i)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// For each class j</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="built_in">int</span> j = <span class="number">0</span>; j &lt; i; j++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// Retrieve the associated machine</span></span><br><span class="line">            <span class="keyword">var</span> machine = msvm[i,j];</span><br><span class="line"></span><br><span class="line">            <span class="comment">// Retrieve the associated classes</span></span><br><span class="line">            <span class="built_in">int</span>[] idx = outputs.Find(x =&gt; x == i || x == j);</span><br><span class="line">            <span class="built_in">double</span>[][] subInputs = inputs.Submatrix(idx);</span><br><span class="line">            <span class="built_in">int</span>[] subOutputs = outputs.Submatrix(idx);</span><br><span class="line">   </span><br><span class="line">            <span class="comment">// Transform in a two-class problem</span></span><br><span class="line">            subOutputs.ApplyInPlace(x =&gt; x = (x == i) ? <span class="number">-1</span> : <span class="number">1</span>);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// Train the machine on the two-class problem.</span></span><br><span class="line">            configure(machine, subInputs, subOutputs).Run(<span class="literal">false</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>上面的代码利用了<a class="link"   href="http://www.codeproject.com/KB/cs/aforge_parallel.aspx" >AForge.NET Parallel<i class="fas fa-external-link-alt"></i></a>的构造器和<a class="link"   href="http://crsouza.blogspot.com/2010/08/matrix-manipulation-using-accordnet.html" >Accord.NET matrix extensions<i class="fas fa-external-link-alt"></i></a>。我决定不用最新加的 .NET 4.0 Parallel Extensions,所以这个框架还是兼容.NET 3.5 applications的应用的。</li>
</ul>
<h2 id="数字识别"><a href="#数字识别" class="headerlink" title="数字识别"></a>数字识别</h2><h3 id="UCI的光学数字数据集"><a href="#UCI的光学数字数据集" class="headerlink" title="UCI的光学数字数据集"></a>UCI的光学数字数据集</h3><ul>
<li>如果你读了上一篇文章<a class="link"   href="http://crsouza.blogspot.com/2010/01/kernel-discriminant-analysis-in-c.html" >Kernel Discriminant Analysis for Handwritten Digit Recognition<i class="fas fa-external-link-alt"></i></a>，那么请跳过本小节。本小节只是对UCI机器学习的光学数字数据库的介绍。</li>
<li><a class="link"   href="http://archive.ics.uci.edu/ml/" >UCI机器学习库<i class="fas fa-external-link-alt"></i></a>是一个被机器学习社区用于做机器学习算法实践分析的数据库，域理论，数据生成器的集合。其中一个就是<a class="link"   href="http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits" >光学识别的手写数字数据集<i class="fas fa-external-link-alt"></i></a>，又叫Optdigits Dataset.</li>
<li>原始的光学数字数据是一个个32x32的矩阵。它们提供经过预处理的数字形式，数字被分成非重叠的4x4块，每一块上像素都合计了。这就生成了8x8输入矩阵，每一个元素都是0到16的整数。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/digit.png"></li>
</ul>
<h3 id="基于多分类的SVM的数字分类器"><a href="#基于多分类的SVM的数字分类器" class="headerlink" title="基于多分类的SVM的数字分类器"></a>基于多分类的SVM的数字分类器</h3><ul>
<li>核方法引起了很大的兴趣，因为它可以应用到那些需要进行预处理的(例如，数据降维)数据的问题上和被模型化的数据结构的扩展知识上。即使我们对数据知之甚少，核方法的直接应用往往得到令人感兴趣的结果。利用核方法实现最佳化是一个非常难的任务，因为我们用无穷多的核函数可供选择，而每个核函数也有无穷多的参数可供调整。</li>
<li>下面的代码向我们展示了基于核函数的支持向量机是怎么实现的。输入的是一个1024的全向量。这个对神经网络来说是不切实际的，例如，通常的核方法处理高维数的问题是没问题的，因为它不会遭受维数灾难。<figure class="highlight c#"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Extract inputs and outputs</span></span><br><span class="line"><span class="built_in">int</span> samples = <span class="number">500</span>;</span><br><span class="line"><span class="built_in">double</span>[][] input = <span class="keyword">new</span> <span class="built_in">double</span>[samples][];</span><br><span class="line"><span class="built_in">int</span>[] output = <span class="keyword">new</span> <span class="built_in">int</span>[samples];</span><br><span class="line"><span class="keyword">for</span> (<span class="built_in">int</span> i = <span class="number">0</span>; i &lt; samples; i++)</span><br><span class="line">&#123;</span><br><span class="line">   ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Create the chosen Kernel with given parameters</span></span><br><span class="line">IKernel kernel = <span class="keyword">new</span> Polynomial((<span class="built_in">int</span>)numDegree.Value, (<span class="built_in">double</span>)numConstant.Value);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Create the Multi-class Support Vector Machine using the selected Kernel</span></span><br><span class="line">ksvm = <span class="keyword">new</span> MulticlassSupportVectorMachine(<span class="number">1024</span>, kernel, <span class="number">10</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Create the learning algorithm using the machine and the training data</span></span><br><span class="line"><span class="keyword">var</span> ml = <span class="keyword">new</span> MulticlassSupportVectorLearning(ksvm, input, output);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Extract training parameters from the interface</span></span><br><span class="line"><span class="built_in">double</span> complexity = (<span class="built_in">double</span>)numComplexity.Value;</span><br><span class="line"><span class="built_in">double</span> epsilon = (<span class="built_in">double</span>)numEpsilon.Value;</span><br><span class="line"><span class="built_in">double</span> tolerance = (<span class="built_in">double</span>)numTolerance.Value;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Configure the learning algorithm</span></span><br><span class="line">ml.Configure = <span class="built_in">delegate</span>(KernelSupportVectorMachine svm, </span><br><span class="line">                        <span class="built_in">double</span>[][] cinput, <span class="built_in">int</span>[] coutput)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">var</span> smo = <span class="keyword">new</span> SequentialMinimalOptimization(svm, cinput, coutput);</span><br><span class="line">    smo.Complexity = complexity;</span><br><span class="line">    smo.Epsilon    = epsilon;</span><br><span class="line">    smo.Tolerance  = tolerance;</span><br><span class="line">    <span class="keyword">return</span> smo;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Train the machines. It should take a while.</span></span><br><span class="line"><span class="built_in">double</span> error = ml.Run();</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="应用例子"><a href="#应用例子" class="headerlink" title="应用例子"></a>应用例子</h2><h3 id="学习"><a href="#学习" class="headerlink" title="学习"></a>学习</h3><ul>
<li>样例应用附带源代码，它实现了基于核函数的多分类支持向量机的手写数字识别。下载了应用后，打开并点击菜单，然后选择”Open”。它就会载入数据。</li>
<li>要开始训练数据，点击“Start training”。利用默认设置，应该不会太长时间。因为代码是用了并行运算，核数越多，训练越快。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/app-1.png"></li>
<li>训练完成后，点击“Classify”开始分类测试数据集。利用默认值，它应该可以得到95%的正确率，大概是500个数据中有475个分类正确。识别率的大小会随着每次训练的不同而有小小的波动。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/app-2.png"></li>
<li>相同的集合和相同的训练和测试样本已经在上一篇中的基于核方法的判别分析方法中使用。而SVM却得到更高的运行效率和更少的内存，更多的样本数可能得到更高的正确率。</li>
<li>训练后，创建的SVM可以在“Machine”这个tab中看到。每次的SVM的支持向量和临界值可以在第一个数据格视图中通过选择一个数据入口而看到。向量越暗，在决策过程中它的权值就越大。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/app-3.png"></li>
</ul>
<h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><ul>
<li>即使识别率刚刚超过3%，但是识别的正确率已经比KDA大大的提升了。点击“Classification”tab，我们可以手动地为用户手写的数字测试多分类支持向量机。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/app-4.png"></li>
<li>我们看到SVM方法产生了更强壮的结果，即使手写很差的数字也能识别正确：<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/app-5.png"></li>
<li>最后，有一个视频演示：</li>
</ul>
<iframe height=498 width=610 src="http://player.youku.com/embed/XODYzNjk3NzMy" frameborder=0 allowfullscreen></iframe>

<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li>在本文中，我们详细叙述和探索了基于核方法的SVM来解决手写数字识别的问题，并且可以得到更好的结果。</li>
<li>SVM适合小样本的数据训练。</li>
</ul>
<h2 id="继续阅读"><a href="#继续阅读" class="headerlink" title="继续阅读"></a>继续阅读</h2><ul>
<li><a class="link"   href="http://www.codeproject.com/KB/recipes/handwriting-kda.aspx" >Handwriting Recognition using Kernel Discriminant Analysis<i class="fas fa-external-link-alt"></i></a></li>
<li><a class="link"   href="http://crsouza.blogspot.com/2010/04/kernel-support-vector-machines-for.html" >Kernel Functions for Machine Learning Applications<i class="fas fa-external-link-alt"></i></a></li>
<li><a class="link"   href="http://crsouza.blogspot.com/2010/04/kernel-support-vector-machines-for.html" >Kernel Support Vector Machines (SVM)<i class="fas fa-external-link-alt"></i></a></li>
<li><a class="link"   href="http://crsouza.blogspot.com/2009/09/principal-component-analysis-in-c.html" >Principal Component Analysis (PCA)<i class="fas fa-external-link-alt"></i></a></li>
<li><a class="link"   href="http://crsouza.blogspot.com/2010/01/kernel-principal-component-analysis-in.html" >Kernel Principal Component Analysis (KPCA)<i class="fas fa-external-link-alt"></i></a></li>
<li><a class="link"   href="http://crsouza.blogspot.com/2010/01/linear-discriminant-analysis-in-c.html" >Linear Discriminant Analysis (LDA)<i class="fas fa-external-link-alt"></i></a></li>
<li><a class="link"   href="http://crsouza.blogspot.com/2010/01/kernel-discriminant-analysis-in-c.html" >Non-Linear Discriminant Analysis with Kernels (KDA)<i class="fas fa-external-link-alt"></i></a></li>
<li><a class="link"   href="http://crsouza.blogspot.com/2010/02/logistic-regression-in-c.html" >Logistic Regression Analysis<i class="fas fa-external-link-alt"></i></a></li>
</ul>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul>
<li>Wikipedia contributors,<a class="link"   href="http://en.wikipedia.org/wiki/Sequential_Minimal_Optimization" >“Sequential Minimal Optimization”<i class="fas fa-external-link-alt"></i></a>, Wikipedia, The Free Encyclopedia,<a class="link"   href="http://en.wikipedia.org/wiki/Sequential_Minimal_Optimization" >http://en.wikipedia.org/wiki/Sequential_Minimal_Optimization<i class="fas fa-external-link-alt"></i></a> (accessed April 24, 2010).</li>
<li>Wikipedia contributors, <a class="link"   href="http://en.wikipedia.org/wiki/Support_vector_machine" >“Support Vector Machine”<i class="fas fa-external-link-alt"></i></a>, Wikipedia, The Free Encyclopedia,<a class="link"   href="http://en.wikipedia.org/wiki/Support_vector_machine" >http://en.wikipedia.org/wiki/Support_vector_machine<i class="fas fa-external-link-alt"></i></a>,(accessed April 24, 2010).</li>
<li>John C. Platt,<a class="link"   href="http://research.microsoft.com/en-us/um/people/jplatt/smoTR.pdf" >Sequential Minimal Optimization: A Fast Algorithm for Training Support Vector Machines<i class="fas fa-external-link-alt"></i></a> , Microsoft Research, 1998.</li>
<li>J. P. Lewis,<a class="link"   href="http://www.idiom.com/~zilla/Work/Notes/svmtutorial.pdf" >A Short SVM (Support Vector Machine) Tutorial.<i class="fas fa-external-link-alt"></i></a>,CGIT Lab &#x2F; IMSC, University of Southern California.</li>
<li>A. J. Smola and B. Scholkopf,<a class="link"   href="http://www.kernel-machines.org/publications/SmoSch98c" >A Tutorial on Support Vector Regression.<i class="fas fa-external-link-alt"></i></a>,NeuroCOLT2 Technical Report Series, 1998.</li>
<li>S. K. Shevade et al.<a class="link"   href="http://drona.csa.iisc.ernet.in/~chiru/papers/ieee_smo_reg.ps.gz" >Improvements to SMO Algorithm for SVM Regression<i class="fas fa-external-link-alt"></i></a>,1999.</li>
<li>G. W. Flake, S. Lawrence<a class="link"   href="http://www.keerthis.com/smoreg_ieee_shevade_00.pdf" >Efficient SVM Regression Training with SMO<i class="fas fa-external-link-alt"></i></a></li>
<li>A. Asuncion &amp; D.J. Newman,<a class="link"   href="http://archive.ics.uci.edu/ml/index.html" >UCI Machine Learning Repository.<i class="fas fa-external-link-alt"></i></a>Irvine, CA: University of California, School of Information and Computer Science (2007).</li>
<li>Andrew Kirillov,<a class="link"   href="http://aforgenet.com/framework" >The AForge.NET Framework<i class="fas fa-external-link-alt"></i></a>.The AForge.NET Computer Vision, Artificial Intelligence and Robotics Website, 2010.</li>
<li>C. R. Souza, <a class="link"   href="http://crsouza.blogspot.com/2010/03/kernel-functions-for-machine-learning.html" >Kernel Functions for Machine Learning Applications.<i class="fas fa-external-link-alt"></i></a> 17 Mar. 2010. Web.</li>
</ul>
<h1 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h1><ul>
<li>翻译这篇文章后，除了对翻译的难度有了更深一层的认知之后，本次只要是对SVM进行多分类问题的解决有了更深的认识。SVM本来是一个二类分类器，那么要解决多分类问题，应该要什么思路呢？就是用二类分类器进行组合，然后通过“一对一”策略来解决多分类分类器。</li>
</ul>
]]></content>
      <categories>
        <category>毕业设计系列</category>
      </categories>
      <tags>
        <tag>手写数字识别</tag>
        <tag>Kernel Support Vector Machine</tag>
      </tags>
  </entry>
  <entry>
    <title>基于SVM技术的手写数字识别-毕业设计博客系列-连载</title>
    <url>/2015/12/30/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%E7%B3%BB%E5%88%97/%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB-%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%E5%8D%9A%E5%AE%A2%E7%B3%BB%E5%88%97-%E8%BF%9E%E8%BD%BD/</url>
    <content><![CDATA[<h1 id="写在前面的话"><a href="#写在前面的话" class="headerlink" title="写在前面的话"></a>写在前面的话</h1><ul>
<li>本系列博客是为记录本人大学毕业设计过程所有点滴而设。因为人生只有一次毕业设计，它如流水，一去不复返，错过了就永远失去了。很多时候，每件事情的发生，都会带着甜酸苦辣，而文字可以记录它们的痕迹，日后可让我细细品味这段曾经的奋斗。</li>
</ul>
<h1 id="毕业设计简介"><a href="#毕业设计简介" class="headerlink" title="毕业设计简介"></a>毕业设计简介</h1><ul>
<li>本人的毕业设计的题目和其他同学的选题都不大相同，同学一般都选了做个系统或网站，而我选的是“基于SVM技术的手写数字识别的设计和实现”，它是属于模式识别的范畴，模式识别这个名字看上去就感觉到好高大上。根据<a class="link"   href="http://baike.baidu.com/link?url=QmW1EdwddM0FNenkkuump1MyXVxQNQ4KJYIo2QWOcUMDHb4HYwLxo44kqgwI6jUofmuHy7t2MI3OBd7Z4iBFD_" >百度百科<i class="fas fa-external-link-alt"></i></a>的解释：模式识别（英语：Pattern Recognition），就是通过计算机用数学技术方法来研究模式的自动处理和判读。通俗的来说，就是想让机器模仿人的认知，比如“听”懂人说的话(语音识别)，“看”懂人写的文字(自然语言处理)，甚至乎拥有人的思维能力。而我的“手写数字识别”就是看“懂”人写的文字的一部分，它是属于光学字符识别的一个子分支。所以，这个毕业设计还是比较有难度的，对我来说，如果我能很好的完成了这个选题，那么无论是对我个人能力的提升，还是以后的发展都是有很大的帮助的。所以，我要好好对待我的毕业设计，用心做好它。</li>
</ul>
<h1 id="毕业设计时间安排"><a href="#毕业设计时间安排" class="headerlink" title="毕业设计时间安排"></a>毕业设计时间安排</h1><ul>
<li><img src="/img/paperBlog/schedule.png"></li>
</ul>
<h1 id="毕业设计流程"><a href="#毕业设计流程" class="headerlink" title="毕业设计流程"></a>毕业设计流程</h1><h2 id="开题报告-11月30日"><a href="#开题报告-11月30日" class="headerlink" title="开题报告(11月30日)"></a>开题报告(11月30日)</h2><h3 id="什么是开题报告"><a href="#什么是开题报告" class="headerlink" title="什么是开题报告"></a>什么是开题报告</h3><ul>
<li>开题报告是是指开题者对科研课题的一种文字说明材料。开题报告包括综述、关键技术、可行性分析和时间安排等四个方面 。由于开题报告是用文字体现的论文总构想,因而篇幅不必过大,但要把计划研究的课题、如何研究、理论适用等主要问题写清楚。开题报告一般为表格式，它把要报告的每一项内容转换成相应的栏目，这样做，既避免遗漏；又便于评审者一目了然，把握要点。</li>
<li><a class="link"   href="http://baike.baidu.com/link?url=raHVwGFA26__ZMa8ds-SdM539mknHb5BSxwqmpFZ7eYRvUE3eCGiZ_GMIkf-tVXFEs_SV40JFjxOviu3sSCes_" >百度百科<i class="fas fa-external-link-alt"></i></a></li>
</ul>
<h3 id="开题报告格式"><a href="#开题报告格式" class="headerlink" title="开题报告格式"></a>开题报告格式</h3><ul>
<li><p>毕业论文开题报告提纲</p>
<ul>
<li>一、开题报告封面：论文题目、系别、专业、年级、姓名、导师</li>
<li>二、目的意义和国内外研究概况</li>
<li>三、论文的理论依据、研究方法、研究内容</li>
<li>四、研究条件和可能存在的问题</li>
<li>五、预期的结果</li>
<li>六、进度安排</li>
</ul>
</li>
<li><p><a class="link"   href="http://wenku.baidu.com/link?url=XOQOwUC-yYYg0y4JhSQq3RIi8FiGF-Mlynw81eeUglTJNYA27GhXzZ3lxl9s3uthkHR0gkEtcemzLDeLy2DQLc2W81IHODwJSot2befvShlkKWlFWPPNSERlu6OmdKsf" >参考模板<i class="fas fa-external-link-alt"></i></a></p>
</li>
</ul>
<h3 id="参考文献规范"><a href="#参考文献规范" class="headerlink" title="参考文献规范"></a>参考文献规范</h3><ul>
<li><p>参考文献的书写也是有一定的要求，所以这个不可随意乱写的。参考文献书写格式要符合GB7714-2005《文后参考文献著录规则》。</p>
</li>
<li><p>文献标注</p>
<ul>
<li>参考文献类型<ul>
<li>专著[M]，论文集[C]，报纸文章[N]，期刊文章[J]，学位论文[D]，报告[R]，标准[S]，专利[P]，论文集中的析出文献[A]</li>
</ul>
</li>
<li>电子文献类型<ul>
<li>数据库[DB]，计算机[CP]，电子公告[EB]</li>
</ul>
</li>
<li>电子文献的载体类型<ul>
<li>互联网[OL]，光盘[CD]，磁带[MT]，磁盘[DK]</li>
</ul>
</li>
</ul>
</li>
<li><p>参考示例</p>
<ul>
<li>专著、论文集、学位论文、报告<ul>
<li>[序号]主要责任者.文献题名[文献类型标识].出版地：出版者，出版年.起止页码（任选）.</li>
<li>[1]刘国钧，陈绍业，王凤翥. 图书馆目录[M]. 北京：高等教育出版社，1957.15-18.</li>
</ul>
</li>
<li>期刊文章<ul>
<li>[序号]主要责任者.文献题名[J].刊名，年，卷（期）：起止页码.</li>
<li>[8] Heider,E.R.&amp; D.C.Oliver. The structure of color space in naming and memory of two languages [J]. Foreign Language Teaching and Research,1999⑶： 62-67.</li>
</ul>
</li>
</ul>
</li>
<li><p><a class="link"   href="http://baike.baidu.com/link?url=14wUrtxW1meyj7N7pKRq79lDfLSRIq6zieEF8WB9aboaiL5M9ATQE5fTr9evBGAi39b1QWrDVcKgVqv-z8j5yq" >百度百科<i class="fas fa-external-link-alt"></i></a></p>
</li>
<li><p><a class="link"   href="http://www.360doc.com/content/12/1016/17/9728351_241853882.shtml" >360图书馆<i class="fas fa-external-link-alt"></i></a></p>
</li>
</ul>
<h3 id="我的开题报告"><a href="#我的开题报告" class="headerlink" title="我的开题报告"></a>我的开题报告</h3><p><a href="">本地内存中</a></p>
<h2 id="我的毕业设计规划-12月22日"><a href="#我的毕业设计规划-12月22日" class="headerlink" title="我的毕业设计规划(12月22日)"></a>我的毕业设计规划(12月22日)</h2><ul>
<li>由于我的毕业设计偏向理论，所以我给自己定了两条计划路线，一条是系统实现路线(偏软件实现的)，另一条是理论学习路线(偏理论的)。整体规划如下图：<br><img src="/img/paperBlog/plan-routine.png"></li>
<li>系统实现这一块，算法实现用的是Python语言，GUI用PyGame库实现；理论学习这一块，只要是参考了July的博客<a class="link"   href="http://blog.csdn.net/v_july_v/article/details/7624837" >支持向量机通俗导论（理解SVM的三层境界）<i class="fas fa-external-link-alt"></i></a>为主线对SVM进行系统的学习。其只要学习路线如下：<br> <img src="/img/paperBlog/SVM-three.png"></li>
</ul>
<h2 id="中期检查-12月24日"><a href="#中期检查-12月24日" class="headerlink" title="中期检查(12月24日)"></a>中期检查(12月24日)</h2><h3 id="毕业设计完成情况"><a href="#毕业设计完成情况" class="headerlink" title="毕业设计完成情况"></a>毕业设计完成情况</h3><ul>
<li>由于课程安排，本人在前一个月中都在做HIS系统的实训，搁置了毕业设计，所以毕业设计的完成情况还是处于初始阶段。在初始阶段，我主要做了以下工作。<ul>
<li>系统的原型设计</li>
<li>手写画板的实现</li>
<li>学习线性分类器-感知机</li>
</ul>
</li>
</ul>
<h3 id="做了哪些工作"><a href="#做了哪些工作" class="headerlink" title="做了哪些工作"></a>做了哪些工作</h3><hr>
<h4 id="系统实现路线"><a href="#系统实现路线" class="headerlink" title="系统实现路线"></a>系统实现路线</h4><ul>
<li><p>系统的原型设计</p>
<ul>
<li>系统主面板的设计</li>
<li><img src="/img/paperBlog/main-borad.png"></li>
<li>数据集训练等待过程面板的设计</li>
<li><img src="/img/paperBlog/wait-borad.png"></li>
<li>数据集训练完成面板的设计</li>
<li><img src="/img/paperBlog/train-result-borad.png"></li>
</ul>
</li>
<li><p>手写画板的实现(Demo)</p>
<ul>
<li><img src="/img/paperBlog/painting-board-demo.png"></li>
</ul>
</li>
<li><p>参考资料</p>
</li>
</ul>
<iframe height=498 width=510 src="http://player.youku.com/embed/XODYxMDI2ODA0" frameborder=0 allowfullscreen></iframe>

<h4 id="理论实现路线"><a href="#理论实现路线" class="headerlink" title="理论实现路线"></a>理论实现路线</h4><ul>
<li>学习线性分类器-感知机<ul>
<li><a class="link"   href="http://chenyuqing.github.io/2015/01/01/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91-%E6%AF%95%E8%AE%BE%E7%B3%BB%E5%88%97/" >最小二乘法论文翻译<i class="fas fa-external-link-alt"></i></a></li>
<li>梯度下降法</li>
<li>对偶形式</li>
<li>感知机</li>
</ul>
</li>
</ul>
<h4 id="线路图完成度-中期检查"><a href="#线路图完成度-中期检查" class="headerlink" title="线路图完成度(中期检查)"></a>线路图完成度(中期检查)</h4><ul>
<li><img src="/img/paperBlog/plan-routine-00.png"></li>
</ul>
<h3 id="遇到了哪些问题"><a href="#遇到了哪些问题" class="headerlink" title="遇到了哪些问题"></a>遇到了哪些问题</h3><h3 id="哪些问题已经解决了，哪些没有解决"><a href="#哪些问题已经解决了，哪些没有解决" class="headerlink" title="哪些问题已经解决了，哪些没有解决"></a>哪些问题已经解决了，哪些没有解决</h3><h3 id="下一步的计划"><a href="#下一步的计划" class="headerlink" title="下一步的计划"></a>下一步的计划</h3><ul>
<li>根据线路图，下一步的计划是继续完善面板框架，学习SVM理论知识，实现SVM识别手写数字的算法。</li>
</ul>
<h2 id="末期检查"><a href="#末期检查" class="headerlink" title="末期检查"></a>末期检查</h2><h2 id="参加答辩"><a href="#参加答辩" class="headerlink" title="参加答辩"></a>参加答辩</h2><h2 id="答辩成绩"><a href="#答辩成绩" class="headerlink" title="答辩成绩"></a>答辩成绩</h2><h2 id="个人总结"><a href="#个人总结" class="headerlink" title="个人总结"></a>个人总结</h2><h1 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h1>]]></content>
      <categories>
        <category>毕业设计系列</category>
      </categories>
      <tags>
        <tag>手写数字SVM</tag>
      </tags>
  </entry>
  <entry>
    <title>最小二乘法论文翻译-毕设系列</title>
    <url>/2015/01/01/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%E7%B3%BB%E5%88%97/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91-%E6%AF%95%E8%AE%BE%E7%B3%BB%E5%88%97/</url>
    <content><![CDATA[<h1 id="写在前面的话"><a href="#写在前面的话" class="headerlink" title="写在前面的话"></a>写在前面的话</h1><ul>
<li>本篇论文是布朗大学数学系Steven J. Miller∗教授的论文翻译。</li>
<li>出处：<a class="link"   href="http://web.williams.edu/Mathematics/sjmiller/public_html/BrownClasses/54/handouts/MethodLeastSquares.pdf" >The Method of Least Squares-Steven J. Miller∗<i class="fas fa-external-link-alt"></i></a></li>
</ul>
<h1 id="最小二乘法"><a href="#最小二乘法" class="headerlink" title="最小二乘法"></a>最小二乘法</h1><ul>
<li>Steven J. Miller*</li>
<li>布朗大学，数学系</li>
<li>普罗维登斯（美国罗得岛州的首府），RI 02912</li>
</ul>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><ul>
<li>原文<br><img src="/img/paperBlog/LSM-translation/LSM-abstract.png"></li>
<li>译文</li>
<li>最小二乘法是求解数据的最佳线性拟合的过程；它可以用简单微积分和线性代数来证明。根本的问题就是根据给定数据集(xn,yn),其中n属于{1,…,N}，然后对这些数据集求解y&#x3D;ax+b最佳拟合直线。这个方法容易推广为求解最佳拟合直线的形式为：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-0.1.png"><br>上式中右边的f(x)不需要对x成线性关系，但等式右边的必须是函数的线性组合。</li>
</ul>
<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ol>
<li><strong>问题的描述</strong></li>
<li><strong>概率与统计知识的回顾</strong></li>
<li><strong>最小二乘法</strong></li>
</ol>
<h3 id="1-问题的描述"><a href="#1-问题的描述" class="headerlink" title="1.问题的描述"></a>1.问题的描述</h3><ul>
<li>现实生活中，我们经常需要找到多个变量之间的线性关系。比如，弹簧的拉力和弹簧的长度成线性关系：y&#x3D;kx(y是拉力，x是弹簧的长度，k是常数)。为了验证以上线性关系，研究者们在实验室测量不同拉力下的不同长度。然后他们按(xn,yn)，其中n属于{1,…,N}的形式收集数据，这里的yn是以牛顿为单位，xn是以米为单位。<img src="/img/paperBlog/LSM-translation/LSM-figure-1.png"></li>
<li>很不幸的，它很难验证出我们上面那么精确的线性关系。原因有以下两个。第一个是实验误差，第二个是可能弹簧的拉力和长度不是成线性关系的。观察图1，弹簧定长为5的拉力和长度的测量数据集模拟。</li>
<li>最小二乘法是一个过程，它需要简单的微积分和线性代数，去决定什么是数据的“最佳拟合”线。当然，我们需要衡量“最佳拟合”的标准，那我们就要用上一些概率和统计学的知识了。</li>
<li>对证明的一个比较谨慎分析表明最小二乘法有很强的泛化能力。虽然求解不出精确的最佳拟合直线，但我们可以求解出给定的特定函数的有限线性组合。所以问题是，给定函数f1,f2…fk，求出以下线性组合中的系数a1,a2…ak的值。<br><img src="/img/paperBlog/LSM-translation/LSM-formula-1.1.png"><br>就是对数据的最好的估计。</li>
</ul>
<h3 id="2-概率与统计知识的回顾"><a href="#2-概率与统计知识的回顾" class="headerlink" title="2.概率与统计知识的回顾"></a>2.概率与统计知识的回顾</h3><ul>
<li>下面我们对最小二乘法需要用到的概率和统计相关的基本元素做一个快速的介绍；详细请看[BD, CaBe, Du, Fe, Kel, LF, MoMc]。</li>
<li>给定一个数据序列x1,x2…xN,我们定义<strong>平均数</strong>(或<strong>期望值</strong>)为(x1+x2+…+xN)&#x2F;N。我们在x的上面加上一横作为标记：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-2.2.png"><br>平均数就是数据的均值。</li>
<li>观察下面两个数据序列：{10, 20, 30, 40, 50}和{30, 30, 30, 30, 30}。两个序列有相同的均值；但是，对于各个数和均值的差值，第一个序列有更大的变动。这就导出了方差的概念，方差是验证数据距离均值的波动程度大小的有用的工具。{x1, . . . , xN}的方差记为<img src="/img/paperBlog/LSM-translation/LSM-variance-note.png">，式子如下：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-2.3.png"><br>标准差<img src="/img/paperBlog/LSM-translation/LSM-standard-deviation-note.png">是方差的开平方：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-2.4.png"></li>
<li>注意到如果x的单位是米，那么方差的单位是平方米，而标准差和平均数的单位还是米。所以，用标准差来测量数据距离均值的波动更合适。</li>
<li>当然，我们还有另外的方法可用，例如：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-2.5.png"></li>
<li>但是这是一个带符号的数量，最大的正偏差和最大的负偏差会相互抵消。实际上，由平均数的定义就可以知道上面的式子结果为0！这是一个非常糟糕的数据偏差的测量，因为0对数据来说一点意义都没有。</li>
<li>我们可以通过绝对值来纠正这个问题，就如下面的式子：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-2.6.png"></li>
<li>虽然绝对值的好处是消除征服误差相互抵消的问题（而且它也有相同的单位），但绝对值函数并非一个好的函数分析。它是不可微的。这也是我们选用标准差的首要原因–它可以让我们利用微积分工具。</li>
<li>现在我们可以衡量“最佳拟合”的标准了。如果我们相信y&#x3D;ax+b,那么y-(ax+b)应该等于0.所以，给定观测量<br><img src="/img/paperBlog/LSM-translation/LSM-formula-2.7.png"><br>我们观察：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-2.8.png"></li>
<li>均值和应该是越小越好，然后求出方差就可以知道我们的数据拟合得好不好了。</li>
<li>那么这个数据集的方差是：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-2.9.png"></li>
<li>大误差应该给于大的权值，而小误差应该给于小的权值(因为误差进行了平方)。所以我们的最小二乘法更喜欢中等的误差而不是大误差。如果我们利用绝对值函数求误差(式子2.6)，那么所有的误差的权值都是一样的；而且，绝对值函数是不可微的，也就是用不了微积分工具的。</li>
</ul>
<h3 id="3-最小二乘法"><a href="#3-最小二乘法" class="headerlink" title="3.最小二乘法"></a>3.最小二乘法</h3><ul>
<li><p>给定数据<img src="/img/paperBlog/LSM-translation/LSM-data.png">,我们可以根据y&#x3D;ax+b计算误差：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-3.10.png"></p>
</li>
<li><p>这就是数据集<img src="/img/paperBlog/LSM-translation/LSM-data-variance.png">方差的N倍。那么我们研究方差的N倍和方差本身是没有差别的，我们注意到上面的错误是两个变量的函数。</p>
</li>
<li><p>我们的目标是求出令误差E(a,b)达到最小的a和b的值。在多变量微积分中我们知道对E(a,b)要分布求a和b的偏导数，并且偏导数等于0：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-3.11.png"></p>
</li>
<li><p>我们不需要考虑边界点：因为|a|和|b|值越大，拟合就变得越差。所以，我们不需要考虑边界点。</p>
</li>
<li><p>对E(a,b)求偏微分得：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-3.12.png"></p>
</li>
<li><p>假设<img src="/img/paperBlog/LSM-translation/LSM-bia-difference.png">(除以2)得到：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-3.13.png"></p>
</li>
<li><p>我们可以重写这些等式：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-3.14.png"></p>
</li>
<li><p>我们已经得到a和b的值了，它们能令误差最小，满足以下矩阵等式：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-3.15.png"></p>
</li>
<li><p>我们会证明矩阵是不可逆的，暗示着：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-3.16.png"></p>
</li>
<li><p>记矩阵为M，那么M的行列式是：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-3.17.png"></p>
</li>
<li><p>当：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-3.18.png"></p>
</li>
<li><p>我们得到：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-3.19.png"></p>
</li>
<li><p>上面最后的等式遵循简单的代数。所以，只要所有的Xn都不相等，detM的值就是非0而且是可逆的。</p>
</li>
<li><p><strong>结论是，只要所有的x都不相等，那么最好的拟合的a和b的值可以通过求解一个线性方程组而得到；解在式子3.16给出了。</strong></p>
</li>
<li><p><strong>标记3.1</strong> 描绘在图1中的点是令xn&#x3D;5+0.2<em>n，然后令yn&#x3D;5</em>xn，再加上一个均值为0，标准差为4(n ∈ {1, . . . , 100})的正态分布的随机误差。利用这些值，我们找到一条最佳拟合直线为：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-3.20.png"><br>所以，a&#x3D;4.99,b&#x3D;0.48.相比我们期望的关系：y&#x3D;5*x,我们期望一个更好的拟合值，a&#x3D;5,b&#x3D;0.</p>
</li>
<li><p>当a的值越来越接近真实值，b的值就会越来越小了。我们特地选取数据的这个特性来反映出在使用最小二乘法的问题。我们知道斜率的最佳值是4.99，而截距的最佳值是0.48，但是这并不是最好的估计。理论需要误差评估的技术支持。所以，我们想知道根据给定的数据，a落在(4.96,5.02)之间和b落在(-0.33,1.18)之间有99%的机会；这比我们仅仅知道最佳值更有用。</p>
</li>
<li><p>另外，如果我们用绝对值的方法：<br><img src="/img/paperBlog/LSM-translation/LSM-formula-3.21.png"><br>那么算出的a的最佳值是5.03，b的最佳值是小于10的负10次方。这两种方法(绝对值方法和最小二乘法)求解出的不同的a和b是因为它们对错误的权值取值不同。</p>
</li>
</ul>
<h1 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h1><ul>
<li>这次虽然不是第一次翻译，但还是遇到许多人埋怨的翻译问题，就是由原文翻译到中文是一道很大的坑，真的很多地方不知道如何翻译，你要联系上下文，分析清楚语境，才能准确地翻译出它想表达的意思，而这不是一件很容易的事件，对于那些需要某些领域的专业知识的就是更难了。</li>
<li>所以，那么老是埋怨翻译人翻译的很差的人，还是不要那么激动的好，毕竟翻译也有翻译的痛。不过，无论怎样，这次翻译无论对我的理论知识的理解还是阅读英文文刊的能力都是有所增进的。</li>
</ul>
<h1 id="参考文献列表"><a href="#参考文献列表" class="headerlink" title="参考文献列表"></a>参考文献列表</h1><p><img src="/img/paperBlog/LSM-translation/LSM-reference.png"></p>
]]></content>
      <categories>
        <category>毕业设计系列</category>
      </categories>
      <tags>
        <tag>最小二乘法 论文翻译</tag>
      </tags>
  </entry>
  <entry>
    <title>支持向量网络论文原文-Vapnik-论文翻译</title>
    <url>/2015/03/13/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%E7%B3%BB%E5%88%97/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E7%BD%91%E7%BB%9C%E8%AE%BA%E6%96%87%E5%8E%9F%E6%96%87-Vapnik-%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/</url>
    <content><![CDATA[<p><img src="/img/paperBlog/Support-Vector-Networks/head.png"></p>
<ul>
<li><strong>摘要</strong>：<ul>
<li>支持向量网络是一种新的用于二类分类问题的学习机。这个机器(方法)概念地实现了以下想法：非线性的输入向量被映射到高维度的特征空间。在这个特征空间中找出一个线性决策超平面。决策超平面的特殊属性可以保证学习机的强泛化能力。这个支持向量网路的思想在训练资料严格线性可分的情况下已被实现。现在我们来谈一下在训练资料非线性可分的情况下的结果。</li>
<li>支持向量网络的高泛化能力是利用多项式输入转换。我们同样比较了支持向量网络和和其他经典的学习算法在OCR(光学字符识别)这个基准上的表现。</li>
</ul>
</li>
<li><strong>关键字</strong>：<ul>
<li>模式识别， 有效的学习算法， 神经网络， 径向基函数分类器， 多类分类器</li>
</ul>
</li>
</ul>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><ul>
<li>60多年前R.A. Fisher(Fisher, 1936)提出了模式识别的第一个算法。有两个服从正态分布的模型，<img src="/img/paperBlog/Support-Vector-Networks/01/01.PNG">和<img src="/img/paperBlog/Support-Vector-Networks/01/02.PNG">，n维向量X，其中均值向量分别是m1和m2，方差分别是<img src="/img/paperBlog/Support-Vector-Networks/01/03.PNG">和<img src="/img/paperBlog/Support-Vector-Networks/01/04.PNG">，最后得到的最优解(贝叶斯)是一个二次规划函数：<br><img src="/img/paperBlog/Support-Vector-Networks/01/05.PNG"></li>
<li>若果<img src="/img/paperBlog/Support-Vector-Networks/01/06.PNG">，那么上式化简为一个线性函数：<br><img src="/img/paperBlog/Support-Vector-Networks/01/07.PNG"></li>
<li>要解式子(1)中的二次规划函数，必须有<img src="/img/paperBlog/Support-Vector-Networks/01/08.PNG">个自由参数。要解式子(2)中线性函数仅仅要n个自由参数。观测量的数量小(比如说小于<img src="/img/paperBlog/Support-Vector-Networks/01/09.PNG">个)估算<img src="/img/paperBlog/Support-Vector-Networks/01/10.PNG">个参数是不可靠的。因此Fisher推荐，即使是在<img src="/img/paperBlog/Support-Vector-Networks/01/11.PNG">的情况下，仍然对线性判别函数(2)使用以下<img src="/img/paperBlog/Support-Vector-Networks/01/12.PNG">的形式：<br><img src="/img/paperBlog/Support-Vector-Networks/01/13.PNG"></li>
<li>上式中的<img src="/img/paperBlog/Support-Vector-Networks/01/14.PNG">是一个常量。Fisher另外推荐了当两个分布不是服从正态的时候，利用一个线性决策函数。</li>
<li>模式识别的算法最开始就和线性决策超平面的构建有关。</li>
<li><img src="/img/paperBlog/Support-Vector-Networks/01/15.PNG"></li>
<li>在1962年Rosenblatt(Rosenblatt, 1962)发明了一种新型的学习机：感知机或者神经网络。感知机包含多个相连的神经元，每个神经元实现一个分离超平面，所以整个感知机实现了分段的线性分离超平面。见图Fig.1。</li>
<li>在Rosenblatt时期还没有算法通过调整网络的权值来最小化向量集的错误。根据其他权值的固定值，输入向量被非线性地转换到特征空间Z中,在单元的最后一层。在这个空间中一个线性决策函数被构造：<br><img src="/img/paperBlog/Support-Vector-Networks/01/16.PNG"></li>
<li>通过调节从第i层隐藏层到输出单元的<img src="/img/paperBlog/Support-Vector-Networks/01/17.PNG">的权值以最小化在整个训练资料上的一些误差。根据Rosenblatt的方法的结果来看，决策规则的构造再一次联系到信息超平面的构造，在某些空间上。</li>
<li>第一次出现一个算法允许通过调整神经网络的权值来最小化属于模式识别问题的向量集的局部误差是在1986年,(Rumelhart, Hinton &amp; Williams, 1986, 1987; Parker, 1985; LeCun 1985)因为那个时候发现了反向传播算法。它的解法是一个轻微修改的神经元的数学模型。所以，神经网络实现了“分段线性类型”的决策函数。</li>
<li>在本文中，我们构造一个新型的学习机(方法)，所谓的“支持向量网络”。支持向量网络实现了一下想法：它通过一些事先选择好的非线性的映射规则把输入向量映射到高维度的特征空间Z。在这个空间当中，通过一些特殊属性来构造线性决策超平面来保证网络的高泛化能力。</li>
<li><img src="/img/paperBlog/Support-Vector-Networks/01/18.PNG"></li>
<li>例子：要求得二次多项式的决策超平面，可以创建一个特征空间Z，它有 N&#x3D; <img src="/img/paperBlog/Support-Vector-Networks/01/08.PNG">个坐标形式：<br><img src="/img/paperBlog/Support-Vector-Networks/01/19.PNG"></li>
<li>上面的方法中有两个新的问题：一个是概念上的，一个是技术上的。概念上的问题是怎么才能找到一个推广能力较好的分离超平面：特征空间的维数将会很大，而且并不是所有的可分离训练资料的超平面都有很好的推广能力。然后技术上的问题是面对如此高维的空间，怎么简化计算量：在一个200维德空间中构造一个4次方或者5次方的多项式可能需要构造一个数以数以亿计的维数的空间。</li>
<li>概念上的问题在1965(Vapnik, 1982)被解决了，鉴于<em>为线性可分的类寻找最佳化的分离超平面</em>这个case.这里定义的最佳化的超平面是两个可分的向量中寻找最大的分类间隔，看Fig.2.被证明说要构造这样一个最佳化的超平面只需要很少的训练数据，这些数据就被称为<em>支撑向量</em>，它们是用来决定间隔的。资料表明，如果训练资料被一个最佳化的超平面完美无误地分离，那么在测试例子中预测新数据的误差期望值等于支持向量的数量的期望值和训练向量的数量的比：<br><img src="/img/paperBlog/Support-Vector-Networks/01/20.PNG"></li>
<li>注意到这个约束并没有明显的包含可分空间的维数。这个约束遵循这个规则的：如果构造最佳化的超平面包含的支持向量的数量越少，那么这个模型的泛化能力就越高–即使是在无穷的维数空间中。在Section 5我们会通过一个实际生活问题说明上面(5)式子的比值可以低到0.03，而且这个最佳化超平面在数以亿计的维数的特征空间中的推广能力很好。</li>
<li>让<br><img src="/img/paperBlog/Support-Vector-Networks/01/21.PNG"></li>
<li>作为空间中最佳化超平面的表示。我们会把特征空间中的最佳化超平面的权值<img src="/img/paperBlog/Support-Vector-Networks/01/22.PNG">写成支持向量的线性组合式<br><img src="/img/paperBlog/Support-Vector-Networks/01/23.PNG"></li>
<li>特征空间中的线性决策函数<img src="/img/paperBlog/Support-Vector-Networks/01/26.PNG">会相应地变成以下形式：<img src="/img/paperBlog/Support-Vector-Networks/01/24.PNG"></li>
<li><img src="/img/paperBlog/Support-Vector-Networks/01/27.PNG">表示的是再特征空间中的支持向量zi和z的点积。决策函数能够被描述为一个两层的网络。(Fig.3.)</li>
<li>然而，即使最佳化超平面的推广能力比较好，但是关于怎样处理高维度空间的技术的问题还没解决。在1992年(Boser, Guyon, &amp; Vapnik, 1992)，构造决策函数的操作顺序是可以互换的：我们可以先比较输入空间中的两个向量(比如，计算它们的点积，或者一些距离测量)对结果的值做非线性转换，而不是拿特征空间中两个点积的向量做非线性的转换。这样促成了更多分类的决策超平面的构造，例如，任意次方的多项式决策超平面。我们把这种类型的学习机叫做支持向量网络。</li>
<li>支持向量网络的技巧当初是为了毫无误差地找到更精准的分类训练数据的超平面。在这篇文章当中，我们对支持向量网络进行拓展，拓展到当不能毫无误差的进行分类数据的情况下也能使用。在这种情形之下，我们把支持向量网络当成一种新的学习机。一种像神经网络一样更强大更通用的学习机。在Section 5我们会对在一个高维空间(维度256)，多项式次方高达7的情形下，支持向量网络的泛化能力还能有多好进行说明。这种学习机的表现可以与那些经典的学习机(像线性分类器，k邻近分类器和神经网络等)相媲美。Section 2，3和4主要讲算法的推导和它的一些属性的讨论。关于推导的细节请看附录部分。<br><img src="/img/paperBlog/Support-Vector-Networks/01/25.PNG"></li>
</ul>
<h2 id="最佳化超平面"><a href="#最佳化超平面" class="headerlink" title="最佳化超平面"></a>最佳化超平面</h2><ul>
<li>在这个section当中，让我们来回顾一下0误差分离训练资料的最佳化超平面的方法(Vapnik, 1982).而在下一个section，我们介绍软间隔的记号，它允许在分类的过程当中存在误差。</li>
</ul>
<h3 id="最佳超平面算法"><a href="#最佳超平面算法" class="headerlink" title="最佳超平面算法"></a>最佳超平面算法</h3><ul>
<li>训练模式的标签集<br><img src="/img/paperBlog/Support-Vector-Networks/02/01.PNG"></li>
<li>被认为是线性可分的，如果向量W和标量b满足以下不等式条件：<br><img src="/img/paperBlog/Support-Vector-Networks/02/02.PNG"></li>
<li>被认为说是对(8)中的所有的训练集都是有效的。然后把(9)中的不等式写成一下形式：<br><img src="/img/paperBlog/Support-Vector-Networks/02/04.PNG"></li>
<li><img src="/img/paperBlog/Support-Vector-Networks/02/03.PNG"></li>
<li>最佳化超平面是：<br><img src="/img/paperBlog/Support-Vector-Networks/02/05.PNG"></li>
<li>它是唯一一个把训练资料分离出最大间隔：它保证了两个不同类别的训练向量映射在<img src="/img/paperBlog/Support-Vector-Networks/02/06.PNG">方向上的距离是最大的。回顾Fig.2.这个距离<img src="/img/paperBlog/Support-Vector-Networks/02/07.PNG">表示如下：<br><img src="/img/paperBlog/Support-Vector-Networks/02/08.PNG"></li>
<li>最佳化超平面<img src="/img/paperBlog/Support-Vector-Networks/02/09.PNG">是使得(12)中距离最大的参数。它符合(12)和(10)的约束<img src="/img/paperBlog/Support-Vector-Networks/02/10.PNG"></li>
<li>这就是说最佳化超平面在符合(10)式当中的约束的条件下是唯一一个可以最小化<img src="/img/paperBlog/Support-Vector-Networks/02/11.PNG">的.所以构造最佳化超平面的问题就是一个二次规划问题。</li>
<li><img src="/img/paperBlog/Support-Vector-Networks/02/13.PNG">当中的向量<img src="/img/paperBlog/Support-Vector-Networks/02/12.PNG">学术上被称为<em>支持向量</em>。在附录A.1中，我们说明了能够决定最佳化超平面的向量<img src="/img/paperBlog/Support-Vector-Networks/02/14.PNG">可以写成一个训练向量的线性组合形式：<img src="/img/paperBlog/Support-Vector-Networks/02/15.PNG"></li>
<li>(14)中当<img src="/img/paperBlog/Support-Vector-Networks/02/16.PNG">.因为<img src="/img/paperBlog/Support-Vector-Networks/02/17.PNG">仅仅是符合支持向量(看附录)，(14)当中的表达式是<img src="/img/paperBlog/Support-Vector-Networks/02/14.PNG">的简写形式。我们也说明了要找参数<img src="/img/paperBlog/Support-Vector-Networks/02/18.PNG">的向量：<br><img src="/img/paperBlog/Support-Vector-Networks/02/19.PNG"></li>
<li>必须要解决以下的二次规划问题：<br><img src="/img/paperBlog/Support-Vector-Networks/02/20.PNG"></li>
<li>其中<img src="/img/paperBlog/Support-Vector-Networks/02/21.PNG">满足的约束条件是：<br><img src="/img/paperBlog/Support-Vector-Networks/02/22.PNG"></li>
<li>其中<img src="/img/paperBlog/Support-Vector-Networks/02/23.PNG">是一个<img src="/img/paperBlog/Support-Vector-Networks/02/24.PNG">维的单位向量，<img src="/img/paperBlog/Support-Vector-Networks/02/25.PNG">是一个<img src="/img/paperBlog/Support-Vector-Networks/02/24.PNG">维的标签向量，<img src="/img/paperBlog/Support-Vector-Networks/02/26.PNG">是一个带元素的对称的<img src="/img/paperBlog/Support-Vector-Networks/02/27.PNG">矩阵<br><img src="/img/paperBlog/Support-Vector-Networks/02/28.PNG"></li>
<li>(16)当中的不等式描述的是非负象限。所以我们在(17)的约束条件下最大化(15)中的二次规划式。</li>
<li>当(8)中的训练资料可以0误差的分离时，我们同样在附录中进行了说明，(15)中的最大值，<img src="/img/paperBlog/Support-Vector-Networks/02/29.PNG">对和(13)中的最大间隔<img src="/img/paperBlog/Support-Vector-Networks/02/35.PNG">的关系：<br><img src="/img/paperBlog/Support-Vector-Networks/02/30.PNG"></li>
<li>对于某些<img src="/img/paperBlog/Support-Vector-Networks/02/31.PNG">和大的常量<img src="/img/paperBlog/Support-Vector-Networks/02/32.PNG">，不等式<br><img src="/img/paperBlog/Support-Vector-Networks/02/33.PNG"></li>
<li>是合理的，有一个可以断言的是所有的可分离训练资料(8)的超平面都满足<br><img src="/img/paperBlog/Support-Vector-Networks/02/34.PNG"></li>
<li>如果(8)中的训练资料不能被一个超平面分离，那么两个模式类别之间的间隔将会非常小，导致函数<img src="/img/paperBlog/Support-Vector-Networks/02/36.PNG">的值非常大。在约束条件(16)和(17)下最大化函数(15)的值，其中一个达到最大值时(这种情况是其中一个通过最大间隔<img src="/img/paperBlog/Support-Vector-Networks/02/35.PNG">构建了一个超平面)，或者其中一个找到了最大值超过了给定的常量<img src="/img/paperBlog/Support-Vector-Networks/02/32.PNG">(这种情况是训练资料的分离超平面比<img src="/img/paperBlog/Support-Vector-Networks/02/37.PNG">还要大是不可能的)。</li>
<li>在约束条件(16)和(17)下最大化函数(15)的问题很有效地通过以下模式解决。把训练资料合理的分成多个不大的部分。首先利用第一部分的训练资料来解决二次规划的问题。对于这样的处理会有两种可能的结果：这部分的训练资料不能找打一个可分离的超平面(这样的话整个资料也是找不到可分离的超平面的)，或者在第一部分的训练资料中就找到了最佳化的分离超平面。</li>
<li>如果是在第一部分的训练资料中就找到了分离超平面，我们把它称作向量<img src="/img/paperBlog/Support-Vector-Networks/02/38.PNG">，让它来最大化函数(15).在向量<img src="/img/paperBlog/Support-Vector-Networks/02/38.PNG">当中有一些值是等于0的。它们对应于这部分资料的非支持向量。创建一个新的训练资料集，其中包含第一部分资料的支持向量和第二部分资料的那些不符合约束(10)的向量，其中<img src="/img/paperBlog/Support-Vector-Networks/02/39.PNG">是由<img src="/img/paperBlog/Support-Vector-Networks/02/38.PNG">决定的。在这个新的资料集当中创造了一个新的函数<img src="/img/paperBlog/Support-Vector-Networks/02/40.PNG">和这个函数在<img src="/img/paperBlog/Support-Vector-Networks/02/41.PNG">处达到最大。然后重复这样的做法，覆盖到所有的训练资料中，不断增加新的解法向量<img src="/img/paperBlog/Support-Vector-Networks/02/31.PNG">，如果找不到0误差的分离超平面，或者对所有训练资料可以构造一个最佳化分离超平面<img src="/img/paperBlog/Support-Vector-Networks/02/42.PNG">.请注意，在这个过程当中，函数<img src="/img/paperBlog/Support-Vector-Networks/02/36.PNG">的值是单调递增的，因为越来越多的训练向量被划分为最佳化，导致两个类别之间的分隔越来越小。</li>
</ul>
<h2 id="软间隔超平面"><a href="#软间隔超平面" class="headerlink" title="软间隔超平面"></a>软间隔超平面</h2><ul>
<li>考虑到那种不能0误差的把训练资料分离的情况。这样的话，我们想说要达到误差的最小化来分离资料。要正式地表达这个，让我们先引入一些非负变量<img src="/img/paperBlog/Support-Vector-Networks/03/01.PNG"></li>
<li>我们现在最小化函数<br><img src="/img/paperBlog/Support-Vector-Networks/03/02.PNG"></li>
<li>其中<img src="/img/paperBlog/Support-Vector-Networks/03/03.PNG">，约束于<br><img src="/img/paperBlog/Support-Vector-Networks/03/04.PNG"></li>
<li><img src="/img/paperBlog/Support-Vector-Networks/03/05.PNG">足够小，函数(21)描述的是训练错误的个数。</li>
<li>最小化(21)，我们要找出一些最小的训练错误的子集：<br><img src="/img/paperBlog/Support-Vector-Networks/03/06.PNG"></li>
<li>如果这些误差资料不包含在训练资料中，那么训练资料就可以毫无误差的进行分离，并且在两个类别之间找到一个超平面。</li>
<li>这个想法可以正式的表达为：最小化函数<br><img src="/img/paperBlog/Support-Vector-Networks/03/07.PNG"></li>
<li>约束条件为(22)和(23)，其中<img src="/img/paperBlog/Support-Vector-Networks/03/08.PNG">是一个单调的凸函数，<img src="/img/paperBlog/Support-Vector-Networks/03/09.PNG">是一个常量。</li>
<li>足够大的<img src="/img/paperBlog/Support-Vector-Networks/03/09.PNG">和足够小的<img src="/img/paperBlog/Support-Vector-Networks/03/05.PNG">，在约束条件(22)和(23)下的最小化函数(24)的向量<img src="/img/paperBlog/Support-Vector-Networks/03/10.PNG">和常数<img src="/img/paperBlog/Support-Vector-Networks/03/11.PNG">，可以决定一个超平面，这个超平面是最小化在训练集上的错误个数和把剩余的元素利用最大间隔进行分离。</li>
<li>注意到，在训练集上构造一个能够最小化错误数的超平面是一个正常的NPC问题(因不能用多项式算法而使问题无法解决的；非完全多项式).为避免我们的问题出现NPC问题，我们设定<img src="/img/paperBlog/Support-Vector-Networks/03/12.PNG"></li>
</ul>
]]></content>
      <categories>
        <category>毕业设计系列</category>
      </categories>
      <tags>
        <tag>SVM入门</tag>
      </tags>
  </entry>
  <entry>
    <title>毕设报告-2015-03-10</title>
    <url>/2015/03/10/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%E7%B3%BB%E5%88%97/%E6%AF%95%E8%AE%BE%E6%8A%A5%E5%91%8A-2015-03-10/</url>
    <content><![CDATA[<h2 id="毕业设计完成情况"><a href="#毕业设计完成情况" class="headerlink" title="毕业设计完成情况"></a>毕业设计完成情况</h2><h3 id="我的感受"><a href="#我的感受" class="headerlink" title="我的感受"></a>我的感受</h3><ul>
<li>写论文绝不是一件轻松的工作，特别是如果你选的题目和你现在的水平相差甚远时。自从<a class="link"   href="http://chenyuqing.github.io/2015/12/30/%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB-%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%E5%8D%9A%E5%AE%A2%E7%B3%BB%E5%88%97-%E8%BF%9E%E8%BD%BD" >上一次的毕业论文中期检查<i class="fas fa-external-link-alt"></i></a>之后，我实习了一个月，然后回家过了个年，所以把时间分配到做毕设的也不多，而且我现在明白到了做理论这一块的论文，特别是面对一连串关数学的推导，一大片难懂的公式，那就更是不知所云。不过就像我的指导老师易老师说的那样，写论文不是简单的拼凑文章，而是需要大量的去阅读前人在你的这个领域范围内的文章，去慢慢吸收里面的知识，然后可以通过自己的话来描述清楚一个问题。“读书千遍，其义自见”这句谚语的个中滋味我也终有领会。特别是偏理论的问题，读第一遍，不知所云，读第二遍，不知所云，读第三遍，不知所云。。。然后突然再读下一遍，就发现自己找到了头绪，那感觉就好像身陷死角里摸不着头了好久，然后突然看到了一线光明一样，整个人都开朗了起来。</li>
</ul>
<h3 id="完成情况概述"><a href="#完成情况概述" class="headerlink" title="完成情况概述"></a>完成情况概述</h3><ul>
<li>我的毕设规划是分两个路线进行，一个是理论学习路线，一个是系统实现路线。<br><img src="/img/paperBlog/plan-routine.png"></li>
<li>上次的完成情况如下图：<br><img src="/img/paperBlog/plan-routine-00.png"></li>
<li>现在的完成进度则如下：<br><img src="/img/paperBlog/plan-routine-01.png"></li>
<li>所以到目前为止，还是注重于理论这一块的学习，因为这一块的难度比重是占的比较大的。</li>
</ul>
<h2 id="做了哪些工作"><a href="#做了哪些工作" class="headerlink" title="做了哪些工作"></a>做了哪些工作</h2><h3 id="阅读了以下优秀的博客文章："><a href="#阅读了以下优秀的博客文章：" class="headerlink" title="阅读了以下优秀的博客文章："></a>阅读了以下优秀的博客文章：</h3><ul>
<li><a class="link"   href="http://blog.csdn.net/v_july_v/article/details/7624837" >支持向量机通俗导论（理解SVM的三层境界）<i class="fas fa-external-link-alt"></i></a></li>
<li><a class="link"   href="http://chenyuqing.github.io/2015/01/08/SVM%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%97%E5%8D%9A%E6%96%87-%E8%BD%AC%E8%87%AAJasper-s-Java-Jacal-%E5%A4%87%E4%BB%BD-%E6%AF%95%E8%AE%BE%E7%B3%BB%E5%88%97/" >SVM入门系列博文-转自Jasper’s Java Jacal<i class="fas fa-external-link-alt"></i></a></li>
<li><a class="link"   href="http://www.cnblogs.com/jerrylead/archive/2011/03/13/1982639.html" >支持向量机SVM（一）<i class="fas fa-external-link-alt"></i></a></li>
</ul>
<h3 id="翻译了一下国外优秀的文章："><a href="#翻译了一下国外优秀的文章：" class="headerlink" title="翻译了一下国外优秀的文章："></a>翻译了一下国外优秀的文章：</h3><ul>
<li><a class="link"   href="http://chenyuqing.github.io/2015/01/12/Support-Vector-Machines-scikielearn/" >Support Vector Machines-scikielearn-翻译-毕设系列<i class="fas fa-external-link-alt"></i></a></li>
<li><a class="link"   href="http://chenyuqing.github.io/2015/01/13/%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB-Kernel%20Support%20Vector%20Machine-%E5%8D%9A%E5%AE%A2%E7%BF%BB%E8%AF%91-%E6%AF%95%E8%AE%BE%E7%B3%BB%E5%88%97/" >手写数字识别-Kernel Support Vector Machine-论文翻译-毕设系列<i class="fas fa-external-link-alt"></i></a></li>
<li><a class="link"   href="http://chenyuqing.github.io/2015/01/01/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91-%E6%AF%95%E8%AE%BE%E7%B3%BB%E5%88%97" >最小二乘法论文翻译-毕设系列<i class="fas fa-external-link-alt"></i></a></li>
</ul>
<h3 id="草拟了论文目录框架"><a href="#草拟了论文目录框架" class="headerlink" title="草拟了论文目录框架"></a>草拟了论文目录框架</h3><ul>
<li><img src="/img/paperBlog/%E6%AF%95%E8%AE%BE%E8%AE%BA%E6%96%87%E7%9B%AE%E5%BD%95%E6%8B%9F%E7%A8%BF.png"></li>
</ul>
<h3 id="利用pygame实现系统的UI，完成了模块的划分"><a href="#利用pygame实现系统的UI，完成了模块的划分" class="headerlink" title="利用pygame实现系统的UI，完成了模块的划分"></a>利用pygame实现系统的UI，完成了模块的划分</h3><ul>
<li><img src="/img/paperBlog/%E7%A8%8B%E5%BA%8F%E6%A8%A1%E5%9D%97%E8%AE%BE%E8%AE%A1.png"></li>
</ul>
<h3 id="利用scikit-learn软件包实现了SVM算法"><a href="#利用scikit-learn软件包实现了SVM算法" class="headerlink" title="利用scikit-learn软件包实现了SVM算法"></a>利用scikit-learn软件包实现了SVM算法</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#-*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment">### Support Vector Machine for Handwritten Digit Recognition</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm, datasets, cross_validation</span><br><span class="line"><span class="keyword">from</span> sklearn.grid_search <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> gmtime, strftime</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;1- Start 载入训练数据&quot;</span></span><br><span class="line"><span class="built_in">print</span> strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>, gmtime())</span><br><span class="line"></span><br><span class="line"><span class="comment">### Load Training data</span></span><br><span class="line">trainTargetArray = []</span><br><span class="line">trainDataArray = []</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./train.csv&#x27;</span>, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> trainFile:</span><br><span class="line">    trainReader = csv.reader(trainFile, delimiter = <span class="string">&#x27;,&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> trainReader:</span><br><span class="line">        trainTargetArray.append(row[<span class="number">0</span>])</span><br><span class="line">        trainDataArray.append(row[<span class="number">1</span>:])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;1- End 载入训练数据&quot;</span></span><br><span class="line"><span class="built_in">print</span> strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>, gmtime())</span><br><span class="line">    </span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;2- Start 删除列头&quot;</span></span><br><span class="line"><span class="built_in">print</span> strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>, gmtime())</span><br><span class="line">    </span><br><span class="line"><span class="comment">### Delete Column Headers</span></span><br><span class="line"><span class="keyword">del</span> trainTargetArray[<span class="number">0</span>]</span><br><span class="line"><span class="keyword">del</span> trainDataArray[<span class="number">0</span>]</span><br><span class="line">trainData = np.array(trainDataArray)</span><br><span class="line">trainTarget = np.array(trainTargetArray)</span><br><span class="line">trainData = trainData.astype(np.<span class="built_in">float</span>)/<span class="number">255.0</span></span><br><span class="line">trainTarget = trainTarget.astype(np.<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;2- End 删除列头&quot;</span></span><br><span class="line"><span class="built_in">print</span> strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>, gmtime())</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;3-Start  载入测试数据&quot;</span></span><br><span class="line"><span class="built_in">print</span> strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>, gmtime())</span><br><span class="line"><span class="comment">### Load Testing data</span></span><br><span class="line">testDataArray = []</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./test.csv&#x27;</span>, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> testFile:</span><br><span class="line">    testReader = csv.reader(testFile, delimiter = <span class="string">&#x27;,&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> testReader:</span><br><span class="line">        testDataArray.append(row)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;3- End  载入测试数据&quot;</span></span><br><span class="line"><span class="built_in">print</span> strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>, gmtime())</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;4 -Start 删除列头&quot;</span></span><br><span class="line"><span class="built_in">print</span> strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>, gmtime())</span><br><span class="line"><span class="comment"># Delete column Headers</span></span><br><span class="line"><span class="keyword">del</span> testDataArray[<span class="number">0</span>]</span><br><span class="line">testData = np.array(testDataArray)</span><br><span class="line">testData = testData.astype(np.<span class="built_in">float</span>)/<span class="number">255.0</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;4-End 删除列头&quot;</span></span><br><span class="line"><span class="built_in">print</span> strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>, gmtime())</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;5-Start 设置分类器并训练模型&quot;</span></span><br><span class="line"><span class="built_in">print</span> strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>, gmtime())</span><br><span class="line"><span class="comment"># Set up classification and fit he model data</span></span><br><span class="line">svc = svm.SVC(gamma=<span class="number">0.128</span>, C=<span class="number">1</span>)</span><br><span class="line">svc.fit(trainData, trainTarget)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;5-End 模型训练完成&quot;</span></span><br><span class="line"><span class="built_in">print</span> strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>, gmtime())</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;6- Start 利用模型预测测试数据中的手写数字&quot;</span></span><br><span class="line"><span class="built_in">print</span> strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>, gmtime())</span><br><span class="line"><span class="comment"># Predict / Determine Value of New images</span></span><br><span class="line">prediction = svc.predict(testData)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;6-End 预测&quot;</span></span><br><span class="line"><span class="built_in">print</span> strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>, gmtime())</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;7- Start  保存输出文件&quot;</span></span><br><span class="line"><span class="built_in">print</span> strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>, gmtime())</span><br><span class="line"><span class="comment"># Save output to file</span></span><br><span class="line">output = <span class="built_in">open</span>(<span class="string">&#x27;./output.csv&#x27;</span>, <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> x, value <span class="keyword">in</span> np.ndenumerate(prediction):</span><br><span class="line">    output.write(<span class="built_in">str</span>(<span class="built_in">int</span>(value)))</span><br><span class="line">    output.write(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">output.close()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;7- End  结束！&quot;</span></span><br><span class="line"><span class="built_in">print</span> strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>, gmtime())</span><br></pre></td></tr></table></figure>
<ul>
<li>本次SVM的实现是利用了网上比较健全的开源机器学习工具—<a class="link"   href="http://scikit-learn.org/stable/" >scikit-learn<i class="fas fa-external-link-alt"></i></a>,Scikit-Learn是基于python的机器学习模块，基于BSD开源许可证。这个项目最早由DavidCournapeau 在2007 年发起的，目前也是由社区自愿者进行维护。</li>
<li>scikit-learn的SVM说明，也是我翻译了一篇文章<a class="link"   href="http://chenyuqing.github.io/2015/01/12/Support-Vector-Machines-scikielearn/" >Support Vector Machines-scikielearn-翻译-毕设系列<i class="fas fa-external-link-alt"></i></a></li>
<li>然后本次的数据是Kaggle上的数字识别的数据<a class="link"   href="http://www.kaggle.com/c/digit-recognizer" >Digit Recognizer<i class="fas fa-external-link-alt"></i></a>。<a class="link"   href="http://www.kaggle.com/" >Kaggle<i class="fas fa-external-link-alt"></i></a>是一个数据建模和数据分析竞赛平台。企业和研究者可在其上发布数据，统计学者和数据挖掘专家可在其上进行竞赛以产生最好的模型。这一众包模式依赖于这一事实，即有众多策略可以用于解决几乎所有预测建模的问题，而研究者不可能在一开始就了解什么方法对于特定问题是最为有效的。Kaggle的目标则是试图通过众包的形式来解决这一难题，进而使数据科学成为一场运动。<a class="link"   href="http://zh.wikipedia.org/wiki/Kaggle" >Kaggle的Wiki简介<i class="fas fa-external-link-alt"></i></a></li>
<li>SVM的训练日志：<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">log-<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="number">1</span>- Start Load Training data</span><br><span class="line"><span class="number">2015</span>-03-09 <span class="number">14</span>:<span class="number">15</span>:<span class="number">33</span></span><br><span class="line"><span class="number">1</span>- End Load Training data</span><br><span class="line"><span class="number">2015</span>-03-09 <span class="number">14</span>:<span class="number">15</span>:<span class="number">37</span></span><br><span class="line"></span><br><span class="line"><span class="number">2</span>- Start Delete Column Headers</span><br><span class="line"><span class="number">2015</span>-03-09 <span class="number">14</span>:<span class="number">15</span>:<span class="number">37</span></span><br><span class="line"><span class="number">2</span>- End Delete Column Headers</span><br><span class="line"><span class="number">2015</span>-03-09 <span class="number">14</span>:<span class="number">15</span>:<span class="number">51</span></span><br><span class="line"></span><br><span class="line"><span class="number">3</span>-Start  Load Testing data</span><br><span class="line"><span class="number">2015</span>-03-09 <span class="number">14</span>:<span class="number">15</span>:<span class="number">51</span></span><br><span class="line"><span class="number">3</span>- End  Load Testing data</span><br><span class="line"><span class="number">2015</span>-03-09 <span class="number">14</span>:<span class="number">15</span>:<span class="number">55</span></span><br><span class="line"></span><br><span class="line"><span class="number">4</span> -Start Delete column Headers</span><br><span class="line"><span class="number">2015</span>-03-09 <span class="number">14</span>:<span class="number">15</span>:<span class="number">55</span></span><br><span class="line"><span class="number">4</span>-End Delete column Headers</span><br><span class="line"><span class="number">2015</span>-03-09 <span class="number">14</span>:<span class="number">16</span>:05</span><br><span class="line"></span><br><span class="line"><span class="number">5</span>-Start <span class="type">Set</span> up classification <span class="keyword">and</span> fit he model data</span><br><span class="line"><span class="number">2015</span>-03-09 <span class="number">14</span>:<span class="number">16</span>:05</span><br><span class="line"><span class="number">5</span>-End <span class="type">Set</span> up classification <span class="keyword">and</span> fit he model data</span><br><span class="line"><span class="number">2015</span>-03-09 <span class="number">15</span>:<span class="number">40</span>:<span class="number">12</span></span><br><span class="line"></span><br><span class="line"><span class="number">6</span>- Start Predict / Determine Value of New images</span><br><span class="line"><span class="number">2015</span>-03-09 <span class="number">15</span>:<span class="number">40</span>:<span class="number">12</span></span><br><span class="line"><span class="number">6</span>-End Predict / Determine Value of New images</span><br><span class="line"><span class="number">2015</span>-03-09 <span class="number">15</span>:<span class="number">57</span>:<span class="number">34</span></span><br><span class="line"></span><br><span class="line"><span class="number">7</span>- Start  Save output to file</span><br><span class="line"><span class="number">2015</span>-03-09 <span class="number">15</span>:<span class="number">57</span>:<span class="number">34</span></span><br><span class="line"><span class="number">7</span>- End  Save output to file</span><br><span class="line"><span class="number">2015</span>-03-09 <span class="number">15</span>:<span class="number">57</span>:<span class="number">34</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li>由日志可以看出，用时最长的是在第5步，有开始到结束共用时1小时10秒。这一步是利用训练数据训练SVM模型，也即是通过支持向量机训练出一个手写数字识别的分类器模型的过程。</li>
<li>第七步是利用生成的模型来对新的数据进行预测，即是对新的手写数字进行识别。用时17分22秒。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">log-<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="number">1</span>- Start 载入训练数据</span><br><span class="line"><span class="number">2015</span>-03-<span class="number">10</span> 02:<span class="number">43</span>:<span class="number">27</span></span><br><span class="line"><span class="number">1</span>- End 载入训练数据</span><br><span class="line"><span class="number">2015</span>-03-<span class="number">10</span> 02:<span class="number">43</span>:<span class="number">45</span></span><br><span class="line"></span><br><span class="line"><span class="number">2</span>- Start 删除列头</span><br><span class="line"><span class="number">2015</span>-03-<span class="number">10</span> 02:<span class="number">43</span>:<span class="number">45</span></span><br><span class="line"><span class="number">2</span>- End 删除列头</span><br><span class="line"><span class="number">2015</span>-03-<span class="number">10</span> 02:<span class="number">43</span>:<span class="number">59</span></span><br><span class="line"></span><br><span class="line"><span class="number">3</span>-Start  载入测试数据</span><br><span class="line"><span class="number">2015</span>-03-<span class="number">10</span> 02:<span class="number">43</span>:<span class="number">59</span></span><br><span class="line"><span class="number">3</span>- End  载入测试数据</span><br><span class="line"><span class="number">2015</span>-03-<span class="number">10</span> 02:<span class="number">44</span>:<span class="number">21</span></span><br><span class="line"></span><br><span class="line"><span class="number">4</span> -Start 删除列头</span><br><span class="line"><span class="number">2015</span>-03-<span class="number">10</span> 02:<span class="number">44</span>:<span class="number">21</span></span><br><span class="line"><span class="number">4</span>-End 删除列头</span><br><span class="line"><span class="number">2015</span>-03-<span class="number">10</span> 02:<span class="number">44</span>:<span class="number">30</span></span><br><span class="line"></span><br><span class="line"><span class="number">5</span>-Start 设置分类器并训练模型</span><br><span class="line"><span class="number">2015</span>-03-<span class="number">10</span> 02:<span class="number">44</span>:<span class="number">30</span></span><br><span class="line"><span class="number">5</span>-End 模型训练完成</span><br><span class="line"><span class="number">2015</span>-03-<span class="number">10</span> 04:04:<span class="number">19</span></span><br><span class="line"></span><br><span class="line"><span class="number">6</span>- Start 利用模型预测测试数据中的手写数字</span><br><span class="line"><span class="number">2015</span>-03-<span class="number">10</span> 04:04:<span class="number">19</span></span><br><span class="line"><span class="number">6</span>-End 预测</span><br><span class="line"><span class="number">2015</span>-03-<span class="number">10</span> 04:<span class="number">21</span>:<span class="number">18</span></span><br><span class="line"></span><br><span class="line"><span class="number">7</span>- Start  保存输出文件</span><br><span class="line"><span class="number">2015</span>-03-<span class="number">10</span> 04:<span class="number">21</span>:<span class="number">18</span></span><br><span class="line"><span class="number">7</span>- End  结束！</span><br><span class="line"><span class="number">2015</span>-03-<span class="number">10</span> 04:<span class="number">21</span>:<span class="number">18</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>第二次训练，模型生成的时间是1小时19分39秒。预测用时16分59秒。</li>
</ul>
<h2 id="遇到了那些问题？那些问题已经解决了，哪些没有解决？"><a href="#遇到了那些问题？那些问题已经解决了，哪些没有解决？" class="headerlink" title="遇到了那些问题？那些问题已经解决了，哪些没有解决？"></a>遇到了那些问题？那些问题已经解决了，哪些没有解决？</h2><ul>
<li>梳理SVM流程如下<br><img src="/img/paperBlog/svm-route.png"></li>
<li>上图中涉及的理论较繁，而且理解难度不小。对于各方面还需要多加理解。</li>
</ul>
<h2 id="下一步的计划"><a href="#下一步的计划" class="headerlink" title="下一步的计划"></a>下一步的计划</h2><ul>
<li>下一步的计划从以下三个路线出发<ul>
<li>手写数字识别这个问题的描述</li>
<li>SVM如何应用到手写数字识别</li>
<li>pygame实现手写数字识别系统</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>毕业设计系列</category>
      </categories>
      <tags>
        <tag>SVM入门</tag>
      </tags>
  </entry>
  <entry>
    <title>现代机器学习监控的混乱局面：重新思考流媒体评估（2/4）</title>
    <url>/2023/05/24/%E7%8E%B0%E4%BB%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9B%91%E6%8E%A7%E7%9A%84%E6%B7%B7%E4%B9%B1%E5%B1%80%E9%9D%A2/model_monitoring_mess_part02/</url>
    <content><![CDATA[<ul>
<li>作者：Shreya Shankar</li>
<li>原文连接：<a class="link"   href="https://www.shreya-shankar.com/rethinking-ml-monitoring-2/" >rethinking ml monitoring 2<i class="fas fa-external-link-alt"></i></a></li>
</ul>
<hr>
<ul>
<li>在《现代ML监控乱象》系列的最后一篇文章中，我讨论了现有流式ML指标失败的一些方式。在这篇文章中，我从 “以数据为中心 “的角度过渡到软件工程的角度：我调查了现有的部署后问题，并将其分类，以激励更好的开源ML监控工具。</li>
</ul>
<h2 id="作为ML从业者，我们如何分配我们的时间？"><a href="#作为ML从业者，我们如何分配我们的时间？" class="headerlink" title="作为ML从业者，我们如何分配我们的时间？"></a>作为ML从业者，我们如何分配我们的时间？</h2><ul>
<li>最近，Zillow因其最新的ML灾难而在社交媒体上引起热议。一些人声称他们的ML购房和售房项目因低质量的预测而关闭。另一些人则认为，关闭的原因是没有关于如何对预测采取行动的组织程序–员工手动推翻了预测，以满足他们自己的配额。谁知道问题是什么，但我认为Zillow的新闻变得非常流行的一个重要原因是<strong>我们所做的许多ML应用在生产中都是不稳定的。</strong> 我们不知道他们是否或何时会失败。我们不知道，在组织上，如何对模型输出采取行动。而且我们肯定不知道当我们怀疑ML管道或管理方面出现一些故障时该怎么做。</li>
<li>为了剖析如何改善应用ML的令人苦恼的状态，我认为了解ML从业者目前如何分配他们的时间很重要。经过广泛的搜索，我在一篇关于87%的机器学习项目失败的文章中发现了一个相当准确的细分（在我看来），即行业ML项目是如何分配时间的：</li>
<li><img src="/img/wuweiwu/ml/model_monitor_translate/time-spend.png" alt="time spend"></li>
<li>图1：分解ML项目时间分配的图表，取自iiot-world。</li>
<li>图1显然解释了为什么数据标签初创公司目前在MLOps市场上获胜，但我更感兴趣的是，随着越来越少的ML项目失败，细分市场将如何变化。就像在软件方面一样，我怀疑在未来5年内，图表中的大部分大众都会在运营化方面。<strong>我们如何从数据化中去除质量，并将更多的质量放在监测上？</strong></li>
</ul>
<h2 id="构建一个ML管道"><a href="#构建一个ML管道" class="headerlink" title="构建一个ML管道"></a>构建一个ML管道</h2><ul>
<li><p>上图所示的分类对于失败的ML项目来说感觉很准确。在我以前的ML工作的任期结束时，我们最终遵循这个过程来建立新的成功的ML管道：</p>
<ol>
<li>想出针对ML的服务水平目标（SLO），比如在每月的窗口中90%的召回率 🪟</li>
<li>编写为占位的ML管道输出计算SLO的函数（例如，基线预测概率） 🪠</li>
<li>编写确认校准输出的函数 ⚖️</li>
<li>编写管道的所有组件或阶段，除了模型训练&#x2F;评估之外 🔧</li>
<li>进行仔细的探索性数据分析，编写清理数据、选择特征等的管道组件 📊</li>
<li>将上述所有内容生产化 🚧</li>
<li>训练&#x2F;评估逻辑回归模型或决策树 🌲</li>
<li>逐步改善模型 📈</li>
</ol>
</li>
<li><p>这里的关键是，<strong>在管道的一些骨干部分投入生产之前，我们没有做任何建模工作</strong>、消除了花在数据预处理上的时间，这可能是特定的训练&#x2F;测试分割。然而，在我上面描述的范式中，我们在管道中的数据处理组件中仍然有bug（我认为这是不可避免的）。当采用这种模式时，我注意到我的大部分开发人员的时间从 “研发 “建模工作转移到监控生产ML服务。</p>
</li>
<li><p>几个月来，我一直记录着我个人在监控时面临的部署后问题。缺少数据导致空值键的连接，子组表示法随时间变化，将错误的模型推广到生产中，上游依赖关系（如嵌入）变化，Spark节点故障……这个清单似乎没有尽头。每当我面临一个新问题时，我都试图设计一个警报，以防止未来出现这种故障模式。<strong>随后，管道代码逐渐变得不可持续，而我在生产中仍然面临着许多新的挑战–促使我思考更清洁的部署后问题的分解。</strong></p>
</li>
</ul>
<h2 id="部署后问题的分类"><a href="#部署后问题的分类" class="headerlink" title="部署后问题的分类"></a>部署后问题的分类</h2><ul>
<li>假设一个团队为一项任务定义了一个具体的ML SLO，比如在每月的窗口中90%的召回。重新表述我关于部署后问题的问题–这些SLO没有达到的原因有哪些？我喜欢Neptune.ai博客文章中的这个表格：</li>
</ul>
<table>
<thead>
<tr>
<th></th>
<th>生产挑战</th>
<th>关键问题</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>数据分布变化</td>
<td>为什么我的特征值会有突然的变化？</td>
</tr>
<tr>
<td>2</td>
<td>生产中的模型所有权</td>
<td>谁拥有生产中的模型？DevOps团队？工程师？数据科学家？</td>
</tr>
<tr>
<td>3</td>
<td>训练-部署不一致</td>
<td>尽管我们在开发过程中进行了严格的测试和验证尝试，但为什么该模型在生产中给出的结果不佳？</td>
</tr>
<tr>
<td>4</td>
<td>模型&#x2F;概念漂移</td>
<td>为什么我的模型在生产中表现良好，而随着时间的推移，性能突然下降？</td>
</tr>
<tr>
<td>5</td>
<td>黑匣子模型</td>
<td>我如何根据商业目标并向相关的利益相关者解释和说明我的模型的预测？</td>
</tr>
<tr>
<td>6</td>
<td>一致的对手</td>
<td>我怎样才能确保我的模型的安全？我的模型被攻击了吗？</td>
</tr>
<tr>
<td>7</td>
<td>模型准备情况</td>
<td>我如何将我的模型的较新版本的结果与正在生产的版本进行比较？</td>
</tr>
<tr>
<td>8</td>
<td>管道健康问题</td>
<td>为什么我的训练管道在执行时失败？为什么再培训工作需要这么长时间才能运行？</td>
</tr>
<tr>
<td>9</td>
<td>表现不佳的系统</td>
<td>为什么我的预测服务的延迟非常高？为什么我的不同模型的延迟有很大的不同？</td>
</tr>
<tr>
<td>10</td>
<td>极端事件的案例（异常值）</td>
<td>我将如何在极端和非计划的情况下跟踪我的模型的效果和性能？</td>
</tr>
<tr>
<td>11</td>
<td>数据质量问题</td>
<td>我怎样才能确保生产数据的处理方式与训练数据的处理方式相同？</td>
</tr>
</tbody></table>
<ul>
<li>图2：部署后问题表，取自Neptune.ai。</li>
<li>说实话，很多博客文章读起来就像洗衣清单。作为一个懒人，我绝不会在每个拉动请求上手动检查每个清单项目。<strong>我们如何使这些挑战更容易推理，以便我们能够建立一个监测工具？</strong> 戴上我的软件工程帽子，我发现将这些生产挑战（以及其他挑战）提炼成四种类型的问题是很有帮助的，这些问题沿着两个轴线（状态和组件）分组：</li>
<li><img src="/img/wuweiwu/ml/model_monitor_translate/state-componet.jpg" alt="state and component"></li>
<li>图3：将少数部署后的问题按状态和组件轴进行分类。</li>
<li>让我定义一下 “状态 “和 “组件”，以便图3真正有意义。很多时候，只有当你将数据点与历史上的一组数据点进行比较时，你才知道ML系统中存在一个错误。例如，也许代表传感器数据的表格中的一列主要是空值。是传感器刚刚坏了，还是它一直都在坏？为了回答这样的问题，你需要跟踪历史数据，或状态。此外，你可能需要来自多个不同组件的信息来诊断一个ML系统的故障模式。例如，假设模型训练的数据和模型推断预测的实时数据之间存在差异。显然，一个调试器应该关心ML管道的训练和推理部分。我把这种错误定义为跨组件的错误。</li>
<li>对我来说，理解这些轴线，就可以知道为什么ML监控从根本上说比传统的软件监控更难，也更有区别。软件SLI完全属于单组件区域，如平均响应延迟。最复杂的软件SLI是有状态的和单组件的，促使了像Prometheus这样的工具。<strong>但最基本的ML SLI，如准确度，是有状态的和跨组件的–最难处理的桶。</strong> 一旦你能够有效地监控这种有状态的跨组件指标（如实时准确性），以确定何时有bug，了解有状态的单组件指标，如第90个百分点的特征值，是很有用的，因为你就可以确定bug在你的管道中的位置。</li>
</ul>
<h2 id="通过状态-组件视角查看现有的工具"><a href="#通过状态-组件视角查看现有的工具" class="headerlink" title="通过状态-组件视角查看现有的工具"></a>通过状态-组件视角查看现有的工具</h2><ul>
<li>我个人对一个完全开源的监控解决方案很感兴趣，它可以有效地、快速地、以一种需要用户付出最小努力的方式来跟踪可能属于这4组中任何一组的指标。现有的工具能做到这一点吗？从我的研究中，我发现开源监控工具只涉及4个组的一个子集。我在头脑中把现有的工具分为以下几个 “层次”：<ol>
<li>缠绕着的报告 scipy.your_favorite_statistical_test(finite_sample_from_dist_A_that_you_define, finite_sample_from_dist_B_that_you_define) —用户被迫跟踪状态和组件。在这里，用户需要解决数据管理问题，即为他们关心的每个组件存储历史输入和输出，编写作业来反复对感兴趣的数据进行子采样并创建这些报告，并在这个过程中组织所有工件。</li>
<li>工作流协调工具（如Airflow、Argo、Kubeflow）–用户被迫跟踪状态。在这里，仪表盘会向你显示单个管道运行中不同任务或组件的详细结果。但用户无法真正访问当前运行中的历史运行值。</li>
<li>Postgres数据库持有单个组件的历史输入和输出，以及一个显示np.some_aggregation(dist_A)随时间变化的仪表板–用户被迫跟踪组件。在这里，用户需要知道要监控哪些组件，手动连接组件的输入和输出以进行任何自定义的聚合（例如，F1分数），并定义他们自己的标准，即如何以及何时对仪表盘的结果采取行动。例如，如果一个特征的平均值变化了10%，用户会怎么做？</li>
<li>专有的供应商，鉴于对你的数据和模型的访问，为你监控一切。不知道这些公司是做什么的，所以我不作评论。</li>
</ol>
</li>
</ul>
<h2 id="回顾总结"><a href="#回顾总结" class="headerlink" title="回顾总结"></a>回顾总结</h2><ul>
<li>在这篇文章中，我讨论了如何通过两个简单的轴对部署后问题进行分类：状态和组件。我不想讨论如何监测我在图3中描述的每个问题，但回到我在本期第一篇文章中提出的一个问题–要如何扩展现有工具以支持有状态的组件和跨组件的情况？是否有可能轻松地扩展它们？在下一篇文章中，我将探讨如何调整Prometheus以监测ML，并研究它的缺陷所在。</li>
<li>感谢Laszlo Sragner对早期草案的反馈。</li>
</ul>
<hr>
<h2 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h2><ol>
<li>我喜欢数据科学博客文章中点击率高的标题。🙃</li>
<li>这并不是要挖苦博文作者；而是要说明生产ML问题的广泛性。</li>
<li>这并不明显，为什么像准确性这样的实时指标的近似是一个有状态的和跨组件的程序。这是有状态的，因为你需要一组历史预测和标签来计算这个指标。这是跨组件的，因为在许多情况下，提供预测的组件与收集反馈（标签）的组件不同。</li>
</ol>
]]></content>
      <categories>
        <category>技能-修行-进步-MLOps</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>MLOps</tag>
      </tags>
  </entry>
  <entry>
    <title>现代机器学习监控的混乱局面：重新思考流媒体评估（1/4）</title>
    <url>/2023/05/24/%E7%8E%B0%E4%BB%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9B%91%E6%8E%A7%E7%9A%84%E6%B7%B7%E4%B9%B1%E5%B1%80%E9%9D%A2/model_monitoring_mess_part01/</url>
    <content><![CDATA[<ul>
<li>作者：Shreya Shankar</li>
<li><ul>
<li>原文连接：<a class="link"   href="https://www.shreya-shankar.com/rethinking-ml-monitoring-1/" >rethinking ml monitoring 1<i class="fas fa-external-link-alt"></i></a></li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>我对MLOps感兴趣的部分原因是有太多的工具，而且我无法相信一些受人尊敬的软件老手和学者正在向左、向右、向中间推出新的创业公司。在我之前的公司，使用现有的DevOps工具来简化ML的部署和生产，让我走得很远–但还不够远，促使我思考MLOps问题的定制解决方案，比如ML监控。</li>
<li>我喜欢当博士生，因为我可以思考问题，而没有人嚷嚷着要我建立什么。事实是，当涉及到监测ML时，我不知道到底应该建立什么。ML监控的现状是，不加掩饰，一团糟。在这个由四篇文章组成的文集中，我说明了我对获得一个好的开源ML监控解决方案的想法，其大纲如下：</li>
</ul>
<ol>
<li>重新思考流媒体机器学习的评估(本篇)</li>
<li>对部署后的各种问题进行分类</li>
<li>调查现有的DevOps工具（如Prometheus）在机器学习监控方面的不足之处</li>
<li>建立一个通用的机器学习监测解决方案的具体研究挑战</li>
</ol>
<h2 id="重新思考流媒体ML的评估"><a href="#重新思考流媒体ML的评估" class="headerlink" title="重新思考流媒体ML的评估"></a>重新思考流媒体ML的评估</h2><ul>
<li>在我讨论什么是监控之前，我将把监控定义为：跟踪指标以确定应用程序何时失败。有很多文章都在说服你，监控对于机器学习应用是必要的。下面是我对为什么我们需要监控的两点看法：</li>
</ul>
<ol>
<li>生产中的应用程序将不可避免地遇到问题。我们希望尽早发现并解决这些问题，以尽量减少停机时间。</li>
<li>机器学习越来越多地被部署在高风险的场景中（例如，累犯、贷款、信用卡欺诈、招聘、自动驾驶汽车），其中的监管是不可避免的。</li>
</ol>
<ul>
<li>许多文章还讨论了在生产型ML系统中会出现哪些类型的错误，促使人们去监测什么。我个人对所有可能发生的bug以及必须执行和监控的大量测试和指标清单感到不知所措，以确保管道的 “良好 “健康。在我以前的工作中，我曾经有过一次生存危机，因为我不知道为什么要监控成千上万的东西；我只是认为这是管道 “不失败 “的必要条件。但 “失败 “是什么意思，特别是在ML背景下？</li>
</ul>
<h2 id="为什么造成这样的局面？"><a href="#为什么造成这样的局面？" class="headerlink" title="为什么造成这样的局面？"></a>为什么造成这样的局面？</h2><ul>
<li>机器学习领域有一个有趣的评估历史。针对ML的指标被设计用来评估一个特定模型在特定数据集上的表现。为了在 “学术 “环境中评估一个模型，几十年来，我们一直在测量固定的指标，如准确率、精确率和召回率，这些指标是我们的模型在训练期间没有看到的 “验证 “集。为了评估一个模型是否能推广到新的数据，机器学习入门课程强调了检查过拟合的重要性（即验证集指标应该接近训练集指标）。这真的是我们宣称可推广性所需要的全部吗？</li>
<li>在今天这个基准的黄金时代，我们并没有真正质疑这种在一些静态或固定的数据集上计算指标的评估程序（有一些例外）。最近，我的朋友Deb和其他ML领导人一直在提高人们对当前通用的ML评估方法在评估ML系统中与关键子群体（如种族）和外部性（如能源消耗）相关的失败模式方面的认识。我提到这项工作是因为我认为它非常重要，尽管与我在这里要谈的内容正交。</li>
<li>我们很清楚，在实践中，虽然所有的模型都是错误的，但有些模型是有用的。在 “行业 “背景下的ML评估，毫不奇怪，可以追溯到50年代和60年代的军事背景下。ROC曲线是在第二次世界大战期间发明的，用于对战场上的敌方物体进行分类，我想主要是因为从业者需要计算有用的模型，并随着时间的推移抛弃无用的模型。我喜欢把ROC曲线和PR曲线看作是更好的指标 “聚合”，它有助于告知模型输出的哪个阈值，以及这种阈值如何随时间变化。当在实践中（例如医疗）长期部署ML时，这种聚合显然是必要的。</li>
<li>因为在实践中，我们与数据流打交道，而不是固定的数据集，ML监测的行业标准（可能是软件监测的结果）遵循这些步骤：</li>
</ul>
<ol>
<li>选择他们认为代表模型性能的指标和阈值</li>
<li>选择一个滑动窗口大小（单位是基于时间的，如天或周）来计算指标。</li>
<li>当指标值下降到阈值以下时，设置警报。</li>
<li>警报后，手动或自动触发重新训练</li>
</ol>
<ul>
<li>这个过程假设故障被定义为指标值下降到其阈值以下。为什么我们需要把这个定义弄正确呢？在你不需要的时候触发重新训练的影响可能是不好的：它可能会浪费计算，或者如果最近的窗口不能代表未来的数据，它实际上可能会降低性能。在需要的时候不触发重新训练的影响是，你的性能将继续恶化–甚至可能无声无息。因此，我们希望我们的警报是健全的（即，没有错误的警报）和完整的（即，每次出现故障时都触发）。不幸的是，我总是得到太多或者太少的警报，促使我质疑–我们的评估程序有什么问题？</li>
</ul>
<h2 id="我们目前的做法有什么问题？"><a href="#我们目前的做法有什么问题？" class="headerlink" title="我们目前的做法有什么问题？"></a>我们目前的做法有什么问题？</h2><ul>
<li><p>现在我将论证为什么这种在数据流上评估ML的程序被打破了。假设我们有一个从时间t&#x3D;0开始的数据流。我们在t&#x3D;0和t&#x3D;i之间的数据上训练和验证一个模型。我们在t&#x3D;i处 “部署”，并连续计算跨越d天的滚动窗口的ML指标。</p>
</li>
<li><p><img src="/img/wuweiwu/ml/model_monitor_translate/train-d.png"></p>
</li>
<li><p>有一些自然和常见的现象会被计入公制计算中：</p>
<ul>
<li><strong>代表性差异</strong>。各个窗口的类比可能不一样（例如，一个窗口的阳性比例可能与另一个窗口的阳性比例有很大不同）。</li>
<li><strong>不同的样本大小</strong>。每个窗口中的数据点数量可能不同（例如，周日收到的请求数量少于周一收到的请求数量）。</li>
<li><strong>延迟的反馈</strong>。由于合理的事件（如失去互联网连接），标签可能会滞后出现，使得没有标签的预测不可能被纳入当前窗口的评估指标。</li>
</ul>
</li>
<li><p>在每一种情况下，即使你测量auROC和auPRC这样的聚合，指标值也会发生剧烈变化–而模型与预期任务的 “一致性”（即预测能力）或 “概念漂移 “没有任何变化。当我们触发重新训练时，我们隐含地相信我们的模型不具有我们预期的预测能力。如果我们的滚动窗口与我们的保留验证集的假设不一致（例如，我们的滚动窗口跨度为一周，而我们的验证集跨度为一个月），我们怎么能对这个信念有信心？大多数时候，我们并没有明确意识到在训练时所作的所有假设。<strong>我认为在一个滚动窗口上评估的ML特定指标告诉你的是模型的一致性，而不是该窗口中数据的属性。</strong></p>
</li>
<li><p>因此，由于我们不知道如何评价模型与预期任务的一致性，对数据流的评价在不同的组织中是不同的。我们不知道在哪里为可接受的业务绩效划线，所以我们看所有可辩护的指标（例如auROC），并试图为它们的一些聚合进行优化。虽然我们没有更好的选择（据我所知），但这显然是破绽百出的，并使ML在如此多的产品设置中变得毫无用处。许多行业的ML资深人士谈到，我们需要从ML指标到商业结果的清晰明确的映射–成熟的组织有一个ML模型的 “SLO “概念，其中BizDev和数据人员合作，以确定单一任务（SLO）的指标集合、窗口大小和警报程序。当SLO与任务不一致时，你不知道一个指标的下降是否应该触发一个重新训练！这种合作来计算SLO参数！这种计算SLO参数的合作迫使人们定义如何对模型输出采取行动。疯狂的是，可能需要几个月甚至一年的时间来确定正确的参数来计算SLO。更重要的是，与我的兴趣更相关的是—<strong>这样一个针对特定环境的ML SLO选择程序与建立一个通用工具来监控ML管道是不一致的。</strong></p>
</li>
</ul>
<h2 id="回顾总结"><a href="#回顾总结" class="headerlink" title="回顾总结"></a>回顾总结</h2><ul>
<li><p>因此，在我所概述的流媒体ML评估中确实有两个不同的问题：</p>
<ol>
<li>要使目前的 “行业标准 “评估程序（选择指标、阈值和窗口大小）发挥作用需要时间和许多资源</li>
<li>这个程序可能永远不会成功，这取决于数据的性质，而且通用性很差（即，需要同样多的时间和资源来解决新任务的评估协议或SLO）–使得ML在生产中真的很难实现</li>
</ol>
</li>
<li><p>我猜想，与ML相关的敏捷宣言的延伸以及围绕ML的优点和缺点的更好的教育可以解决第一个问题。第二个问题对我来说似乎更难解决–作为一个ML信息员，我对规定具体的SLO不感兴趣；我感兴趣的是建立基础设施，让任何人都能轻松监控他们关心的ML SLO。</p>
</li>
<li><p><strong>我希望我们的ML社区能更深入地思考如何普遍评估将在数据流上运行的模型的一致性或预测能力。</strong> 也许我们不能比我们已经有的程序做得更好，但我很好奇–我们能不能建立技术来理解ML结果的特定数据的时间性，并使用这些信息来为我们选择SLO？我们能不能建立更多的一般性指标，明确地与业务成果挂钩，如 “ML Apdex Score”？这些一般的指标能否对我上面概述的所有三种现象–代表性差异、不同的样本量和延迟反馈–保持稳健？我不知道这最终会是什么样子，但我相当有信心，能够阐明和衡量正确的SLO将为从生产性ML应用中获得价值提供巨大的突破。我很高兴我们能取得进展。</p>
</li>
<li><p>感谢Alex Tamkin、Rolando Garcia和Peter Schafhalter对许多草案的反馈。</p>
</li>
</ul>
<hr>
<h2 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h2><ol>
<li>没有任何MLOps公司付钱给我写这个。我无法对隐藏在付费墙之外的解决方案发表明智的看法，所以我对现有的专有工具不做任何声明。另外，我认为完全开源的ML监控解决方案是有市场的。</li>
<li>对我来说，最有用的MLOps资源来自博客文章、Slack频道和口碑，这很疯狂。这个领域完全处于起步阶段。</li>
</ol>
]]></content>
      <categories>
        <category>技能-修行-进步-MLOps</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>MLOps</tag>
      </tags>
  </entry>
  <entry>
    <title>现代机器学习监控的混乱局面：重新思考流媒体评估（4/4）</title>
    <url>/2023/05/24/%E7%8E%B0%E4%BB%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9B%91%E6%8E%A7%E7%9A%84%E6%B7%B7%E4%B9%B1%E5%B1%80%E9%9D%A2/model_monitoring_mess_part04/</url>
    <content><![CDATA[<h2 id="作者：Shreya-Shankar-原文连接：rethinking-ml-monitoring-4"><a href="#作者：Shreya-Shankar-原文连接：rethinking-ml-monitoring-4" class="headerlink" title=" 作者：Shreya Shankar- 原文连接：rethinking ml monitoring 4"></a> 作者：Shreya Shankar<br>- 原文连接：<a class="link"   href="https://www.shreya-shankar.com/rethinking-ml-monitoring-4/" >rethinking ml monitoring 4<i class="fas fa-external-link-alt"></i></a></h2><ul>
<li>在过去的几篇文章中，我讨论了流式ML评估，思考了要监控的内容（跨状态和组件轴），并探索了现有软件监控工具（如Prometheus）的故障模式。在这最后一篇文章中，<strong>我为ML监控中的问题提出了一个更广泛的研究议程</strong>，由 “真实世界 “的ML部署后问题所激发。</li>
</ul>
<h2 id="预备工作"><a href="#预备工作" class="headerlink" title="预备工作"></a>预备工作</h2><ul>
<li>我们将用一个例子来阐述这个议程：</li>
<li><strong>任务</strong>：对于乘坐出租车，我们想预测出租车乘客给司机的小费超过车费10%的概率。这是一个二元分类问题。预测值是在0和1之间的浮点数。</li>
<li><strong>数据集</strong>：我们使用从纽约市出租车联盟收集的2020年1月1日至5月31日的数据。这是一个 “时间上演变的表格数据 “的例子（这句话是从阿伦-库马尔那里偷来的）。</li>
<li><strong>SLI</strong>：我们衡量准确度，或者当四舍五入到最接近的整数时，正确预测的例子的分数。在ML社区，SLI通常被称为评估指标。</li>
<li><strong>管道结构</strong>：我们的例子只包括一个模型。2有两条管道–代表训练和推理–共享一些组件，如清洗和特征生成。请参考本系列的第三篇文章中的图表。</li>
</ul>
<h2 id="挑战的保护伞"><a href="#挑战的保护伞" class="headerlink" title="挑战的保护伞"></a>挑战的保护伞</h2><ul>
<li>我的研究议程主要集中在数据管理，而不是算法。</li>
</ul>
<h3 id="度量衡计算"><a href="#度量衡计算" class="headerlink" title="度量衡计算"></a>度量衡计算</h3><ul>
<li>我将指标计算分为粗粒度和细粒度两类。3 粗粒度指标是SLI（如准确率、精确率、召回率），与商业价值最接近，需要一些反馈，或标签。我们使用粗粒度的指标来检测ML性能问题。细粒度指标是可能表明或解释粗粒度指标变化的指标，不一定需要标签（例如，一个特征的两个连续滑动窗口之间的KL分歧）。我们使用细粒度的指标来诊断ML的性能问题。相关的、<strong>我认为许多组织都落入了这样的陷阱，即首先监测细粒度的指标、</strong> 仿佛一个不起眼的特征的中位值的一些变化会对是否重新训练一个模型提供任何可操作的洞察力。<strong>当粗粒度的度量应该被视为一等公民时。</strong></li>
</ul>
<h4 id="粗粒度的监控：检测ML性能问题"><a href="#粗粒度的监控：检测ML性能问题" class="headerlink" title="粗粒度的监控：检测ML性能问题"></a>粗粒度的监控：检测ML性能问题</h4><ul>
<li>令人惊讶的是，各组织发现要了解其SLI的实时价值具有挑战性。一些原因是：<ul>
<li><p><strong>预测和反馈组件之间的分离</strong>。如果一条流水线进行预测，而另一条流水线摄取反馈，我们就需要对一个高权重的属性进行连接。这可能不是一个研究问题本身，但却是一个需要考虑的恼人的工程问题，特别是在流媒体环境中。</p>
</li>
<li><p><strong>改变感兴趣的子群体</strong>。许多组织监测不同子群体（如客户）的SLI 随着时间的推移，新的子群体或人口统计学可能逐渐进入数据流。组织很难知道要监测哪些子人群–考虑到覆盖面（即支持）、时间变化或高培训损失。</p>
</li>
<li><p><strong>标签滞后</strong>。由于预测和反馈部分的分离，在我们做出预测后，其相应的反馈（即标签）在一段时间后（或根本没有）到达系统中。不同的预测或子组之间的延迟可能并不一致。在需要人类手动标注数据的情况下，延迟会加剧。此外，我们假设<strong>标签滞后是一个非平稳的时间序列</strong>（即未预料到的问题可能导致滞后，而且可能没有一个模式）。</p>
</li>
</ul>
</li>
</ul>
<h5 id="Scalable-Monitoring-Infrastructure"><a href="#Scalable-Monitoring-Infrastructure" class="headerlink" title="Scalable Monitoring Infrastructure"></a>Scalable Monitoring Infrastructure</h5><ul>
<li><p>解决前两个问题，特别是在规模上，需要更好的监控基础设施，优先考虑增量维护的连接，灵活定义SLI（即用户定义的功能），智能建议监控的内容，以及在部署后添加新的SLI定义并通过历史数据窗口计算的能力。我的上一篇文章展示了Prometheus如何不满足这些需求。为此，我正在考虑一个具有以下层次的ML监控系统：</p>
</li>
<li><p><strong>存储</strong>。我们需要一个时间序列数据库用于持久性存储（计算的度量值、直方图或总结、原始输出和反馈），以及用于快速连接和度量计算的内存流。</p>
</li>
<li><p><strong>执行</strong>。用户应该能够将度量函数指定为Python UDFs，我们可以用一个基于数据流的差分系统（Murray等人）在数据窗口上增量运行。考虑一个假想的用户工作流：</p>
</li>
<li><p><img src="/img/wuweiwu/ml/model_monitor_translate/code3.png"></p>
</li>
<li><p>在上面的工作流程中，用户定义他们自己的度量函数，并用记录函数来记录他们的代码。我们将需要加入输出和反馈–增量的，以节省时间–并在任意的窗口大小上计算度量。一个初步的原型4计算流式ML SLI，定义为Python UDFs，跨越不同的组件，显示出有希望的度量计算时间和最小的日志开销：</p>
</li>
<li><p><img src="/img/wuweiwu/ml/model_monitor_translate/querylatencyall.png"></p>
</li>
<li><p><img src="/img/wuweiwu/ml/model_monitor_translate/loggingtimeall.png"></p>
</li>
<li><p>图1：ML查询和记录的延迟。</p>
</li>
<li><p><strong>查询</strong>。支持快速和灵活的查询是最重要的。在用户查询之前预先计算和存储摘要–包括连接和度量值–会产生最低的延迟查询；然而，用户可能希望在查询时改变窗口大小和其他参数。在查询时间之前进行预计算和在飞行中计算所有内容之间的最佳权衡是什么？此外，随着用户添加新的UDF和新的子群的出现，我们如何有效地回填部署以来所有窗口的度量值？</p>
</li>
</ul>
<h5 id="估计有标签滞后的实时SLI"><a href="#估计有标签滞后的实时SLI" class="headerlink" title="估计有标签滞后的实时SLI"></a>估计有标签滞后的实时SLI</h5><ul>
<li>我们不仅需要考虑监测基础设施，而且还需要能够正确计算SLI。滞后为计算SLI引入了有趣的算法挑战。如果用户不能及时收到所有预测的标签（反馈），我们如何尽可能正确地估计实时SLI？</li>
</ul>
<h6 id="全面反馈"><a href="#全面反馈" class="headerlink" title="全面反馈"></a>全面反馈</h6><ul>
<li>在这种情况下，为了计算一个窗口的SLI，我们只需要执行一个流式连接。挑战发生在规模上，或者当我们的窗口尺寸太大，无法在内存中容纳预测和反馈时。一个自然的解决方案可能是执行近似的流式连接，但是众所周知，在连接之前对流式进行均匀的子采样，可以在结果中产生四倍的少的图元（Chaudhuri等人）。现有的流式连接的近似查询处理（AQP）技术在图元的数量或所产生的连接的代表性之间权衡准确性。在我们的案例中，我们关心的是后者，因为我们想使我们的SLI近似的误差最小化（即近似的精度应该接近于精确的精度）。所以我们可能不想利用最先进的宇宙抽样技术（Kandula等人）来保留大量的连接结果图元，因为它们不一定能提供准确的估计（Huang等人）。</li>
<li>为了优先考虑我们连接样本的代表性，我们可以从渐进式近似连接的分层抽样技术中得到启发（Tok等人）。直观地说，为了使我们的SLI近似值的误差最小化，我们应该构建具有相似预测误差（即ML模型目标认为的损失）的阶层或子组。不幸的是，在我们的高数据设置中，我们无法计算每个预测的误差（因为我们无法将每个预测连接到其相应的标签上）!也许我们可以在高层特征分组中识别 “典范”（即 “重要 “的数据点），并在分组标签上加入典范。例如，在我们的高尖预测问题中，我们可以将我们的预测和标签按邻里（例如FiDi、Tribeca、Midtown）分组，在这些组中挑选典范，汇总这些典范的预测和标签，并将它们连接起来以计算指标。研究的挑战在于设计出高效、高准确度的方法–可能是混合的ML和数据处理技术–来计算群体和典范。</li>
</ul>
<h6 id="无反馈"><a href="#无反馈" class="headerlink" title="无反馈"></a>无反馈</h6><ul>
<li><p>这种情况通常在部署后立即发生。在我们纽约市出租车的例子中，假设我们有两个原始数据来源：出租车传感器遥测数据（如里程、位置）和计价器数据（如支付信息）。计价器数据可能会在以后分批出现，促使我们找到其他方法来估计没有标签的实时性能。</p>
</li>
<li><p>一个想法是使用重要性加权（IW）技术（Sugiyama等人）。在高层次上，我们可以根据输入特征确定子组，算出每个子组的训练SLI（例如准确度），并根据实时（部署后，未标记）数据中每个子组的点的数量来加权这些准确度。在我们的例子中，基本的子组定义可以是街区–对于纽约市的每一个街区，我们会找到训练的准确性，并通过相应街区中的实时点的比例来加权，以获得其 “估计 “的准确性。然后，我们将每个社区的估计值汇总，得到一个整体的估计精度。对于一个更复杂（和更高置信度）的方法，我们可以构建不同的分组，并对所产生的SLI估计值进行平均。同样，研究的挑战在于确定这些分组，当然也包括评估这些方法的效果。</p>
</li>
<li><p>我们可以在训练集或直播流中确定子群。最便宜的选择是根据训练数据点来计算子群，因为这可以做一次。然而，有了这个 “静态子群 “选项，实时的SLI估计就变得不那么准确了，因为子群的代表性随时间而变化。因此，我们希望在实时数据中计算出适应性的子群。我们可以利用流式聚类算法，这些算法对不断变化的数据分布具有明确的鲁棒性（Zubaroğlu等人）；然而，这在我们的案例中是额外昂贵的，因为每次有新的实时数据进来，我们都需要重复地将训练数据集的点重新分配给聚类。此外，集群在训练集中可能很少或没有相应的数据点，使我们无法估计出SLI。因此，我们需要<strong>研究在高维的、不断变化的数据流中有效识别子群的方法，并考虑到参考数据集（即训练集）</strong>。</p>
</li>
</ul>
<h6 id="部分反馈"><a href="#部分反馈" class="headerlink" title="部分反馈"></a>部分反馈</h6><ul>
<li>这种情况是我在 “野外 “看到的ML管线中最常见的。通常情况下，实时数据只在时间表上标注，更多的时候，一些上游的数据收集问题影响了反馈的到来（例如，在Tribeca的某个地区有一个手机塔的中断，导致支付表的数据比预期的晚到）。<strong>假设标签滞后的分布是未知和非平稳的</strong>, (即训练一个单独的模型来预测哪些预测不会有反馈可能是不可行的），在这种情况下，我们如何估计实时SLI？</li>
<li>乍一看，也许我们可以简单地汇总全反馈和无反馈的估计值，按每个子组的数据点的数量加权。但现实情况是，标签滞后很少在各桶中均匀分布，识别具有类似反馈滞后时间的数据点组，对产生实时SLI的准确估计至关重要6。我们可以利用无反馈部分所描述的流式聚类算法，但这种聚类可能无法解释，或者只用谓词中的几个条款简单描述（Saisubramanian等人）。出于调试的目的，我们还关心这些 “滞后 “的数据点集群如何随时间变化，或者滞后的异常情况。</li>
<li>也许我们可以从流模式挖掘算法中获得灵感，比如频繁项集（Rajaraman和Ullman等人）。然而，这类算法是在标签不变的数据点窗口中寻找特征组，而我们想要应用频繁项集算法的数据点–那些没有反馈的数据点（即 “滞后 “点）–在我们计算出频繁项集后可能会得到反馈。因此，<strong>我们如何扩展流式频繁项集算法，以便在删除数据点后有效地重新计算项集</strong>？我们可以在频繁项集的增量维护工作的基础上（Tobji等人）。</li>
</ul>
<h4 id="细致的监控：诊断ML性能问题"><a href="#细致的监控：诊断ML性能问题" class="headerlink" title="细致的监控：诊断ML性能问题"></a>细致的监控：诊断ML性能问题</h4><ul>
<li>当SLI较低时，最优先考虑的是尽快使其回升。”细粒度 “监测类别涉及表现不佳的管道的 “根本原因分析”–模型是否应该重新训练，或者管道中的工程问题是否是失败的根本原因。此外，如果模型应该被重新训练（例如，有 “漂移 “或 “转移”），我们应该如何改变训练集以提高性能？</li>
</ul>
<h5 id="检测数据质量问题"><a href="#检测数据质量问题" class="headerlink" title="检测数据质量问题"></a>检测数据质量问题</h5><ul>
<li>针对ML可观察性的数据管理研究在自动识别数据管道中的工程问题方面取得了进展（Schelter等人，Breck等人）。诸如模式验证、检测批次内的异常值以及对特征统计的约束（如预期平均值、完整性和范围）等技术可以标示出意外的数据质量问题，如传感器损坏和不完整的上游数据摄取。对于少量的特征和对问题领域的高度熟悉，宣布界限或预期可能是可行的，但这能否扩展到高维设置–例如，当数据科学家向xgboost模型投掷2000或更多的特征时？此外，<strong>在 “工程问题 “和 “漂移 “之间划清界限是很难的</strong>、特别是如果我们想自动检测问题。像TFX（Modi等人）这样的工具允许用户监测感兴趣的距离指标，如KL发散和Kolmogorov-Smirnov测试统计，但在视觉检查的L1距离很低的情况下，这些工具会失效–这可能发生在成千上万的数据点的规模上（Breck等人）。缓解这个问题的策略是假设拥有一个FAANG公司可能正在处理的数据点的数量（如果不是数十亿，也是数亿）。如果在FAANG公司之外，我们可以用什么技术来弥补经验漂移d(p̂, q̂)和理论漂移d(p, q)之间的差距，其中p和q是两个不同的分布？</li>
</ul>
<h5 id="朝着重新训练模型的方向发展"><a href="#朝着重新训练模型的方向发展" class="headerlink" title="朝着重新训练模型的方向发展"></a>朝着重新训练模型的方向发展</h5><ul>
<li><p>在研究和实践界都存在一个巨大的问题，那就是 <strong>“分配转变 “是一个定义不明确的、负担过重的短语</strong>、造成全面的混乱。当人们说 “分布转移 “时，他们指的是一种现象，即一个数据集来自与另一个数据集不同的分布。”分布转移 “可能会导致ML性能下降–例如，在一个出租车公司供应商的数据上训练的模型在取自另一个出租车公司供应商的数据上可能表现不佳。这个重载的短语包含了不同类型的转变；例如：</p>
</li>
<li><p><strong>概念转变</strong>：输入特征和目标输出（即标签）之间关系的变化。这方面的一个例子是华尔街的年终奖金导致乘客在一周内多给小费。</p>
</li>
<li><p><strong>协变量转移</strong>：训练数据中输入变量分布的变化，而不是目标输出分布。这方面的一个例子是在新年前夕在中城（时代广场的落球）收到更多的出租车乘坐。</p>
</li>
<li><p><strong>年龄转移</strong>：一个输入变量的分布随着时间的推移预期增加或减少。这方面的一个例子是出租车的总里程数，它只能随着时间的推移而增加。</p>
</li>
<li><p>在 “分布转变 “方面的很多研究和现有方法都集中在比较两组有限的数据。正如我在本系列文章前面提到的，在实践中，我们关心的是在无限的数据流上部署模型，或在可预见的未来的数据。难道我们应该任意地将生产数据切割成两个固定大小的数据集，以想知道是否有 “分布转移”？这似乎并不正确。在流式ML设置中，我们真正关心的问题是：在什么时候我的模型对我当前的数据不能像预期那样工作？(即我何时需要重新训练我的模型？)。</p>
</li>
<li><p>在现实中，SLI的下降是由不同类型的转变组合而成的，特别是在高度非平稳的环境中。从产品的角度考虑，告诉用户 “78%来自概念转变，22%来自协变量转变”，即使我们能精确地确定这种细分，其可操作性如何？<strong>我们希望告诉用户何时以及如何在部署后重新训练模型</strong>,鉴于当前数据窗口中出现的 “异常”。假设我们有标签或反馈Y和输入数据或特征X，其中Xi代表所有数据点中第i个特征的数据。按照颗粒度增加的顺序，异常情况的类型可以包括：：</p>
</li>
<li><p>P(Y | X)有变化，但P(X)没有变化</p>
</li>
<li><p>P(Y | X)没有变化，但P(X)有变化</p>
</li>
<li><p>P(Xi)中的移位</p>
</li>
<li><p>P(Xi | Xj)中的移位，其中i ≠ j</p>
</li>
<li><p>P(Xi | Xj , Xk , …)中的移位，其中i ≠ j ≠ k</p>
</li>
<li><p><strong>在规模上跟踪许多距离度量</strong>。如前所述，为了接近上述的异常情况，现有的工作提出在连续的滑动窗口和训练集上跟踪KL分歧和Kolmogorov-Smirnov检验等指标（即Breck等人所述的训练-服务倾斜）。在内存中保留许多实时数据的窗口和训练集可能是不可行的，因此我们可以利用AQP技术来计算具有合理误差的距离指标。例如，度量计算功能可以在特征的直方图上运行，而不是在完整的数据流上运行；然而，直方图槽在流式设置中需要随着数据的演变而变化。研究的挑战在于将增量维护的近似直方图（Gibbons等人）的想法与自适应直方图（Leow等人）的想法相结合，以产生不断变化的数据窗口的总结。</p>
</li>
<li><p><strong>识别距离度量中的静止性</strong>。通常情况下，模型在周末、工作时间以外或节假日表现不佳。一个有趣的想法是训练一个模型来识别滑动窗口中观察到的P（Y | X）和P（X）之间的距离是否存在季节性模式。追踪所有的特征组合是不切实际的（Heise等人），那么是否有可能利用预测寻找算法（如Wu等人）来简化追踪距离指标的空间？</p>
</li>
<li><p><strong>自我调整的训练集</strong>。最后，根据检测到的异常类型，我们可以建议增加或改变训练集的方法。例如，在P(X)发生变化但P(Y | X)不变的情况下，我们可以建议对代表性不足的子群体进行增加采样。在P(Y | X)变化但P(X)不变的情况下，也许用户可以在最近的数据窗口上重新训练他们的模型。研究的挑战在于具体的、有用的提示，以构建新的训练数据集来避免低性能的陷阱。</p>
</li>
</ul>
<h3 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h3><ul>
<li><p><strong>目前的ML监控仪表盘信息量过大</strong>.用户看到数以百计，甚至数以千计的柱状图和图表，试图将 “分布转移 “可视化。<strong>这些图表没有可操作性，特别是当人们可以用同一组图表来讲述两个相互矛盾的故事时。</strong>例如，一个用户可以说，一个模型需要重新训练，因为一个特征的平均值在过去的几天里急剧下降了。另一方面，用户可以说这个特征不是三个最重要的特征之一，所以重新训练模型不会有很大影响。因此，从界面的角度来看，在给定数百个图形的情况下，在何时重新训练一个模型上划线是一个任意的过程。我们如何想出更好的可视化工具？</p>
</li>
<li><p><strong>仪表盘的目标</strong>。监测可视化的目的是帮助用户与他们的数据和模型保持同步。为此，好的监测仪表板应该毫不含糊地回答具体问题，如：：</p>
<ul>
<li>实时ML的性能是什么？</li>
<li>这个性能是比预期的高还是低？比要求的（即满足SLOs）？</li>
<li>性能降低的原因是数据质量问题吗？</li>
<li>模型应该被重新训练吗？</li>
</ul>
</li>
<li><p>仪表盘应该只包含少数几个描述 “统治它们的单一指标”（即SLI）的图，这样用户就不会被淹没了。</p>
</li>
<li><p><strong>仪表盘的挑战</strong>。在两个以上的维度上实现指标的可视化是非常困难的。不幸的是，在涉及到ML指标时，我们至少有以下几个维度：</p>
<ul>
<li>度量值</li>
<li>组件（即管道中跨组件的连接，见本系列第二篇文章中的单组件与跨组件的讨论）。</li>
<li>状态（即输入和输出的历史值）</li>
<li>子种群（包括特征群）</li>
<li>时间（一般意义上的时间，例如，绘制过去6个月内100天窗口的滚动平均值）</li>
</ul>
</li>
<li><p>我们如何开发出能明确传达所有这些维度的信息而又没有太多认知开销的可视化产品？</p>
</li>
<li><p><strong>争取实现有洞察力的可视化</strong>。与前文所述的细粒度监测信息相结合，一个好的仪表盘将有深刻的可视化，让用户对分布如何变化有直观感受。ML工程师使用的现有的 “最先进的 “可视化（通过口口相传确定，所以要慎重对待8）包括比较两个数据集的静态条形图直方图。这在流式ML环境中很难推理。什么新的可视化类型可以解释细粒度指标的变化？这里有一个高尖预测的 “动态 “小提琴图的例子，显示了输出的分布如何随时间变化：</p>
</li>
<li><p><img src="/img/wuweiwu/ml/model_monitor_translate/output_violin.gif"></p>
</li>
<li><p>图2：产出随时间的分布。</p>
</li>
<li><p>在上面的例子中，由于我们有充分的反馈（即所有的预测都有标签），SLI（准确性）有确认的下降。在我们需要近似SLI和假设推理细粒度指标的情况下，也许用户可以直观地看到这样一个可视化的季节性。这绝对不是万能的解决方案，但要回到主要的问题：<strong>研究的挑战在于如何以有原则的方式提出更好的可视化来理解数据漂移，并根据用户工作的数据和ML任务自动将其呈现给用户。</strong></p>
</li>
</ul>
<h3 id="数据集和基准"><a href="#数据集和基准" class="headerlink" title="数据集和基准"></a>数据集和基准</h3><ul>
<li>由于缺乏对 “真实世界 “流式ML任务的访问，许多研究人员和开发人员主要用玩具数据或合成分布转移来工作。为此，有几个问题围绕着数据集和基准来加速ML监测的进展：</li>
</ul>
<ol>
<li><strong>一个实时数据流的存储库，对应于可操作的ML任务。</strong>一个好的数据流的属性包括：它是无限的，代表了一个真实世界的现象，并且有一个比预测天气或股票价格更容易解决的ML任务。一个影响特别大的问题可能是以太坊天然气价格预测。具体来说，一个模型能否以95%的置信度输出未来一小时内一笔交易所需的最低天然气价格？另一个选择是将现有的基准转换为流格式（例如，从WILDS的训练和测试分布（D和D’）中取样点xt，用一个函数，当时间戳t小时，xt∈D的概率很高，当t大时，xt∈D’的概率很高）。理想情况下，我们收集更多的 “时间演化的表格数据流”，因为这种类型的数据在研究界大量存在。</li>
<li><strong>以直观的方式从资源库中查询数据的接口</strong>,大多数数据科学家并不使用流式系统，那么我们如何让他们进行范围查询并接收Pandas或PyTorch数据集？我们如何保障用户在试验新想法时不被标签泄露或意外地偷看到未来？</li>
<li><strong>用于创建和评估训练模型的策略的接口</strong>（我敢说是DSL？)mltrace的愿景是成为一个类似于React的库，用户在其中定义管道的组件，并在每个组件运行之前和之后运行触发器。在这些触发器中，用户可以根据自己的标准决定重新训练模型–比如数据漂移指标或预定更新。</li>
</ol>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li>有了关于一个ML任务的足够的上下文，就有可能解决该任务特有的数据管理问题。但在构建一个通用的监控工具时，还有其他一些挑战，这些挑战源于ML管道和系统复杂性的增加，包括：</li>
<li><strong>壮大的数据科学团队和工具栈</strong>。软件工程表明，团队和工具栈的分散性使其很难保持系统的可持续性。这将适用于ML，特别是当可能的ML数据管理工具的数量每年大量增加时。调试一个别人训练的模型是一件很痛苦的事情。</li>
<li><strong>模型堆叠</strong>。许多组织将模型连锁在一起以产生最终的预测。漂移检测对于一个模型来说已经很困难了。将错误的预测追溯到需要调试的特定模型上，似乎更具挑战性。</li>
<li><strong>无法解释的特征</strong>。许多组织使用ML来产生嵌入，并将其作为特征输入到下游的ML任务中。数据质量警报，如用户定义的特征列的约束，然后无法构建。</li>
<li><strong>将组件作为容器化应用进行部署</strong>。在Kubernetes集群中很难做ML。容器化基础设施主要适用于无状态的应用程序，不幸的是，在线和持续学习是有状态的（即模型权重被更新，需要在预测服务荚之间共享）。</li>
<li><strong>多模态数据</strong>。我在这篇文章中概述的许多解决方案想法都是针对表格数据的。我们可以在图像、音频和视频案例中使用什么技术？我敢说，信息的 “数据湖”？</li>
<li>我还没有太深入地思考这些临时性的挑战，但我怀疑一个好的ML监测工具至少会意识到这些挑战。最后，我想以个人名义结束这个系列。10我很感激有时间批判性地思考ML监控，以及行业专家和学术合作者的支持。我很幸运能读博士，我为自己能写出的论文感到兴奋!</li>
<li>感谢Divyahans Gupta和我的导师Aditya Parameswaran的头脑风暴帮助和对许多草案的反馈。</li>
</ul>
<hr>
<h2 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h2><ol>
<li>通常情况下，我谈论的是可观察性。监测是可观察性中的一个子问题，有最有趣的研究问题（在我看来）。</li>
<li>新的挑战出现在模型的堆叠上，或者将模型串联在一起，形成最终的预测结果。</li>
<li>不清楚 “粗粒度 “和 “细粒度 “是否是这里的最佳术语。DG建议采用 “外部 “与 “内部 “的衡量标准。如果您对此有任何想法，请告诉我！</li>
<li>基于 timely-dataflow（基于Rust的差分数据流实现）。向Peter Schafhalter致敬，感谢他在这方面的快速工作。</li>
<li>我应该进一步阐述这些方法。</li>
<li>更不用说，确定哪些子组有较高的滞后时间，对调试工作有帮助。</li>
<li>这里不点名，但如果你有兴趣，请查看ML监控公司的演示。</li>
<li>我们RISELab的几个人正在进行一项采访研究，以正式撰写部署后ML维护的 “最佳实践”。</li>
<li>深度学习的危险性就属于这个范畴。</li>
<li>向那些能看完本系列所有4篇文章的人表示敬意。我是认真的。我很确定我还没有读完这里的所有字。</li>
</ol>
]]></content>
      <categories>
        <category>技能-修行-进步-MLOps</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>MLOps</tag>
      </tags>
  </entry>
  <entry>
    <title>现代机器学习监控的混乱局面：重新思考流媒体评估（3/4）</title>
    <url>/2023/05/24/%E7%8E%B0%E4%BB%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9B%91%E6%8E%A7%E7%9A%84%E6%B7%B7%E4%B9%B1%E5%B1%80%E9%9D%A2/model_monitoring_mess_part03/</url>
    <content><![CDATA[<ul>
<li>作者：Shreya Shankar</li>
<li>原文连接：<a class="link"   href="https://www.shreya-shankar.com/rethinking-ml-monitoring-3/" >rethinking ml monitoring 3<i class="fas fa-external-link-alt"></i></a></li>
</ul>
<hr>
<ul>
<li>在上一篇文章中，我调查了现有的部署后问题，并将它们分为两个轴：状态和组件。我提到，监控跨组件的状态指标，如模型的准确性，对于维护ML管道至关重要，但在现有的工具中却很困难。在这篇文章中，我们将亲身体验这些困难：我们将用Prometheus（一种流行的软件监控工具）扩展一个玩具ML管道，以提供ML监控。在这个过程中，我们将看到Prometheus的许多不足之处，从代码混乱到算法的低效率</li>
</ul>
<h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><ul>
<li>有一天在工作中，当我在Slack频道中浏览AWS警报的时候，我突然意识到我的infra同事和我对 “标签 “一词的解释非常不同。他指的是一个标识符。我是指预测的真实值。我们只是在一个大项目进行了几个月后才发现我们是错位的。值得庆幸的是，我们从未在同一个任务上合作过，所以对我们没有任何影响。但我想知道这种错位是否会在其他组织中造成问题。</li>
<li>我认为关于ML监测的讨论中最令人困惑的方面是术语。像 “度量 “和 “标签 “这样的术语是超载的。在这篇文章中，我将利用以下定义：<ul>
<li>指标：一个汇总数据的函数，以评估管道的性能如何（例如，平均值、准确度）。</li>
<li>普罗米修斯公制：数字测量的时间序列</li>
<li>标识符：分配给一个对象或对象集合的唯一名称</li>
<li>预测：由一个ML模型做出的输出</li>
<li>反馈：预测的 “真实 “值</li>
<li>服务水平指标（SLI）：一个汇总预测和反馈的函数，以评估管道的性能如何（例如，准确性）</li>
</ul>
</li>
</ul>
<h2 id="ML任务，数据源，和管道"><a href="#ML任务，数据源，和管道" class="headerlink" title="ML任务，数据源，和管道"></a>ML任务，数据源，和管道</h2><ul>
<li>在这个练习中，我使用纽约市出租车联盟的数据构建了一个ML管道来预测出租车乘客是否会给司机高额小费（二元分类）。使用Prometheus，我们将监测<strong>累积的准确性</strong>，或者说自部署以来所有预测的准确性。训练和推理管道在架构上共享一些组件，看起来像这样：</li>
<li><img src="/img/wuweiwu/ml/model_monitor_translate/pipeline.svg" alt="ml pipeline"></li>
<li>图1：ML管道架构。</li>
<li>由于这是一个二元分类问题，推理组件产生0和1之间的浮动值预测，而反馈组件返回0或1的值。我把我的管道和实验代码寄存在这个资源库中，结构如下：</li>
<li><img src="/img/wuweiwu/ml/model_monitor_translate/repo_structure.png"></li>
<li>我在2020年1月的数据上运行训练管道，模拟2020年2月1日开始的部署。我没有进行任何再训练，主要是因为这个练习的目的是展示Prometheus的故障模式，而不是调试由 “数据漂移 “导致的低SLI。</li>
</ul>
<h2 id="Prometheus入门"><a href="#Prometheus入门" class="headerlink" title="Prometheus入门"></a>Prometheus入门</h2><ul>
<li><p>普罗米修斯(Prometheus)是一个开源的软件监控工具：</p>
<ol>
<li>收集和存储指标，如响应延迟</li>
<li>允许用户通过一种名为PromQL的查询语言查询公制值的集合（例如平均延迟）。</li>
</ol>
</li>
<li><p>普罗米修斯支持四种类型的度量值：</p>
<ul>
<li><strong>计数器</strong>：一个单调增长的累积度量。例如，可用于跟踪预测服务的数量。</li>
<li><strong>仪表</strong>：一个代表单一数值的度量，可以任意改变。例如，可以用来跟踪当前的内存使用情况。</li>
<li><strong>直方图</strong>：一个将观察到的数值归类到用户预先定义的桶中的度量衡。这有很高的服务器端成本，因为服务器在查询时要计算量值。</li>
<li><strong>摘要</strong>：在一个滑动的时间窗口中跟踪用户预先定义的量化指标。这具有较低的服务器端成本，因为量值是在登录时配置和跟踪的。另外，摘要指标一般不支持查询中的聚合。</li>
</ul>
</li>
<li><p>通常情况下，企业的DevOps或SRE人员使用Prometheus来监控软件SLO。用户用他们的应用程序代码来记录Metric值。这些值被刮取并存储在Prometheus服务器中。这些值可以使用PromQL进行查询，并导出到Grafana等可视化工具中。该架构看起来像这样：</p>
</li>
<li><p><img src="/img/wuweiwu/ml/model_monitor_translate/promarchitecture.png" alt="prom architecture"></p>
</li>
<li><p>图2：普罗米修斯架构。</p>
</li>
<li><p>Ivan Velichko的这一系列教育性的帖子很好地解释了普罗米修斯。我将总结他的一些关键点：</p>
<ul>
<li>普罗米修斯不是一个时间序列数据库（TSDB）。它只是利用了一个TSDB。</li>
<li>由于普罗米修斯定期刮取数值，如果度量值的变化比刮取间隔更频繁，一些度量类型（如仪表）会失去精度。这个问题不适用于单调增长的度量（如计数器）。</li>
<li>Metrics可以用任意的标识符来记录，这样在查询时，用户可以通过标识符的值来过滤Metrics。</li>
<li>PromQL很灵活–用户可以在不同的窗口大小上计算许多不同的度量值聚集，这些参数可以在查询时指定。</li>
</ul>
</li>
<li><p>Velichko承认，PromQL在实际软件应用中的使用 “远非微不足道”（也就是说，令人讨厌）。然而，在学习了矢量匹配和其他语法之后，我认为它并不太糟糕–特别是当我们不需要加入Metrics的时候。PromQL查询通常不会太长，而且在查询时有许多辅助函数可以使用。但我们会看到它对ML监控的情况有多糟糕。</p>
</li>
</ul>
<h2 id="Prometheus-🤝-ML"><a href="#Prometheus-🤝-ML" class="headerlink" title="Prometheus 🤝 ML"></a>Prometheus 🤝 ML</h2><ul>
<li>以下问题将有助于评估Prometheus是否是一个合适的ML监控解决方案：<ol>
<li>我们可以使用Prometheus Metrics来跟踪我们的ML管道中的任何ML指标吗？将 “ML度量 “映射到Prometheus Metric类型并不直接。对于单一组件的有状态指标，也许我们想使用直方图或汇总指标。如果我们对跨组件的有状态度量感兴趣，我们需要考虑如何将不同组件的度量 “连接 “起来，以计算ML SLI，如准确度和精确度。</li>
<li>用PromQL编写ML SLI有多难？</li>
<li>ML SLI的查询延时是多少？</li>
</ol>
</li>
</ul>
<h2 id="管线仪表"><a href="#管线仪表" class="headerlink" title="管线仪表"></a>管线仪表</h2><h3 id="跨组件的有状态度量"><a href="#跨组件的有状态度量" class="headerlink" title="跨组件的有状态度量"></a>跨组件的有状态度量</h3><ul>
<li>普罗米修斯的指标类型（计数器、测量仪、直方图或摘要）没有一个明显地映射到我们想要测量的SLI：累积精度。相反，我们将使用2个Gauge Metric3–一个用于管道预测，一个用于反馈–并在PromQL中聚合它们来计算准确性。在mext&#x2F;prometheus_ml_ext.py中，我定义了一个BinaryClassificationMetric类，其中包含Gauge Metrics以及logOutputs和logFeedbacks方法，以便在每次推理调用后更新它们。对应用程序进行仪表化是非常直接的。下面是inference&#x2F;main.py中的Prometheus专用代码：</li>
<li><img src="/img/wuweiwu/ml/model_monitor_translate/code1.png" alt="inference code"></li>
<li>将累积的准确度表现为两个Gauge Metrics并不完全是直接的，但我仍将这种经验评为简单。</li>
</ul>
<h3 id="单一成分的有状态度量"><a href="#单一成分的有状态度量" class="headerlink" title="单一成分的有状态度量"></a>单一成分的有状态度量</h3><ul>
<li>ML监控解决方案经常监控输入和输出的聚集，如中位数和p90，以粗略地测量 “数据漂移”。有时，他们还计算更复杂的统计测试（如Kolmogorov-Smirnov测试），我肯定永远无法用PromQL来写。这些方法既不健全也不完整，但为了这个练习的目的，我们可以用直方图度量来跟踪输出值的各种百分位数。下面是inference&#x2F;main.py中的相关仪表代码：</li>
<li><img src="/img/wuweiwu/ml/model_monitor_translate/code2.png"></li>
<li>这种整合比跨组件的情况更容易，但一个主要的缺点是，我们需要提前定义我们的直方图桶。这有两个原因：（1）我们常常不知道输出的分布是什么样子的，（2）分布可能随着数据的 “漂移 “而改变。</li>
</ul>
<h2 id="用于ML-SLI的PromQL"><a href="#用于ML-SLI的PromQL" class="headerlink" title="用于ML SLI的PromQL"></a>用于ML SLI的PromQL</h2><ul>
<li><p>现在我们已经检测了我们的管道，我们可以通过Docker-Compose启动我们的容器，开始使用PromQL刮取记录的Metric值并提取我们的ML指标。使用PromQL结构和一个很大的白板，我想出了以下查询：</p>
</li>
<li><p><img src="/img/wuweiwu/ml/model_monitor_translate/cmp.png"></p>
</li>
<li><p>在ML SLI中使用PromQL有几个问题：</p>
</li>
<li><p><strong>不正确性</strong>。当我第一次运行查询的准确性时，我很惊讶，结果并不完全准确（哈哈）。这是因为我的搜刮间隔是15秒，这对于我产生新预测的速度来说太大了。把搜刮间隔缩短到5秒，提高了查询的精确性，但使Prometheus容器的速度变慢，消耗更多的内存和计算资源。</p>
</li>
<li><p><strong>滑动窗口的挑战</strong>。即使在几个小时后，我也无法弄清楚如何在固定的窗口大小上计算前3个指标中的任何一个（交叉成分）。我没有发现关于在滑动窗口上计算PromQL中的连接的资源。我不太擅长使用Prometheus，所以请让我知道是否有可能通过窗口计算这些指标。</p>
</li>
<li><p><strong>复杂的查询</strong>。表中的最后3个指标（单成分）并不像前3个（跨成分）那样错综复杂。我不会期望任何数据科学家编写这些跨组件的PromQL查询，特别是对于那些简单地调用scikit-learn模块的函数。一个理想的监测工具应该允许用户将自定义的Python函数作为指标传入，并在后端有效地产生这些指标的值。</p>
</li>
</ul>
<h2 id="查询延时"><a href="#查询延时" class="headerlink" title="查询延时"></a>查询延时</h2><ul>
<li>在本小节中，我将重点讨论延迟问题，特别是跨组件查询的延迟。为了计算类似SLI的准确性，如上一小节所示，我们需要对output_id做一个连接。这是对Prometheus的严重滥用，因为output_id的cardinality显然会随着ML管道的预测数量而增长。<strong>Prometheus并不是为了处理高卡数的标识符，更不用说高卡数的连接了。</strong></li>
<li>为了证明Prometheus的扩展性有多差，我设计了一个小型的Postgres后端，将预测和反馈放在以时间戳为索引的表中。我计算了PromQL和PostgreSQL的准确度，并测量了与管道产生的预测数量有关的延时：</li>
<li><img src="/img/wuweiwu/ml/model_monitor_translate/querylatency.png"></li>
<li>图3：ML查询的延迟。</li>
<li>由于Prometheus度量值不是急于计算的（也就是说，当用户想在Grafana上查询或绘制一段时间的度量值时，它们都会被计算出来）、<strong>这种延迟是不可接受的，而且不能扩展。</strong> 随着更多预测的产生，许多想要跟踪实时ML SLI的组织可能无法足够快地更新或刷新他们的SLI。也许在某些领域，每天甚至每小时计算一次SLI可能就足够了，但对于数据和用户偏好经常变化的领域来说，这就不适用了。我知道我在使用Prometheus的情况下，它并不是为之设计的，但总的来说，这些问题共同突出了企业的需要：（1）有一个ML监控团队，在Postgres或现有的DBMS之上创建一个层，或者（2）利用一个专门用于ML监控的专有供应商。我相信，现在、<strong>我们需要更好的ML监测实践和工具。</strong></li>
</ul>
<h2 id="回顾总结"><a href="#回顾总结" class="headerlink" title="回顾总结"></a>回顾总结</h2><ul>
<li><p>在这篇文章中，我强调了使用Prometheus进行ML监控的一些主要隐患，最明显的是：</p>
</li>
<li><p>需要使用多个普罗米修斯公制类型进行跨组件监测</p>
</li>
<li><p>需要提前定义直方图桶以进行单组件监控</p>
</li>
<li><p>查询结果的正确性取决于搜刮时间间隔</p>
</li>
<li><p>无法处理滑动窗口</p>
</li>
<li><p>看起来很恶心的PromQL查询</p>
</li>
<li><p>跨组件指标的高延迟（即高cardinality连接）。</p>
</li>
<li><p>在这个系列的下一篇也是最后一篇文章中，我将讨论建立一个通用的ML监控工具的一些关键要求和想法。我非常高兴能与大家分享，同时还有一个监测实时ML SLI的原型。更多的内容将陆续推出，新年快乐!</p>
</li>
<li><p>感谢Divyahans Gupta, Preetum Nakkiran, 和Peter Schafhalter对许多草案的反馈。</p>
</li>
</ul>
<hr>
<h2 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h2><ol>
<li>这个帖子是针对ML工程师和信息员的。我建议对数据库（如表、连接、索引）、ML SLI（如准确性、精确性、召回率）和查询语言（如SQL、PromQL）有基本认识。</li>
<li>我用大写的Metric来指代Prometheus Metric的抽象概念。</li>
<li>我为预测和反馈选择了Gauge Metric，因为它们表示可以上升或下降的数值。由于反馈和推理组件在ML管道中通常是相互分离的，所以真的没有办法（我能想到的）避免连接。</li>
<li>如果这些查询是错误的，我也不会感到惊讶。如果有错误，请纠正我。</li>
<li>也许这不是一个失败的模式–我只是想不通。如果我错了，请让我知道!</li>
</ol>
]]></content>
      <categories>
        <category>技能-修行-进步-MLOps</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>MLOps</tag>
      </tags>
  </entry>
  <entry>
    <title>Steve Jobs&#39; 2005 Stanford Commencement Address</title>
    <url>/2023/07/20/%E8%AE%A4%E7%9F%A5-%E4%BF%AE%E8%A1%8C-%E5%B9%B3%E8%A1%A1/SJobs_speech2005/</url>
    <content><![CDATA[<h1 id="【BibiGPT】AI-课代表一键总结：Steve-Jobs’-2005-Stanford-Commencement-Address"><a href="#【BibiGPT】AI-课代表一键总结：Steve-Jobs’-2005-Stanford-Commencement-Address" class="headerlink" title="【BibiGPT】AI 课代表一键总结：Steve Jobs’ 2005 Stanford Commencement Address"></a>【BibiGPT】AI 课代表一键总结：<a class="link"   href="https://b.jimmylv.cn/watch?v=UF8uR6Z6KLc" >Steve Jobs’ 2005 Stanford Commencement Address<i class="fas fa-external-link-alt"></i></a></h1><p><img src="//i.ytimg.com/vi/UF8uR6Z6KLc/maxresdefault.jpg" alt="Steve Jobs&#39; 2005 Stanford Commencement Address"></p>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>这篇演讲是斯蒂夫·乔布斯在2005年斯坦福大学毕业典礼上的演讲，他分享了生活中的三个故事，讲述了连接点、爱与失去以及死亡对他人生的影响。</p>
<h2 id="Highlights"><a href="#Highlights" class="headerlink" title="Highlights"></a>Highlights</h2><ul>
<li>🧩 斯蒂夫·乔布斯分享了自己在大学期间的经历，强调了在人生中寻找兴趣和跟随内心的重要性。<ul>
<li>放弃大学对乔布斯来说是一个重要的决定，让他有机会追随自己的兴趣并最终成功创办苹果公司。</li>
<li>他强调了人们要相信生活中的各个点会在未来连接起来，要相信自己的直觉和命运。</li>
</ul>
</li>
<li>💔 乔布斯分享了自己被苹果公司开除的经历，但这一打击成为他生命中的转折点。<ul>
<li>这次挫折让他重新开始，创办了NeXT和Pixar，成功走上创业之路，并找到了真正热爱的事业和妻子。</li>
<li>他认为被开除是最好的事情，因为它使他从成功的重压中解放出来，重新成为一个创业者，实现了人生的突破。</li>
</ul>
</li>
<li>⏳ 乔布斯谈到了死亡的重要性，他说面对死亡能够帮助人们做出人生中重要的选择。<ul>
<li>死亡是生命中不可避免的事实，但乔布斯认为它是生活中最好的发明，它清除旧有，为新事物让路。</li>
<li>死亡的意识能够使人们摆脱外界的影响和束缚，追随内心和直觉，去做自己热爱的事情。</li>
</ul>
</li>
<li>🌟 乔布斯引用了《全地球目录》的后封面，给新毕业生们留下了鼓舞的寄语。<ul>
<li>“Stay hungry, stay foolish”（保持渴望，保持愚蠢）成为乔布斯的人生座右铭，鼓励人们在生活中保持好奇心和冒险精神。</li>
<li>乔布斯希望毕业生</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>认知-修行-平衡</category>
      </categories>
      <tags>
        <tag>Steven Jobs</tag>
        <tag>GPT视频总结</tag>
      </tags>
  </entry>
  <entry>
    <title>桥水基金Ray Dalio给年轻人的建议</title>
    <url>/2023/07/20/%E8%AE%A4%E7%9F%A5-%E4%BF%AE%E8%A1%8C-%E5%B9%B3%E8%A1%A1/advice4young_raydalio/</url>
    <content><![CDATA[<ul>
<li><a class="link"   href="https://youtu.be/GDuXvOs0d_k" >Ray Dalio - Modern Wisdom, youtube<i class="fas fa-external-link-alt"></i></a></li>
</ul>
<ol>
<li><p>了解自己的天性，性格，原动力是什么。可以通过pricipleyou.com测试</p>
</li>
<li><p>去学习，去经历，去反思。<br>(1). Ray Dalio的进步公式：痛苦pain + 反思reflection &#x3D; 进步progress<br><img src="/img/wuweiwu/methology/5steps.png"></p>
</li>
<li><p>培养自己的远见<br>(1). 理解发生的事情-&gt;发现事情的周期-&gt;获得自己的观点-&gt;清楚自己在周期中的位置-&gt;了解自己的生命周期<br>(2). 佛曰：成住败空，Anything has a cycle.</p>
</li>
<li><p>如何在动乱不安的世界中寻找慰藉？<br>(1). 活在当下，知足常乐，回归自然，冥想🧘</p>
</li>
</ol>
]]></content>
      <categories>
        <category>认知-修行-平衡</category>
      </categories>
      <tags>
        <tag>人生建议</tag>
      </tags>
  </entry>
  <entry>
    <title>常霖法師講-學佛修行信願行</title>
    <url>/2023/03/18/%E8%AE%A4%E7%9F%A5-%E4%BF%AE%E8%A1%8C-%E5%B9%B3%E8%A1%A1/buddism/</url>
    <content><![CDATA[<h2 id="一、信：眾生皆可成佛，包含世界萬物，一草一木。"><a href="#一、信：眾生皆可成佛，包含世界萬物，一草一木。" class="headerlink" title="一、信：眾生皆可成佛，包含世界萬物，一草一木。"></a>一、信：眾生皆可成佛，包含世界萬物，一草一木。</h2><ul>
<li><a class="link"   href="https://youtu.be/UQiJj-gldWw" >【淨薈主辦】常霖法師講「學佛修行信願行」之一: 信 - YouTube<i class="fas fa-external-link-alt"></i></a></li>
<li>佛偈：<ul>
<li>人生難得今已得，佛法難聞今已聞；</li>
<li>此身不向今生度，更待何生度此身？</li>
</ul>
</li>
<li>世间万物必经阶段：成住坏空</li>
<li>佛曰：眾生皆苦，都有很多不完美，很多缺憾，所以我們需要修佛。</li>
<li>學佛是學習與自己的心相處，修佛是提升自己的覺察力，成佛是成為更好的自己，每個人心中都有一個佛陀，我們需要不斷進行修行，成為自己的佛陀，才能擺脫六道輪迴，進入西方極樂世界。</li>
<li>六道輪迴：天道，地道，人道，餓鬼道，地獄道，阿修羅道。只有在人道才能進行修行。</li>
</ul>
<h2 id="二、愿"><a href="#二、愿" class="headerlink" title="二、愿"></a>二、愿</h2><ul>
<li><a class="link"   href="https://youtu.be/TupysCEEJHA" >【淨薈主辦】常霖法師講「學佛修行信願行」之二: 願 - YouTube<i class="fas fa-external-link-alt"></i></a><br>1、 佛缘 -&gt; 佛愿，由因-&gt;果，被动-&gt;主动，清楚自己想要什么，愿意做，并且坚持做，直到达成所愿。</li>
</ul>
<h2 id="三、行"><a href="#三、行" class="headerlink" title="三、行"></a>三、行</h2><ul>
<li><a class="link"   href="https://youtu.be/Qizh3j_GPG4" >【淨薈主辦】常霖法師講「學佛修行信願行」之三: 行 - YouTube<i class="fas fa-external-link-alt"></i></a></li>
<li>一念一动一缘生</li>
<li>学佛，学菩萨<ul>
<li>观世音菩萨，喜欢帮助众生</li>
<li>地藏菩萨，没有什么做不了的事情，有心者事竟成</li>
<li>逆行菩萨，针对你搞你，但是在这个过程中你可以学习和进步，最终其实是帮助你</li>
</ul>
</li>
<li>打座是提升你的觉察力</li>
<li>一切都是最好的安排</li>
</ul>
]]></content>
      <categories>
        <category>认知-修行-平衡</category>
      </categories>
      <tags>
        <tag>佛学</tag>
      </tags>
  </entry>
  <entry>
    <title>人生建立系统，而不是目标</title>
    <url>/2024/03/10/%E8%AE%A4%E7%9F%A5-%E4%BF%AE%E8%A1%8C-%E5%B9%B3%E8%A1%A1/build-system-not-goal/</url>
    <content><![CDATA[<h2 id="人生建立系统，而不是目标"><a href="#人生建立系统，而不是目标" class="headerlink" title="人生建立系统，而不是目标"></a>人生建立系统，而不是目标</h2><p>| 目标有助于确定你的方向，而系统最有助于取得进展。- James Clear 《原子习惯》作者</p>
<ul>
<li><h2 id="什么是系统？"><a href="#什么是系统？" class="headerlink" title="什么是系统？"></a>什么是系统？</h2></li>
<li><h2 id="什么是目标？"><a href="#什么是目标？" class="headerlink" title="什么是目标？"></a>什么是目标？</h2></li>
</ul>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a class="link"   href="https://www.youtube.com/watch?v=RppBZk7OvDM&t=224s&ab_channel=NebulaPKM" >一个将改变你生活的观点，建立系统而不是目标-Neula PKM<i class="fas fa-external-link-alt"></i></a></li>
<li><a class="link"   href="https://book.douban.com/review/15425706/" >豆瓣笔记-强烈推荐我的改命之书：《我的人生样样稀松照样赢》<i class="fas fa-external-link-alt"></i></a></li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-平衡</category>
      </categories>
      <tags>
        <tag>建立系统</tag>
      </tags>
  </entry>
  <entry>
    <title>任正非：让工程师成为技术商人</title>
    <url>/2023/07/20/%E8%AE%A4%E7%9F%A5-%E4%BF%AE%E8%A1%8C-%E5%B9%B3%E8%A1%A1/be-a-bussinessman/</url>
    <content><![CDATA[<h2 id="第一节：概述"><a href="#第一节：概述" class="headerlink" title="第一节：概述"></a>第一节：概述</h2><ul>
<li>进入21世纪以来，市场导向已经成为绝大多数企业尤其是高科技企业的共识。但是，正如赵本山在央视春晚的小品里的表演一样：“感谢CCTV，感谢MTV，感谢TV……”然而他并不知道他嘴里说的这一大堆TV到底是什么？就像很多企业并不知道真正的市场导向是什么一样，因此，市场导向无法真正落实，空喊口号就成了大多数中国高科技企业的通病。</li>
<li>例如，由于缺乏真正了解市场的职能和手段，无法找到充分了解市场状况和客户需求的集成的市场营销方法，很多企业只能照顾到眼前的利益，企业经营是远远落后于市场的，客户不断流失，满意度日益降低，甚至犯了方向性的错误。</li>
<li>又如，随着企业的不断成长和业务的多元化，不可避免的使得产品组合和业务模型变得愈加复杂。这导致很多企业在产品开发方面反应开始变得迟缓，日益与市场脱节，运作效果和效率明显降低。</li>
<li>再如，由于客户需要的是一个系统的解决方案，高科技企业不可避免的从产品&#x2F;技术向服务转型，很多中国的高科技企业没有及时认识到这一点，不得不面临被整合甚至被淘汰的命运。</li>
<li>在种种困难和阵痛面前，企业界进行了不停的探索，其中，中国高科技企业中当之无愧的标杆——华为——率先多年寻求到了业界最佳的业务管理模型，就是建立端到端的流程，从了解市场到产品开发，再到生命周期管理，流程中的每一步都是由客户的输入牵引的，每一步都直接面对客户。<br>这种业务管理模型的核心就在于它帮助企业找到了一个最佳平衡点，即既要保持技术的领先，更要确保技术在商业运作上的成功，我们称之为技术商业化。在这个大变革、大转型中，华为总裁任正非提出了鲜明的口号：<span style="color:red">
让工程师成为技术商人！
</span></li>
<li>在全球领域，如IBM、微软等世界级领袖企业,也早就将技术商业化作为公司的战略付诸实施：<ul>
<li>IBM——从思考到服务，让技术走向市场，让技术满足市场与客户需求；</li>
<li>微软——人才战略：只找既懂技术又懂经营的精英人士。</li>
</ul>
</li>
<li>那么，这些领袖企业为什么不约而同的选择了这一路径，其内涵究竟是什么，它们又是如何做到这一点的？</li>
</ul>
<h2 id="第二节：技术领先企业，为何难逃衰退厄运？"><a href="#第二节：技术领先企业，为何难逃衰退厄运？" class="headerlink" title="第二节：技术领先企业，为何难逃衰退厄运？"></a>第二节：技术领先企业，为何难逃衰退厄运？</h2><ul>
<li>进入21世纪的前后一段时间，企业界发生了一次不可抗拒的洪流，就是那些曾经依靠技术取得领先的企业，试图继续带着技术领先的优势进入21世纪时，几乎不约而同地步入了衰落甚至消亡。</li>
<li>20世纪90年代的贝尔实验室和蓝色巨人IBM可以说是其中的典型。贝尔实验室代表了一个技术导向的顶尖研发机构的没落，IBM则代表了一个技术导向型的领袖企业的没落——它们的经历有着惊人的相似：依靠技术取得空前的成功，曾经非常富有，把技术的重要性摆在市场前面，以及缺乏把技术市场化的动力和能力，最终不约而同的步入没落。</li>
</ul>
<h3 id="一、贝尔实验室：从翘楚到房地产商的猎物"><a href="#一、贝尔实验室：从翘楚到房地产商的猎物" class="headerlink" title="一、贝尔实验室：从翘楚到房地产商的猎物"></a>一、贝尔实验室：从翘楚到房地产商的猎物</h3><ul>
<li>贝尔实验室的名气，无人不晓，在过去的近一个世纪里，贝尔实验室有11位科学家在诺贝尔奖中榜上有名，其中有位科学家验证了“宇宙大爆炸”理论。这里诞生过镭射，光纤、卫星通讯、调制解调器、太阳能电池、电子麦克风和数字式计算机等。虽然贝尔实验室获得了无数殊荣，它自身却几乎没有将相关科研成果应用到市场上并获利。AT&amp;T几乎垄断了电话通讯业务，因此钱多得数不过来。一点都不缺钱的贝尔实验室经理们从来都没有将新技术商业化的动力，进而也失去了这种能力。因此，长期以来，贝尔实验室的科研活动没有走出实验室，相关的科研成果不能及时转化为市场需要的东西。但是，美国电话电报公司1984年进行了拆分，后来朗讯科技于1996年从美国电话电报中剥离出去，从此贝尔实验室进入了动荡时期。在科技电讯业泡沫破灭及公司产品需求下降后，朗讯科技削减了对贝尔实验室的资助。人们理所当然的认为贝尔实验室将一如既往地充当商业技术研究的翘楚，然而随着母公司在市场竞争的一系列不利，实验室慢慢的丧失了影响力。研究项目逐项被砍掉，科学家相继离去，这个全球闻名的实验室变得人去楼空，“如今，贝尔实验室的走廊到处都黑乎乎。在走廊里随便看看，有一大堆的空屋子”，以至于成为房地产商收购的猎物。</li>
</ul>
<h3 id="二、IBM：带着思考走向悬崖"><a href="#二、IBM：带着思考走向悬崖" class="headerlink" title="二、IBM：带着思考走向悬崖"></a>二、IBM：带着思考走向悬崖</h3><ul>
<li>在IBM成立早期，老华尔森为IBM定下了一个口号“思考”，以此作为IBM的精神。这个口号引导了IBM人对科学技术的不懈探索，激起了一代又一代IBM人的技术热情。<br>带着这个口号，IBM从20世纪50年代进入计算机行业，并于80年代登上辉煌的顶峰，蓝色巨人一路高歌，以势如潮水的趋势不断扩张壮大，终于垄断了大型计算机领域。“IBM永远是第一”，IBM人对此确信不疑。</li>
<li>IBM在技术领先的路上一路狂跑，以至于忘记了市场环境的变化。它一味地沉迷于大型计算机市场所获得的成功，对数据设备公司、苹果公司进入个人电脑市场的个人计算机视而不见，并且将中央处理芯片CPU交给了英特尔公司，将DOS操作系统交给了微软，为自己培养了未来最为强大的敌人。</li>
<li>IBM将主要精力集中于对技术的思考的另一个后果是，IBM的组织机构逐步地、远远地脱离了市场，臃肿、反应迟缓、毫无创新精神。</li>
<li>IBM终于错失多次良机，迎来了接二连三的失败，到1992年已经是一发而不可收拾，净损失49．7亿美元，埃克斯引咎辞职，大批员工被裁减。</li>
<li>IBM总部的杰克-贝尔如此描述当时的情形：“我们就要从悬崖上坠落，对此我们却一无所知。”的确如此，即使在IBM跌落到最低谷的时候， IBM人依然是一帮对技术充满了幻想和崇拜的疯子，对于早已到来的外部危机毫无感觉，在一次战略会议上，刚刚入主IBM的郭士纳发现，那些高级经理们在会议上使用的技术行话、缩略语以及晦涩的术语，足以让任何人晕倒，以至于郭士纳置身其中的时候，发现身为总裁的自己纯属多余，“我宁可变成墙上的一只苍蝇”。</li>
<li>郭士纳重振IBM的最重要举措，就是改变IBM的这种技术至上的文化，他提出了一个新的口号——“服务”。从思考走向服务，代表着IBM从技术走向市场，对技术商业化的坚定决心。</li>
<li>贝尔实验室和IBM这两个不同领域的翘楚，以同样的方式取得成功，也以同样的方式衰落下去，它们身上浓缩了最近几十年来单纯依赖旧的商业模式（仅仅把成功建立在技术或产品的基础上）取得成功并不可避免的进入衰败的一代企业的经历。列在它们身后的企业名单还有很长，包括：通用汽车、加拿大北电网络、中国巨人电脑、大唐电讯…….</li>
<li>IBM比贝尔实验室幸运的是，它提前了十年采取行动，而韩国人金锺勋(Jeong Kim)接管贝尔实验室，成立“技术商业化”小组，提出让实验室振兴的计划时，已是2005年。</li>
</ul>
<h2 id="第三节-技术商业化模式的兴起"><a href="#第三节-技术商业化模式的兴起" class="headerlink" title="第三节 技术商业化模式的兴起"></a>第三节 技术商业化模式的兴起</h2><ul>
<li>此消则彼涨。曾经靠技术领先获得优势的企业逐步淡出商业舞台，取而代之的是那些在“技术商业化”方面有着卓越能力的企业。</li>
</ul>
<h3 id="一、微软的崛起"><a href="#一、微软的崛起" class="headerlink" title="一、微软的崛起"></a>一、微软的崛起</h3><ul>
<li>这期间，微软作为其中的代表崛起了。与其说，微软在上世纪90年代的崛起是一个商业神话，不如说，这是新商业模式适应新的市场环境的必然。微软崛起的秘诀：聘用一大批既懂技术又善于经营的高素质人才</li>
<li>说比尔-盖茨是一个电脑技术天才是不准确的，确切的说，他是一个深谙如何利用经营技术的天才。微软在IBM没落的同时崛起，似乎一开始就吸收了IBM的教训，即聘用一大批既懂技术又善于经营的精明的高素质人才来经营公司。微软的管理人员和工程师，似乎和比尔-盖茨是一个模板刻出来的：这些人都深刻理解软件技术以及如何将这种技术转化为市场需要的东西。</li>
<li>如果总裁、管理人员及工程师们真正理解他们的技术和市场，那么，公司就能始终走在别人前面，因此，微软总是能在市场激烈竞争中操作自如，叱咤风云。<br>微软公司为此专门组建了职能交叉的专家小组，以便把这种技术商业化的能力以组织的形式进行强化。</li>
<li>同时，微软不断的向未来进军，不断创新，并且找到了一种令技术的市场价值最大化的办法，即把大规模市场作为目标，开发出了理论上让每个家庭、每个个人均可使用的产品。</li>
<li>从最近二十年的全球经济进程来看，微软崛起的另一层意义在于，它引领了一批新兴企业，正式宣布了一种新的商业模式的诞生（尽管该模式非微软首创），无论是西方，还是东方，我们都可以看到，近20年，那些活跃在市场上，具有旺盛生命力的领先企业身上，都印刻着这种商业模式。</li>
<li>特别需要提起的是，曾一度没落的IBM，一旦真正面对自己的问题，就立刻发起了强大的变革，在技术商业化道路上，演绎了新的神话，重新站起来的蓝色巨人不但夺回了失去的市场，走到了行业的最前端，并且，在商业运作模式上更为成功，还帮助一大批企业构建了世界级水平的组织体系，其中就包括中国的华为公司。后者在短短20年时间里实现了从零到250亿美元的井喷式增长，毫无争议的跨入了世界500强之列，其速度之快，效率之高，堪称奇迹。</li>
</ul>
<h3 id="二、构建技术商业化的组织体系"><a href="#二、构建技术商业化的组织体系" class="headerlink" title="二、构建技术商业化的组织体系"></a>二、构建技术商业化的组织体系</h3><ul>
<li><p>这些新的世界领袖级企业的成功，似乎暗示了一条很重要的商业规律，市场和技术应该是同一个东西，反过来说，如果你不能把它们有机的结合起来，就会在竞争中收获失败。</p>
</li>
<li><p>过去几十年来，我国以市场换技术已经被证明是失败的，其失败就在于，我们误以为市场和技术是两个完全不同的东西，摸石头过河20载后才发现，市场换不来技术，技术也换不来市场。被市场充分接受的技术才是有价值的技术，富有技术含量的市场才是有生命力的市场。</p>
</li>
<li><p>当然，在如此巨大的代价下，也不是完全没有斩获，华为公司就在摸爬滚打中，最终有效地把二者融合起来，成为中国目前唯一一家在市场领域和研发领域同时具有世界级竞争力的企业，并建立了与之对应的组织运作体系。</p>
</li>
<li><p>如果以组织体系的形式对技术商业化模式进行诠释的话，那就是，构建从传统的流线型组织体系到端到端的组织体系。</p>
</li>
<li><p>传统的流线型组织，在工业时代是非常有效的，在今天的知识经济、网络经济环境下，则由于客户需求、市场竞争变化的快速性和不确定性，暴露除了一系列问题：缺乏准确、前瞻的客户需求关注，组织的前端、中端、后端衔接不畅甚至脱节，反复做无用功，浪费资源，造成高成本；没有跨部门的结构化流程，部门流程之间是靠人工衔接，运作过程割裂；组织上存在本位主义各自为政，内耗大；项目计划无效，项目实施混乱等等。</p>
</li>
<li><p>端到端组织流程则从客户需求端出发，到满足客户需求端去，提供端到端服务，端到端的输入端是市场，输出端也是市场。这个端到端非常快捷，非常有效，好比中间没有水库、没有三峡的长江，流程很顺畅。如果达到这么快速的服务，降低了人工成本，降低了财务成本，降低了管理成本，也就是降低了运作成本。其实，端到端的改革就是进行内部最简单的最科学的管理体系的改革，形成一支最精简的队伍。</p>
</li>
<li><p>常山之灵蛇，现代商业组织的榜样</p>
</li>
<li><p>说到这个端对端的组织，最好的比喻，当然是我们大家都熟悉的“常山之灵蛇”，击其首则尾至，击其尾则首至，击其中则首尾俱至。而这条灵蛇的灵，就在于它节节贯通，各个关节配合无间，没有丝毫阻滞，就像没有三峡，没有水库的长江，畅通无阻。这正是现代商业组织需要达到的境界，可以说，这常山之灵蛇，正是现代商业组织的榜样。</p>
</li>
<li><p>我们可以看到，华为的端到端组织，从战略规划，到市场，到产品开发，到销售，到工程交付等等，从头到尾，都是直接面对客户，无疑具备了常山之灵蛇的特点，可以快速应对市场和客户的各种需求和变化。</p>
</li>
</ul>
<h2 id="第四节：技术商业化的必然路径——让工程师成为商人"><a href="#第四节：技术商业化的必然路径——让工程师成为商人" class="headerlink" title="第四节：技术商业化的必然路径——让工程师成为商人"></a>第四节：技术商业化的必然路径——让工程师成为商人</h2><h3 id="一、技术商业化的核心在于工程师"><a href="#一、技术商业化的核心在于工程师" class="headerlink" title="一、技术商业化的核心在于工程师"></a>一、技术商业化的核心在于工程师</h3><ul>
<li>在传统的组织流程里，前端通常是市场销售人员，中端是技术工程师，后端是售后服务人员。<br>很明显，这样的人才结构无法适应端到端的组织流程的要求。因为前面的人不懂技术，后面的人不了解市场变化和客户需求，将前、中、后三节打通的成本非常高，也很难实现。</li>
<li>端对端组织流程的一个重要特点是，工程师存在于在前、中、后三节之中，并发挥核心作用，就像前面提到的常山之灵蛇一样，首、躯干、尾密切协作，共同发挥作用。这些工程师就是新型的商业工程师。</li>
<li>前端的工程师即是售前工程师，包括企业里通常称谓的产品经理、技术支援工程师、方案设计工程师等，其责任是方案营销（包括技术需求了解、技术牵引、方案设计、技术交流）。在这样的组织里，实际上存在两类销售人员，一类即以上所言售前工程师，另一类才是传统意义上的销售人员，负责客户信息和客户关系。</li>
<li>中端的工程师就是我们通常所言的研发工程师。在端到端的组织里，研发工程师与前面讲的售前工程师一样，既懂技术又懂市场。好比我们在前面微软案例里提到的，他们必须是既懂技术懂经营之道的高素质人才；华为的研发工程师也一样，都是从市场上摸爬滚打下来的。</li>
<li>后端的工程师包括工程项目经理、技术服务工程师等。除了传统的技术工作以外，他们还要承担更重要、更贴近客户的职责，包括：项目利润策划、服务产品设计与营销、通过对客户需求的深入了解驱动研发等等。在很多公司，后端的工程师往往被当成没人管的小孩子，但是，在端对端组织里，后端工程师的作用是极为重要的，请留意以下数据：2008年，IBM的服务收入已经占总收入的约70%，华为公司的数据为约30%！</li>
<li>由此可见，端到端组织有效运作的核心，在于工程师。一个组织只有具备上述所说的三类工程师，才有可能真正做到从客户需求端出发，到满足客户需求端去，提供端到端服务，两端直通，没有任何水库的阻滞。一旦建立起这样的组织，则如常山之灵蛇，击其首则尾至，击其尾则首至，击其中则首尾俱至，可以做到以不变应万变，如兵法所云：“其疾如风，其徐如林；侵掠如火，不动如山”。</li>
<li>一言以蔽之，让工程师成为商人！</li>
<li>这是从技术领先型组织蜕变为技术商业化组织的必然路径。</li>
</ul>
<h3 id="二、什么是商业工程师，商业工程师的事业是什么？"><a href="#二、什么是商业工程师，商业工程师的事业是什么？" class="headerlink" title="二、什么是商业工程师，商业工程师的事业是什么？"></a>二、什么是商业工程师，商业工程师的事业是什么？</h3><ul>
<li>让工程师成为商人，就是企业需要造就一大批的商业工程师。<br>任正非则把商业工程师称之为科学商人，意思是对科学技术知识进行商业经营的高素质人才。</li>
<li>简言之，商业工程师就是技术工程师和商人的结合者。</li>
<li>技术和市场、业务和商业经营，对多数人而言，是两个不同截然不同的领域，对人有着截然不同的要求。要同时掌握二者的知识和运作规则，确非易事。一流企业的高明之处就在于它们找到了这样的人才，或者通过某些不寻常的方法把上述两样东西成功的融入到员工身上。</li>
<li>商业工程师的来源通常是企业原有的技术工程师，当需要跨越自身的技术领域，去掌握商业经营这一新领域的知识和运作规则时，其难点主要在于如何成为商人。<br>古人认为商人就是那些能够做到“变贵贱，调余缺，度远近”的人，意即通过对不同地域的有余和不足物资的调剂，把南方的东西运输到北边以较高的价格卖出，在满足人们的要求的同时自己也获利。这里包含了商人定义的两个要点：对市场行情的敏锐把握，以及满足人们的需要。</li>
<li>这个定义放在今天，用于商业工程师身上，依然是非常准确的：对市场行情的敏锐把握，代表了商业工程师必须具备的商业意识；如何满足人们的需要，则代表了商业工程师满足客户需求的商业技能。</li>
<li>因此，技术工程师转化为商业工程师，其要点就在于如何具备商业意识和商业技能。</li>
<li>我们不主张如社会有些观点所言，把商业或商人等同于一味追逐利润，实践证明，那些把利润放在第一位而漠视社会民众真正需求的企业，如安然等，其成功终究是昙花一现，社会最终会选择放弃它们，因此不足以为代表，这种企业也缺乏延续的根基。正如管理大师德鲁克所言，企业存在的目的是为了满足社会的某些需要，因此确切的说，企业并不存在利润，利润只是企业正确的履行了责任之后的一个自然的结果。刻意地、不计手段地追逐利润，其结果必会适得其反。</li>
<li>从事业的角度讲，无论个人还是企业，不关赚多少钱，获取多少利润，并不代表就成功了，或者说事业有成了。所谓事业，不是个人，也不是一个单个组织的所谓成功，而在于其对社会的贡献程度。孔子在《易经-系辞》对事业做了非常贴切的定义：举而措之天下之民，谓之事业。就是你做的事情对天下人们都有利益，才能算事业。对于商业工程师而言，凭借自己对技术和市场的双重了解，从社会的真实需求中来，到真正满足人们的需求中去，做到了这两点，就算是在做事业。我们今天的社会，在技术主导、商业利润主导下，已经走了很远很偏了，其结果就如我们今天经历的，我们制造了一切我们所能想象和制造的东西，社会资源以飞快的速度在浪费着，日益枯竭，污染加剧；在以商业利润为基础的剧烈竞争下，人文环境也日益恶化，如今的社会整体环境日益不适合人居。了解社会的真实需求，真正满足人们的需求，既是商业工程师群体的事业，也是一份使命。</li>
</ul>
<h3 id="三、商业工程师的诞生：以技术为主体开展市场营销的优势"><a href="#三、商业工程师的诞生：以技术为主体开展市场营销的优势" class="headerlink" title="三、商业工程师的诞生：以技术为主体开展市场营销的优势"></a>三、商业工程师的诞生：以技术为主体开展市场营销的优势</h3><ul>
<li>华为、微软、复兴后的IBM等领袖企业的成功的同时，也完成了对企业最核心的人力资源即工程师的全新定义，传统的技术工程师成为了新型的商业工程师。<br>新型的工程师们也改变了市场营销的模式，尤其是在高科技行业。<br>在商业工程师诞生以前，企业市场营销的主体通常是营销人员；现在，市场营销的则以技术为主体展开。<br>以技术为主体展开市场营销有着传统营销无可比拟的优势。要之，有以下三点：</li>
<li><ol>
<li>真正把握市场和理解客户需求<br>技术工程师从公司内部走向市场，走向客户，会同销售人员一起，可以实现对市场需求和客户需求的真正了解。<br>高科技行业的营销不同于快速消费品营销，是解决方案的营销，具有非常高的技术含量，专业性强，要求前端的人员具备从解决方案的角度对客户需求有深刻理解的能力。当前很多高科技企业还没有完成营销模式的转型，常遇到的情况是，客户在前期往往对自己的需求未必能描述清楚，传统的销售人员又不懂技术，对企业内部的运作不甚了解，最擅长做的事情就是请客户吃饭、洗脚、打球、培训、旅游，先签下单再说，二者碰到一起，往往是瞎猫撞死耗子，签下的合同无法执行，研发说版本出不来，采购说货到不了，财务说没有现金流……甚至签下一些非常怪异的合同。<br>你见过要服务一辈子的合同吗？<br>有一家高科技企业，由于销售人员缺乏对工程服务知识和产品生命周期的理解，在与客户所签订的合同里，注明的服务期限竟然是永久。最后再加上公司内部合同审核环节的疏忽，该公司于是与客户签订了承诺服务一辈子的合同！</li>
</ol>
</li>
<li><ol start="2">
<li>最低成本运作<br>以技术为主体展开营销，企业的营销队伍其实是由两部分组成的，一部分就是传统的销售人员，负责客户关系，一部分就是我们说的商业工程师，他们往往是研发技术或工程技术出身，对产品、解决方案有着非常透彻的了解。这两个队伍一起参与营销，从不同的角度同时与市场、客户进行深入接触，既能做到对市场趋势的准确把握，又能深刻了解客户的个性化需求，因此可以做到一开始就做正确的事情，并且一次把事情做对，相对于多数企业十次八次反反复复还不能把事情做好，这在很大程度上既节约了社会资源，也节约了企业内部资源，可以做到最低成本运作。</li>
</ol>
</li>
<li><ol start="3">
<li>通过技术引导，达到不战而胜<br>兵法云：“胜兵，先胜而后求战”，战争的胜负不是在战场上决定的，而是在战前决定的，战前的人心向背、地形、敌我之众寡、将能与不能等因素，已经在战前就宣布了战争的胜负。历史上有名的淝水之战、官渡之战、赤壁之战等等，几乎是“胜兵，先胜而后求战”的同一个版本。<br>销售也是一样，从一个长期来看，签单往往不是在招标会上决定的，标前的一系列工作，如参展、标准引导、软文宣传、样板店、专家讲座等等，这一系列的工作，在无形中，已经让客户形成了决策。而这种引导，客观上也让客户变得更专业，可以提前做出一些业务规划方面的预测或决策，有利于形成供需双方的良性理解和良性循环。<br>反之，如果没有这些技术引导的工作，公司的销售就会陷入无休止的抢单，天天救火，疲于奔命，这恰恰是当前大多数企业的现状。<br>商业工程师积极参与市场工作，充当销售的先锋、主力，就是要让企业打有准备的仗、打胜利的仗，避免以大量资源消耗为代价的恶性竞争。<br>华为在全球布置了数千名售前工程师，他们准确地把握了海外市场的真实需求，提前做好了一系列的铺垫工作，正是他们让华为2007年、2008年的爆炸式增长成为可能，并且支撑了华为未来3-5年1000亿美金的市场。</li>
</ol>
</li>
</ul>
<h2 id="第五节-华为技术商业化之路——造就商业工程师"><a href="#第五节-华为技术商业化之路——造就商业工程师" class="headerlink" title="第五节 华为技术商业化之路——造就商业工程师"></a>第五节 华为技术商业化之路——造就商业工程师</h2><ul>
<li>自中国企业进入世界经济体以来，道路就极为曲折、艰辛，并且真正获得成功的企业非常少。尤其是在代表一国经济核心竞争力的高科技行业，中国的绝大多数高科技企业其实缺乏真正的技术含量，即使少数企业具备了自主研发的能力，也因为缺乏对商业运作知识和规则的理解而在走向世界的路上举步维艰。</li>
<li>中国的国有企业，由于资源便利，加上体制的原因，缺乏自力更生的动力，大多民营企业，则先天基础薄弱，在种种条件的挤压下，往往成长乏力。</li>
<li>在这种背景下，在一些缺乏资源支持，竞争极为残酷的地区（如深圳），一些企业经过艰苦卓绝的奋斗，在与世界级企业的贴身肉搏和学习过程中，率先成长起来，具备了在世界舞台上与西方企业共舞的能力。华为公司就是其中一个，它用短短20年的时间，在没有任何外部资源可依赖的条件下，自力更生，从一无所有到250亿美元，成为目前中国唯一一家在研发、市场两个领域同时具备世界级竞争力的企业，并且，它的成功绝非偶然，通过市场管理流程（MM）、集成产品开发流程（IPD）、任职资格体系的建设，在机制和人才两方面都具有了核心竞争力。</li>
<li>在华为的核心竞争力中，数量庞大的商业工程师队伍尤其是核心中的核心。因为西方的高科技企业巨头早已完成了商业工程师队伍的建设，因此能在全球市场叱咤风云，而中国的高科技企业，在该方面还只是刚刚起步。在很多企业还在概念、摸索、尝试阶段时，华为公司已经率先数年系统、完整地建立起了这支队伍，成为其在国内外市场称雄的秘密武器。</li>
<li>下面，我们就以华为公司为例，看看在华为的技术商业化进程中，商业工程师队伍是如何建立起来的。</li>
</ul>
<h3 id="一、“最幼稚的研发部门”"><a href="#一、“最幼稚的研发部门”" class="headerlink" title="一、“最幼稚的研发部门”"></a>一、“最幼稚的研发部门”</h3><ul>
<li>到９０年代中期的时候，华为在国内市场已经取得了空前的成功，但是也曝露出一系列的问题，产品品质不稳定，交付周期长，维护成本高，过于依赖人海战术等等，这种在国内成功的模式，根本无法在国际上立足，而如果无法走出国门，通讯行业的残酷竞争将很快把华为打回原形，华为再次面临生死抉择。华为将进行的变革的所有方面，几乎都与研发队伍有关。<br>而当年华为的研发部门，从组织体系上讲，一片迷茫和混乱；从研发工程师个体上讲，一方面如郭士纳曾描述过的IBM人，充满了自信、狂热、执着，另一方面，又如任正非描述的，像刚从青纱帐走出来的土八路，浑身是土，一点也不职业化，对面临的国际化竞争不知所措。<br>任正非曾把研发部门描述成华为最幼稚、管理最差的部门。从当年“研发部门发放呆死物料、机票”活动及一系列的反思批判会上可见一斑。<br>为了使华为研发人员能够铭心牢记“从对科研成果负责转变为对产品的市场成功负责”这句话，华为在年终将把库房里的呆滞物料打成一个个包，发给研发人员做奖状。把用户中心的飞机票（为了维修而导致的大量往返），也打成一个个包，发给中研人员做奖状，让他拿回家去对亲人说是自己得的浪费奖！<br>任正非在会议上阐述他对“从对科研成果负责转变为对产品市场成功负责”这一口号的理解：<br>“对待产品也要像对待你的儿子一样”<br>“现在在座的所有的人都必须对产品的市场成功负责，产品犹如你的儿子，你会不会只是关心你儿子的某一方面？你不会吧。一个产品能生存下来，最重要的可能不是它的功能，而只是一个螺丝钉，一根线条，甚至一个电阻。因此，需要你对待产品也要像对待你的儿子一样。”<br>结合这次活动，研发部人员举办了反思批判会，其中详细记载了华为研发的不少“幼稚”故事，而通过对这些幼稚做法的自省，华为人的思维受到的根本性的触动。兹举几例：<br>你到底是研发工程师还是售后工程师？<br>因为产品质量经常出问题，研发工程师需要在国内各城市不断穿梭往返现场解决问题，有些人几乎把天上的飞机都坐遍了。一次，某位研发工程师对一位新来的没怎么出过差的同事吹嘘，他对各种飞机型号和性能的熟练程度，结果该同事反唇相讥，“我还以为你是做售后服务的，真不敢相信，你居然是一个开发人员，是不是国内的研发都这个样子？”<br>上海市话局某部长的牢骚<br>上海市话局的某部长对华为研发的评价：“我对你们的产品很不满意，特别是对你们的态度很不满意，你们总以为你们的产品很先进，总以为是我们的维护人员水平低才出的问题。国外的机器也出问题，但是人家几个小时就定位出来，你们是东派一个高手，西派一个高手，不晓得要多少天才能定位出来……”<br>“亩产十万斤”的华为软件工程师<br>印度高级软件师每人月可以编写300行代码，华为的数据则是10000-20000行，结果就是印度的软件很稳定，华为的软件则漏洞百出……<br>就是在这样反思和批判中，华为人，特别是技术工程师们的头脑中，一种新的思维方式逐渐的孕育起来。华为技术工程师的商业意识也逐步形成。</li>
</ul>
<h3 id="二、卖出去的技术才有价值——研发是地狱之门"><a href="#二、卖出去的技术才有价值——研发是地狱之门" class="headerlink" title="二、卖出去的技术才有价值——研发是地狱之门"></a>二、卖出去的技术才有价值——研发是地狱之门</h3><ul>
<li>任正非对公司的研发做了一个形象的比喻：研发是地狱之门。一个公司的研发水平高还是不高，都非常有可能进入地狱，万劫不复。公司研发水平高，一方面意味着很大的投入，也许在没有收回成本以前就死掉了；另一方面，研发水平高，代表你的技术非常先进，非常超前，就容易重蹈贝尔实验室之辙，也是死路一条；公司的研发水平不高，你拿什么去和人家竞争，结局还是死。可见研发之难。<br>任正非意识到，华为必须保持技术上的优势，但是，如果死抱着一定要做世界上最先进的产品的理想，华为人能不能在市场上生存下来都成问题，就像梵高的“向日葵”，作品固然好，固然价值连城，可那都是在梵高饿死多年后的事情了。因此，华为公司的调整要以商业为导向，而不能以技术为导向，在对技术部门、技术工程师的评价体系中同样一定要以商业为导向。<br>华为的战略由此发生了根本性的变化，即从技术驱动转变为市场驱动，既要保持技术的领先，更要强调技术商业化的能力。坚决不研发“卖不掉的世界顶尖水平”，华为人认为，“卖出去的技术才有价值。”</li>
</ul>
<h3 id="三、培养技术商人而不是培养科学家：华为工程师任职资格体系"><a href="#三、培养技术商人而不是培养科学家：华为工程师任职资格体系" class="headerlink" title="三、培养技术商人而不是培养科学家：华为工程师任职资格体系"></a>三、培养技术商人而不是培养科学家：华为工程师任职资格体系</h3><ul>
<li>要增强公司技术商业化的能力，做到卖出去的技术才有价值，华为的人才战略也必须进行重大转型，那就是，华为必须培养工程商人而不是培养科学家，并且必须大批量培养。<br>围绕成批培养商业工程师的问题，华为开始了新的探索。<br>探索的结果，就是华为必须建立一套国内没有过的、全新的人才培养体系。这套体系以英国的职业资格体系为蓝本，充分吸取IBM、微软等西方企业和日本企业的特点，在结合中国国情的基础上，逐步发育起来了。它就是被任正非称为华为过去十年三大变革的任职资格体系。<br>华为工程师任职资格体系不同于外部的能力体系，它涵盖内容更广、对能力的要求程度更深，更重要的是，它针对具体的职位类的理解非常透彻，是由当初IBM、华为等一批最为顶级的相关领域内的专家，在借鉴最佳实践和华为成功经验上得出来的，因此，决不能把它当成是简单的人才能力体系，确切的说，它是一套关于如何做到业界最佳的最佳组织能力宝典。<br>不同于以往的能力体系，华为的工程师任职资格体系可以说是集采众长，而又独具特色。<br>它首先对每个岗位需要的知识点进行了详细的提炼，每个员工在走向岗位前就知道，自己需要具备哪些知识。<br>其次，它针对不同职位类的特点，建立了对应的素质模型，一开始就选对人，让最合适的人最做合适的事情。关于素质模型，值得一提的是，很多企业认为建员工能力体系，就是建素质模型，这实在是一个很严重的误会。素质，无论如何，都是一个人在走向工作岗位前就已经形成的，所谓江山易改本性难移，素质一旦形成就很难改变，对在岗人员建立素质模型，试图以培训的方式来改变员工素质，无异于愚公移山，也许最终可以移走，但是估计没有几家现代企业就可接受其时间成本。华为建立素质模型，主要是用于岗前的人才选择，以及用作长期培养。例如，从现有的技术工程师中，找出那些具备市场素质的人员，让他们冲到市场一线，完成从技术工程师到售前工程师的转变。<br>正因为素质较难改变的特点，华为从另一个角度来帮助员工能力的提升，这就是专业技能。华为从IBM的请来了操作指导书，针对转变为专业、职业人所需要的专业技能，华为以操作指导书的形式固化下来，并将其尊为圣经，任正非曾公开表示，华为的员工总是认为自己很聪明，自以为是，现在，华为从IBM买来了美国鞋，华为“削足适履”也要适应它。华为工程师的操作指导书，巧妙的将工程师需要的商业意识、商业技能融入到日常的作业行为中，既便于操作，又易于考量。例如，我们无法考量一个售前工程师是否具有良好的商业意识，但是，如果他能够按操作指导书的要求，在拜访客户前详细收集信息，资料准备充分，拜访时提出正确的问题，能根据事前的准备对现场的不同情况做出相对应的调整，拜访后及时总结，提出相应策略，这个过程既培养了他的商业意识，也形成了他的商业技能。如果他能认真遵照有关要求操作，我们就认为他具备了良好的商业意识和技能。<br>华为工程师任职资格标准最重要的一点，就是它从成果出发，对工程师以市场贡献为重点进行考量。在华为的工程师任职资格标准里，对售前工程师、研发工程师、售后工程师，都从市场成果的角度进行了的要求：<br>售前工程师：从被动技术方案设计到主动方案营销，提炼卖点，引导销售成功。<br>研发工程师：关注市场需求，对产品的市场成功负责。<br>售后工程师：从被动服务到主动创造客户价值，营造收费氛围，发现客户需求，拓展服务领域。<br>以上是从大类的角度进行的宏观要求，对于具体到不同类别、不同层级的工程师，华为都规定了非常详细的衡量成果。<br>成果是最可衡量的，也是大家最容易关注到的，正是这一点，真正的把华为工程师从技术工程师转变为商业工程师。<br>在建立工程师任职资格标准的基础上，华为通过培训培训再培训，按照资格要求，开展了大量的商业化课程培训。从华为后来的培训课程设置来看，我们可以看出商业工程师任职资格标准的建立所起到的巨大作用，例如，华为先后对市场人员进行过国学、奢侈品知识培训等，如果不是事先完成了商业工程师的角色转变和相关任职资格标准的建立，任何人都很难想象这些培训课程跟售前工程师们有什么关系，如今，这些课程的设置则更深入的反映了华为在商业化方面的超前思维和务实作风，华为最近几年的巨大成功，足资证明。<br>为了使商业工程师队伍的建设更为迅速、更为有效、更为深入，华为同时也做出了许多相关的配套措施，例如：<br>没有市场一线经验的研发人员不能提拔。<br>公司明确规定，每年必须有一定比例的研发人员走向市场，同时有一定比例的市场人员转做研发；<br>成立战略市场部，主要由技术工程师出身的人员担任其中职责，这些人凭着对技术的敏感，把触角伸到市场的每一个角落，深入了解客户当前和未来的需求，他们成了华为前进过程中的“侦察连”。<br>从市场的角度考核研发人员。评价研发人员，不仅仅是技术、开发周期维度，更重要的是新产品获利、上市周期等指标。<br>……<br>通过这一系列的战略调整，华为的工程师队伍完成了脱胎换骨的变化，华为在技术商业化的路上越走越顺了。其中的两个关键数据最能说明问题，一是，华为在最初打入国际市场的时候，到处碰壁，有些地区甚至长达两三年颗粒无收，最后华为在全球各地派出一支合计1000多人的技术工程师队伍进行市场工作，国际市场的缺口很快就打开了；二是，随着华为国际市场的成功，以及10年来在商业工程师队伍培养方面逐步开花结果，组织人才建设有力地推动了业务增长，华为迎来的业务上的井喷式增长，到2008年达到250亿美元！<br>如果没有早在10年前做出的这一系列举措，以及长期不懈的坚持，很难想象华为会有今天的巨大成功。<br>中国不缺乏技术人才，缺乏的是商业化环境下的产品研发工程师、售前工程师、售后工程师。一个企业的工程师商业化水平决定了这家企业的市场竞争力的高低。<br>中国高科技企业成长的障碍就是技术人员商业化问题。当技术人才商业化之后，它的能量将是无限的。摆在绝大多数高科技企业面临的最大挑战，就是如何批量培养商业工程师。</li>
</ul>
]]></content>
      <categories>
        <category>认知-修行-平衡</category>
      </categories>
      <tags>
        <tag>技术商人</tag>
      </tags>
  </entry>
  <entry>
    <title>how to build self discipline(如何自律)</title>
    <url>/2020/02/17/%E8%AE%A4%E7%9F%A5-%E4%BF%AE%E8%A1%8C-%E5%B9%B3%E8%A1%A1/how-to-build-self-discipline/</url>
    <content><![CDATA[<h2 id="Marcus-Aurelius"><a href="#Marcus-Aurelius" class="headerlink" title="Marcus Aurelius"></a>Marcus Aurelius</h2><ul>
<li>hello, you are amazing!</li>
<li><a class="link"   href="https://www.youtube.com/watch?v=njDLNt-1ugM&feature=youtu.be" >YT-How to build self-discipline<i class="fas fa-external-link-alt"></i></a></li>
</ul>
<h3 id="Self-discipline-starts-with-finding-your-purpose"><a href="#Self-discipline-starts-with-finding-your-purpose" class="headerlink" title="Self discipline starts with finding your purpose."></a>Self discipline starts with finding your purpose.</h3><ul>
<li><p>(1) 自律始于找到自己的目标。</p>
</li>
<li><p>Marcus Aurelicus believed that we each have a purpose something that we were created for. It’s our duty to carry out that purpose because it is purpose that gets you out of bed each morining.</p>
</li>
<li><p>马可 奥勒留相信我们每个人生来就有一个目标。实现这个目标是我们的义务，而这个目标是我们每天早上起床的动力。</p>
</li>
<li><p>If you have a clear understanding of your goals and how your task fits within them, you are much more likely to complete it.</p>
</li>
<li><p>如果你对你的目标有一个清晰的认知并且知道如何实施，那么你就更有可能实现这个目标。</p>
</li>
<li><p>The biggest source of self discipline is to have a reason to do the task.</p>
</li>
<li><p>自律的最大动力来源是给自己找到一个完成任务的理由。</p>
</li>
<li><p>If you don’t know what to do, just start. Like if you want to be a programmer, just do the coding every day.</p>
</li>
<li><p>如果你不知道怎么开始，just do it，做简单的事。例如，你想成为一个程序员，那么你每天练习写代码，准没错。</p>
</li>
<li><p>Self discipline is about finding compelling reasons to do something, then commintting yourself to see that task or activity through to the very end.</p>
</li>
<li><p>(总结)自律就是找到一个令你信服的理由去做某件事，然后承诺自己付诸行动并且坚持到最后。</p>
</li>
</ul>
<h3 id="Count-on-yourself"><a href="#Count-on-yourself" class="headerlink" title="Count on yourself."></a>Count on yourself.</h3><ul>
<li><p>(2) 靠自己(全力以赴)。</p>
</li>
<li><p>Ture your desire to stone. Quench your appetites. Keep your mind centered on itself.</p>
</li>
<li><p>把你的欲望变成石头。抑制你的欲望，集中精力在落实上面。</p>
</li>
<li><p>We must be fully committed to doing whatever it takes to get the job done no matter what challenges get in the way.</p>
</li>
<li><p>我们必须全力以赴，无论遇到任何困难险阻。</p>
</li>
<li><p>Self discipline is the ability to set yourself to take action, to do what you need to do. Regardless of your physical, mental, or emotional state.</p>
</li>
<li><p>要自律必须要行动，做你需做的东西。无论你的身体，精神或者情绪是什么状态。一句话，全力以赴。</p>
</li>
<li><p>You can start with forming an effective plan of action that is comprised of a deadline for accomplishing your goal.</p>
</li>
<li><p>为你的目标制定有效的计划，并且设定一个最后期限。</p>
</li>
<li><p>It must also be built on the foundation of mini-milestones that break your goal down into mangeable chunks.</p>
</li>
<li><p>可以把你的目标分解成多个容易管理和预测的迷你小任务(里程碑)。</p>
</li>
<li><p>What you’re ultimately trying to avoid is succumbing to being overwhelmed. Overwhelming can quickly digress to procrastination, and procrastination can, subsequently, lead to stagnation. And, of course, where there is stagnation, self discipline cannot exist.</p>
</li>
<li><p>你应该尽量避免的是自己不给压垮。压垮自己目标就会被拖延，而拖延则会导致停滞不前。当然，停滞不前时则自律也不存在了。</p>
</li>
</ul>
<h3 id="Show-up-every-day"><a href="#Show-up-every-day" class="headerlink" title="Show up every day"></a>Show up every day</h3><ul>
<li><p>(3) 坚持不懈！</p>
</li>
<li><p>We need to show up, every dat. And put in the work.</p>
</li>
<li><p>我们应该每天坚持，认真落实。</p>
</li>
<li><p>Self-Discipline is nothing more but the habit of consistency, finding the motivation to do something again and again until you do it on autopilot and start seeing results.</p>
</li>
<li><p>自律不过是一种持之以恒的习惯，找到重复做某件事的动力，直到你会自动去做这件事并开始看到结果。</p>
</li>
<li><p>A bad day doesn’t have to become a bad week, a bad week doesn’t have to become a bad year.</p>
</li>
<li><p>糟糕的一天不会变成糟糕的一周，糟糕的一周不会变成糟糕的一年。</p>
</li>
<li><p>The moment you wake up, remember that the new day is a new life and move forward by opening your eyes and focusing on what’s in front of you, which is life itself.</p>
</li>
<li><p>你起床的每一天都是你人生新的一天，你要每天保持前进，睁开眼关注你面前的，生活！</p>
</li>
</ul>
<h3 id="Practice-voluntary-hardship"><a href="#Practice-voluntary-hardship" class="headerlink" title="Practice voluntary hardship"></a>Practice voluntary hardship</h3><ul>
<li><p>(4) 培养自愿吃苦(我太南了！)</p>
</li>
<li><p>Voluntary hardship means constantly testing ourselves and by making life routinely uncomfortable in some way.</p>
</li>
<li><p>自愿吃苦意味着要不断考验自己，习惯过一些不是很舒服的日子。</p>
</li>
<li><p>We are hardening ourselves for the day we may live it for real.</p>
</li>
<li><p>我们不断让自己进步，以备真正艰苦的那一天的到来。</p>
</li>
</ul>
<h3 id="Practice-dichotomy-of-control"><a href="#Practice-dichotomy-of-control" class="headerlink" title="Practice dichotomy of control"></a>Practice dichotomy of control</h3><ul>
<li><p>(5) 训练控制二分法</p>
</li>
<li><p>Being distressed, being bothered by small things instantly is terrible for discipline.</p>
</li>
<li><p>容易被小事情困扰对自律来说是非常糟糕的。意味着你的情绪不受自己控制。</p>
</li>
<li><p>Try to apply dichotomy of control.</p>
</li>
<li><p>尝试 利用控制二分法。</p>
</li>
<li><p>Reinforce to yourself what is within your control and what is out of your control.</p>
</li>
<li><p>总结自己能控制什么，不能控制什么。</p>
</li>
<li><p>Try to ask yourself these questions</p>
</li>
<li><p>Do you have a problem in your life ?</p>
</li>
<li><p>No, then don’t worry. </p>
</li>
<li><p>Or yes. </p>
</li>
<li><p>Can you do something about it? </p>
</li>
<li><p>Yes. Then don’t worry.</p>
</li>
<li><p>No again, then don’t worry.</p>
</li>
</ul>
<h3 id="Never-Play-the-victim"><a href="#Never-Play-the-victim" class="headerlink" title="Never Play the victim"></a>Never Play the victim</h3><ul>
<li><p>(6) 永远不要扮演受害者。</p>
</li>
<li><p>Do your job, without whining.</p>
</li>
<li><p>做好你的事情，不要抱怨。</p>
</li>
<li><p>Have you ever said these things ?</p>
</li>
<li><p>I was just born this way.</p>
</li>
<li><p>I never learned anything different.</p>
</li>
<li><p>My parents set terrible example.</p>
</li>
<li><p>Every one else does it.</p>
</li>
<li><p>Those are execuses for you to become better man.</p>
</li>
<li><p>You need to assume responsibility.</p>
</li>
<li><p>你要学会承担责任。</p>
</li>
<li><p>Your life depends on you determing what’s within your control and taking those things into your own hands.</p>
</li>
<li><p>你想过什么生活，取决于你决定你敢承担多少责任或者能控制多少事情。</p>
</li>
<li><p>Be that person who steps in to take action not the one who looks the other way and casts blame.</p>
</li>
<li><p>做一个主动解决问题的人，而不是那个推卸责任的人。</p>
</li>
<li><p>Without a sense of ownership, meaningful progress becomes an impossible task.</p>
</li>
<li><p>没有主人翁精神，有意义的进步就会变成不可能的任务。</p>
</li>
</ul>
<h3 id="Practice-Delayed-Gratification"><a href="#Practice-Delayed-Gratification" class="headerlink" title="Practice Delayed Gratification"></a>Practice Delayed Gratification</h3><ul>
<li><p>(7) 训练延迟满足。</p>
</li>
<li><p>Delayed gratification involves the ability to wait to get what you want.</p>
</li>
<li><p>延迟满足指的是你需要有耐性，等待你想得到的东西。</p>
</li>
<li><p>Put off what we want now so that we can perhaps get something else, something better, later on.</p>
</li>
<li><p>暂时搁置我们现在想要的东西，在未来我们可能得到一些其他的，更好的东西。</p>
</li>
</ul>
<h3 id="Ignore-Naysayers"><a href="#Ignore-Naysayers" class="headerlink" title="Ignore Naysayers"></a>Ignore Naysayers</h3><ul>
<li><p>(8) 忽略反对者。</p>
</li>
<li><p>Naysayers just love to say nay, criticise you, objectify you, oppose you.</p>
</li>
<li><p>反对者只是意味的说不，批判你，反对你。</p>
</li>
<li><p>Don’t hand over your peace of mind to outsiders to disrupt as they please.</p>
</li>
<li><p>不要将你内心的平静交与外人，并且按照他们的意愿去破坏。</p>
</li>
<li><p>You should actively seek honest feedback from those you respect. But if someone just has a history of being a naysayer, ignore them.</p>
</li>
<li><p>你应该积极从你尊敬的人那里获得正面的反馈，但是如果你发现他有naysayer的历史，那么请忽略他。</p>
</li>
</ul>
<h3 id="Find-Wise-People-to-emulate"><a href="#Find-Wise-People-to-emulate" class="headerlink" title="Find Wise People to emulate"></a>Find Wise People to emulate</h3><ul>
<li><p>(9) 效仿有智慧的人。</p>
</li>
<li><p>Identify role models.</p>
</li>
<li><p>寻找你的榜样。</p>
</li>
<li><p>You can ask yourself ?</p>
</li>
<li><p>Who is doing this right now ?</p>
</li>
<li><p>Who has successfully achieved this goal?</p>
</li>
<li><p>Who has successfully mastered this habit ?</p>
</li>
<li><p>Who has successfully made this change ?</p>
</li>
<li><p>Who has the necessary self-discipline in this area ?</p>
</li>
<li><p>What can I learn from this person that can help me along my journey ?</p>
</li>
</ul>
<h3 id="Honestly-review-your-day"><a href="#Honestly-review-your-day" class="headerlink" title="Honestly review your day"></a>Honestly review your day</h3><ul>
<li><p>(10) 诚实的回顾你的一天(feed backs.)。</p>
</li>
<li><p>self-awareness, self-examination, and self-determination.</p>
</li>
<li><p>自我意识，自我反省，自我决定。</p>
</li>
<li><p>One of the best ways to become more disciplined is to scrutinize yourself, and find your weak spots.</p>
</li>
<li><p>一个更自律的方法是审视自己，发现自己的弱点。</p>
</li>
<li><p>Practicing evening retrospections on a consistent basis will allow you to become more self-aware through every step of your day.</p>
</li>
<li><p>坚持每天晚上进行回顾会让你每一天变得更有自我意识。</p>
</li>
<li><p>Ask yourself today </p>
</li>
<li><p>What did I do well ?</p>
</li>
<li><p>Where was my discipline tested ?</p>
</li>
<li><p>What did I do bad ?</p>
</li>
<li><p>How can I improve ?</p>
</li>
</ul>
]]></content>
      <categories>
        <category>认知-修行-平衡</category>
      </categories>
      <tags>
        <tag>自律</tag>
      </tags>
  </entry>
  <entry>
    <title>人类简史/人类发展周期</title>
    <url>/2023/07/19/%E8%AE%A4%E7%9F%A5-%E4%BF%AE%E8%A1%8C-%E5%B9%B3%E8%A1%A1/huamn_his/</url>
    <content><![CDATA[<p><img src="/img/wuweiwu/human_his/human-cycle.png"></p>
<h2 id="狩猎社会"><a href="#狩猎社会" class="headerlink" title="狩猎社会"></a>狩猎社会</h2><ul>
<li>公元前200万年</li>
</ul>
<h2 id="认知革命"><a href="#认知革命" class="headerlink" title="认知革命"></a>认知革命</h2><ul>
<li>公元前5万年到10万年</li>
<li>智人产生，想象力，虚构的神</li>
<li>开始出现了部落社会</li>
<li>大家开始学会了合作，智人的合作事建立在虚构的故事上的</li>
<li>开发并学习使用工具</li>
<li>把其他人种挤出了历史跑道</li>
</ul>
<h2 id="农业革命"><a href="#农业革命" class="headerlink" title="农业革命"></a>农业革命</h2><ul>
<li>公元前1万年前，想要获得更多的蔬果粮食</li>
<li>开始了定居社会，因为农田搬不动</li>
<li>农民的历史总结为一句话：日出而作，日落而息</li>
<li>历史的发展说明：没有平等，公义可言</li>
<li>国家就是一个想象的秩序，人们无法逃离</li>
<li>为什么人们会逃不出呢？<ul>
<li><ol>
<li>现实世界就是一个想象的秩序，如果你打破了秩序，就是打破了现实世界</li>
</ol>
</li>
<li><ol start="2">
<li>人们都有欲望</li>
</ol>
</li>
<li><ol start="3">
<li>主观意志</li>
</ol>
</li>
</ul>
</li>
<li>为什么人们会趋于统一呢？<ul>
<li><ol>
<li>金钱，信用</li>
</ol>
</li>
<li><ol start="2">
<li>帝国</li>
</ol>
</li>
<li><ol start="3">
<li>宗教</li>
</ol>
</li>
</ul>
</li>
</ul>
<h2 id="工业革命"><a href="#工业革命" class="headerlink" title="工业革命"></a>工业革命</h2><ul>
<li>18世纪末，纺织工业新技术革命</li>
<li>19世纪中期，蒸汽和钢铁技术革命</li>
<li>20世纪初，电气和化学技术革命，汽车工业革命</li>
<li>20世纪中叶，人们意识到经济的制高点不在于对现有工业的控制，而是在于创造未来的能力</li>
</ul>
<h2 id="资本革命"><a href="#资本革命" class="headerlink" title="资本革命"></a>资本革命</h2><p>- </p>
<h2 id="科技革命"><a href="#科技革命" class="headerlink" title="科技革命"></a>科技革命</h2><ul>
<li>的</li>
</ul>
<h2 id="未来"><a href="#未来" class="headerlink" title="未来"></a>未来</h2><ul>
<li>生物工程&#x2F;基因工作</li>
<li>仿生工程</li>
<li>无机的生命&#x2F;数字个体</li>
</ul>
<h2 id="快乐是怎么来的"><a href="#快乐是怎么来的" class="headerlink" title="快乐是怎么来的"></a>快乐是怎么来的</h2><ul>
<li>放弃主动追求快乐，因为快乐是一时的，佛教最是支持去快乐，众生皆苦，皆要成佛，去掉贪嗔痴</li>
</ul>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a class="link"   href="https://www.bilibili.com/video/BV1z3411Z7W1/?spm_id_from=333.337.search-card.all.click&vd_source=22a442828b11ac7475c8bd5407da1afb" >B站-1小时看透人类10万年，《人类简史》从动物到上帝<i class="fas fa-external-link-alt"></i></a></li>
</ul>
]]></content>
      <categories>
        <category>认知-修行-平衡</category>
      </categories>
      <tags>
        <tag>人类简史</tag>
        <tag>发展周期</tag>
      </tags>
  </entry>
  <entry>
    <title>问题解决框架</title>
    <url>/2023/07/20/%E8%AE%A4%E7%9F%A5-%E4%BF%AE%E8%A1%8C-%E5%B9%B3%E8%A1%A1/methodology/</url>
    <content><![CDATA[<h2 id="办公室教授"><a href="#办公室教授" class="headerlink" title="办公室教授"></a>办公室教授</h2><p><img src="/img/wuweiwu/methology/office-staff.jpg"></p>
<h2 id="7步工作法-Seven-Steps-to-Efficitive-Problem-Solving"><a href="#7步工作法-Seven-Steps-to-Efficitive-Problem-Solving" class="headerlink" title="7步工作法 Seven Steps to Efficitive Problem Solving"></a>7步工作法 Seven Steps to Efficitive Problem Solving</h2><p><img src="/img/wuweiwu/methology/7step-1.png"><br><img src="/img/wuweiwu/methology/7step-2.png"></p>
<h2 id="根源分析-Root-Cause-Analysis"><a href="#根源分析-Root-Cause-Analysis" class="headerlink" title="根源分析 Root Cause Analysis"></a>根源分析 Root Cause Analysis</h2><p><img src="/img/wuweiwu/methology/problem-solving-framework-Root-Cause-Analysis-Process.jpg"></p>
<h2 id="CIRCLES-method-for-problem-solving"><a href="#CIRCLES-method-for-problem-solving" class="headerlink" title="CIRCLES method for problem-solving"></a>CIRCLES method for problem-solving</h2><p><img src="/img/wuweiwu/methology/Circles-Framework-problem-solving.png"></p>
<h2 id="Product-Kano-analysis"><a href="#Product-Kano-analysis" class="headerlink" title="Product Kano analysis"></a>Product Kano analysis</h2><p><img src="/img/wuweiwu/methology/framework-problem-solving-kano.jpg"></p>
<h2 id="DMAIC-framework-for-problem-solving"><a href="#DMAIC-framework-for-problem-solving" class="headerlink" title="DMAIC framework for problem-solving"></a>DMAIC framework for problem-solving</h2><p><img src="/img/wuweiwu/methology/problem-solving-framework-DMAIC.png"></p>
]]></content>
      <categories>
        <category>认知-修行-平衡</category>
      </categories>
      <tags>
        <tag>方法论</tag>
      </tags>
  </entry>
  <entry>
    <title>水墨先生算命</title>
    <url>/2023/05/28/%E8%AE%A4%E7%9F%A5-%E4%BF%AE%E8%A1%8C-%E5%B9%B3%E8%A1%A1/mozi91_luck/</url>
    <content><![CDATA[<p><img src="/img/wuweiwu/about/mozi_luck/01.png" alt="01"><br><img src="/img/wuweiwu/about/mozi_luck/02.png" alt="02"><br><img src="/img/wuweiwu/about/mozi_luck/03.png" alt="03"><br><img src="/img/wuweiwu/about/mozi_luck/04.png" alt="04"><br><img src="/img/wuweiwu/about/mozi_luck/05.png" alt="05"><br><img src="/img/wuweiwu/about/mozi_luck/06.png" alt="06"></p>
]]></content>
      <categories>
        <category>认知-修行-平衡</category>
      </categories>
      <tags>
        <tag>命理</tag>
      </tags>
  </entry>
  <entry>
    <title>Ray Dalio： Principles, the Economic Machine, AI &amp; the Arc of Life</title>
    <url>/2023/07/20/%E8%AE%A4%E7%9F%A5-%E4%BF%AE%E8%A1%8C-%E5%B9%B3%E8%A1%A1/raydalio-interview/</url>
    <content><![CDATA[<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><ul>
<li>Ray Dalio, founder of Bridgewater Associates, discusses the importance of truth, experimentation, and adaptation in achieving goals and success.</li>
<li>Highlights<ul>
<li>🚀 Truth and Experimentation: Truth is essential for success, and one must experiment to discover it, especially when pursuing new and groundbreaking ideas.</li>
<li>🎯 The 5-Step Process: Dalio describes a five-step process for success: setting goals, identifying problems, diagnosing root causes, designing solutions, and following through with experimentation.</li>
<li>🌟 Shapers: Dalio highlights individuals like Elon Musk and Marc Benioff as “shapers” who visualize unique ideas and execute them, changing the world.</li>
<li>💼 Balancing Vision and Detail: Shapers balance their audacious visions with a practical understanding of the details required to achieve their goals.</li>
<li>👥 Concern for Others: Successful leaders prioritize the mission over personal concerns and hold high standards for their team members.</li>
<li>🤝 Embracing Different Perspectives: Great leaders appreciate diverse perspectives and learn from others to create a successful and harmonious team.</li>
<li>🤔 Confidence and Open-mindedness: Successful leaders possess both supreme confidence in their vision and the openness to consider different viewpoints.(Note: The provided transcript has been edited for brevity and clarity to fit the bullet points template.)</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>认知-修行-平衡</category>
      </categories>
      <tags>
        <tag>Ray Dalio</tag>
        <tag>活出真我</tag>
      </tags>
  </entry>
  <entry>
    <title>何为系统思考？</title>
    <url>/2023/07/20/%E8%AE%A4%E7%9F%A5-%E4%BF%AE%E8%A1%8C-%E5%B9%B3%E8%A1%A1/system_thinking/</url>
    <content><![CDATA[<p><a class="link"   href="https://www.youtube.com/watch?v=75EOg3njVdI" >read a book with me,<i class="fas fa-external-link-alt"></i></a></p>
<h2 id="听第一遍总结："><a href="#听第一遍总结：" class="headerlink" title="听第一遍总结："></a>听第一遍总结：</h2><p>增强回路：因果关系，正反馈<br>调节回路：</p>
<p>我们终将找到一个平衡点</p>
<h2 id="听第二遍总结："><a href="#听第二遍总结：" class="headerlink" title="听第二遍总结："></a>听第二遍总结：</h2><ol>
<li>为什么我们需要系统思考？<ol>
<li>系统思考可以改变我们的单向思维模式，从全局看待问题；</li>
<li>透过现象看本质；</li>
<li>看清事物之间存在的延迟现象。</li>
</ol>
</li>
<li>如何掌握系统思考的能力？<ol>
<li>有且仅有2种回路：增强回路和调节回路；</li>
<li>回路是一种闭合的因果循环；</li>
<li>增强回路：事物之间的关系是正反馈的关系；</li>
<li>调节回路：调节因素，是一种解决问题的机制；</li>
<li>延迟：不能忽略时间延迟的因素，效果存在延迟性。</li>
</ol>
</li>
<li>工具：系统循环图<ol>
<li>拿出纸和笔</li>
<li>列出当前的问题</li>
<li>找原因</li>
<li>找后果</li>
<li>找回路</li>
<li>注意：使用名词，不实用动词，箭头是单向的</li>
</ol>
</li>
</ol>
]]></content>
      <categories>
        <category>认知-修行-平衡</category>
      </categories>
      <tags>
        <tag>系统思考</tag>
      </tags>
  </entry>
  <entry>
    <title>We become what we think about.</title>
    <url>/2023/07/27/%E8%AE%A4%E7%9F%A5-%E4%BF%AE%E8%A1%8C-%E5%B9%B3%E8%A1%A1/we_become_what_we_think_about/</url>
    <content><![CDATA[<h2 id="关键总结"><a href="#关键总结" class="headerlink" title="关键总结"></a>关键总结</h2><ul>
<li>一段对话引入：和博士医生的对话，我问：请问博士，今天的人是怎么了？博士沉默了一会儿，说道：今天的人就是不思考。</li>
<li>例子：100个人从25岁到65岁，100个在25岁时都相信自己会成为一个成功的人。当他们65岁时，有1个人会变成富翁，4个人在经济上独立，5个人还在工作，54个破产了。在这个100个人当中只有5个人成功了，这是为什么呢？为什么大部分人都是失败的呢？为什么人与人之间的差距会这个巨大的？</li>
<li>成功的定义：成功就是你清楚自己的目标并且朝着目标循序渐进的前进，直到最好。问题是大部分人都是没有目标的，他们都是从众的活着，因为别人都是早上起床上班，所以我也是早上起床上班。</li>
<li>有志者事竟成，we become what we think about。和佛学中所说的：信，愿，行。信就是相信自己能够成功，愿就是有一个目标，行就是朝着目标前进。</li>
<li>一位伟大的医生说过六个步骤助你成功：1. 给自己确定一个明确的目标；2. 对成功保持乐观；3. 别再想你为什么不能成功，而是思考你怎么才能成功；4.  回想过去你的态度，甚至是童年，寻找你当时不成功的原因；5. 改变对自己的印象，写出你想成为的那个人的印象；6. 扮演那个你想成为的人，直到你真的成为那个人。</li>
<li>Start today, you have nothing to loose, but you have a life to win.</li>
<li>想要和得到之间还有一个做到。因和果之间还有一个愿。</li>
<li>提升觉察能力，人生就是不断的做选择，觉察能力高的可以帮助做出更明智的选择。</li>
<li>对抗你的惯性。你越习惯什么，但是你又觉得你是必须去打破的，那你就学习对抗这个惯性，尽量多的去做你认为正确的事。</li>
<li>你的生活就是你的思想的产物。你的思想就是你的生活的产物。</li>
<li>要相信相信的力量。你相信什么，你就会得到什么。所以你要永远保持乐观。</li>
<li>经济建设决定上层建筑，经济独立很重要，很重要，若果你要实现自我，首先你必须要经济独立。</li>
</ul>
<h2 id="核心观点"><a href="#核心观点" class="headerlink" title="核心观点"></a>核心观点</h2><ul>
<li>做一个有目标的人，知道你需要什么很重要。</li>
<li>建立自己的生命之树。</li>
<li>功利主义讲究的是效率，以结果为导向的“法家”思想。</li>
<li>人控制不了自己的欲望，控制不了自己的人，有可能走向“自废”的人生。</li>
<li>不是所有人都拥有思想的，普通没有思想的人也可以活的的不错，但是有思想就是一条分界线。</li>
<li>野蛮征服文明，劣币驱逐良币，这是自然界的规律，也是人类社会的规律。</li>
<li>兴趣就是你会废寝忘食去做的事情。迷茫是人生的常态，你可以去选择一些你感兴趣和有挑战性的事情坚持去做，你会找到自己的答案的。</li>
<li>人生就是不断的做选择，觉察能力高的可以帮助做出更明智的选择。</li>
<li>拥有了觉察能力，你需要去学会控制自己，自律，take action。</li>
</ul>
]]></content>
      <categories>
        <category>认知-修行-平衡</category>
      </categories>
      <tags>
        <tag>心想事成</tag>
      </tags>
  </entry>
  <entry>
    <title>近代史大事件</title>
    <url>/2023/08/07/%E8%AE%A4%E7%9F%A5-%E4%BF%AE%E8%A1%8C-%E5%B9%B3%E8%A1%A1/%E4%B8%AD%E5%9B%BD%E8%BF%91%E4%BB%A3%E5%8F%B2%E5%A4%A7%E4%BA%8B%E4%BB%B6/</url>
    <content><![CDATA[<h2 id="Part-1-从鸦片战争开始"><a href="#Part-1-从鸦片战争开始" class="headerlink" title="Part 1 从鸦片战争开始"></a>Part 1 从鸦片战争开始</h2><h2 id="Part-2-辛亥革命来了"><a href="#Part-2-辛亥革命来了" class="headerlink" title="Part 2 辛亥革命来了"></a>Part 2 辛亥革命来了</h2><ul>
<li>1911年10月10号，武昌起义来开辛亥革命序幕，清皇朝濒于灭亡</li>
<li>1912年1月1号晚10点，中华民国宣告成立，孙文宣誓就任临时大总统</li>
<li>1912年2月12日，溥仪宣布退位，孙文领导的辛亥革命推翻了清王朝</li>
<li>1912年2月15日，孙文宣布辞去临时大总统职务</li>
<li>1912年3月10日，袁世凯出任临时大总统</li>
<li>1913年3月20号晚10点45分，宋教仁在上海火车站被刺杀</li>
<li>1913年12月23日，袁世凯在天坛举行仪式，妄想称帝</li>
<li>1916年6月6日，袁世凯在举国声讨中死去</li>
<li>1917年6月14日，张勋在保皇党策动下入京</li>
<li>1917年7月12日，张勋复辟12天即告失败，孙文在广州发起护发运动</li>
<li></li>
</ul>
<h2 id="Part-3-新中国成立了"><a href="#Part-3-新中国成立了" class="headerlink" title="Part 3 新中国成立了"></a>Part 3 新中国成立了</h2>]]></content>
      <categories>
        <category>认知-修行-平衡</category>
      </categories>
      <tags>
        <tag>从历史中进行学习</tag>
      </tags>
  </entry>
  <entry>
    <title>什么是人性？</title>
    <url>/2023/07/13/%E8%AE%A4%E7%9F%A5-%E4%BF%AE%E8%A1%8C-%E5%B9%B3%E8%A1%A1/%E4%BA%BA%E6%80%A7%E6%98%AF%E4%BB%80%E4%B9%88/</url>
    <content><![CDATA[<ul>
<li>人性是一个概念性的词语，它是人对事物反应的情绪总和。</li>
<li>世上所有关系的结合和打破，就是关乎两个字：利益。人性背后的本质就是利益，而利益包含了物质利益和精神利益。</li>
<li>如何懂得人性？就是要有认知，认知来之两个途径：学习和实践。</li>
<li>道德，道和德拆解。道是一种自然规律。德是人自我约制的表象。舍得，先舍后得。</li>
</ul>
]]></content>
      <categories>
        <category>认知-修行-平衡</category>
      </categories>
      <tags>
        <tag>人性</tag>
      </tags>
  </entry>
  <entry>
    <title>什么是系统？</title>
    <url>/2023/04/05/%E8%AE%A4%E7%9F%A5-%E4%BF%AE%E8%A1%8C-%E5%B9%B3%E8%A1%A1/%E4%BB%80%E4%B9%88%E6%98%AF%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<h2 id="系统定义"><a href="#系统定义" class="headerlink" title="系统定义"></a>系统定义</h2><ul>
<li>系统是一个由若干相互作用相互依赖的元素组成的一个有特定功能的有机整体。</li>
<li><a class="link"   href="https://www.itma.vt.edu/courses/d4l2/lesson_2.php#3" >design for learning<i class="fas fa-external-link-alt"></i></a></li>
<li><a class="link"   href="https://baike.baidu.com/item/%E7%B3%BB%E7%BB%9F/479832" >百度百科<i class="fas fa-external-link-alt"></i></a></li>
<li><img src="/img/wuweiwu/what_is_system/system.png"></li>
<li>系统在生活中无处不在，一个班级，一个家庭，一个人等等，正所谓一叶一菩提，一花一世界.</li>
<li>人生来世，就像游戏打怪升级一样，面对林林种种的挑战，那么挑战如果是一个系统，该是怎么样的呢？</li>
</ul>
<h2 id="挑战系统"><a href="#挑战系统" class="headerlink" title="挑战系统"></a>挑战系统</h2><ul>
<li><img src="/img/wuweiwu/what_is_system/challenge.png"></li>
<li>有了挑战，自然就有解决方案，我们俗称how to archive&#x3D;this is your value，而这恰恰是你的价值所在，那sollution sytem又是怎么样的呢？</li>
</ul>
<h2 id="解决方案系统"><a href="#解决方案系统" class="headerlink" title="解决方案系统"></a>解决方案系统</h2><ul>
<li>利用树状的思维结构，分成3个部分，简称pdp，（1）to prove&#x3D;root（2）to define&#x3D;trunk（3）to practice&#x3D;leaves</li>
<li><img src="/img/wuweiwu/what_is_system/solution.png"></li>
</ul>
]]></content>
      <categories>
        <category>认知-修行-平衡</category>
      </categories>
      <tags>
        <tag>系统, 方法论</tag>
      </tags>
  </entry>
  <entry>
    <title>中国历史路线演进图</title>
    <url>/2023/07/13/%E8%AE%A4%E7%9F%A5-%E4%BF%AE%E8%A1%8C-%E5%B9%B3%E8%A1%A1/%E4%B8%AD%E5%9B%BD%E5%8E%86%E5%8F%B2%E8%B7%AF%E7%BA%BF%E5%9B%BE/</url>
    <content><![CDATA[<h3 id="从历史学习经验，人生充满希望！"><a href="#从历史学习经验，人生充满希望！" class="headerlink" title="从历史学习经验，人生充满希望！"></a>从历史学习经验，人生充满希望！</h3><p> <img src="/img/wuweiwu/world/china/history-line/01.jpg"></p>
]]></content>
      <categories>
        <category>认知-修行-平衡</category>
      </categories>
      <tags>
        <tag>中国历史路线</tag>
      </tags>
  </entry>
  <entry>
    <title>停一停 心呼吸 每日銘言 202307</title>
    <url>/2023/02/03/%E8%AE%A4%E7%9F%A5-%E4%BF%AE%E8%A1%8C-%E5%B9%B3%E8%A1%A1/%E5%BF%83%E9%9D%92%E5%B9%B4-202307/</url>
    <content><![CDATA[<table>
<thead>
<tr>
<th>日期</th>
<th>銘言</th>
</tr>
</thead>
<tbody><tr>
<td>7月29号</td>
<td><img src="/img/wuweiwu/zen_sayings/2023/07/29-min.jpeg"></td>
</tr>
<tr>
<td>7月25号</td>
<td><img src="/img/wuweiwu/zen_sayings/2023/07/25-min.jpeg"></td>
</tr>
<tr>
<td>7月24号</td>
<td><img src="/img/wuweiwu/zen_sayings/2023/07/24-min.jpeg"></td>
</tr>
<tr>
<td>7月21号</td>
<td><img src="/img/wuweiwu/zen_sayings/2023/07/21-min.jpeg"></td>
</tr>
<tr>
<td>7月16号</td>
<td><img src="/img/wuweiwu/zen_sayings/2023/07/16.jpg"></td>
</tr>
<tr>
<td>7月14号</td>
<td><img src="/img/wuweiwu/zen_sayings/2023/07/006.jpg"></td>
</tr>
<tr>
<td>7月12号</td>
<td><img src="/img/wuweiwu/zen_sayings/2023/07/005.jpg"></td>
</tr>
<tr>
<td>7月9号</td>
<td><img src="/img/wuweiwu/zen_sayings/2023/07/004.jpg"></td>
</tr>
<tr>
<td>7月7号</td>
<td><img src="/img/wuweiwu/zen_sayings/2023/07/003.jpg"></td>
</tr>
<tr>
<td>7月6号</td>
<td><img src="/img/wuweiwu/zen_sayings/2023/07/002.jpg"></td>
</tr>
<tr>
<td>7月3号</td>
<td><img src="/img/wuweiwu/zen_sayings/2023/07/001.jpg"></td>
</tr>
<tr>
<td>7月2号</td>
<td><img src="/img/wuweiwu/zen_sayings/2023/07/000.jpg"></td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>认知-修行-平衡</category>
      </categories>
      <tags>
        <tag>佛学</tag>
      </tags>
  </entry>
  <entry>
    <title>何仁讀通鑑 观后感</title>
    <url>/2023/05/21/%E8%AE%A4%E7%9F%A5-%E4%BF%AE%E8%A1%8C-%E5%B9%B3%E8%A1%A1/%E4%BD%95%E4%BB%81%E8%AF%BB%E9%80%9A%E9%89%B4/</url>
    <content><![CDATA[<ul>
<li><a class="link"   href="https://www.youtube.com/watch?v=nrfczKWPZUo&list=PLl7zeOiApUFV6s8wLEO9bRoojIqDmCNPY&index=95" >何仁讀通鑑-Youtube<i class="fas fa-external-link-alt"></i></a></li>
</ul>
<h2 id="第二集：三家分晋"><a href="#第二集：三家分晋" class="headerlink" title="第二集：三家分晋"></a>第二集：三家分晋</h2><ul>
<li>蠢人-&gt;小人-&gt;君子-&gt;圣人</li>
<li>德才兼备谓之圣人，才德皆无谓之蠢人。</li>
<li>有德无才谓之君子，有才无德谓之小人。</li>
</ul>
<h2 id="第三集：商鞅变法"><a href="#第三集：商鞅变法" class="headerlink" title="第三集：商鞅变法"></a>第三集：商鞅变法</h2><ul>
<li>过程：<ul>
<li>为鞅对秦孝公说：</li>
<li>变法开始的时候，普通大众是不会自动自觉与你一起规划的，但是等到有成果可以享受的时候，他们就会心服诚服了 </li>
<li>立志实现至善大德之人不应该迎接草根阶层的想法，希望建立宏伟工业的人不能寄望于大众能够与你合作，</li>
<li>所以，只要能够使国家富强，圣人并不会一味固守旧法， 但是既得利益者就会反驳，因为他们要保住自己的利益能够维持下去，</li>
<li>为鞅答道：普通人因循守旧，知识分子满足于道听途说 ，他们只适宜于规规矩矩地做官生活，你不能和他们讨论超出这个特定范围的事物， </li>
<li>聪明人要制定规矩，蠢人就会加以掣肘；有才能的人要改变现有的秩序，没出息的人就会来捣乱。</li>
<li>秦孝公表示十分认同！</li>
</ul>
</li>
<li>变法涵盖经济，社会，政制等多个方面</li>
<li>变革，制定规则并且严格执行，重奖，严罚，大众和权贵都要遵守规则，变法才能发挥作用</li>
<li>支持精英治国，支持专业性，精英政治，以结果为第一评估原则</li>
<li>没有为自己埋好退路</li>
</ul>
<h2 id="第四集：怀王弱智"><a href="#第四集：怀王弱智" class="headerlink" title="第四集：怀王弱智"></a>第四集：怀王弱智</h2><ul>
<li>贪，狂，怨，软</li>
</ul>
<h2 id="第五集：秦王逐客"><a href="#第五集：秦王逐客" class="headerlink" title="第五集：秦王逐客"></a>第五集：秦王逐客</h2><ul>
<li>既要用才，亦要防才。所谓疑人不用，用人不疑好像是一个极端的说法，中国人最终都要找到一个中庸之道，找到一个平衡之处。</li>
<li>一代君主一朝臣</li>
</ul>
<h2 id="第八集：南越归汉"><a href="#第八集：南越归汉" class="headerlink" title="第八集：南越归汉"></a>第八集：南越归汉</h2><ul>
<li>真诚信件，趋利避害，不急一时的耐心</li>
</ul>
<h2 id="第九集：七国之乱"><a href="#第九集：七国之乱" class="headerlink" title="第九集：七国之乱"></a>第九集：七国之乱</h2><ul>
<li>固本培元</li>
</ul>
]]></content>
      <categories>
        <category>认知-修行-平衡</category>
      </categories>
      <tags>
        <tag>从历史学习经验</tag>
      </tags>
  </entry>
  <entry>
    <title>停一停 心呼吸 每日銘言 202308</title>
    <url>/2023/08/03/%E8%AE%A4%E7%9F%A5-%E4%BF%AE%E8%A1%8C-%E5%B9%B3%E8%A1%A1/%E5%BF%83%E9%9D%92%E5%B9%B4-202308/</url>
    <content><![CDATA[<table>
<thead>
<tr>
<th>日期</th>
<th>銘言</th>
</tr>
</thead>
<tbody><tr>
<td>8月30号</td>
<td><img src="/img/wuweiwu/zen_sayings/2023/08/30-min.jpeg"></td>
</tr>
<tr>
<td>8月29号</td>
<td><img src="/img/wuweiwu/zen_sayings/2023/08/29-min.jpeg"></td>
</tr>
<tr>
<td>8月25号</td>
<td><img src="/img/wuweiwu/zen_sayings/2023/08/25-min.jpeg"></td>
</tr>
<tr>
<td>8月23号</td>
<td><img src="/img/wuweiwu/zen_sayings/2023/08/23-min.jpeg"></td>
</tr>
<tr>
<td>8月21号</td>
<td><img src="/img/wuweiwu/zen_sayings/2023/08/21-min.jpeg"></td>
</tr>
<tr>
<td>8月19号</td>
<td><img src="/img/wuweiwu/zen_sayings/2023/08/19-min.jpeg"></td>
</tr>
<tr>
<td>8月18号</td>
<td><img src="/img/wuweiwu/zen_sayings/2023/08/18-min.jpeg"></td>
</tr>
<tr>
<td>8月17号</td>
<td><img src="/img/wuweiwu/zen_sayings/2023/08/17-min.jpeg"></td>
</tr>
<tr>
<td>8月16号</td>
<td><img src="/img/wuweiwu/zen_sayings/2023/08/16-min.jpeg"></td>
</tr>
<tr>
<td>8月15号</td>
<td><img src="/img/wuweiwu/zen_sayings/2023/08/15-min.jpeg"></td>
</tr>
<tr>
<td>8月14号</td>
<td><img src="/img/wuweiwu/zen_sayings/2023/08/14-1-min.jpeg"></td>
</tr>
<tr>
<td>8月14号</td>
<td><img src="/img/wuweiwu/zen_sayings/2023/08/14-2-min.jpeg"></td>
</tr>
<tr>
<td>8月12号</td>
<td><img src="/img/wuweiwu/zen_sayings/2023/08/12-min.jpeg"></td>
</tr>
<tr>
<td>8月11号</td>
<td><img src="/img/wuweiwu/zen_sayings/2023/08/11-min.jpeg"></td>
</tr>
<tr>
<td>8月10号</td>
<td><img src="/img/wuweiwu/zen_sayings/2023/08/10-min.jpeg"></td>
</tr>
<tr>
<td>8月9号</td>
<td><img src="/img/wuweiwu/zen_sayings/2023/08/09-min.jpeg"></td>
</tr>
<tr>
<td>8月8号</td>
<td><img src="/img/wuweiwu/zen_sayings/2023/08/08-min.jpeg"></td>
</tr>
<tr>
<td>8月5号</td>
<td><img src="/img/wuweiwu/zen_sayings/2023/08/05-min.jpeg"></td>
</tr>
<tr>
<td>8月4号</td>
<td><img src="/img/wuweiwu/zen_sayings/2023/08/04-min.jpeg"></td>
</tr>
<tr>
<td>8月3号</td>
<td><img src="/img/wuweiwu/zen_sayings/2023/08/03-min.jpeg"></td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>认知-修行-平衡</category>
      </categories>
      <tags>
        <tag>佛学</tag>
      </tags>
  </entry>
  <entry>
    <title>停一停 心呼吸 每日銘言 202402</title>
    <url>/2024/02/23/%E8%AE%A4%E7%9F%A5-%E4%BF%AE%E8%A1%8C-%E5%B9%B3%E8%A1%A1/%E5%BF%83%E9%9D%92%E5%B9%B4-202402/</url>
    <content><![CDATA[<table>
<thead>
<tr>
<th>日期</th>
<th>銘言</th>
</tr>
</thead>
<tbody><tr>
<td>2月29号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/02/29-min.jpg"></td>
</tr>
<tr>
<td>2月28号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/02/28-min.jpg"></td>
</tr>
<tr>
<td>2月27号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/02/27-min.jpg"></td>
</tr>
<tr>
<td>2月26号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/02/26-min.jpg"></td>
</tr>
<tr>
<td>2月23号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/02/23-min.jpg"></td>
</tr>
<tr>
<td>2月22号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/02/22-min.jpg"></td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>认知-修行-平衡</category>
      </categories>
      <tags>
        <tag>佛学</tag>
      </tags>
  </entry>
  <entry>
    <title>停一停 心呼吸 每日銘言 202403</title>
    <url>/2024/03/01/%E8%AE%A4%E7%9F%A5-%E4%BF%AE%E8%A1%8C-%E5%B9%B3%E8%A1%A1/%E5%BF%83%E9%9D%92%E5%B9%B4-202403/</url>
    <content><![CDATA[<table>
<thead>
<tr>
<th>日期</th>
<th>銘言</th>
</tr>
</thead>
<tbody><tr>
<td>3月31号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/03/31-min.jpg"></td>
</tr>
<tr>
<td>3月30号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/03/30-min.jpg"></td>
</tr>
<tr>
<td>3月29号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/03/29-min.jpg"></td>
</tr>
<tr>
<td>3月28号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/03/28-min.jpg"></td>
</tr>
<tr>
<td>3月27号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/03/27-min.jpg"></td>
</tr>
<tr>
<td>3月26号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/03/26-min.jpg"></td>
</tr>
<tr>
<td>3月25号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/03/25-min.jpg"></td>
</tr>
<tr>
<td>3月24号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/03/24-min.jpg"></td>
</tr>
<tr>
<td>3月23号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/03/23-min.jpg"></td>
</tr>
<tr>
<td>3月22号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/03/22-min.jpg"></td>
</tr>
<tr>
<td>3月21号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/03/21-min.jpg"></td>
</tr>
<tr>
<td>3月20号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/03/20-min.jpg"></td>
</tr>
<tr>
<td>3月19号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/03/19-min.jpg"></td>
</tr>
<tr>
<td>3月18号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/03/18-min.jpg"></td>
</tr>
<tr>
<td>3月17号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/03/17-min.jpg"></td>
</tr>
<tr>
<td>3月16号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/03/16-min.jpg"></td>
</tr>
<tr>
<td>3月15号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/03/15-min.jpg"></td>
</tr>
<tr>
<td>3月14号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/03/14-min.jpg"></td>
</tr>
<tr>
<td>3月13号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/03/13-min.jpg"></td>
</tr>
<tr>
<td>3月12号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/03/12-min.jpg"></td>
</tr>
<tr>
<td>3月11号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/03/11-min.jpg"></td>
</tr>
<tr>
<td>3月10号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/03/10-min.jpg"></td>
</tr>
<tr>
<td>3月9号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/03/9-min.jpg"></td>
</tr>
<tr>
<td>3月8号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/03/8-min.jpg"></td>
</tr>
<tr>
<td>3月6号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/03/6-min.jpg"></td>
</tr>
<tr>
<td>3月5号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/03/5-min.jpg"></td>
</tr>
<tr>
<td>3月4号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/03/4-min.jpg"></td>
</tr>
<tr>
<td>3月3号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/03/3-min.jpg"></td>
</tr>
<tr>
<td>3月2号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/03/2-min.jpg"></td>
</tr>
<tr>
<td>3月1号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/03/1-min.jpg"></td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>认知-修行-平衡</category>
      </categories>
      <tags>
        <tag>佛学</tag>
      </tags>
  </entry>
  <entry>
    <title>停一停 心呼吸 每日銘言 202404</title>
    <url>/2024/04/01/%E8%AE%A4%E7%9F%A5-%E4%BF%AE%E8%A1%8C-%E5%B9%B3%E8%A1%A1/%E5%BF%83%E9%9D%92%E5%B9%B4-202404/</url>
    <content><![CDATA[<table>
<thead>
<tr>
<th>日期</th>
<th>銘言</th>
</tr>
</thead>
<tbody><tr>
<td>4月3号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/04/3-min.jpg"></td>
</tr>
<tr>
<td>4月2号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/04/2-min.jpg"></td>
</tr>
<tr>
<td>4月1号</td>
<td><img src="/img/wuweiwu/zen_sayings/2024/04/1-min.jpg"></td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>认知-修行-平衡</category>
      </categories>
      <tags>
        <tag>佛学</tag>
      </tags>
  </entry>
  <entry>
    <title>炼金术士1-前言</title>
    <url>/2024/04/03/%E8%AE%A4%E7%9F%A5-%E4%BF%AE%E8%A1%8C-%E5%B9%B3%E8%A1%A1/%E7%82%BC%E9%87%91%E6%9C%AF%E5%A3%AB1/</url>
    <content><![CDATA[<ul>
<li>Paulo Coelho 保罗·科埃略</li>
<li>“一天晚上，当他们仰望无月的天空时，男孩对炼金术士说：”我的心害怕受苦”。告诉你的心，对苦难的恐惧比苦难本身更可怕。没有一颗心在追寻梦想的过程中受过苦难”。</li>
<li>每隔几十年，就会出版一本永远改变读者生活的书。《炼金术士》就是这样一本书。《炼金术士》已在全球售出一百五十多万册，成为举世推崇的现代经典。保罗-科埃略这本迷人的寓言故事现在首次以英文面世，它将使更多的读者为之着迷，并激励他们世世代代继续阅读下去。</li>
<li>《炼金术士》讲述了一个神奇的故事：安达卢西亚牧羊少年圣地亚哥渴望旅行，寻找前所未有的世间珍宝。他从西班牙的家出发，前往丹吉尔的市场，穿越埃及沙漠，与炼金术士进行了一次命运的邂逅。</li>
<li>圣地亚哥沿途发现宝藏的故事告诉我们，倾听内心的声音、学会解读散落在人生道路上的预兆，以及最重要的是追随梦想，这些都是至关重要的智慧。</li>
</ul>
]]></content>
      <categories>
        <category>认知-修行-平衡</category>
      </categories>
      <tags>
        <tag>炼金术士</tag>
      </tags>
  </entry>
  <entry>
    <title>炼金术士2-序幕</title>
    <url>/2024/04/03/%E8%AE%A4%E7%9F%A5-%E4%BF%AE%E8%A1%8C-%E5%B9%B3%E8%A1%A1/%E7%82%BC%E9%87%91%E6%9C%AF%E5%A3%AB2/</url>
    <content><![CDATA[<ul>
<li><p>Paulo Coelho 保罗·科埃略</p>
</li>
<li><p>炼金术士拿起商队中有人带来的一本书。翻开书，他发现了一个关于水仙的故事。</p>
</li>
<li><p>炼金术士知道水仙的传说，他是一个每天跪在湖边思考自己的美丽的青年。他被自己深深吸引，一天早晨，他掉进湖里淹死了。在他掉下去的地方，诞生了一朵花，人们称它为水仙。</p>
</li>
<li><p>但书的作者并没有这样结束故事。</p>
</li>
<li><p>他说，水仙死后，森林女神出现了 发现淡水湖变成了咸泪湖</p>
</li>
<li><p>“你为什么哭泣？”女神问。</p>
</li>
<li><p>湖水回答说：”我为水仙哭泣”。</p>
</li>
<li><p>“啊，你为水仙哭泣并不奇怪”，他们说，”虽然我们总是在森林里追逐他，但只有你能近距离欣赏他的美”。</p>
</li>
<li><p>“可是……水仙美吗？”湖水问道。</p>
</li>
<li><p>“有谁比你更清楚呢？”女神们惊奇地说。”毕竟，他每天都跪在你的河畔沉思！”。</p>
</li>
<li><p>湖水沉默了一会儿。最后，它说：</p>
</li>
<li><p>“我为水仙哭泣，但我从未注意到水仙的美丽。我哭泣是因为，每当他跪在我的河岸旁，我都能从他的眼睛深处看到我自己的美丽”。</p>
</li>
<li><p>炼金术士想：”多么可爱的故事啊”。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>认知-修行-平衡</category>
      </categories>
      <tags>
        <tag>炼金术士</tag>
      </tags>
  </entry>
  <entry>
    <title>solidity导语</title>
    <url>/2023/08/16/Web3/solidity/00-%E5%AF%BC%E8%AF%AD-solidity/</url>
    <content><![CDATA[<ul>
<li><p>Github库地址： <a class="link"   href="https://github.com/chenyuqing/solidity-by-example/tree/main" >solidity-by-example<i class="fas fa-external-link-alt"></i></a></p>
</li>
<li><p>solidity是一门编译性语言，需要经过编译器编译成字节码，然后再部署到区块链上，所以需要安装编译器，推荐使用<a class="link"   href="https://remix.ethereum.org/" >remix<i class="fas fa-external-link-alt"></i></a>在线编译器，也可以使用<a class="link"   href="https://www.trufflesuite.com/" >truffle<i class="fas fa-external-link-alt"></i></a>本地编译器，但是truffle需要安装nodejs，npm，ganache等环境，比较麻烦，所以推荐使用remix。</p>
</li>
<li><p>solidity是一门面向合约的语言，所以需要有合约的概念，合约是一种特殊的类，合约中可以定义状态变量，函数，事件，修饰器，结构体，枚举等。</p>
</li>
<li><p><img src="/img/wuweiwu/solidity-study/solidity-basic.png"></p>
</li>
</ul>
<h2 id="Remix-IDE"><a href="#Remix-IDE" class="headerlink" title="Remix-IDE"></a>Remix-IDE</h2><ul>
<li><a class="link"   href="https://remix.ethereum.org/" >remix<i class="fas fa-external-link-alt"></i></a></li>
<li>面板介绍<ul>
<li><img src="/img/wuweiwu/solidity-study/remix-ide.png"></li>
</ul>
</li>
</ul>
<h2 id="Hello-World"><a href="#Hello-World" class="headerlink" title="Hello World"></a>Hello World</h2><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// SPDX-License-Identifier: MIT</span></span><br><span class="line">pragma solidity ^<span class="number">0.8</span><span class="number">.18</span>;</span><br><span class="line">contract helloWorld&#123;</span><br><span class="line">    string <span class="keyword">public</span> _str = <span class="string">&quot;hello world&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>代码解释<ul>
<li><code>// SPDX-License-Identifier: MIT</code>：开源协议</li>
<li><code>pragma solidity ^0.8.18;</code>：版本声明</li>
<li><code>contract helloWorld</code>：合约声明</li>
<li><code>string public _str = &quot;hello world&quot;;</code>：状态变量声明</li>
</ul>
</li>
</ul>
<h2 id="Solidity基础知识"><a href="#Solidity基础知识" class="headerlink" title="Solidity基础知识"></a>Solidity基础知识</h2><ul>
<li><a href="/2023/08/16/Web3/solidity/01-solidity%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" title="solidity基础知识">solidity基础知识</a></li>
</ul>
<h2 id="Solidity高级主题"><a href="#Solidity高级主题" class="headerlink" title="Solidity高级主题"></a>Solidity高级主题</h2><ul>
<li><a href="/2024/02/28/Web3/solidity/02-solidity%E9%AB%98%E7%BA%A7%E4%B8%BB%E9%A2%98/" title="solidity高级主题">solidity高级主题</a></li>
</ul>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a class="link"   href="https://github.com/ethereum/wiki/wiki/%5B%E4%B8%AD%E6%96%87%5D-%E4%BB%A5%E5%A4%AA%E5%9D%8A%E7%99%BD%E7%9A%AE%E4%B9%A6" >以太坊白皮书<i class="fas fa-external-link-alt"></i></a></li>
<li>极力推荐入门教程，配合食用更佳！写智能合约，节省gas费用永远放在第一位。<ul>
<li><a class="link"   href="https://solidity-cn.readthedocs.io/zh/develop/" >solidity中文网<i class="fas fa-external-link-alt"></i></a></li>
<li><a class="link"   href="https://cryptozombies.io/en/solidity" >僵尸打怪-Solidity: Beginner to Intermediate Smart Contracts<i class="fas fa-external-link-alt"></i></a></li>
<li><a class="link"   href="https://www.wtf.academy/solidity-start" >WTF-Solidity 101 入门<i class="fas fa-external-link-alt"></i></a></li>
<li>Solidity8.0全面精通-B站崔棉大师<ul>
<li><iframe src="//player.bilibili.com/player.html?aid=810148091&bvid=BV1E34y147JC&cid=562223215&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe></li>
</ul>
</li>
<li><a class="link"   href="https://www.youtube.com/@thinkingchain/playlists" >理想区块链<i class="fas fa-external-link-alt"></i></a></li>
<li><a class="link"   href="https://www.youtube.com/@fredsolidity4455/playlists" >Fred带你学solidity<i class="fas fa-external-link-alt"></i></a></li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步-Web3</category>
      </categories>
      <tags>
        <tag>solidity</tag>
      </tags>
  </entry>
  <entry>
    <title>solidity基础知识</title>
    <url>/2023/08/16/Web3/solidity/01-solidity%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</url>
    <content><![CDATA[<h2 id="基础知识目录"><a href="#基础知识目录" class="headerlink" title="基础知识目录"></a>基础知识目录</h2><ul>
<li>Solidity数据类型</li>
<li>Solidity运算符</li>
<li>Solidity控制结构</li>
<li>Solidity函数</li>
<li>Solidity事件</li>
<li>Solidity修饰器</li>
</ul>
<h2 id="类型和值"><a href="#类型和值" class="headerlink" title="类型和值"></a>类型和值</h2><ul>
<li>所有的数据类型都有默认值，如果没有赋值，就是默认值。也有一定的数值范围。</li>
<li>它们通常还包含增、删、改、查4个操作中的其中一个或者几个。(set&#x2F;get, push&#x2F;pop, delete)</li>
<li>数据类型也包含基础类型和复合类型两种。<ul>
<li>基础类型：整数，浮点数，布尔值，地址，字节。</li>
<li>复合类型：数组，枚举，结构体，映射。</li>
</ul>
</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// SPDX-License-Identifier: MIT</span></span><br><span class="line">pragma solidity ^<span class="number">0.8</span><span class="number">.18</span>;</span><br><span class="line"></span><br><span class="line">contract dataType&#123;</span><br><span class="line">    uint <span class="keyword">public</span> uint_min = <span class="built_in">type</span>(uint).min;</span><br><span class="line">    uint <span class="keyword">public</span> uint_max = <span class="built_in">type</span>(uint).max;</span><br><span class="line">    uint <span class="keyword">public</span> uint_def;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> <span class="keyword">public</span> int_min = <span class="built_in">type</span>(<span class="type">int</span>).min;</span><br><span class="line">    <span class="type">int</span> <span class="keyword">public</span> int_max = <span class="built_in">type</span>(<span class="type">int</span>).max;</span><br><span class="line">    <span class="type">int</span> <span class="keyword">public</span> int_def;</span><br><span class="line"></span><br><span class="line">    address <span class="keyword">public</span> addr;</span><br><span class="line">    <span class="type">bool</span> <span class="keyword">public</span> bol;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<details> <summary><font color="red">点我查看图片：solidity数据类型大小范围 </font></summary>

<ul>
<li><img src="/img/wuweiwu/solidity-study/sol-datatype-1.png"></li>
</ul>
</details>
- 有符号整数，无符号整数

<table>
<thead>
<tr>
<th>类型</th>
<th>默认值</th>
<th>最小值</th>
<th>最大值</th>
</tr>
</thead>
<tbody><tr>
<td>int(默认: int256)</td>
<td>0</td>
<td>-2**255</td>
<td>2**255-1</td>
</tr>
<tr>
<td>int128</td>
<td>0</td>
<td>-2**127</td>
<td>2**127-1</td>
</tr>
<tr>
<td>int64</td>
<td>0</td>
<td>-2**63</td>
<td>2**63-1</td>
</tr>
<tr>
<td>int32</td>
<td>0</td>
<td>-2**31</td>
<td>2**31-1</td>
</tr>
<tr>
<td>int16</td>
<td>0</td>
<td>-2**15</td>
<td>2**15-1</td>
</tr>
<tr>
<td>int8</td>
<td>0</td>
<td>-2**7</td>
<td>2**7-1</td>
</tr>
<tr>
<td>uint(默认: uint256)</td>
<td>0</td>
<td>0</td>
<td>2**256-1</td>
</tr>
<tr>
<td>uint128</td>
<td>0</td>
<td>0</td>
<td>2**128-1</td>
</tr>
<tr>
<td>uint64</td>
<td>0</td>
<td>0</td>
<td>2**64-1</td>
</tr>
<tr>
<td>uint32</td>
<td>0</td>
<td>0</td>
<td>2**32-1</td>
</tr>
<tr>
<td>uint16</td>
<td>0</td>
<td>0</td>
<td>2**16-1</td>
</tr>
<tr>
<td>uint8</td>
<td>0</td>
<td>0</td>
<td>2**8-1</td>
</tr>
</tbody></table>
<ul>
<li>字节，布尔值</li>
</ul>
<table>
<thead>
<tr>
<th>类型</th>
<th>默认值</th>
</tr>
</thead>
<tbody><tr>
<td>address</td>
<td>0x0…(total 40 zeros)</td>
</tr>
<tr>
<td>｜bool</td>
<td>false</td>
</tr>
</tbody></table>
<h2 id="数组-array（增、删、改、查）"><a href="#数组-array（增、删、改、查）" class="headerlink" title="数组 - array（增、删、改、查）"></a>数组 - array（增、删、改、查）</h2><ul>
<li><font color="red"> Copilot生成： </font></li>
<li>在memory中不能定义动态数组，不能使用push()和pop()方法</li>
<li>动态数组只能存在于状态变量中,stableVariable</li>
<li>固定数组可以存在于memory中，也可以存在于状态变量中</li>
<li>固定数组的长度是固定的，不能改变；动态数组的长度是动态的，可以改变</li>
<li>固定数组的长度是在编译时确定的，动态数组的长度是在运行时确定的</li>
<li>固定数组的长度是在定义数组的时候确定的，动态数组的长度是在定义数组的时候确定的，也可以在运行时确定</li>
</ul>
<h2 id="枚举-enum（改、查）"><a href="#枚举-enum（改、查）" class="headerlink" title="枚举 - enum（改、查）"></a>枚举 - enum（改、查）</h2><ul>
<li>枚举：是对一个对象的所有可能取到的值的集合。</li>
<li>set的时候，传入的参数是数字0，1，2…，如果不在枚举定义的范围内，会报错。</li>
<li>delete会重置默认值，默认值是枚举定义中的第一个值0。</li>
</ul>
<h2 id="结构体-struct-（增、删、改、查）"><a href="#结构体-struct-（增、删、改、查）" class="headerlink" title="结构体 - struct （增、删、改、查）"></a>结构体 - struct （增、删、改、查）</h2><ul>
<li>结构体：是对一个对象的所有属性的集合。</li>
<li>push()方法</li>
</ul>
<h2 id="映射-mapping-（增、删、改、查）"><a href="#映射-mapping-（增、删、改、查）" class="headerlink" title="映射 - mapping （增、删、改、查）"></a>映射 - mapping （增、删、改、查）</h2><ul>
<li>delete map[key]，不会删除value，而是把value重置为默认值了</li>
</ul>
<h2 id="函数返回值-returns"><a href="#函数返回值-returns" class="headerlink" title="函数返回值 - returns"></a>函数返回值 - returns</h2><ul>
<li><font color="red"> Copilot生成： </font></li>
<li>函数返回值可以有多个，也可以没有返回值</li>
<li>函数返回值可以是任何类型，包括自定义的类型</li>
<li>函数返回值可以是内部函数，也可以是外部函数</li>
<li>函数返回值可以是可见的，也可以是不可见的</li>
<li>函数返回值可以是常量，也可以是变量</li>
<li>函数返回值可以是单个值，也可以是数组，映射，结构体等复合类型</li>
</ul>
<h2 id="pure-view-关键字"><a href="#pure-view-关键字" class="headerlink" title="pure view 关键字"></a>pure view 关键字</h2><ul>
<li><p>view &gt; pure</p>
</li>
<li><p><font color="red"> ChatGPT生成： </font></p>
</li>
<li><p>在 Solidity 中，<code>pure</code> 和 <code>view</code> 关键字用于标识函数的状态修改行为，以便在编译时进行优化和验证。它们之间的主要区别在于函数对合约状态的访问和修改：</p>
<ol>
<li><strong><code>pure</code> 函数：</strong></li>
</ol>
<ul>
<li><code>pure</code> 函数声明表示函数不访问合约的状态变量，也不修改状态。它是一个纯函数，仅通过输入参数来计算并返回结果。</li>
<li><code>pure</code> 函数不会访问合约的存储区域，也不会调用其他合约或发送以太币。</li>
<li>使用 <code>pure</code> 关键字声明的函数对于调用者和其他合约的状态都是完全透明的，可以保证函数的执行结果不受外部环境的影响。</li>
</ul>
<ol start="2">
<li><strong><code>view</code> 函数：</strong></li>
</ol>
<ul>
<li><code>view</code> 函数声明表示函数只读取合约的状态变量，而不修改状态。它也是一个纯函数，因为它不会改变合约的状态。</li>
<li><code>view</code> 函数可以访问合约的存储区域，但不能对其进行修改。它也不能调用其他修改状态的函数。</li>
<li>使用 <code>view</code> 关键字声明的函数可以在不消耗 gas 的情况下被调用，因为它们不会改变区块链的状态。</li>
</ul>
</li>
<li><p>总的来说，<code>pure</code> 和 <code>view</code> 关键字都用于标识函数的纯度和对状态的访问和修改行为，但<code>pure</code> 函数不允许访问状态变量，而 <code>view</code> 函数允许读取状态变量但不允许修改。</p>
</li>
</ul>
<h2 id="异常报错-error"><a href="#异常报错-error" class="headerlink" title="异常报错 - error"></a>异常报错 - error</h2><ul>
<li>gas费用：require &gt; assert &gt; error</li>
<li>asser()：断言，不能带说明信息，如果断言失败，会消耗所有的gas，所有的状态变量都会被重置，所以不要使用断言。一般不会用，通常在调试的时候使用。</li>
</ul>
<h2 id="修饰器-modifier"><a href="#修饰器-modifier" class="headerlink" title="修饰器 - modifier"></a>修饰器 - modifier</h2><ul>
<li>类似于java中的注解，可以在函数前面加修饰器，修饰器可以用来检查函数的输入，比如检查函数的调用者是否是合约的拥有者，是否是合约的管理员，是否是合约的成员等等。</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// SPDX-License-Identifier: MIT</span></span><br><span class="line">pragma solidity ^<span class="number">0.8</span><span class="number">.18</span>;</span><br><span class="line"></span><br><span class="line">contract PauseFuncion&#123;</span><br><span class="line">    <span class="type">bool</span> <span class="keyword">public</span> paused;</span><br><span class="line">    uint <span class="keyword">public</span> num;</span><br><span class="line"></span><br><span class="line">    <span class="function">function <span class="title">setPause</span><span class="params">(<span class="type">bool</span> _paused)</span> external </span>&#123;</span><br><span class="line">        paused = _paused;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function">modifier <span class="title">whenNotPaused</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="built_in">require</span>(!paused, <span class="string">&quot;paused&quot;</span>);</span><br><span class="line">        _; <span class="comment">// _;代表被调用的代码块如果符合条件会在这里继续运行</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function">function <span class="title">inc</span><span class="params">()</span> external whenNotPaused</span>&#123;</span><br><span class="line">        <span class="comment">// require(!paused, &quot;paused&quot;);</span></span><br><span class="line">        num += <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function">function <span class="title">dec</span><span class="params">()</span> external whenNotPaused</span>&#123;</span><br><span class="line">        <span class="comment">// require(!paused, &quot;paused&quot;);</span></span><br><span class="line">        num -= <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="payable关键字"><a href="#payable关键字" class="headerlink" title="payable关键字"></a>payable关键字</h2><ul>
<li><font color="red"> ChatGPT生成： </font> 在 Solidity 中，<code>payable</code> 是一个关键字，用于标记函数或变量可以接收以太币。它通常用于两个地方：</li>
</ul>
<ol>
<li><p><strong>函数修饰符：</strong> 使用 <code>payable</code> 修饰符标记的函数可以接收以太币。这些函数可以被其他账户发送以太币调用，并且可以执行向其他账户发送以太币的操作。</p>
</li>
<li><p><strong>合约构造函数：</strong> 在合约构造函数中，如果你想要合约在部署时接收以太币，你可以将构造函数标记为 <code>payable</code>。</p>
</li>
</ol>
<ul>
<li>以下是使用 <code>payable</code> 的两个示例：</li>
</ul>
<ol>
<li><strong>函数修饰符：</strong><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pragma solidity ^0.8.0;</span><br><span class="line"></span><br><span class="line">contract MyContract &#123;</span><br><span class="line">    // 接收以太币的函数，标记为 payable</span><br><span class="line">    function receiveEther() public payable &#123;</span><br><span class="line">        // 函数逻辑</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<ul>
<li>在这个示例中，<code>receiveEther</code> 函数被标记为 <code>payable</code>，表示它可以接收以太币。调用这个函数时，可以通过 <code>msg.value</code> 获取发送的以太币数量。</li>
</ul>
<ol start="2">
<li><strong>构造函数：</strong><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pragma solidity ^0.8.0;</span><br><span class="line"></span><br><span class="line">contract MyContract &#123;</span><br><span class="line">    // 合约构造函数，标记为 payable</span><br><span class="line">    constructor() payable &#123;</span><br><span class="line">        // 构造函数逻辑</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<ul>
<li>在这个示例中，合约的构造函数被标记为 <code>payable</code>，这意味着在部署合约时可以发送以太币。在构造函数中，可以通过 <code>msg.value</code> 获取发送的以太币数量。</li>
</ul>
<h2 id="payable-中transfer-send-call-的区别"><a href="#payable-中transfer-send-call-的区别" class="headerlink" title="payable 中transfer(), send(), call()的区别"></a>payable 中transfer(), send(), call()的区别</h2><ul>
<li><font color="red"> ChatGPT生成： </font> 在 Solidity 中，<code>payable</code> 关键字用于标记合约函数，以表示该函数可以接收以太币。当一个合约需要处理以太币时，通常会使用 <code>transfer</code>、<code>send</code> 或 <code>call</code> 函数之一来执行支付操作。这些函数之间有一些区别，下面是它们的简要比较：</li>
</ul>
<ol>
<li><p><strong><code>transfer</code>：</strong></p>
<ul>
<li><code>transfer</code> 是 Solidity 中最简单的发送以太币的方法。</li>
<li>它是 <code>address</code> 类型的成员函数，只能发送固定的 2300 gas，并且在失败时会抛出异常（即抛出异常后所有状态改变都会被回滚）。</li>
<li>它被认为是比较安全的发送以太币的方式，因为它不允许发生回调（也就是说，接收方不能执行代码以影响交易的结果）。</li>
</ul>
</li>
<li><p><strong><code>send</code>：</strong></p>
<ul>
<li><code>send</code> 函数与 <code>transfer</code> 函数相似，但它返回一个布尔值来指示发送是否成功，而不是抛出异常。</li>
<li><code>send</code> 函数会发送所有可用的 gas（最多 2300 gas），但是在发送失败时不会抛出异常，而是返回 <code>false</code>。</li>
<li>这个函数通常用于与外部地址进行简单的支付操作，但不建议在需要确保交易原子性的情况下使用。</li>
</ul>
</li>
<li><p><strong><code>call</code>：</strong></p>
<ul>
<li><code>call</code> 函数是最通用的发送以太币的方法，它允许发送任意数量的 gas，并且返回一个布尔值来指示调用是否成功。</li>
<li><code>call</code> 函数可以传递额外的数据和设置 gas 限制，也可以捕获执行过程中的异常。</li>
<li>这个函数通常用于与合约进行交互，或者需要更复杂逻辑的支付操作。</li>
</ul>
</li>
</ol>
<ul>
<li>总的来说，<code>transfer</code> 是最简单且最安全的发送以太币的方法，适用于大多数情况。<code>send</code> 函数在需要检查支付是否成功时比较有用，但在复杂场景下不够灵活。<code>call</code> 函数是最通用的方法，可以满足各种需求，但需要更小心地处理异常情况和 gas 的使用。</li>
</ul>
<h2 id="public-internal-external-private关键字"><a href="#public-internal-external-private关键字" class="headerlink" title="public internal external private关键字"></a>public internal external private关键字</h2><h3 id="修饰变量：internal-public-private"><a href="#修饰变量：internal-public-private" class="headerlink" title="修饰变量：internal public private"></a>修饰变量：internal public private</h3><ul>
<li>权限开放程度：public &gt; internal &gt; private</li>
<li>public：公开的，自动生成getter()函数，可以在合约内部外部访问。</li>
<li>private: 私有的，只能在当前合约中访问，不会生成getter()函数，也不能被子合约继承。</li>
<li>internal：只能在当前合约或子合约中访问<ul>
<li><p>适用情况<font color="red"> ChatGPT生成： </font> </p>
</li>
<li><p><code>internal</code> 关键字通常用于需要在当前合约及其派生合约中共享和访问的状态变量。它提供了一种在合约内部实现继承和代码重用的方式，并且可以限制对变量的访问权限，以提高合约的安全性和封装性。</p>
<ul>
<li>以下是一些常见的情况下使用 <code>internal</code> 修饰变量的示例：</li>
</ul>
<ol>
<li><p><strong>共享状态数据：</strong> 如果你希望在当前合约及其派生合约中共享和访问某个状态变量的值，但不希望它被合约外部的调用者直接访问，你可以将该状态变量声明为 <code>internal</code>。</p>
</li>
<li><p><strong>内部状态追踪：</strong> 在复杂的合约中，可能会有一些状态需要在多个函数之间共享和更新。使用 <code>internal</code> 修饰的状态变量可以确保这些状态只能在合约内部被访问和修改，从而降低了出错的可能性。</p>
</li>
<li><p><strong>继承和重用：</strong> 在使用继承的合约结构中，<code>internal</code> 修饰的状态变量可以在父合约和子合约之间共享，从而实现代码的重用和扩展。子合约可以直接访问父合约中的 <code>internal</code> 变量，而不需要重新定义相同的变量。</p>
</li>
</ol>
<ul>
<li>总的来说，使用 <code>internal</code> 修饰变量可以在合约内部提供数据共享和封装的能力，同时限制对变量的访问权限，使得合约更加安全和可靠。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="修饰函数-internal-external-public-private"><a href="#修饰函数-internal-external-public-private" class="headerlink" title="修饰函数: internal external public private"></a>修饰函数: internal external public private</h3><ul>
<li><p>权限开放程度：public &gt; internal &gt; external &gt; private</p>
</li>
<li><p>public：公开的，可以在合约内部外部访问。</p>
</li>
<li><p>private: 私有的，只能在当前合约中访问，不能被子合约继承。</p>
</li>
<li><p>internal：只能在当前合约或子合约中访问.</p>
</li>
<li><p>external：外部函数，只能在外部调用，不能在合约内部调用。</p>
</li>
<li><p><font color="red"> ChatGPT生成： </font>在 Solidity 中，<code>internal</code> 和 <code>external</code> 是用于修饰函数的访问权限的关键字，它们在修饰函数时有以下区别：</p>
<ol>
<li><p><strong>Internal（内部）：</strong></p>
<ul>
<li>使用 <code>internal</code> 关键字修饰的函数只能在当前合约及其派生合约内部调用，无法被合约外部的调用者访问。这种访问权限对于实现合约内部逻辑提供了保护和封装。</li>
<li>示例：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">contract MyContract &#123;</span><br><span class="line">    // 内部函数</span><br><span class="line">    function internalFunction() internal &#123;</span><br><span class="line">        // 函数逻辑</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p><strong>External（外部）：</strong></p>
<ul>
<li>使用 <code>external</code> 关键字修饰的函数只能通过外部调用方式来访问，不能在合约内部被直接调用。这种访问权限通常用于合约的接口函数，供合约外部的调用者调用。</li>
<li>示例：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">contract MyContract &#123;</span><br><span class="line">    // 外部函数</span><br><span class="line">    function externalFunction() external &#123;</span><br><span class="line">        // 函数逻辑</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
<ul>
<li>总的来说，<code>internal</code> 修饰的函数适用于合约内部调用和继承，而 <code>external</code> 修饰的函数适用于合约外部调用。这两种修饰符的选择取决于你希望函数被调用的方式以及对函数的访问权限的要求。</li>
</ul>
</li>
</ul>
<h2 id="msg-关键字"><a href="#msg-关键字" class="headerlink" title="msg 关键字"></a>msg 关键字</h2><ul>
<li><font color="red"> ChatGPT生成： </font>在 Solidity 中，<code>msg</code> 是一个全局预定义变量，用于提供有关当前交易或消息的信息。它是一个包含以下属性的特殊对象：</li>
</ul>
<ol>
<li><code>msg.sender</code>：返回当前交易或消息的发送者（即合约调用者的地址）。</li>
<li><code>msg.value</code>：返回当前交易发送的以太币数量（以 wei 为单位）。</li>
<li><code>msg.data</code>：返回当前消息的数据。</li>
<li><code>msg.gas</code>：返回当前交易还剩余的 gas 数量。</li>
</ol>
<ul>
<li><p>这些属性可以在合约的函数中使用，以便根据当前交易或消息的上下文进行逻辑判断或处理。</p>
</li>
<li><p>以下是一个简单的示例，演示了如何在 Solidity 中使用 <code>msg</code>：</p>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pragma solidity ^0.8.0;</span><br><span class="line"></span><br><span class="line">contract MyContract &#123;</span><br><span class="line">    address public owner;</span><br><span class="line">    uint256 public valueReceived;</span><br><span class="line"></span><br><span class="line">    // 构造函数，在部署合约时设置合约的拥有者</span><br><span class="line">    constructor() &#123;</span><br><span class="line">        owner = msg.sender;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 接收以太币的函数</span><br><span class="line">    receive() external payable &#123;</span><br><span class="line">        // 更新接收到的以太币数量</span><br><span class="line">        valueReceived = msg.value;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 提取合约中的以太币的函数</span><br><span class="line">    function withdraw() external &#123;</span><br><span class="line">        require(msg.sender == owner, &quot;Only the owner can withdraw&quot;);</span><br><span class="line">        </span><br><span class="line">        // 向合约拥有者发送合约中的所有以太币</span><br><span class="line">        payable(owner).transfer(address(this).balance);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>在这个示例中，我们使用了 <code>msg.sender</code> 和 <code>msg.value</code> 属性：</li>
<li>在构造函数中，<code>owner</code> 变量被设置为部署合约的账户地址，即 <code>msg.sender</code>。</li>
<li>在 <code>receive</code> 函数中，接收到的以太币数量被记录在 <code>valueReceived</code> 变量中，并且该函数被标记为 <code>external</code> 和 <code>payable</code>，表示它可以接收以太币。</li>
<li>在 <code>withdraw</code> 函数中，我们检查调用者是否是合约的拥有者（即 <code>msg.sender == owner</code>），然后将合约中的所有以太币发送给拥有者地址。</li>
</ul>
<h2 id="address-this"><a href="#address-this" class="headerlink" title="address(this)"></a>address(this)</h2><ul>
<li><font color="red"> ChatGPT生成： </font>在 Solidity 中，<code>address(this)</code> 是一个特殊的表达式，用于获取当前合约的地址。它通常用于以下场景：</li>
</ul>
<ol>
<li><p><strong>合约内部调用：</strong> 当合约需要获取自身的地址时，可以使用 <code>address(this)</code> 表达式来获取。例如，合约可以在部署时记录自己的地址，或者在与其他合约进行交互时将自己的地址传递给它们。</p>
</li>
<li><p><strong>支付操作：</strong> 当合约需要将自己的地址作为收款地址进行支付操作时，可以使用 <code>address(this)</code> 表达式来获取。例如，在向其他地址发送以太币或者接收以太币时，合约可以使用 <code>address(this)</code> 表达式作为收款地址。</p>
</li>
</ol>
<ul>
<li>以下是一些示例，演示了 <code>address(this)</code> 的用法：</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pragma solidity ^0.8.0;</span><br><span class="line"></span><br><span class="line">contract MyContract &#123;</span><br><span class="line">    address public contractAddress;</span><br><span class="line"></span><br><span class="line">    // 构造函数，在部署时记录合约地址</span><br><span class="line">    constructor() &#123;</span><br><span class="line">        contractAddress = address(this);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 向指定地址发送以太币</span><br><span class="line">    function sendEther(address payable receiver) external payable &#123;</span><br><span class="line">        // 发送以太币给指定地址</span><br><span class="line">        receiver.transfer(msg.value);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>在这个示例中，合约在构造函数中使用 <code>address(this)</code> 表达式来获取自身的地址，并将其记录在 <code>contractAddress</code> 变量中。在 <code>sendEther</code> 函数中，合约可以使用 <code>address(this)</code> 表达式作为收款地址来接收以太币。</li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步-Web3</category>
      </categories>
      <tags>
        <tag>solidity</tag>
      </tags>
  </entry>
  <entry>
    <title>openzeppelin学习</title>
    <url>/2024/03/01/Web3/solidity/openzepplin_study/</url>
    <content><![CDATA[<ul>
<li><a class="link"   href="https://www.openzeppelin.com/" >openzeppelin official<i class="fas fa-external-link-alt"></i></a><br><font color="red"> ChatGPT生成： </font> OpenZeppelin 是一个开源的智能合约库和开发框架，它提供了一系列已经经过安全审计和测试的通用智能合约，帮助开发人员构建安全、可靠的去中心化应用（DApps）和智能合约。</li>
</ul>
<h3 id="主要功能和特点包括："><a href="#主要功能和特点包括：" class="headerlink" title="主要功能和特点包括："></a>主要功能和特点包括：</h3><ol>
<li><p><strong>安全的智能合约：</strong> OpenZeppelin 提供了一系列经过审计和测试的智能合约，涵盖了代币标准（如 ERC-20、ERC-721）、众筹合约、权限管理、多重签名钱包等常用的智能合约模块。这些合约已经被广泛使用，并得到了社区的认可和信任。</p>
</li>
<li><p><strong>模块化设计：</strong> OpenZeppelin 的智能合约库采用了模块化的设计，使得开发人员可以根据自己的需求选择性地使用其中的部分功能。这样可以提高代码的可重用性和可维护性。</p>
</li>
<li><p><strong>安全审计：</strong> OpenZeppelin 的智能合约经过了严格的安全审计和测试，以确保合约的安全性和可靠性。它们经过了专业的安全团队的审查，并且经过了时间的验证，已被广泛应用于生产环境中。</p>
</li>
<li><p><strong>社区支持：</strong> OpenZeppelin 拥有一个庞大的开发者社区，其中包括了来自世界各地的开发者、安全专家和区块链爱好者。开发者可以在社区中分享经验、提出问题、提交问题报告和贡献代码。</p>
</li>
<li><p><strong>开发工具和文档：</strong> OpenZeppelin 提供了丰富的开发工具和文档，包括代码示例、开发指南、安全建议等，帮助开发人员快速入门和使用 OpenZeppelin 的智能合约库。</p>
</li>
</ol>
<ul>
<li>总的来说，OpenZeppelin 是一个功能丰富、安全可靠的智能合约库和开发框架，为开发人员提供了构建安全、可靠的去中心化应用的重要工具和资源。</li>
</ul>
<hr>
<h2 id="让我们开始吧"><a href="#让我们开始吧" class="headerlink" title="让我们开始吧"></a>让我们开始吧</h2>]]></content>
      <categories>
        <category>技能-修行-进步-Web3</category>
      </categories>
      <tags>
        <tag>openzeppelin</tag>
      </tags>
  </entry>
  <entry>
    <title>solidity高级主题</title>
    <url>/2024/02/28/Web3/solidity/02-solidity%E9%AB%98%E7%BA%A7%E4%B8%BB%E9%A2%98/</url>
    <content><![CDATA[<h2 id="高级主题目录"><a href="#高级主题目录" class="headerlink" title="高级主题目录"></a>高级主题目录</h2><h3 id="继承-inheritance"><a href="#继承-inheritance" class="headerlink" title="继承 inheritance"></a>继承 inheritance</h3><ul>
<li>Solidity继承<ul>
<li>关键字is，合约继承父合约</li>
<li>对于变量和函数，如果父合约中的权限是private则不能被子合约继承</li>
<li>对于变量，如果父合约中的权限是internal和public，则能被子合约继承，而如果是external时就不能继承</li>
<li>对于函数，如果父合约中的权限是internal和public, 则能被子合约继承，而如果是external时也能继承，但是在调用时使用的是：this.functionName()</li>
</ul>
</li>
<li><font color="red"> ChatGPT生成： </font> Internal Protected：<ul>
<li>Solidity 0.8.0 版本引入了 internal protected 关键字修饰符，用于在派生合约中继承父合约的 internal 变量。这样的变量在父合约中是 internal 访问权限，但在派生合约中则是 protected 访问权限。</li>
<li>示例：internal protected uint256 myVariable;</li>
</ul>
</li>
</ul>
<h3 id="抽象合约-abstract"><a href="#抽象合约-abstract" class="headerlink" title="抽象合约 abstract"></a>抽象合约 abstract</h3><ul>
<li>Solidity抽象合约<ul>
<li>抽象合约是不能被实例化的合约，只能被继承</li>
<li>抽象合约中的函数不能有实现</li>
<li>抽象合约中的函数不能是private</li>
<li>抽象合约中的函数不能是external</li>
<li>抽象合约中的函数不能是pure</li>
<li>抽象合约中的函数不能是view</li>
<li>抽象合约中的函数不能是payable</li>
<li>抽象合约中的函数不能是internal</li>
<li>抽象合约中的函数不能是public</li>
<li>抽象合约中的函数不能是final</li>
<li>抽象合约中的函数不能是override</li>
<li>抽象合约中的函数不能是virtual</li>
<li>抽象合约中的函数不能是external</li>
<li>抽象合约中的函数不能是constant</li>
<li>抽象合约中的函数不能是immutable</li>
<li>抽象合约中的函数不能是stateMutability</li>
<li>抽象合约中的函数不能是returns</li>
</ul>
</li>
</ul>
<h3 id="接口-interface"><a href="#接口-interface" class="headerlink" title="接口 interface"></a>接口 interface</h3><ul>
<li>Solidity接口<ul>
<li>无法实现任何功能</li>
<li>可以继承其他接口</li>
<li>所有声明的函数必须是外部的</li>
<li>无法声明构造函数, 无法声明状态变量</li>
</ul>
</li>
</ul>
<h3 id="库函数-library"><a href="#库函数-library" class="headerlink" title="库函数 library"></a>库函数 library</h3><ul>
<li>Solidity库函数，一种函数集合-library<ul>
<li>库与合约类似，但你不能声明任何状态变量，也不能发送以太币。</li>
<li>库的目的是重用代码，库的函数可以被其他合约调用。</li>
<li>如果所有库函数都是内部的，则库将嵌入到合约中。否则，必须在部署合约之前部署并链接库。</li>
</ul>
</li>
</ul>
<h3 id="多态-polymorphism"><a href="#多态-polymorphism" class="headerlink" title="多态 polymorphism"></a>多态 polymorphism</h3><ul>
<li>Solidity多态</li>
</ul>
<h3 id="异常处理-exception"><a href="#异常处理-exception" class="headerlink" title="异常处理 exception"></a>异常处理 exception</h3><ul>
<li>Solidity异常处理</li>
</ul>
<h3 id="安全性-security"><a href="#安全性-security" class="headerlink" title="安全性 security"></a>安全性 security</h3><ul>
<li>Solidity安全性</li>
</ul>
<h3 id="日志-log"><a href="#日志-log" class="headerlink" title="日志 log"></a>日志 log</h3><ul>
<li>event(), emit()</li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步-Web3</category>
      </categories>
      <tags>
        <tag>solidity</tag>
      </tags>
  </entry>
  <entry>
    <title>chainlink学习</title>
    <url>/2024/03/01/Web3/solidity/chainlink_study/</url>
    <content><![CDATA[<ul>
<li><a class="link"   href="https://chain.link/" >chainlink official<i class="fas fa-external-link-alt"></i></a><br><font color="red"> ChatGPT生成： </font> Chainlink 是一个去中心化的预言机网络，旨在连接区块链智能合约与外部数据源、API 和传统金融市场。它的目标是解决区块链智能合约无法直接获取外部数据的问题，从而使得智能合约能够更加智能和功能丰富。</li>
</ul>
<h3 id="主要特点和功能包括："><a href="#主要特点和功能包括：" class="headerlink" title="主要特点和功能包括："></a>主要特点和功能包括：</h3><ol>
<li><p><strong>外部数据接入：</strong> Chainlink 允许区块链智能合约访问外部的数据源，包括网络 API、传感器数据、天气数据、金融市场数据等。这些数据可以用于触发智能合约的执行或影响其状态。</p>
</li>
<li><p><strong>数据验证和可信性：</strong> Chainlink 提供了一套机制来验证外部数据的真实性和可信度，以确保数据的准确性和安全性。这包括使用多个数据源、数据签名、可信执行环境等技术。</p>
</li>
<li><p><strong>可编程性和灵活性：</strong> Chainlink 允许开发人员根据自己的需求定义和部署预言机网络，从而实现各种不同类型的数据访问和验证。它提供了灵活的合约编程接口和工具，使开发人员能够根据应用场景定制预言机网络。</p>
</li>
<li><p><strong>安全和去中心化：</strong> Chainlink 采用去中心化的设计和安全机制，确保数据访问和验证的安全性和可靠性。它使用区块链技术和密码学算法来保护数据的安全，并通过分散化的节点网络来提供服务。</p>
</li>
<li><p><strong>可扩展性和互操作性：</strong> Chainlink 的设计具有良好的可扩展性和互操作性，可以与各种不同的区块链平台和智能合约系统集成，实现跨链数据访问和交互。</p>
</li>
</ol>
<ul>
<li>总的来说，Chainlink 是一个重要的基础设施项目，为区块链智能合约提供了可靠的外部数据访问和验证机制，推动了区块链技术在金融、保险、供应链等领域的应用和发展。</li>
</ul>
<hr>
<h2 id="让我们开始吧"><a href="#让我们开始吧" class="headerlink" title="让我们开始吧"></a>让我们开始吧</h2><ul>
<li>官网开发者文档6大板块功能</li>
<li><img src="/img/wuweiwu/chainlink/what/chainlink-dev-frame.png"></li>
<li>Chainlink Web3 服务可分为三大类<ul>
<li>数据 data<ul>
<li>data feeds</li>
<li>data streams</li>
<li>functions</li>
</ul>
</li>
<li>计算 compute<ul>
<li>VRF</li>
<li>Automation</li>
</ul>
</li>
<li>跨链 cross-chain<ul>
<li>CCIP</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Data-Feeds-喂价"><a href="#Data-Feeds-喂价" class="headerlink" title="Data Feeds 喂价"></a>Data Feeds 喂价</h3><ul>
<li>业务流程</li>
<li><img src="/img/wuweiwu/chainlink/what/df_workflow.png"></li>
<li>技术架构</li>
<li><img src="/img/wuweiwu/chainlink/what/df_technical_frame.png"></li>
<li>用户案例</li>
<li><img src="/img/wuweiwu/chainlink/what/df-usce.png"></li>
</ul>
<h3 id="Functions-函数"><a href="#Functions-函数" class="headerlink" title="Functions 函数"></a>Functions 函数</h3><ul>
<li>业务流程</li>
<li><img src="/img/wuweiwu/chainlink/what/func-workflow.png"></li>
<li>用户案例</li>
<li><img src="/img/wuweiwu/chainlink/what/func-use.png"></li>
<li><img src="/img/wuweiwu/chainlink/what/func-example.png"></li>
</ul>
<h3 id="VRF-随机数"><a href="#VRF-随机数" class="headerlink" title="VRF 随机数"></a>VRF 随机数</h3><ul>
<li>业务流程</li>
<li><img src="/img/wuweiwu/chainlink/what/vrf-workflow.png"></li>
</ul>
<h3 id="CCIP-跨链"><a href="#CCIP-跨链" class="headerlink" title="CCIP 跨链"></a>CCIP 跨链</h3><ul>
<li>业务流程</li>
</ul>
<h2 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h2><ul>
<li><a class="link"   href="https://www.youtube.com/watch?v=NpfRX4jTA8M&ab_channel=Chainlink" >Chainlink产品讲解-Frank<i class="fas fa-external-link-alt"></i></a></li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步-Web3</category>
      </categories>
      <tags>
        <tag>chainlink</tag>
      </tags>
  </entry>
  <entry>
    <title>solidity study by ChatGPT</title>
    <url>/2023/08/22/Web3/solidity/solidity101/</url>
    <content><![CDATA[<p>chenyuqing: 请生成一个学习solidity的目录。<br>GitHub Copilot: 好的，以下是一个学习Solidity的目录，供您参考：</p>
<h1 id="Solidity学习笔记"><a href="#Solidity学习笔记" class="headerlink" title="Solidity学习笔记"></a>Solidity学习笔记</h1><h2 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h2><ul>
<li>Solidity简介</li>
<li>Solidity开发环境搭建</li>
<li>Solidity数据类型</li>
<li>Solidity运算符</li>
<li>Solidity控制结构</li>
<li>Solidity函数</li>
<li>Solidity事件</li>
<li>Solidity修饰器</li>
</ul>
<h2 id="高级主题"><a href="#高级主题" class="headerlink" title="高级主题"></a>高级主题</h2><ul>
<li>Solidity面向对象编程</li>
<li>Solidity库</li>
<li>Solidity接口</li>
<li>Solidity继承</li>
<li>Solidity多态</li>
<li>Solidity异常处理</li>
<li>Solidity安全性</li>
</ul>
<h2 id="智能合约开发"><a href="#智能合约开发" class="headerlink" title="智能合约开发"></a>智能合约开发</h2><ul>
<li>智能合约开发流程</li>
<li>智能合约部署</li>
<li>智能合约调用</li>
<li>智能合约测试</li>
<li>智能合约优化</li>
<li>智能合约安全</li>
</ul>
<h2 id="DApp开发"><a href="#DApp开发" class="headerlink" title="DApp开发"></a>DApp开发</h2><ul>
<li>DApp开发流程</li>
<li>DApp前端开发</li>
<li>DApp后端开发</li>
<li>DApp测试</li>
<li>DApp部署</li>
<li>DApp安全</li>
</ul>
<h2 id="Solidity生态系统"><a href="#Solidity生态系统" class="headerlink" title="Solidity生态系统"></a>Solidity生态系统</h2><ul>
<li>Solidity工具</li>
<li>Solidity框架</li>
<li>Solidity库</li>
<li>Solidity应用</li>
</ul>
<h2 id="我想学的"><a href="#我想学的" class="headerlink" title="我想学的"></a>我想学的</h2><ul>
<li>openzeppelin</li>
<li>chainlink</li>
</ul>
<p>希望这个目录能够帮助您更好地学习Solidity。如果您有任何问题或需要进一步的帮助，请随时告诉我。</p>
<ul>
<li>What are smart contracts ?<ul>
<li>A smart contract is a computer program or a transaction protocol which is intended to automatically execute, control or document legally relevant events and actions according to the terms of a contract or an agreement.</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步-Web3</category>
      </categories>
      <tags>
        <tag>solidity</tag>
      </tags>
  </entry>
  <entry>
    <title>fundme dapp开发</title>
    <url>/2024/03/06/Web3/solidity/03-fundme_dapp/</url>
    <content><![CDATA[<h2 id="项目背景"><a href="#项目背景" class="headerlink" title="项目背景"></a>项目背景</h2><ul>
<li>在学习完solidity的基础知识后的第一个实践项目。</li>
</ul>
<ol>
<li>捐款项目主要功能<ol>
<li>任何人可以进行捐款，捐款有最低额度限制</li>
<li>只有合约部署者能进行提款</li>
<li>使用的是ETH&#x2F;USD，需要导入chainlink预言机查找eth实时价格</li>
</ol>
</li>
<li>本项目中涉及的solidity知识：<ol>
<li>库（library）的使用</li>
<li>接口（interface）的使用</li>
<li>关键字payable的使用, transfer, send, call三种方法的区别，receive() external payable{} 和 fallback() external payable{}</li>
<li>关键字internal和external的用法</li>
<li>address(this).balance，msg.sender msg.value</li>
<li>如何优化gas，例如使用constant，immutable等关键字定义相关变量，custom error</li>
<li>emit日志使用方法</li>
<li>chainlink预言机的调用</li>
</ol>
</li>
</ol>
<h2 id="项目UML图"><a href="#项目UML图" class="headerlink" title="项目UML图"></a>项目UML图</h2><ul>
<li><img src="/img/wuweiwu/fundme_dapp/uml.png" alt="UML"></li>
</ul>
<h2 id="chainlink预言机的调用"><a href="#chainlink预言机的调用" class="headerlink" title="chainlink预言机的调用"></a>chainlink预言机的调用</h2><ul>
<li><a href="/2024/03/01/Web3/solidity/chainlink_study/" title="chainlink学习">chainlink学习</a></li>
</ul>
]]></content>
      <categories>
        <category>技能-修行-进步-Web3</category>
      </categories>
      <tags>
        <tag>solidity</tag>
      </tags>
  </entry>
  <entry>
    <title>炼金术士3-第一章</title>
    <url>/2024/04/03/%E8%AE%A4%E7%9F%A5-%E4%BF%AE%E8%A1%8C-%E5%B9%B3%E8%A1%A1/%E7%82%BC%E9%87%91%E6%9C%AF%E5%A3%AB3/</url>
    <content><![CDATA[<ul>
<li><p>Paulo Coelho 保罗·科埃略</p>
</li>
<li><p>男孩名叫圣地亚哥。黄昏时分，男孩带着他的牛群来到一座废弃的教堂。屋顶早已坍塌，圣器室曾经所在的地方长出了一棵巨大的梧桐树。</p>
</li>
<li><p>他决定在那里过夜。他让所有的羊都从被毁坏的大门进去，然后在门上铺上一些木板，防止羊群在夜间走失。这一带没有狼，但有一次，一只动物在夜里走失了，男孩不得不花了一整天的时间去寻找它。</p>
</li>
<li><p>他用外套扫了扫地，然后躺下，用刚读完的书当枕头。他告诉自己，他得开始读厚一点的书：这样能看得更久，做枕头也更舒服。</p>
</li>
<li><p>当他醒来时，天还是黑的，抬头仰望，他可以透过半毁的屋顶看到星星。</p>
</li>
<li><p>他想，我还想再睡一会儿。那天晚上，他做了一个和一周前一样的梦，他又一次在梦结束之前醒了过来。</p>
</li>
<li><p>他站起来，拿起羊角锤，开始唤醒还在熟睡的羊群。他注意到，只要他一醒来，他的大多数动物也开始躁动起来。仿佛有一种神秘的能量将他的生命与羊群的生命紧紧联系在一起，在过去的两年里，他一直与羊群在一起，带领它们在乡间寻找食物和水。他喃喃自语道：”它们已经习惯了我，知道我的日程安排”。想了一会儿，他意识到事情可能恰恰相反：是他习惯了羊群的作息时间。</p>
</li>
<li><p>但其中有些人需要更长的时间才能醒来。小男孩用羊角棒挨个戳它们，叫着每只羊的名字。他一直相信，羊能听懂他说的话。因此，有时他会给羊儿们读自己书中给他留下深刻印象的部分，或者给它们讲牧羊人在田野里的孤独或快乐。有时，他会向羊儿们讲述他在经过的村庄里看到的事物。</p>
</li>
<li><p>但在过去的几天里，他只和他们谈了一件事：那个女孩，她是一个商人的女儿，住在他们大约四天后要到达的村子里。他只去过那个村子一次，是在前年。这位商人是一家干货店的老板，他总是要求当着他的面剪羊毛，以免上当受骗。一个朋友向男孩介绍了这家店，他就把羊带到了那里。</p>
</li>
</ul>
<hr>
<ul>
<li><p>“男孩对商人说：”我要卖一些羊毛。</p>
</li>
<li><p>店里很忙，商人让牧羊人等到下午再去。于是，男孩坐在商店的台阶上，从包里拿出一本书。</p>
</li>
<li><p>“我不知道牧羊人还识字”，他身后传来一个女孩的声音。</p>
</li>
<li><p>女孩是典型的安达卢西亚人，一头飘逸的黑发，一双眼睛让人依稀想起摩尔征服者。</p>
</li>
<li><p>他回答说：”嗯，通常我从羊群中学到的东西比从书本上学到的多”。在他们交谈的两个小时里，她告诉他自己是商人的女儿，并谈到了村里的生活，每天都过得和往常一样。牧羊人告诉她安达卢西亚乡村的情况，并讲述了他停留过的其他城镇的消息。</p>
</li>
<li><p>与羊群的谈话相比，这真是一种令人愉快的改变。</p>
</li>
<li><p>“有一次，女孩问：”你是怎么学会读书的？</p>
</li>
<li><p>他说：”就像每个人学的一样”。”在学校”。</p>
</li>
<li><p>“好吧，如果你识字，为什么你只是个牧羊人？”。</p>
</li>
<li><p>“男孩喃喃自语地回答，以此逃避回答女孩的问题。他相信女孩永远不会明白。他继续讲述他的旅行故事，而她那双明亮的摩尔人眼睛则因恐惧和惊讶而瞪得大大的。随着时间的流逝，男孩发现自己希望这一天永远不要结束，希望她的父亲能一直忙下去，让他等上三天。他意识到自己正在感受着一种从未有过的体验：渴望永远生活在一个地方。有了这个乌发姑娘，他的日子就再也不会一样了。</p>
</li>
<li><p>但是，商人终于出现了，他让男孩剪四只羊的毛。他付了羊毛的钱，并请牧羊人来年再来。</p>
</li>
</ul>
<hr>
<ul>
<li><p>而现在，离他回到那个村庄只有四天了。他很兴奋，同时也很不安：也许那个女孩已经把他忘了。许多牧羊人经过这里，出售羊毛。</p>
</li>
<li><p>“没关系”，他对羊群说。”我在别的地方也认识别的女孩。</p>
</li>
<li><p>但他心里明白，这并不重要。他知道，牧羊人就像海员和旅行推销员一样，总能找到一个小镇，那里有一个能让他们忘记无忧无虑的流浪乐趣的人。</p>
</li>
<li><p>天亮了，牧羊人催促着羊群向着太阳的方向前进。他想，他们从来不需要做任何决定。也许这就是为什么它们总是跟在我身边。</p>
</li>
<li><p>羊只关心食物和水。只要小男孩知道如何找到安达卢西亚最好的牧场，它们就是他的朋友。是的，它们的日子千篇一律，从日出到黄昏的时间似乎没有尽头；它们年轻的时候从未读过一本书，当男孩向它们介绍城市的风景时，它们也听不懂。它们只满足于食物和水，作为交换，它们慷慨地奉献出自己的羊毛、陪伴和偶尔的肉食。</p>
</li>
<li><p>男孩想，如果我今天变成了怪物，决定一个接一个地杀死它们，只有在大部分羊群被屠杀之后，它们才会有所察觉。他们信任我，他们已经忘记了如何依靠自己的本能，因为我带领他们找到了食物。</p>
</li>
<li><p>男孩对自己的想法感到惊讶。也许，那座长着梧桐树的教堂曾经闹过鬼。这让他第二次做了同样的梦，也让他对忠实的同伴感到愤怒。他喝了一点前一晚晚餐剩下的酒，把外套拢得更紧了。他知道，再过几个小时，当太阳升至顶点时，热量会非常大，他将无法带领羊群穿过田野。这是西班牙夏季一天中最热的时候。炎热的天气一直持续到夜幕降临，在这段时间里，他不得不带着外套。但当他想抱怨夹克太重时，他又想起，因为有了夹克，他才抵御住了黎明的寒冷。</p>
</li>
<li><p>他想，我们必须做好应对变化的准备，他对夹克的重量和温暖表示感谢。</p>
</li>
<li><p>夹克有它的用途，男孩也有它的用途。他的人生目标就是旅行，在安达卢西亚的土地上行走了两年之后，他对该地区的所有城市都了如指掌。这次来，他打算向女孩解释，一个普通的牧羊人怎么会识字。他曾在神学院学习到 16 岁。他的父母希望他成为一名牧师，从而成为这个普通农家的骄傲。他们像羊群一样辛勤劳作，只为有饭吃有水喝。他学习过拉丁语、西班牙语和神学。但他从小就想了解这个世界，这对他来说比认识上帝和了解人类的罪孽更重要。</p>
</li>
<li><p>一天下午，在一次探亲途中，他鼓起勇气告诉父亲，他不想当神父。他想去旅行。</p>
</li>
</ul>
<hr>
<ul>
<li><p>“来自世界各地的人都经过这个村子，儿子”，父亲说。</p>
</li>
<li><p>“他们来这里寻找新事物，但当他们离开时，他们基本上还是来时的样子。他们爬上山顶去看城堡，最后却认为过去的一切都比现在的好。他们或金发碧眼，或肤色黝黑，但基本上和生活在这里的人没什么两样”。</p>
</li>
<li><p>“但我想看看他们居住的城镇里的城堡”，男孩解释道。</p>
</li>
<li><p>父亲接着说：”那些人看到我们的土地后，说他们想永远住在这里”。</p>
</li>
<li><p>“儿子说：”嗯，我也想看看他们的土地，看看他们是怎么生活的。</p>
</li>
<li><p>“父亲说：”来这里的人有很多钱花，所以他们有能力旅行。”在我们中间，只有牧羊人会旅行”。</p>
</li>
<li><p>“好吧，那我就当牧羊人！”。</p>
</li>
<li><p>父亲不再多说。第二天，他给了儿子一个小袋，里面装着三枚古老的西班牙金币。</p>
</li>
<li><p>“有一天，我在田野里发现了这些金币。我想把它们作为你遗产的一部分。用它们来买你的羊群 到田里去，总有一天你会知道，我们的乡村是最好的，我们的女人是最美的”。</p>
</li>
<li><p>他向男孩表达了祝福。男孩从父亲的目光中看到了他自己能够周游世界的愿望–尽管他的父亲不得不将这种愿望埋葬在数十载的岁月中，在为水喝、为食物吃、为每天晚上在同一个地方睡觉而挣扎的重担下，这种愿望依然存在。</p>
</li>
</ul>
<hr>
<ul>
<li><p>地平线被染成了红色，太阳突然出现了。小男孩回想起与父亲的那次谈话，感到非常高兴；他已经见过许多城堡，也见过许多女人（但没有一个能与几天后等待他的女人相提并论）。</p>
</li>
<li><p>他拥有了一件夹克、一本可以交换的书和一群羊。但最重要的是，他每天都能实现自己的梦想。如果他厌倦了安达卢西亚的田野，他可以卖掉羊群出海。等他在海上玩够了，他就已经认识了其他城市、其他女人和其他幸福的机会。他看着日出想，我不可能在神学院找到上帝。</p>
</li>
<li><p>只要有机会，他就会寻找新的道路。他从未去过那座被毁坏的教堂，尽管他曾多次走过那些地方。世界之大，无穷无尽；他只需让羊群暂时设定路线，就会发现其他有趣的事物。问题是，他们甚至没有意识到自己每天都在走一条新路。它们看不到田野是新的，季节是变化的。他们只想着食物和水。</p>
</li>
<li><p>也许我们都是这样，男孩喃喃自语。即使是我–自从遇到商人的女儿后，我就再也没想过其他女人了。看着太阳，他计算着中午之前就能到达塔里法。在那里，他可以把书换成更厚的，把酒瓶装满，刮刮胡子，理理头发；他必须为与女孩的会面做好准备，他不想去想是否会有其他牧羊人，带着更多的羊群，比他先到，并向他求婚。</p>
</li>
<li><p>他想，正是梦想成真的可能性让生活变得有趣，他又看了看太阳的位置，加快了脚步。他突然想起，在塔里法，有一位会解梦的老妇人。</p>
</li>
</ul>
<hr>
<ul>
<li><p>老妇人把男孩领到她家后面的一个房间，房间与客厅之间用彩色珠帘隔开。房间里有一张桌子、一尊耶稣圣心像和两把椅子。</p>
</li>
<li><p>女人坐了下来，并让他也坐下。然后，她握住他的双手，开始静静地祈祷。</p>
</li>
<li><p>听起来像是吉普赛人的祈祷。男孩已经有过和吉普赛人一起上路的经历；他们也旅行，但他们没有羊群。人们说吉普赛人一生都在欺骗别人。人们还说，他们与魔鬼有约定，他们绑架孩子，把他们带到神秘的营地，让他们成为自己的奴隶。小男孩从小就害怕被吉普赛人抓走，当老妇人握住他的双手时，这种童年的恐惧又回来了。</p>
</li>
<li><p>但她的手上有耶稣圣心，他想，试图安慰自己。他不想让自己的手开始颤抖，让老妇人知道他在害怕。他默默地念了一句 “我们的父亲”。</p>
</li>
<li><p>“非常有趣”，女人说，眼睛一直没有离开男孩的手，然后她沉默了。</p>
</li>
<li><p>男孩开始紧张起来。他的手开始颤抖，女人也感觉到了。</p>
</li>
<li><p>他赶紧把手抽了出来。</p>
</li>
<li><p>“我不是来让你给我看手相的”，他说，他已经后悔来了。</p>
</li>
<li><p>他想了一会儿，觉得还不如付了钱就走，什么也不学，他太看重自己反复出现的梦了。</p>
</li>
<li><p>“老妇人说：”你来是为了了解你的梦。”梦是上帝的语言。当他用我们的语言说话时，我能解释他说的话。但如果他用灵魂的语言说话，只有你能听懂。</p>
</li>
<li><p>不过，不管是哪一种，我都要向你收取咨询费。</p>
</li>
<li><p>男孩想，这又是一个骗局。但他决定冒险一试。牧羊人总是要冒着狼群和干旱的危险，而这正是牧羊人生活的精彩之处。</p>
</li>
<li><p>“我做过两次同样的梦”，他说。”我梦见自己和羊群在田野里，一个孩子出现了，开始和动物们玩耍。我不喜欢别人这样做，因为羊害怕陌生人。但孩子们似乎总能和它们一起玩耍，而不会吓到它们。我也不知道为什么。我不知道动物怎么知道人类的年龄”。</p>
</li>
<li><p>“再给我讲讲你的梦吧”，女人说。”我得回去做饭了，因为你没有多少钱，所以我不能给你太多时间”。</p>
</li>
<li><p>“孩子继续和我的羊玩了好一会儿”，男孩继续说，有点不高兴。”突然，孩子双手拉着我，把我带到了埃及金字塔。</p>
</li>
<li><p>他停顿了一会儿，想看看女人是否知道埃及金字塔是什么。但她什么也没说。</p>
</li>
<li><p>“然后，在埃及金字塔”–为了让老太太明白，他把最后三个字说得很慢–”那个孩子对我说：’如果你到这里来，就会找到隐藏的宝藏’。就在她要告诉我具体位置时，我醒了过来。两次都是这样”。</p>
</li>
<li><p>女人沉默了一会儿。然后，她再次握住他的手，仔细地研究起来。</p>
</li>
<li><p>“她说：”我现在不会向你收取任何费用。”但如果你找到了宝藏，我想要十分之一。</p>
</li>
<li><p>男孩开心地笑了。因为做了一个关于藏宝的梦，他可以省下他仅有的一点钱了！</p>
</li>
<li><p>他说：”好吧，解梦吧”。</p>
</li>
<li><p>“首先，向我发誓。发誓你会把你的财宝的十分之一给我，以换取我要告诉你的东西”。</p>
</li>
<li><p>牧羊人发誓他愿意。老妇人让他看着耶稣圣心像再次发誓。</p>
</li>
<li><p>她说：”这是用世界语言做的梦”。”我可以解释它，但解释起来非常困难。这就是为什么我觉得我应该从你们的发现中分一杯羹。</p>
</li>
<li><p>“这就是我的解释：你必须去埃及的金字塔。我从未听说过它们，但是，如果是一个孩子向你展示了它们，那么它们是存在的。在那里，你会找到让你成为富翁的宝藏”。</p>
</li>
<li><p>男孩很惊讶，然后又很恼火。他不需要为此去找那个老妇人！但他转念一想，自己又不用付钱。</p>
</li>
<li><p>“他说：”我没必要为此浪费时间。</p>
</li>
<li><p>“我告诉过你，你的梦想很难实现。生活中简单的事情才是最不平凡的；只有智者才能理解它们。因为我没有智慧，所以我不得不学习其他技艺，比如看手相”。</p>
</li>
<li><p>“那我怎么去埃及呢？”。</p>
</li>
<li><p>“我只会解梦。我不知道如何把梦变成现实。所以我只能靠女儿们给我的钱生活”。</p>
</li>
<li><p>“如果我永远到不了埃及呢？”</p>
</li>
<li><p>“那我就拿不到钱了。这又不是第一次了”。</p>
</li>
<li><p>女人让男孩离开，说她已经在他身上浪费了太多时间。</p>
</li>
<li><p>男孩很失望，他决定再也不相信梦了。他想起自己还有很多事情要处理：他去市场买了些吃的，他用自己的书换了一本更厚的书，他在广场上找了一张长椅，在那里他可以品尝他买的新酒。天气炎热，葡萄酒沁人心脾。羊群在城门口一个朋友的马厩里。男孩在城里认识很多人。这正是旅行吸引他的地方–他总能交到新朋友，而且他不需要把所有时间都花在他们身上。</p>
</li>
<li><p>当一个人每天都见到同样的人，就像他在神学院时那样，他们就会成为这个人生活的一部分。然后他们就会希望这个人有所改变。如果一个人不是其他人想要的样子，其他人就会生气。</p>
</li>
<li><p>似乎每个人都对别人的生活方式有清晰的认识，但对自己的生活方式却一无所知。</p>
</li>
<li><p>他决定等到太阳在天空中沉得更低一些时，再跟着羊群穿过田野回去。三天后，他将和商人的女儿在一起。</p>
</li>
<li><p>他开始读他买的那本书。书的第一页描述了一个葬礼仪式。其中涉及的人名非常难念。他想，如果他能写一本书的话，他会一次介绍一个人，这样读者就不用担心记住很多名字了。</p>
</li>
<li><p>当他终于能够集中精力阅读时，他更喜欢这本书了；埋葬的地点是在一个雪天，他欢迎这种寒冷的感觉。当他读下去的时候，一位老人在他身边坐下，试图和他搭讪。</p>
</li>
<li><p>“他们在做什么？”老人指着广场上的人们问道。</p>
</li>
<li><p>“工作”，男孩干巴巴地回答，看起来似乎想专心读书。</p>
</li>
<li><p>其实，他想的是当着商人女儿的面剪羊毛，让她看看他是个能干难事的人。他已经想象过很多次这样的场景了；每次，当他解释必须从后往前剪羊毛时，女孩都会被吸引住。在剪羊毛的过程中，他还努力回忆一些好故事。这些故事大多是他在书上读到的，但他会把它们说成是自己的亲身经历。她永远不会知道其中的差别，因为她不识字。</p>
</li>
<li><p>与此同时，老人继续试图搭讪。他说自己又累又渴，问是否可以喝一口男孩的酒。男孩拿出自己的酒瓶，希望老人不要再打扰他。</p>
</li>
<li><p>但老人还想说话，他问男孩在读什么书。男孩很想不客气地搬到另一张长椅上，但父亲教导他要尊敬老人。于是，他把书递给老人–原因有二：第一，他自己也不知道书名该怎么念；第二，如果老人不识字，他可能会感到羞愧，并主动决定换凳子。</p>
</li>
<li><p>“嗯…… “老人说，他看着书的四面八方，好像它是什么奇怪的东西。”这是一本重要的书，但它真的很烦人”。</p>
</li>
<li><p>男孩吓了一跳。老人会读书，而且已经读过这本书了。</p>
</li>
<li><p>如果真像老人说的那样，这本书令人讨厌，男孩还有时间把它换成另一本书。</p>
</li>
<li><p>老人接着说：”这本书说的和世界上几乎所有其他书说的都一样”。”它描述了人们无法选择自己的命运。它最后说，每个人都相信世界上最大的谎言”。</p>
</li>
<li><p>“什么是世界上最大的谎言？”男孩惊讶地问。</p>
</li>
<li><p>“这就是：在我们生命中的某个时刻，我们失去了对发生在我们身上的事情的控制，我们的生活被命运控制。这是世界上最大的谎言”。</p>
</li>
<li><p>男孩说：”我从没遇到过这种事”。”他们想让我当牧师，但我决定当牧羊人”。</p>
</li>
<li><p>“这样好多了”，老人说。”因为你很喜欢旅行”。</p>
</li>
<li><p>“他知道我在想什么”，男孩自言自语道。与此同时，老人正在翻阅那本书，似乎根本不想把书还回去。男孩注意到老人的衣着很奇怪。他看起来像个阿拉伯人，这在当地并不罕见。非洲距离塔里法只有几个小时的路程，人们只需乘船穿过狭窄的海峡。阿拉伯人经常出现在城市里，他们一边购物，一边念叨着他们奇怪的祷文，一天要念好几遍。</p>
</li>
<li><p>“你从哪里来？”男孩问。</p>
</li>
<li><p>“来自很多地方”。</p>
</li>
<li><p>“男孩说：”没有人可以来自很多地方。”我是一个牧羊人，我去过很多地方，但我只来自一个地方–来自一座古城堡附近的城市。那就是我出生的地方”。</p>
</li>
<li><p>“那么，我们可以说我出生在塞勒姆”。</p>
</li>
<li><p>男孩不知道塞勒姆在哪里，但他不想问，怕显得自己无知。他看了一会儿广场上的人们，他们来来往往，似乎都很忙。</p>
</li>
<li><p>“那么，塞勒姆是个什么样的地方呢？”他问道，试图从中得到一些线索。</p>
</li>
<li><p>“还是老样子”。</p>
</li>
<li><p>还没有线索 但他知道塞勒姆不在安达卢西亚。如果是的话，他早就听说过了。</p>
</li>
<li><p>“那你在塞勒姆做什么？”他坚持问。</p>
</li>
<li><p>“我在塞勒姆做什么？”。老人笑了 “我是塞勒姆的国王！”</p>
</li>
<li><p>男孩想，人们总是说奇怪的话。有时候和羊在一起会更好 因为他们什么都不会说 最好还是一个人看书。在你想听故事的时候，它们就会讲出令人难以置信的故事。但当你与人交谈时，他们会说一些奇怪的话，让你不知如何继续交谈。</p>
</li>
<li><p>老人说：”我叫麦基洗德”。”你有几只羊？”。</p>
</li>
<li><p>男孩说：”够多了”。他看得出，老人想更多地了解他的生活。</p>
</li>
<li><p>“好吧，那我们就有麻烦了。如果你觉得自己的羊够多，我就帮不了你。</p>
</li>
<li><p>男孩被激怒了。他不是在寻求帮助。是老人要喝他的酒，挑起了谈话。</p>
</li>
<li><p>“把我的书给我”，男孩说。”我得去收羊，然后出发”。</p>
</li>
<li><p>“老人说：”给我十分之一的羊，我就告诉你如何找到藏宝”。</p>
</li>
<li><p>男孩想起了自己的梦，突然间一切都明白了。那个老妇人没有向他收取任何费用，但那个老人–也许是她的丈夫–会想办法用更多的钱来换取一些根本不存在的东西的信息。这个老人可能也是个吉普赛人。</p>
</li>
<li><p>但还没等男孩开口，老人就俯下身，拿起一根棍子，开始在广场的沙地上写字。他的胸前反射出明亮的光芒，强烈得让男孩瞬间睁不开眼。老人用他的斗篷遮住了那东西，动作之快不像他这个年纪的人。当他的视力恢复正常后，男孩才看清了老人在沙上写的字。</p>
</li>
<li><p>在那个小城市广场的沙地上，男孩读到了他父亲和母亲的名字，以及他曾经就读的神学院的名字。他读到了商人女儿的名字，而他甚至不知道这个名字，他还读到了一些他从未告诉过别人的事情。</p>
</li>
</ul>
<hr>
<ul>
<li><p>老人说：”我是撒冷的国王”。</p>
</li>
<li><p>“国王为什么要和一个牧羊人说话？”男孩又惊又窘地问道。</p>
</li>
<li><p>“有几个原因。但最重要的原因是，你成功地发现了自己的命运。</p>
</li>
<li><p>男孩不知道一个人的 “命运 “是什么。</p>
</li>
<li><p>他说：”这就是你一直想要完成的事情。每个人在年轻时都知道自己的命运是什么。</p>
</li>
<li><p>“在他们的人生中，一切都很清晰，一切都有可能。他们无所畏惧，敢于梦想，渴望自己一生中希望实现的一切。但是，随着时间的流逝，一种神秘的力量开始让他们相信，他们不可能实现自己的命运”。</p>
</li>
<li><p>老人说的话对男孩来说没有什么意义。但他想知道那股 “神秘的力量 “是什么，如果他告诉商人的女儿，她一定会印象深刻！</p>
</li>
<li><p>“这是一种看似消极的力量，但实际上它告诉你如何实现自己的命运。它让你的精神和意志做好准备，因为在这个星球上有一个伟大的真理：无论你是谁，无论你做什么，当你真正想要什么的时候，那是因为这种欲望源自宇宙的灵魂。这是你在地球上的使命”。</p>
</li>
<li><p>“即使你只想旅行？或者娶一个纺织品商人的女儿？</p>
</li>
<li><p>“是的，甚至是寻找宝藏。人们的幸福滋养着世界的灵魂。不快乐、羡慕和嫉妒也会滋养它。实现自己的命运是一个人唯一真正的义务。万物一体。</p>
</li>
<li><p>“当你想要某样东西时，全宇宙都会合力帮助你实现它。</p>
</li>
<li><p>两人都沉默了一会儿，观察着广场和镇上的人们。还是老人先开口了。</p>
</li>
<li><p>“你为什么要放羊？</p>
</li>
<li><p>“因为我喜欢旅行。</p>
</li>
<li><p>老人指了指站在广场一角橱窗里的面包师。</p>
</li>
<li><p>“他小时候也想去旅行。但他决定先买下自己的面包店，把钱存起来。等他老了，他要去非洲待一个月。他从未意识到，人在一生中的任何时候都有能力去做自己梦想的事情”。</p>
</li>
<li><p>男孩说：”他应该决定成为一名牧羊人”。</p>
</li>
<li><p>“嗯，他想过这个问题”，老人说。”但面包师比牧羊人更重要。面包师有家，而牧羊人露宿街头。父母宁愿看到自己的孩子嫁给面包师，也不愿意看到他们嫁给牧羊人”。</p>
</li>
<li><p>想到商人的女儿，男孩心里一阵酸楚。她的镇上肯定有一个面包师。</p>
</li>
<li><p>老人接着说：”从长远来看，人们对牧羊人和面包师的看法比他们自己的命运更重要。</p>
</li>
<li><p>老人翻了翻书，翻到一页就坐下来读。男孩等待着，然后打断了老人的话，就像他自己被打断一样。”你为什么要告诉我这些？</p>
</li>
<li><p>“因为你正在努力实现自己的命运。而你正处于即将放弃这一切的时刻”。</p>
</li>
<li><p>“那你总是在这个时候出现？”</p>
</li>
<li><p>“并不总是这样，但我总是以这样或那样的形式出现。有时我以解决方案或好主意的形式出现。其他时候，在关键时刻，我让事情更容易发生。 我还做了其他一些事情，但大多数时候人们没有意识到我已经做了这些”。</p>
</li>
<li><p>老人说，一周前，他被迫出现在一名矿工面前，并变成了一块石头。 矿工放弃了一切去开采祖母绿。 五年来，他一直在某条河流工作，检查了数十万块石头，寻找祖母绿。 矿工正要放弃一切，就在此时，如果他再检查一块石头——再检查一块——他就会找到他的祖母绿。 由于矿工为了自己的命运牺牲了一切，老人决定参与其中。 他把自己变成了一块石头，滚到了矿工的脚边。 矿工带着五年毫无结果的愤怒和沮丧，捡起石头扔到一边。 但他扔出的力道太大了，以至于它击碎了落在上面的石头，而破碎的石头中镶嵌着世界上最美丽的祖母绿。</p>
</li>
<li><p>“人们在生命的早期就知道自己存在的理由是什么”，老人带着某种苦涩的语气说道。 “也许这就是他们这么早就放弃的原因。但事实就是这样”。</p>
</li>
<li><p>男孩提醒老人，他说过一些关于隐藏宝藏的事情。</p>
</li>
<li><p>“宝藏被流水的力量发掘出来，也被同样的水流埋葬”，老人说。 “如果你想了解你自己的宝藏，你就必须给我你羊群的十分之一”。</p>
</li>
<li><p>“那我的宝物十分之一呢？”。</p>
</li>
<li><p>老者一脸失望。 “如果你一开始就承诺你还没有得到的东西，你就会失去努力实现它的欲望”。</p>
</li>
<li><p>男孩告诉他，他已经答应将十分之一的财宝送给吉普赛人。</p>
</li>
<li><p>“吉普赛人是让人们这样做的专家”，老人叹了口气。 “无论如何，很高兴你了解到生活中的一切都是有代价的。这就是光之战士试图教导的内容”。</p>
</li>
<li><p>老人把书还给了男孩。</p>
</li>
<li><p>“明天，同时，给我带来十分之一的羊群。我会告诉你如何找到隐藏的宝藏。下午好”。</p>
</li>
<li><p>然后他就消失在广场的拐角处。</p>
</li>
<li><p>男孩又开始看书，但他再也无法集中注意力了。 他既紧张又不安，因为他知道老人是对的。 他走到面包店买了一条面包，想着要不要告诉面包师老人对他的评价。 有时候，保持现状会更好，他心里想，然后决定什么也不说。 如果他要说什么，面包师会花三天的时间考虑放弃这一切，尽管他已经习惯了这种情况。 这个男孩当然可以抵制给面包师带来这种焦虑。 于是他开始在城里闲逛，发现自己已经到了城门口。 那里有一栋小楼，有一个窗口，人们可以在那里购买去非洲的机票。 他知道埃及位于非洲。</p>
</li>
<li><p>“我可以帮你吗？” 窗后的男人问道。</p>
</li>
<li><p>“也许明天，”男孩说着就走开了。 如果他只卖掉一只羊，就足够他到达海峡对岸了。 这个想法让他感到害怕。</p>
</li>
<li><p>“又一个梦想家”，售票员看着男孩走开，对他的助手说道。</p>
</li>
<li><p>“他没有足够的钱去旅行”。</p>
</li>
<li><p>当站在售票窗口时，男孩想起了他的羊群，并决定他应该回去当牧羊人。 两年的时间里，他学会了关于牧羊的一切：他知道如何剪羊毛，如何照顾怀孕的母羊，以及如何保护羊免受狼的侵害。 他熟悉安达卢西亚的所有田野和牧场。 他知道他的每一只动物的合理价格是多少。</p>
</li>
<li><p>他决定尽可能走最长的路返回朋友的马厩。 当他走过城市的城堡时，他中断了返回，爬上了通向城墙顶部的石坡。 从那里，他可以看到远处的非洲。 有人曾经告诉他，摩尔人就是从那里来的，占领了整个西班牙。</p>
</li>
<li><p>从他坐的地方，他几乎可以看到整个城市，包括他和老人谈话的广场。 诅咒我见到那个老人的那一刻，他想。 他来到小镇只是为了寻找一个能够解梦的女人。 无论是女人还是老人，对于他是牧羊人这一事实都没有留下深刻的印象。 他们是孤独的人，不再相信任何事物，也不明白牧羊人会依恋他们的羊。 他了解羊群中每个成员的一切：他知道哪些是跛子，哪些是两个月后就要生孩子的，哪些是最懒的。 他知道如何剪它们，也知道如何宰杀它们。 如果他决定离开他们，他们就会受苦。</p>
</li>
<li><p>风开始刮起来。 他了解那种风：人们称之为黎凡特风，因为摩尔人是乘风从地中海东端的黎凡特而来的。</p>
</li>
<li><p>黎凡特的强度增加了。 我就在这里，在我的羊群和我的宝藏之间，男孩想。 他必须在他已经习惯的东西和他想要拥有的东西之间做出选择。 还有商人的女儿，但她没有他的羊群那么重要，因为她不依赖他。 也许她根本就不记得他了。 他确信他出现的哪一天对她来说没有什么区别：对她来说，每一天都是一样的，当每一天都与下一天一样时，那是因为人们无法认识到生活中发生的美好事情 太阳升起的每一天。</p>
</li>
<li><p>我把父亲、母亲和城镇的城堡抛在了身后。 它们已经习惯了我的离开，我也是。羊也会习惯我的不在，男孩想。</p>
</li>
<li><p>从他坐的地方，可以眺望整个广场。 人们继续从面包店进进出出。 一对年轻夫妇坐在他与老人谈话的长凳上，他们接吻了。</p>
</li>
<li><p>“那个面包师……”他自言自语，但没有完成这个想法。 黎凡特的力量还在增强，他感觉到它的力量打在了他的脸上。 是的，那股风带来了摩尔人，但它也带来了沙漠和蒙着面纱的女人的气味。 它带来了那些曾经离开去寻找未知、黄金和冒险——以及金字塔的人们的汗水和梦想。 男孩嫉妒风的自由，也看到自己也能拥有同样的自由。 除了他自己，没有什么能阻止他。 羊、商人的女儿和安达卢西亚的田野只是他通往命运的几步之遥。</p>
</li>
<li><p>第二天中午，男孩遇见了老人。 他带来了六只羊。</p>
</li>
<li><p>“我很惊讶，”男孩说。 “我的朋友立即买下了所有其他的羊。他说他一直梦想成为一名牧羊人，这是一个好兆头”。</p>
</li>
<li><p>“一直都是这样，”老人说。 “这就是所谓的好感度原则，第一次打牌的时候，几乎肯定会赢，新手的运气”。</p>
</li>
<li><p>“这是为什么？”。</p>
</li>
<li><p>“因为有一种力量要你实现自己的命运，它吊着你的胃口，让你尝到成功的滋味”。</p>
</li>
<li><p>然后老人开始检查羊群，发现其中一只是跛脚的。 男孩解释说，这并不重要，因为那只羊是羊群中最聪明的，产的羊毛最多。</p>
</li>
<li><p>“宝藏在哪里？” 他问。</p>
</li>
<li><p>“它在埃及，靠近金字塔”。</p>
</li>
<li><p>男孩吓了一跳。 老妇人也说过同样的话。 但她没有向他收取任何费用。</p>
</li>
<li><p>“为了找到宝藏，你必须遵循预兆。上帝为每个人准备了一条道路，你只需要阅读他为你留下的预兆”。</p>
</li>
<li><p>还没等男孩回答，一只蝴蝶就出现在他和老人之间。 他想起祖父曾经告诉他的一句话：蝴蝶是好兆头。 喜欢蟋蟀，喜欢期待； 像蜥蜴和四叶草。</p>
</li>
<li><p>“没错。”老人说，他能读懂男孩的想法。 “就像你祖父教你的那样。这些都是好兆头”。</p>
</li>
<li><p>老人掀开斗篷，男孩被眼前的景象震惊了。 老人穿着一件重金胸甲，上面镶满了宝石。 男孩回想起前一天他注意到的光彩。</p>
</li>
<li><p>他真的是一个国王！ 他必须乔装打扮以避免遭遇小偷。</p>
</li>
<li><p>“拿着这些。”老者说道，同时拿出了镶嵌在胸甲中央的一块白色石头和一块黑色石头。 “它们被称为乌陵和土明。黑色表示‘是’，白色表示‘否’。当你无法解读预兆时，它们会帮助你做到这一点。始终提出客观的问题。</p>
</li>
<li><p>“但是，如果可以的话，尝试自己做决定。宝藏在金字塔里；你已经知道了。但我不得不坚持支付六只羊，因为我帮助你做出了决定”。</p>
</li>
<li><p>男孩把石头放进了他的袋子里。 从此以后，他将自己做决定。</p>
</li>
<li><p>“不要忘记，你所面对的一切都只是一件事，别无其他。不要忘记预兆的语言。而且，最重要的是，不要忘记跟随你的命运直到结局。但在我走之前 ，我想给你讲一个小故事。</p>
</li>
<li><p>“某位店主派他的儿子去向世界上最聪明的人学习幸福的秘密。这个小伙子在沙漠中徘徊了四十天，终于来到了高高的山顶上一座美丽的城堡。就在那里， 然而，我们的英雄并没有找到一位圣人，而是在进入城堡的主厅时，看到了一片忙碌的景象：商人来来去去，人们在角落里交谈，一个小管弦乐队正在演奏轻柔的音乐。 ，桌子上摆满了世界上那个地方最美味的食物。智者与每个人交谈，男孩不得不等待两个小时才轮到他的注意。 智者认真地听着男孩解释自己来的原因，但告诉他现在没有时间解释幸福的秘密，建议男孩在宫殿里看看，两个小时后回来。 “我想请你做一件事。”智者说道，递给男孩一把装有两滴油的茶匙。 “当你四处走动时，随身携带这把勺子，不要让油溢出”。 男孩开始在宫殿的许多楼梯上爬上爬下，眼睛一直盯着勺子。 两个小时后，他回到了智者所在的房间。 “那么，”智者问道，“你看到挂在我餐厅里的波斯挂毯了吗？ 你看到园丁大师花了十年时间打造的花园了吗？ 你注意到我图书馆里漂亮的羊皮纸了吗？ 男孩很尴尬，承认他什么也没看到。 他唯一关心的是不要把智者托付给他的油洒出来。 “然后回去观察我的世界的奇迹吧。”智者说道。 “如果你不了解一个人的房子，你就无法信任他。” 男孩松了口气，拿起勺子，继续探索宫殿，这一次观察了天花板和墙壁上的所有艺术品。 他看到了花园、周围的群山、美丽的花朵以及挑选一切的品味。 回到智者身边后，他详细地讲述了他所看到的一切。 “但是我托付给你的那滴油在哪里呢？”智者问道。 男孩低头看了看手里的勺子，发现油已经不见了。 “好吧，我只能给你一条建议。”最聪明的智者说道。 “幸福的秘诀就是看到世界上所有的奇迹，并且永远不会忘记勺子上的油滴”。</p>
</li>
<li><p>牧羊人什么也没说。 他已经听懂了老国王给他讲的故事。 牧羊人可能喜欢旅行，但他永远不应该忘记他的羊。</p>
</li>
<li><p>老人看着男孩，双手合十，在男孩的头顶上做了几个奇怪的手势。 然后，他带着他的羊走开了。</p>
</li>
</ul>
<hr>
<ul>
<li><p>塔里法的最高点有一座古老的堡垒，由摩尔人建造。 从城墙顶上，人们可以一睹非洲的风采。 那天下午，塞勒姆王麦基洗德坐在堡垒的墙上，感觉黎凡特风吹在他脸上。 羊群在附近坐立不安，对新主人感到不安，并对如此多的变化感到兴奋。 他们想要的只是食物和水。</p>
</li>
<li><p>麦基洗德看着一艘小船正驶出港口。 他再也见不到这个男孩了，就像他在向亚伯拉罕收取了十分之一的费用后再也没有见过亚伯拉罕一样。 那是他的工作。</p>
</li>
<li><p>神不应该有欲望，因为他们没有命运。 但塞勒姆国王迫切希望这个男孩能够成功。</p>
</li>
<li><p>可惜他很快就会忘记我的名字，他想。 我应该为他重复一遍。 然后当他谈到我时，他会说我是麦基洗德，撒冷王。</p>
</li>
<li><p>他仰望天空，有些羞愧地说道：“我知道，正如您所说，大人，这是虚荣中的虚荣。但是，一个老国王有时也必须为自己感到骄傲。”</p>
</li>
</ul>
<hr>
<ul>
<li><p>非洲是多么奇怪啊，男孩想。</p>
</li>
<li><p>他坐在一家酒吧里，和他在丹吉尔狭窄的街道上见过的其他酒吧很像。 一些人正在用一根巨大的烟斗抽烟，他们将烟斗从一个烟斗传递到另一个烟斗。 在短短几个小时内，他看到男人们手拉手行走，女人们遮住脸，牧师们爬上塔顶吟诵圣歌——而他周围的每个人都跪下来，把额头放在地上。</p>
</li>
<li><p>“异教徒的做法”，他对自己说。 当他还是个孩子的时候，在教堂里，他总是看着圣圣地亚哥·马塔莫罗斯骑着白马、剑出鞘的图像，以及跪在他脚下的人物。 男孩感到很不舒服，而且非常孤独。 异教徒看上去很邪恶。</p>
</li>
<li><p>除此之外，在他匆忙的旅行中，他忘记了一个细节，只是一个细节，这可能会让他在很长一段时间内失去他的宝藏：这个国家只说阿拉伯语。</p>
</li>
<li><p>酒吧老板走近他，男孩指着邻桌提供的一杯饮料。 原来是苦茶。 这个男孩更喜欢酒。</p>
</li>
<li><p>但他现在不需要担心这个。 他要关心的是他的宝藏，以及他要如何得到它。 卖掉羊后，他的口袋里有了足够的钱，男孩知道金钱是有魔力的；他知道钱是有魔力的。 有钱的人永远不会真正孤独。 不久之后，也许仅仅几天，他就会到达金字塔。 一个戴着黄金胸甲的老人不会为了得到六只羊而撒谎。</p>
</li>
<li><p>老人谈到了征兆和预兆，而当男孩过海峡时，他也想到了预兆。 是的，老人知道他在说什么：男孩在安达卢西亚的田野里度过的那段时间，他已经习惯了通过观察地面和天空来了解自己应该走哪条路。 他发现某种鸟的存在意味着附近有蛇，而某种灌木则表明该地区有水。 羊教会了他这一点。</p>
</li>
<li><p>他想，如果上帝能如此有效地引导羊群，他也会引导一个人，这让他感觉好多了。 茶似乎不那么苦了。</p>
</li>
<li><p>“你是谁？” 他听到一个声音用西班牙语问他。</p>
</li>
<li><p>男孩松了口气。 他正想着预兆，有人出现了。</p>
</li>
<li><p>“你怎么会说西班牙语？” 他问。 新来的人是一名身穿西服的年轻人，但从他的肤色来看，他是这座城市的人。 他的年龄和身高与男孩差不多。</p>
</li>
<li><p>“这里几乎每个人都会说西班牙语。我们距离西班牙只有两个小时”。</p>
</li>
<li><p>男孩说道：“请坐，我请你吃点东西。” “帮我要一杯酒。我讨厌这茶”。</p>
</li>
<li><p>“这个国家没有酒”，年轻人说。 “这里的宗教禁止这样做”。</p>
</li>
<li><p>男孩当时告诉他，他需要去金字塔。 他几乎要开始讲述他的宝藏，但决定不这样做。 如果他这样做了，阿拉伯人可能会想要一部分作为带他去那里的报酬。 他记得老人说过要提供一些你还没有的东西。</p>
</li>
<li><p>“如果可以的话，我希望你带我去那里。我可以付钱给你当我的向导”。</p>
</li>
<li><p>“你知道怎么去那里吗？” 新人问道。</p>
</li>
<li><p>男孩注意到酒吧老板站在附近，聚精会神地听着他们的谈话。 他对这个男人的出现感到不安。 但他已经找到了向导，不想错过这个机会。</p>
</li>
<li><p>“你必须穿越整个撒哈拉沙漠”，年轻人说。 “要做到这一点，你需要钱。我需要知道你是否有足够的钱”。</p>
</li>
<li><p>男孩觉得这个问题很奇怪。 但他相信老人，老人说过，当你真心想要某样东西时，宇宙总会对你有利。</p>
</li>
<li><p>他从袋子里掏出钱给年轻人看。 酒吧老板也过来看了看。 两人用阿拉伯语交谈了几句，酒吧老板似乎很生气。</p>
</li>
<li><p>“我们离开这里吧。”新来的人说道。 “他要我们离开”。</p>
</li>
<li><p>男孩松了口气。 他起身去付账，但店主抓住了他，开始愤怒地对他说话。 男孩很坚强，想要报复，但他身在异国他乡。 他的新朋友把主人推到一边，把男孩拉到外面。 “他想要你的钱”，他说。 “丹吉尔和非洲其他地方不一样。这是一个港口，每个港口都有小偷”。</p>
</li>
<li><p>这个男孩信任他的新朋友。 他在危险的情况下帮助了他。 他拿出钱来数了数。</p>
</li>
<li><p>“我们明天就可以到达金字塔”，另一个人接过钱说道。 “但我必须买两只骆驼”。</p>
</li>
<li><p>他们一起走过丹吉尔狭窄的街道。 到处都有出售物品的摊位。 他们到达了一个举办集市的大广场的中心。</p>
</li>
<li><p>那里有成千上万的人，争论着，卖着，买着。 蔬菜在匕首中出售，地毯与烟草一起展示。 但男孩的目光始终没有离开他的新朋友。 毕竟，他已经拥有了所有的钱。 他考虑过要求他归还，但觉得这样不太友好。 他对异国他乡的风俗习惯一无所知。</p>
</li>
<li><p>“我只会看着他”，他对自己说。 他知道自己比他的朋友更强。</p>
</li>
<li><p>突然，在一片混乱之中，他看到了一把他所见过的最美丽的剑。 刀鞘上有银色浮雕，刀柄是黑色的，上面镶嵌着宝石。 男孩向自己保证，当他从埃及回来时，他会买那把剑。</p>
</li>
<li><p>“问问那个摊位的老板，这把剑多少钱”，他对他的朋友说。 然后他意识到自己有一会儿心不在焉地看着那把剑。 他的心一紧，仿佛胸口突然被压住了。 他不敢环顾四周，因为他知道会发现什么。 他又盯着那把美丽的剑看了一会儿，直到鼓起勇气转身。</p>
</li>
<li><p>周围都是集市，人来人往，叫卖声，买菜声，各种奇怪食物的香味……却找不到他的新同伴。</p>
</li>
<li><p>男孩想要相信他的朋友只是因为意外而与他分开。 他决定留在原地，等待他回来。 在他等待的过程中，一位牧师爬上附近一座塔顶并开始诵经。 市场上的所有人都跪倒在地，用额头触地，开始吟唱。 然后，像一群工蚁一样，他们拆除了摊位并离开了。</p>
</li>
<li><p>太阳也开始离去。 男孩沿着它的轨迹观察了一会儿，直到它隐藏在广场周围的白色房子后面。 他回忆起那天早上太阳升起的时候，他在另一个大陆，仍然是一个带着六十只羊的牧羊人，期待着与一个女孩的见面。 那天早上，当他走过熟悉的田野时，他就知道将会发生在他身上的一切。 但现在，当太阳开始落山时，他身处另一个国家，一个陌生土地上的陌生人，他甚至不会说当地的语言。 他不再是牧羊人，他一无所有，连回去重新开始的钱都没有。</p>
</li>
<li><p>这一切都发生在日出和日落之间，男孩想。 他为自己感到难过，并感叹自己的生活可能会如此突然、如此剧烈地改变。</p>
</li>
<li><p>他羞得想哭。 他甚至从未在自己的羊面前哭泣过。 但市场空无一人，又远离家乡，他就哭了。 他哭是因为上帝不公平，因为这就是上帝报答那些相信梦想的人的方式。</p>
</li>
<li><p>当我拥有我的羊时，我很高兴，我也让周围的人感到高兴。 人们看到我来了就欢迎我，他想。 但现在我感到悲伤和孤独。 我会因为一个人背叛了我而变得痛苦和不信任别人。 我会恨那些找到了宝藏的人，因为我从未找到过我的宝藏。 我会紧紧抓住我所拥有的一切，因为我太渺小了，无法征服世界。</p>
</li>
<li><p>他打开袋子，看看还剩下什么东西。 也许他在船上吃的三明治还剩下一点。 但他只找到了那本厚重的书、他的夹克和老人给他的两块石头。</p>
</li>
<li><p>看着这些石头，他不知道为什么心里松了口气。 他用六只羊换了两块从金胸甲上取下的宝石。 他可以卖掉石头，买回程票。 但这一次我会更聪明，男孩想，把它们从袋子里拿出来，这样他就可以把它们放进口袋里。 这是一个港口城镇，他的朋友告诉他的唯一真实的事情就是港口城镇充满了小偷。</p>
</li>
<li><p>现在他明白酒吧老板为何如此不高兴了：他是想告诉他不要相信那个人。 “我和其他人一样——我根据我希望看到发生的事情来看待世界，而不是实际发生的事情”。</p>
</li>
<li><p>他用手指慢慢地抚过石头，感受它们的温度和表面。 他们是他的宝藏。 光是处理它们就让他感觉好多了。 他们让他想起了那个老人。</p>
</li>
<li><p>他曾说过：“当你想要某样东西时，整个宇宙都会齐心协力帮助你实现它”。</p>
</li>
<li><p>男孩试图理解老人所说的话的真相。 他在空荡荡的市场里，身无分文，也没有一只羊可以守夜。 但这些石头证明他曾见过一位国王——一位知道男孩过去的国王。</p>
</li>
<li><p>“他们被称为乌陵和土明，他们可以帮助你解读预兆”。 男孩把石头放回袋子里，决定做一个实验。 老人说要问非常明确的问题，要做到这一点，男孩必须知道他想要什么。 于是，他询问老人的福气还在吗？</p>
</li>
<li><p>他取出了其中一颗石头。 答案是“是”。</p>
</li>
<li><p>“我能找到我的宝藏吗？” 他问。</p>
</li>
<li><p>他把手伸进袋子里，摸索着寻找其中一颗石头。 当他这样做的时候，他们俩都从袋子上的一个洞里钻了出去，跌倒在地上。 这个男孩甚至从未注意到他的育儿袋上有一个洞。 他跪下来找到乌陵和土明，把它们放回袋子里。 但当他看到躺在地上的他们时，他的脑海里又浮现出另外一句话。</p>
</li>
<li><p>老国王曾说过：“学会识别预兆，并遵循它们”。</p>
</li>
<li><p>一个预兆。 男孩对自己笑了笑。 他捡起两块石头，放回自己的袋子里。 他没有考虑修补这个洞——石头随时都可能掉进去。 他知道，有些事情不应该过问，以免逃避自己的命运。 “我答应过我会自己做决定”，他对自己说。</p>
</li>
<li><p>但石头告诉他，老人还在他身边，这让他更有信心了。 他再次环顾四周空荡荡的广场，感觉不像以前那么绝望了。 这并不是一个奇怪的地方；这是一个奇怪的地方。 这是一件新的。</p>
</li>
<li><p>毕竟，他一直想要的只是：认识新的地方。 即使他从未到达金字塔，他也已经比他认识的任何牧羊人走得更远了。 哦，如果他们知道距离他们所在的地方只有两个小时的船程有多么不同，他想。 虽然现在他的新世界只是一个空荡荡的市场，但生机勃勃的时候他已经见过了，他永远不会忘记。 他想起了那把剑。 想到这里他就有点心痛，但他以前从未见过这样的人。 当他沉思这些事情时，他意识到自己必须在将自己视为小偷的可怜受害者和寻找宝藏的冒险家之间做出选择。</p>
</li>
<li><p>“我是一个冒险家，正在寻找宝藏”，他对自己说。</p>
</li>
</ul>
<hr>
<ul>
<li><p>他被某人摇醒了。 他在市场中央睡着了，广场上的生活即将恢复。</p>
</li>
<li><p>他环顾四周，寻找他的羊，然后意识到自己来到了一个新世界。 但他非但没有悲伤，反而感到高兴。 他不再需要为羊寻找食物和水； 相反，他可以去寻找他的宝藏。 他口袋里一分钱都没有，但他有信心。 前一天晚上，他就决定要像他在书中所崇拜的那样，成为一名冒险家。</p>
</li>
<li><p>他慢慢地穿过市场。 商人们正在布置他们的摊位，男孩帮助一个糖果摊贩布置他的摊位。 卖糖的小贩脸上挂着笑容：他很高兴，知道自己的生活是什么，准备开始一天的工作。 他的笑容让男孩想起了那个老人——他见过的神秘的老国王。 “这个糖果商人生产糖果不是为了以后他可以旅行或娶店主的女儿。</p>
</li>
<li><p>他这样做是因为这是他想做的事，”男孩想。他意识到他可以做老人做过的同样的事情——感知一个人离他的命运是否接近或遥远。只要看着他们。 这很容易，但我以前从未这样做过，他想。</p>
</li>
<li><p>当摊位收拾完毕后，糖果小贩给了男孩他当天做的第一块糖果。 男孩谢过他，吃了它，然后继续上路。 走了没多远，他就发现，他们摆摊的时候，一个说阿拉伯语，另一个说西班牙语。</p>
</li>
<li><p>他们彼此非常了解。</p>
</li>
<li><p>一定有一种不依赖于文字的语言，男孩想。 我已经在我的羊身上经历过这种经历，现在它也发生在人们身上。</p>
</li>
<li><p>他正在学习很多新东西。 有些是他已经经历过的事情，并不是什么新鲜事，但他以前从未察觉过。 他没有察觉到它们，因为他已经习惯了它们。 他意识到：如果我能学会理解这种无需文字的语言，我就能学会理解世界。</p>
</li>
<li><p>他轻松而从容地决定步行穿过丹吉尔狭窄的街道。 只有这样，他才能解读预兆。 他知道这需要很大的耐心，但牧羊人都知道耐心。 他再次看到，在那片陌生的土地上，他正在应用他在羊身上学到的同样的教训。</p>
</li>
<li><p>老人说：“万物皆一”。</p>
</li>
</ul>
<hr>
<ul>
<li><p>水晶商人随着白天的醒来，感受到了每天早晨同样的焦虑。 他已经在同一个地方呆了三十年了：一家位于山街顶上的商店，很少有顾客经过。 现在改变任何事情都为时已晚——他唯一学会做的就是买卖水晶玻璃器皿。 曾经有一段时间，很多人都知道他的店：阿拉伯商人、法国和英国地质学家、总是富有的德国士兵。 那时候，卖水晶是一件很美好的事，他想过随着年龄的增长，自己会变得有钱，身边会有美女相伴。</p>
</li>
<li><p>但随着时间的推移，丹吉尔已经发生了变化。 附近的休达市的发展速度比丹吉尔快，但生意却在下滑。 邻居们都搬走了，山上只剩下几家小商店。 没有人会为了逛几家小商店而爬上山。</p>
</li>
<li><p>但水晶商人也没有办法。 他一生中三十年都在买卖水晶，现在做其他事已经太晚了。</p>
</li>
<li><p>他花了整个上午的时间观察街上稀有的人来人往。</p>
</li>
<li><p>他这样做已经很多年了，知道每个经过的人的日程安排。 但是，就在午餐时间之前，一个男孩停在了商店门前。 他的穿着很平常，但水晶商人老练的眼睛却看出这男孩没有钱花。</p>
</li>
<li><p>尽管如此，商人还是决定推迟几分钟吃午餐，直到男孩继续前进。</p>
</li>
</ul>
<hr>
<ul>
<li><p>门口挂着一张卡片，上面写着店里有多种语言。</p>
</li>
<li><p>男孩看到一个男人出现在柜台后面。</p>
</li>
<li><p>“如果你愿意的话，我可以清理窗户上的玻璃，”男孩说。 “从它们现在的样子来看，没有人会想买它们”。</p>
</li>
<li><p>男人看着他，没有回应。</p>
</li>
<li><p>“作为交换，你可以给我一些吃的。”</p>
</li>
<li><p>男人仍然没有说话，男孩感觉到他必须做出决定。 他的袋子里有他的夹克——他在沙漠里肯定不需要它。 他脱下外套，开始擦眼镜。 半个小时的时间，他就把橱窗里的玻璃都擦干净了，正当他这样做的时候，店里进来了两个顾客，买了一些水晶。</p>
</li>
<li><p>打扫完后，他向那人要吃的。 “走吧，去吃午饭吧。”水晶商人说道。</p>
</li>
<li><p>他在门上贴了一个牌子，然后他们去了附近的一家小咖啡馆。 当他们在唯一一张桌子坐下时，水晶商人笑了。</p>
</li>
<li><p>“你不需要做任何清洁工作”，他说。 “《古兰经》要求我喂饱饥饿的人”。</p>
</li>
<li><p>“那你为什么让我这么做呢？” 男孩问道。</p>
</li>
<li><p>“因为水晶很脏。你和我都需要清除我们头脑中的消极想法”。</p>
</li>
<li><p>吃完饭后，商人对男孩说：“我想让你到我的店里工作。今天你工作的时候进来了两个顾客，这是个好兆头。”</p>
</li>
<li><p>人们经常谈论预兆，牧羊人想。 但他们真的不知道自己在说什么。 正如我没有意识到，这么多年以来，我一直在对我的羊说一种没有文字的语言。</p>
</li>
<li><p>“你愿意去为我工作吗？” 商人问道。</p>
</li>
<li><p>“今天剩下的时间我可以工作”，男孩回答。 “我会工作一整夜，直到天亮，我会清理你们店里的每块水晶。作为回报，我需要明天去埃及的钱”。</p>
</li>
<li><p>商人笑道。 “即使你清理我的水晶一整年……即使你卖掉每件水晶都能赚到不错的佣金，你仍然需要借钱才能去埃及。这里和那里之间有数千公里的沙漠”。</p>
</li>
<li><p>片刻的寂静如此深沉，整个城市似乎都睡着了。 集市上没有任何声音，商人之间没有争论，没有人爬上塔楼吟诵。 没有希望，没有冒险，没有古老的国王或命运，没有宝藏，也没有金字塔。 世界仿佛因为男孩的灵魂而变得寂静。 他坐在那里，呆呆地看着咖啡馆的门外，希望自己已经死了，一切都在那一刻永远结束。</p>
</li>
<li><p>商人焦急地看着男孩。 那天早上他所看到的所有喜悦突然消失了。</p>
</li>
<li><p>“我可以给你回国所需的钱，我的孩子，”水晶商人说道。</p>
</li>
<li><p>男孩什么也没说。 他起身，整理了一下衣服，拿起了袋子。</p>
</li>
<li><p>“我会为你工作”，他说。</p>
</li>
<li><p>经过长时间的沉默，他补充道，“我需要钱买一些羊”。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>认知-修行-平衡</category>
      </categories>
      <tags>
        <tag>炼金术士</tag>
      </tags>
  </entry>
  <entry>
    <title>炼金术士3-第二章</title>
    <url>/2024/04/03/%E8%AE%A4%E7%9F%A5-%E4%BF%AE%E8%A1%8C-%E5%B9%B3%E8%A1%A1/%E7%82%BC%E9%87%91%E6%9C%AF%E5%A3%AB4/</url>
    <content><![CDATA[<ul>
<li>Paulo Coelho 保罗·科埃略</li>
</ul>
<hr>
<ul>
<li><p>男孩在水晶商工作了快一个月了，他看得出来，这并不是一份能让他开心的工作。 商人整天在柜台后面咕哝着，告诉男孩要小心碎片，不要弄坏任何东西。</p>
</li>
<li><p>但他还是坚持了这份工作，因为商人虽然是个脾气暴躁的老人，但对他很公平。 男孩每卖出一件作品都会得到丰厚的佣金，并且已经可以存一些钱了。 那天早上他算了一笔账：如果继续像以前那样每天干活，他需要一整年才能买几只羊。</p>
</li>
<li><p>“我想为水晶做一个展示柜”，男孩对商人说。 “我们可以把它放在外面，吸引那些经过山脚的人”。</p>
</li>
<li><p>商人回答说：“我以前从来没有吃过。” “人走过，撞到，碎片就会碎”。</p>
</li>
<li><p>“好吧，当我带着我的羊穿过田野时，如果我们遇到一条蛇，其中一些可能会死。但这就是羊和牧羊人的生活”。</p>
</li>
<li><p>商人找到一位想要三块水晶玻璃杯的顾客。 他的销量比以往任何时候都好……仿佛时间回到了过去，当时这条街是丹吉尔的主要景点之一。</p>
</li>
<li><p>顾客离开后，他对男孩说：“生意确实好转了。” “我做得好多了，很快你就可以回到你的羊身边了。为什么要对生活要求更多呢？”。</p>
</li>
<li><p>“因为我们必须对预兆做出反应”，男孩几乎无意识地说。 然后他后悔自己说过的话，因为商人从未见过国王。</p>
</li>
<li><p>老国王曾说过：“这就是所谓的有利原则，初学者的运气。因为生活要你实现你的命运”。</p>
</li>
<li><p>但商人听懂了男孩的话。 男孩出现在店里本身就是一个预兆，随着时间的流逝，钱不断涌入钱箱，他并不后悔雇用了这个男孩。 这个男孩得到的钱比他应得的多，因为商人认为销售额不会很高，所以给了男孩很高的佣金。 他原以为自己很快就会回到羊群身边。</p>
</li>
<li><p>“你为什么想去金字塔？” 他要求摆脱显示器的事务。</p>
</li>
<li><p>“因为我一直听说过它们”，男孩回答道，没有提及他的梦想。 那件宝藏现在只是一段痛苦的回忆，他努力避免去想它。</p>
</li>
<li><p>“我不知道这附近有谁愿意穿越沙漠只是为了看看金字塔”，商人说。 “它们只是一堆石头。你可以在你的后院建造一个”。</p>
</li>
<li><p>“你从来没有梦想过旅行。”男孩说着，转身去接待一位走进商店的顾客。</p>
</li>
<li><p>两天后，商人与男孩谈论了这个展览。</p>
</li>
<li><p>“我不太喜欢改变”，他说。 “你和我不像哈桑，那个富商。如果他买错了，对他影响不大。但我们两个必须忍受我们的错误”。</p>
</li>
<li><p>确实如此，男孩悲伤地想。</p>
</li>
<li><p>“你为什么认为我们应该有这个展示？”</p>
</li>
<li><p>“我想更快地回到我的羊身边。当运气站在我们这边时，我们必须利用它，尽可能地帮助它，就像它帮助我们一样。这就是所谓的好感原则。或者初学者的运气”。</p>
</li>
<li><p>商人沉默了一会儿。 然后他说：“先知给了我们《古兰经》，并留给我们一生中要履行的五项义务。最重要的是只相信独一的真主。其他的是每天祈祷五次，在斋月期间禁食 ，并对穷人施舍”。</p>
</li>
<li><p>他停在那里。 当他谈到先知时，他的眼睛里充满了泪水。 他是一个虔诚的人，尽管他非常不耐烦，但他还是想按照穆斯林法律生活。</p>
</li>
<li><p>“第五项义务是什么？” 男孩问道。</p>
</li>
<li><p>“两天前，你说我从来没有梦想过旅行。”商人回答道。</p>
</li>
<li><p>“每个穆斯林的第五项义务是朝圣。我们一生中至少有一次必须参观圣城麦加。</p>
</li>
<li><p>“麦加比金字塔远很多。当我年轻的时候，我只想攒够钱开一家店。我以为有一天我会变得富有，可以去麦加。我开始 赚了一些钱，但我总是舍不得把店留给专人负责，水晶是很娇贵的东西。与此同时，人们一直路过我的店，前往麦加。其中一些是富有的朝圣者， 带着仆人和骆驼乘着商队旅行，但大多数朝圣的人都比我穷。</p>
</li>
<li><p>“所有去那里的人都为此感到高兴。他们把朝圣的标志贴在自家门上。其中一个以补靴子为生的鞋匠说，他已经在这片土地上旅行了将近一年。 沙漠，但当他不得不穿过丹吉尔的街道购买皮革时，他变得更加疲倦”。</p>
</li>
<li><p>“那么，你为什么不现在就去麦加呢？” 男孩问道。</p>
</li>
<li><p>“因为对麦加的思念让我活了下来。这就是帮助我面对这些千篇一律的日子的原因，架子上这些无声的水晶，以及那家可怕的咖啡馆的午餐和晚餐。我担心如果我的梦想 当我意识到这一点时，我就没有理由继续活下去了。</p>
</li>
<li><p>“你梦想着你的羊和金字塔，但你和我不同，因为你想要实现你的梦想。我只想梦想着麦加。我已经想象过一千次穿越沙漠，到达广场 关于圣石，我在允许自己触摸它之前绕着它走了七次。我已经想象过那些会在我身边的人，以及那些在我面前的人，以及我们将分享的对话和祈祷。但是 我担心这一切都会令人失望，所以我宁愿只做梦”。</p>
</li>
<li><p>那天，商人允许男孩建造这个展示架。 并不是每个人都能以同样的方式看到他的梦想成真。</p>
</li>
</ul>
<hr>
<ul>
<li><p>又过了两个月，货架给水晶店带来了很多顾客。</p>
</li>
<li><p>男孩估计，如果他再工作六个月，他就可以回到西班牙买六十只羊，然后再买六十只。 不到一年，他的羊群数量就会增加一倍，而且他将能够与阿拉伯人做生意，因为他现在能够说他们奇怪的语言。 自从那天早上在市场上，他就再也没有使用过乌陵和土明，因为埃及现在对他来说就像麦加对商人一样遥远的梦想。 不管怎样，这个男孩对他的工作感到很高兴，并且一直想着有一天他会作为胜利者在塔里法下船。</p>
</li>
<li><p>老国王曾说过：“你必须永远知道自己想要什么”。 男孩知道了，并且现在正在朝着这个目标努力。 也许这是他的财富，因为他来到了那片陌生的土地，遇到了一个小偷，并且不花一分钱就将他的羊群数量增加了一倍。</p>
</li>
<li><p>他为自己感到骄傲。 他学到了一些重要的东西，比如如何处理水晶、无言的语言……以及预兆。 一天下午，他在山顶上看到一个人，抱怨爬了这么远，找不到一个像样的地方喝点东西。 习惯于识别预兆的男孩对商人说道。</p>
</li>
<li><p>“我们把茶卖给爬山的人吧”。</p>
</li>
<li><p>“这附近有很多卖茶的地方”，商家说。</p>
</li>
<li><p>“但是我们可以用水晶玻璃杯出售茶。人们会喜欢茶并想购买水晶玻璃杯。有人告诉我，美丽是男人的最大诱惑者”。</p>
</li>
<li><p>商人没有回应，但那天下午，在祈祷并关门后，他邀请男孩和他坐在一起，分享他的水烟，这是阿拉伯人使用的一种奇怪的烟斗。</p>
</li>
<li><p>“你在找什么？” 老商人问道。</p>
</li>
<li><p>“我已经告诉过你了，我要把我的羊买回来，所以我必须赚钱”。</p>
</li>
<li><p>商人在水烟袋里放了一些新煤，深深地吸了一口气。</p>
</li>
<li><p>“我开这家店已经三十年了。我知道水晶的好坏，以及关于水晶的一切知识。我知道它的尺寸和它的性能。如果我们用水晶来泡茶，这家店就会扩大 ……然后我就必须改变我的生活方式”。</p>
</li>
<li><p>“嗯，这样不是很好吗？”</p>
</li>
<li><p>“我已经习惯了，在你来之前，我在想，我在同一个地方浪费了多少时间，而我的朋友们却纷纷离开，要么破产，要么过得比以前更好。 这让我很郁闷。现在看来，情况还不错。商店的大小正是我一直想要的。我不想改变任何东西，因为我不知道如何改变 应对变化。我已经习惯了现在的样子”。</p>
</li>
<li><p>男孩不知道该说什么。 老人继续说道：“你对我来说是真正的祝福。今天，我明白了一些我以前从未见过的事情：每一个被忽视的祝福都会变成诅咒。我的生活中不想要任何其他东西。但你却在强迫我 看看我从未了解过的财富和视野。现在我已经看到了它们，现在我看到了我的可能性有多么巨大，我会比你到来之前感觉更糟。</p>
</li>
<li><p>因为我知道我应该能够完成哪些事情，但我不想这样做”。</p>
</li>
<li><p>幸好我没有对塔里法的面包师说什么，男孩心里想。</p>
</li>
<li><p>太阳开始落山时，他们又继续抽了一会儿烟斗。 他们用阿拉伯语交谈，男孩为自己能够做到这一点感到自豪。 曾经有一段时间，他认为他的羊可以教他关于世界的一切知识。 但他们永远不可能教他阿拉伯语。</p>
</li>
<li><p>世界上可能还有其他事情是羊无法教给我的，男孩一边看着老商人，一边想。 实际上，它们所做的就是寻找食物和水。</p>
</li>
<li><p>也许并不是他们在教我，而是我在向他们学习。</p>
</li>
<li><p>“Maktub”，商人最后说道。</p>
</li>
<li><p>“这意味着什么？”</p>
</li>
<li><p>他回答说：“你必须生为阿拉伯人才能理解。” “但用你们的语言来说，它会像‘它是这样写的’”。</p>
</li>
<li><p>当他扑灭水烟袋中的煤炭时，他告诉男孩他可以开始卖水晶杯里的茶了。 有时，没有办法阻止河流。</p>
</li>
</ul>
<hr>
<ul>
<li><p>男人们爬上了山，到达山顶时他们已经累了。 但在那里他们看到了一家水晶店，出售清爽的薄荷茶。 他们进去喝茶，茶装在漂亮的水晶玻璃杯里。</p>
</li>
<li><p>“我妻子从来没有想到过这一点”，一位人士说，他买了一些水晶——那天晚上他正在招待客人，客人们一定会被玻璃器皿的美丽所折服。 另一个人说，用水晶泡茶总是更美味，因为香气得以保留。 第三个说，用水晶杯泡茶是东方的传统，因为它具有神奇的力量。</p>
</li>
<li><p>不久，消息传开，不少人开始爬上山去，一睹这家老字号新花样的店铺的风采。 还有一些卖水晶茶的店也开了，但不是在山顶，生意也很少。</p>
</li>
<li><p>最终，商家不得不再雇用两名员工。 他开始进口大量的茶叶和水晶，他的商店受到了渴望新鲜事物的男男女女的青睐。</p>
</li>
<li><p>就这样，几个月过去了。</p>
</li>
</ul>
<hr>
<ul>
<li><p>天亮前男孩就醒了。 距离他第一次踏上非洲大陆，已经过去了十一个月零九天。</p>
</li>
<li><p>他穿着专门为这一天买的白色亚麻阿拉伯服装。 他将头巾放在适当的位置，并用骆驼皮制成的环将其固定。 他穿着新买的凉鞋，默默走下楼梯。</p>
</li>
<li><p>这座城市还在沉睡中。 他给自己准备了一份三明治，喝了一杯水晶玻璃杯里的热茶。 然后他坐在阳光普照的门口，抽着水烟。</p>
</li>
<li><p>他默默地抽烟，什么也不想，听着风的声音带来沙漠的气味。 当他吸完烟后，他把手伸进口袋，坐了一会儿，思考着他取出的东西。</p>
</li>
<li><p>那是一大笔钱。 足够给自己买一百二十只羊、一张回程机票以及从非洲进口产品到自己国家的许可证。</p>
</li>
<li><p>他耐心地等待着商人醒来并开店。 然后两人又去喝茶了。</p>
</li>
<li><p>男孩说：“我今天就走。” “我有钱买羊。你也有钱去麦加”。</p>
</li>
<li><p>老人什么也没说。</p>
</li>
<li><p>“你愿意给我祝福吗？” 男孩问道。 “你帮助了我”。 男人继续泡茶，没有说话。 然后他转向男孩。</p>
</li>
<li><p>“我为你感到骄傲”，他说。 “你给我的水晶店带来了新的感觉。但你知道我不会去麦加。就像你知道你不会买你的羊一样”。</p>
</li>
<li><p>“谁告诉你的？” 男孩吃惊地问道。</p>
</li>
<li><p>“Maktub”老水晶商人说道。</p>
</li>
<li><p>他给了这个男孩祝福。</p>
</li>
<li><p>男孩回到自己的房间，收拾好行李。 他们装满了三个麻袋。 当他离开时，他在房间的角落里看到了他的旧牧羊人的袋子。 它被扎成一团，他已经很长一段时间几乎没有想到过它了。 当他从袋子里拿出夹克，想把它送给街上的某个人时，两块石头掉到了地板上。 乌陵和土明。</p>
</li>
<li><p>这让男孩想起了老国王，他惊讶地意识到自己已经有多久没有想起他了。 近一年来，他一直在不停地工作，只想着攒够钱，以便能够自豪地回到西班牙。</p>
</li>
<li><p>“永远不要停止梦想”，老国王说过。 “遵循预兆”。</p>
</li>
<li><p>男孩抱起乌陵和土明，再次有一种奇怪的感觉，老国王就在附近。 他辛苦工作了一年，预兆是该离开了。</p>
</li>
<li><p>我要回去做以前做过的事，男孩想。 尽管羊没有教我说阿拉伯语。</p>
</li>
<li><p>但羊教会了他一些更重要的东西：世界上有一种人人都能理解的语言，男孩在他试图改善商店里的东西的整个过程中一直在使用这种语言。 这是一种热情的语言，是用爱和目标完成的事情，也是对所相信和渴望的事物的探索的一部分。 丹吉尔不再是一座陌生的城市，他觉得，就像他征服了这个地方一样，他也能征服世界。</p>
</li>
<li><p>老国王曾说过：“当你想要某样东西时，整个宇宙都会齐心协力帮助你实现它”。</p>
</li>
<li><p>但老国王并没有提到任何关于被抢劫的事情，或者关于无尽的沙漠，或者关于那些知道自己的梦想是什么但不想实现它们的人的事情。 老国王没有告诉他金字塔只是一堆石头，也没有告诉他任何人都可以在他的后院建造一座。 他忘了提到，当你有足够的钱去买比你以前拥有的更大的羊群时，你就应该买它。</p>
</li>
<li><p>男孩拿起他的袋子，把它和其他东西放在一起。 他走下楼梯，发现店家正在接待一对外国夫妇，而另外两名顾客则在店里走来走去，用水晶玻璃杯喝着茶。 早上这个时候的活动比平时要多。 从他站的地方，他第一次看到老商人的头发和老国王的头发非常像。 他记得来到丹吉尔的第一天，当他没有东西吃，也无处可去时，糖果小贩的笑容——那笑容也像老国王的笑容。</p>
</li>
<li><p>他想，就好像他来过这里并留下了自己的印记一样。 然而，这些人都没有见过老国王。 另一方面，他说他总是出现来帮助那些试图实现自己命运的人。</p>
</li>
<li><p>他没有和水晶商人告别就离开了。 他不想和其他人一起哭。 他会想念这个地方和他学到的所有美好事物。</p>
</li>
<li><p>不过，他对自己更有信心，觉得自己可以征服世界。</p>
</li>
<li><p>“但我要回到我熟悉的田野，再次照顾我的羊群”。 他很肯定地对自己这么说，但他对自己的决定不再满意。 他为了梦想而努力了整整一年，而这个梦想却在一分钟一分钟地变得不那么重要了。 也许是因为那并不是他真正的梦想。</p>
</li>
<li><p>谁知道呢……也许像水晶商人那样更好：永远不要去麦加，只是一生都想去麦加，他想，再次试图说服自己。 但当他手里握着乌陵和土明时，它们就向他传递了老国王的力量和意志。 纯属巧合——或者也许这是一个预兆，男孩想——他来到了他第一天进入的酒吧。 小偷不在，店主给他端了一杯茶。</p>
</li>
<li><p>我总能回去当牧羊人，男孩想。 我学会了如何照顾羊，而且我没有忘记那是怎么做的。 但也许我再也没有机会去埃及金字塔了。 这位老人穿着黄金胸甲，他知道我的过去。 他确实是一个国王，一个明智的国王。</p>
</li>
<li><p>安达卢西亚的山丘距离酒店只有两个小时的路程，但他和金字塔之间却是一片沙漠。 然而男孩觉得可以用另一种方式来看待自己的处境：他实际上距离他的宝藏又近了两个小时……这两个小时延长到一整年并不重要。</p>
</li>
<li><p>我知道为什么我想回到我的羊群中，他想。 我了解羊； 他们不再是问题，而且可以成为好朋友。 另一方面，我不知道沙漠是否可以成为朋友，而我必须在沙漠中寻找我的宝藏。 如果找不到，我可以随时回家。 我终于有了足够的钱，以及我需要的所有时间。 为什么不？</p>
</li>
<li><p>他突然感到无比的幸福。 他总能回去当牧羊人。 他总能再次成为一名水晶推销员。 也许世界上还有其他隐藏的宝藏，但他有一个梦想，他遇到了一位国王。 这不会发生在任何人身上！</p>
</li>
<li><p>当他离开酒吧时，他正在计划。 他记得水晶商人的一位供应商通过穿越沙漠的商队运输他的水晶。 他手里拿着乌陵和土明； 因为这两块石头，他再次踏上了寻宝之路。</p>
</li>
<li><p>“当有人想要实现自己的命运时，我总是在附近”，老国王告诉他。</p>
</li>
<li><p>去供应商的仓库看看金字塔是否真的有那么远需要花多少钱？</p>
</li>
</ul>
<hr>
<ul>
<li><p>英国人坐在一座散发着动物、汗水和灰尘气味的建筑里的长凳上。 它一半是仓库，一半是畜栏。 我从来没想过自己会落到这样的境地，他一边翻阅化学期刊，一边想。 大学十年了，而我却在一个畜栏里。</p>
</li>
<li><p>但他必须继续前进。 他相信预兆。 他一生和所有的研究都旨在寻找宇宙中唯一一种真正的语言。 他首先学习了世界语，然后学习了世界宗教，现在又学习了炼金术。 他知道如何说世界语，他了解所有主要宗教，但他还不是炼金术士。 他揭开了重要问题背后的真相，但他的研究已经把他带到了一个他似乎无法超越的地步。 他曾试图与炼金术士建立关系，但没有成功。 但炼金术士们都是奇怪的人，他们只考虑自己，几乎总是拒绝帮助他。 谁知道呢，也许他们没能发现大师之作——贤者之石的秘密——因此将他们的知识保密。</p>
</li>
<li><p>他已经花掉了父亲留给他的大部分财产，徒劳地寻找贤者之石。 他在世界各地的大型图书馆里花费了大量的时间，购买了所有最稀有和最重要的炼金术书籍。 他在一本书中读到，许多年前，一位著名的阿拉伯炼金术士访问了欧洲。 据说他已经两百多岁了，还发现了贤者之石和长生不老药。 这个故事给英国人留下了深刻的印象。 但如果不是他的一位朋友——从沙漠考古探险回来——告诉他有一个阿拉伯人拥有超凡的力量，他绝不会认为这只是一个神话。</p>
</li>
<li><p>“他住在法尤姆绿洲”，他的朋友说。 “人们说他已经两百岁了，能点金成金”。</p>
</li>
<li><p>英国人无法抑制自己的兴奋。 他取消了所有的承诺，并整理了他最重要的书，现在他坐在一个布满灰尘、散发着臭味的仓库里。 外面，一支巨大的商队正在准备穿越撒哈拉沙漠，并计划途经法尤姆。</p>
</li>
<li><p>我要找到那个该死的炼金术士，英国人想。 动物的气味也变得更容易忍受了。</p>
</li>
<li><p>一个年轻的阿拉伯人也背着行李走了进来，向英国人打招呼。</p>
</li>
<li><p>“你被绑在哪里？” 年轻的阿拉伯人问道。</p>
</li>
<li><p>“我要去沙漠”，那人回答道，然后又继续看书。 他此时不想进行任何谈话。 他要做的就是回顾一下自己这些年所学到的一切，因为炼金术士肯定会对他进行考验。</p>
</li>
<li><p>年轻的阿拉伯人拿出一本书开始阅读。 这本书是用西班牙语写的。</p>
</li>
<li><p>那很好，英国人想。 他的西班牙语比阿拉伯语说得更好，而且，如果这个男孩要去法尤姆，当没有其他重要的事情要做时，就会有人可以说话。</p>
</li>
</ul>
<hr>
<p>- </p>
]]></content>
      <categories>
        <category>认知-修行-平衡</category>
      </categories>
      <tags>
        <tag>炼金术士</tag>
      </tags>
  </entry>
  <entry>
    <title>我的情绪为何总被他人左右-读书笔记</title>
    <url>/2024/02/22/books/2024/first-half/%E6%88%91%E7%9A%84%E6%83%85%E7%BB%AA%E4%B8%BA%E4%BD%95%E6%80%BB%E8%A2%AB%E4%BB%96%E4%BA%BA%E5%B7%A6%E5%8F%B3/</url>
    <content><![CDATA[<ol>
<li>一个人一直在重复3件事：thinking思考，feeling感受，acting行为，3者互相影响</li>
</ol>
<ul>
<li><img src="/img/books/2024-1-half/001-3things.png"></li>
<li>人的认知决定思考的高度，思考会产生情绪感受，同时影响人的行为。</li>
</ul>
<ol start="2">
<li>一个被忽略的事实：人的焦虑抑郁或者不开心并不是当前发生的事情，而是发生的事情给你带来的感受feeling情绪，所以通常人是容易被自己的不好的感受和情绪勒索，困住自己的通常是自己的内心。</li>
<li>通常对人产生负面的feelings包含以下四种，被称为“致命四人组”：</li>
</ol>
<ul>
<li><img src="/img/books/2024-1-half/002-4bad-feelings.png"></li>
</ul>
<ol start="4">
<li>它们有一个共同的副词：过分，过分是极端主义的代表。不理智的人儿都容易从一个极端走到另一个极端。</li>
<li>诱因ABC’s</li>
</ol>
<table>
<thead>
<tr>
<th>编号</th>
<th>具体</th>
<th>解析</th>
</tr>
</thead>
<tbody><tr>
<td>A</td>
<td>触发事件</td>
<td>诱因</td>
</tr>
<tr>
<td>B</td>
<td>3种病态思维方式（screw ball thinking）1. 第一种叫灾难性思维方式（catastrophic thinking）；2. 第二种病态思维方式被称作绝对论者思维方式（absolutist thinking）；3. 第三种类型的神经病想法恰好是另一个极端：合理化（rationalization）合理化就是弱反应。</td>
<td>过程</td>
</tr>
<tr>
<td>C</td>
<td>失当的感受和行为</td>
<td>结果</td>
</tr>
</tbody></table>
<ol start="6">
<li>10中疯狂的非理性信条</li>
</ol>
<table>
<thead>
<tr>
<th>编号</th>
<th>非理性信条</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>我太在乎别人怎么看待你。</td>
</tr>
<tr>
<td>2</td>
<td>我决不能在重要任务上失败（生意上，学业，体育项目，性生活，关系等），否则太可怕了，我无法忍受。</td>
</tr>
<tr>
<td>3</td>
<td>人和事都应该总是朝我要他们去的方向发展，如果不是，那就太糟糕、太可怕、太恐怖了，我无法忍受！</td>
</tr>
<tr>
<td>4</td>
<td>如果前面三种坏事中的任何一种出现了（如果我不讨喜或不被尊重，如果我失败了，或结果不像我想的那样好或至少过得去），我总要找个人骂骂才痛快！他们做错了，早就不该这么做，事情做得那么糟糕，一帮烂人！</td>
</tr>
<tr>
<td>5</td>
<td>假如我对即将发生的事或别人对我的看法抱有挥之不去的忧虑，当事情真发生时，定会比我想象的要好。</td>
</tr>
<tr>
<td>6</td>
<td>每个问题都有完美的解决方法，我必须立即找到这些方法！</td>
</tr>
<tr>
<td>7</td>
<td>逃避困境和责任比正视它们要容易得多。</td>
</tr>
<tr>
<td>8</td>
<td>如果我事事不投入，只保持若即若离的关注，我会永远开心。</td>
</tr>
<tr>
<td>9</td>
<td>我的过去、小时候、最近恋情和最近工作中发生的所有可怕的事造成了我此时的感觉和行为。</td>
</tr>
<tr>
<td>10</td>
<td>坏人坏事应该存在，当它们的确存在时，我真不知道该怎么办才好！</td>
</tr>
</tbody></table>
<ol start="7">
<li>解决问题的框架REBT(Rational Emotive Behavior Therapy)，理性情绪行为疗法</li>
</ol>
<ul>
<li><img src="/img/books/2024-1-half/003-REBT.png"></li>
</ul>
]]></content>
      <categories>
        <category>认知-修行-平衡</category>
      </categories>
      <tags>
        <tag>自愈, 情绪管理</tag>
      </tags>
  </entry>
  <entry>
    <title>成瘾始于痛苦，戒瘾终于平衡！</title>
    <url>/2023/08/07/books/2024/first-half/addition/</url>
    <content><![CDATA[<p><a class="link"   href="https://youtu.be/LbbyLeR1ZRk" >read a book with me,<i class="fas fa-external-link-alt"></i></a></p>
<h2 id="听第一遍总结："><a href="#听第一遍总结：" class="headerlink" title="听第一遍总结："></a>听第一遍总结：</h2><ul>
<li>目录<ul>
<li><ol>
<li>对快乐成瘾源自于痛苦的驱使</li>
</ol>
</li>
<li><ol start="2">
<li>成瘾以及难以戒瘾的底层原理</li>
</ol>
</li>
<li><ol start="3">
<li>利用多巴胺机制恢复身体平衡<br>Part 1</li>
</ol>
</li>
</ul>
</li>
<li>人的痛苦是一种常态。痛苦和快乐是天平两边的对手，我们终将要找到一种平衡。</li>
<li>很多成瘾者在重复成瘾行为的时候，已经感受不到快乐，但如果不重复成瘾行为，他们会感觉非常痛苦。</li>
<li>在完成成瘾行为后得到短暂的多巴胺快乐，但快乐过后痛苦还在原地等着你，而且前后落差会让你觉得更痛苦。这样的痛苦反过来又促使你再次成瘾，这就是成瘾的恶性循环。</li>
<li>身体本身就是一个系统，根据系统思考的原理，我们可以通过调节回路来恢复身体的平衡。但同时如果我们放手不管，身体就会记着某种快乐的源泉，并且不断的去重复这种行为。</li>
<li>多巴胺有一种奖赏预测误差机制，就是每一次的快乐需要比上一次的快乐要的更多才能满足。这也是人所说的，欲望是越来越难以满足的。<br>Part 2</li>
<li>成瘾的底层原理其实就是多巴胺作祟。因为人的痛苦是一种常态，而痛苦又是驱使你去寻找快乐的动力。<ul>
<li><ol>
<li>人的快乐是由脑中的多巴胺分泌决定的，人们会追求多巴胺分泌的行为；</li>
</ol>
</li>
<li><ol start="2">
<li>多巴胺的分泌是有限的，一旦分泌完了，由于落差你就会感觉到更痛苦；</li>
</ol>
</li>
<li><ol start="3">
<li>多巴胺有一种奖赏预测误差机制，就是每一次的快乐需要比上一次的快乐要的更多才能满足，所以人就会不断的重复某种成瘾的行为。</li>
</ol>
</li>
<li><ol start="4">
<li></li>
</ol>
</li>
</ul>
</li>
</ul>
<p>Part 3</p>
<ul>
<li>应对方法<ul>
<li><ol>
<li>以痛制痛</li>
</ol>
</li>
<li><ol start="2">
<li>物理阻断</li>
</ol>
</li>
<li><ol start="3">
<li>激进诚实</li>
</ol>
</li>
</ul>
</li>
</ul>
<h2 id="听第二遍总结："><a href="#听第二遍总结：" class="headerlink" title="听第二遍总结："></a>听第二遍总结：</h2><ul>
<li>为什么你会没有动力？因为你没有目标，也没有奖励回路。有了目标，把目标切割成一小段一小段，然后通过奖励来推动你一步一步完成目标。奖励就是一种动力。</li>
<li>重置大脑奖赏回路的时间最短需要一个月。也就是系统思考中的调节回路，通过调节回路来恢复身体的平衡。</li>
<li>痛苦是我们为快乐付出的代价，而快乐是我们从痛苦中获得的回报。</li>
<li>人都是求生的，从我们受精开始的那一刻，我们就具备了竞争力和求生的本能。</li>
<li>时间是最能代表民主，自由，平等的东西。有些东西是随着时间增值，有些东西是随着时间而贬值的。</li>
<li>坐而论道容易，要找到出路很难，也许要一生一世。</li>
<li>所有的系统都需要一个激励机制，来驱动系统的运转。</li>
</ul>
]]></content>
      <categories>
        <category>认知-修行-平衡</category>
      </categories>
      <tags>
        <tag>成瘾戒瘾</tag>
      </tags>
  </entry>
</search>
